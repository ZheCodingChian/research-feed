<!DOCTYPE html>
<html lang="en" data-bs-theme="dark">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Test Papers</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    
    <!-- KaTeX CSS for LaTeX math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" integrity="sha384-nB0miv6/jRmo5UMMR1wu3Gz6NLsoTkbqJghGIsx//Rlm+ZU03BU6SQNC66uf4l5+" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js" integrity="sha384-7zkQWkzuo3B5mTepMUcHkMB5jZaolc2xDwL6VFqjFALcbeS9Ggm/Yr2r3Dy4lfFg" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstbeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous"></script>
    <style>
        body {
            background-color: #0f1011;
            color: #e0e0e0;
        }
        
        .full-width-header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding-top: 2rem;
            margin-bottom: 2rem;
            box-shadow: 0 4px 6px rgba(0,0,0,0.3);
        }
        
        .header-title-section {
            text-align: center;
            margin-bottom: 0;
            padding-bottom: 2rem;
        }
        
        .controls-section {
            background: rgba(0,0,0,0.2);
            border-top: 1px solid rgba(255,255,255,0.1);
            padding: 1rem 0;
            margin-top: 0;
        }
        
        .paper-card {
            margin-bottom: 1.5rem;
            border: 1px solid #404040;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.3);
            transition: transform 0.2s;
            background-color: #191a1b;
        }
        
        .paper-card:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0,0,0,0.4);
        }
        
        .paper-header {
            padding: 1rem;
            border-bottom: 1px solid #404040;
            border-radius: 8px 8px 0 0;
            background: linear-gradient(135deg, #2D3748 0%, #4A5568 100%);
            color: #ffffff;
        }
        
        .paper-title {
            color: #ffffff;
            font-size: 1.25rem;
            margin-bottom: 0.5rem;
        }
        
        .paper-meta {
            color: #e0e0e0;
            font-size: 0.9rem;
            margin-bottom: 0.5rem;
        }
        
        .paper-body {
            padding: 1rem;
            background-color: #191a1b;
        }
        
        .paper-abstract {
            margin-bottom: 1rem;
            color: #d0d0d0;
        }
        
        .paper-categories {
            margin-bottom: 1rem;
        }
        
        .category-tag {
            display: inline-block;
            padding: 0.25rem 0.5rem;
            margin: 0.25rem;
            background-color: #404040;
            border-radius: 4px;
            font-size: 0.85rem;
            color: #e0e0e0;
        }
        
        .justification-text {
            margin-top: 0.5rem;
            padding: 0.5rem;
            background: rgba(0,0,0,0.3);
            border-radius: 4px;
            font-size: 0.85rem;
            line-height: 1.4;
            color: #d0d0d0;
            display: none;
        }
        
        /* Updated LLM Scoring Widget Styles - Consistent with Similarity Widget */
        .llm-scoring-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 1rem;
        }
        
        .llm-scoring-toggle {
            font-size: 0.85rem;
            padding: 0.25rem 0.5rem;
        }
        
        .llm-scoring-columns {
            display: grid;
            grid-template-columns: 1fr 1fr 1fr;
            gap: 1rem;
            margin-bottom: 1rem;
        }
        
        @media (max-width: 768px) {
            .llm-scoring-columns {
                grid-template-columns: 1fr;
                gap: 0.75rem;
            }
        }
        
        .llm-scoring-column {
            display: flex;
            flex-direction: column;
            padding: 0.75rem;
            background-color: rgba(255,255,255,0.03);
            border-radius: 6px;
            border: 1px solid rgba(255,255,255,0.05);
        }
        
        .llm-scoring-label {
            font-weight: 600;
            color: #e0e0e0;
            font-size: 0.9rem;
            margin-bottom: 0.5rem;
        }
        
        .llm-scoring-value {
            font-weight: bold;
            font-size: 1rem;
        }
        
        .llm-scoring-value.must-read { color: #28a745; }
        .llm-scoring-value.should-read { color: #17a2b8; }
        .llm-scoring-value.can-skip { color: #ffc107; }
        .llm-scoring-value.ignore { color: #dc3545; }
        .llm-scoring-value.high { color: #28a745; }
        .llm-scoring-value.moderate { color: #17a2b8; }
        .llm-scoring-value.low { color: #ffc107; }
        .llm-scoring-value.none, .llm-scoring-value.negligible { color: #dc3545; }
        
        .llm-scoring-justifications {
            background-color: rgba(255,255,255,0.03);
            border-radius: 4px;
            padding: 0.75rem;
            border: 1px solid rgba(255,255,255,0.05);
            margin-top: 1rem;
        }
        
        .llm-justification-item {
            margin-bottom: 0.75rem;
            font-size: 0.9rem;
            line-height: 1.4;
            color: #d0d0d0;
        }
        
        .llm-justification-item:last-child {
            margin-bottom: 0;
        }
        
        .llm-scoring-tooltip {
            position: absolute;
            bottom: 100%;
            left: 50%;
            transform: translateX(-50%);
            background: #2d2d2d;
            color: #ffffff;
            padding: 0.5rem 0.75rem;
            border-radius: 4px;
            font-size: 0.8rem;
            white-space: nowrap;
            opacity: 0;
            visibility: hidden;
            transition: opacity 0.2s, visibility 0.2s;
            z-index: 1000;
            margin-bottom: 5px;
            border: 1px solid #404040;
        }
        
        .llm-scoring-tooltip::after {
            content: '';
            position: absolute;
            top: 100%;
            left: 50%;
            transform: translateX(-50%);
            border: 5px solid transparent;
            border-top-color: #2d2d2d;
        }
        
        .llm-scoring-not-relevant:hover .llm-scoring-tooltip {
            opacity: 1;
            visibility: visible;
        }
        
        .paper-metrics-row {
            display: flex;
            gap: 2rem;
            align-items: flex-start;
        }
        
        .similarity-scores {
            flex: 1;
            min-width: 0;
        }
        
        .similarity-summary {
            background-color: rgba(255,255,255,0.05);
            border-radius: 8px;
            padding: 1rem;
            border: 1px solid rgba(255,255,255,0.1);
        }
        
        .similarity-scores-content {
            display: grid;
            grid-template-columns: auto 1fr;
            gap: 0.5rem 1rem;
            align-items: center;
        }
        
        .similarity-label {
            font-weight: 600;
            color: #e0e0e0;
            white-space: nowrap;
        }
        
        .similarity-right-column {
            display: flex;
            align-items: center;
            gap: 0.75rem;
        }
        
        .similarity-bar {
            height: 8px;
            background-color: #404040;
            border-radius: 4px;
            overflow: hidden;
            width: 100px;
            flex-shrink: 0;
        }
        
        .similarity-value {
            color: #e0e0e0;
            font-weight: 600;
            min-width: 45px;
            flex-shrink: 0;
        }
        
        .similarity-bar-fill {
            height: 100%;
            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
            border-radius: 4px;
            transition: width 0.3s ease;
        }
        
        .paper-link {
            color: #ffffff;
            text-decoration: none;
        }
        
        .paper-link:hover {
            text-decoration: underline;
            color: #f0f0f0;
        }
        
        .controls {
            display: flex;
            gap: 1rem;
            justify-content: center;
            align-items: center;
            flex-wrap: wrap;
        }
        
        .control-group {
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }
        
        .form-select, .form-control {
            background-color: rgba(255,255,255,0.1);
            border: 1px solid rgba(255,255,255,0.3);
            color: #ffffff;
        }
        
        .form-select option {
            background-color: #2d2d2d;
            color: #ffffff;
        }
        
        .form-select:focus, .form-control:focus {
            background-color: rgba(255,255,255,0.2);
            border-color: #667eea;
            color: #ffffff;
            box-shadow: 0 0 0 0.25rem rgba(102, 126, 234, 0.25);
        }
        
        .btn-outline-light {
            border-color: rgba(255,255,255,0.5);
        }
        
        .btn-outline-light:hover {
            background-color: rgba(255,255,255,0.2);
            border-color: #ffffff;
        }
        
        .filter-count-section {
            text-align: center;
            margin-top: 1.5rem;
            padding-top: 1rem;
            border-top: 1px solid rgba(255,255,255,0.1);
        }
        
        .filter-count-display {
            font-size: 1.2rem;
            font-weight: 700;
            color: #ffffff;
            text-shadow: 0 1px 2px rgba(0,0,0,0.3);
        }
        
        .main-nav-link {
            color: #ffffff;
            text-decoration: none;
            padding: 0.75rem 1.5rem;
            border-radius: 8px;
            transition: all 0.2s;
            font-weight: 600;
            font-size: 1rem;
            background: linear-gradient(135deg, #2D3748 0%, #4A5568 100%);
            border: 1px solid #404040;
            box-shadow: 0 2px 4px rgba(0,0,0,0.3);
        }
        
        .main-nav-link:hover {
            background: linear-gradient(135deg, #4A5568 0%, #2D3748 100%);
            text-decoration: none;
            color: #ffffff;
            transform: translateY(-1px);
            box-shadow: 0 4px 8px rgba(0,0,0,0.4);
        }
        
        .paper-number {
            font-weight: bold;
            color: #ffffff;
            margin-right: 0.5rem;
        }
        
        .hidden {
            display: none !important;
        }
        
        .llm-validation {
            flex: 1;
            min-width: 0;
        }
        
        .h-index-scores {
            flex: 1;
            min-width: 0;
        }
        
        .h-index-summary {
            background-color: rgba(255,255,255,0.05);
            border-radius: 8px;
            padding: 1rem;
            border: 1px solid rgba(255,255,255,0.1);
        }
        
        .h-index-metric {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 0.5rem;
        }
        
        .h-index-metric:last-child {
            margin-bottom: 0;
        }
        
        .h-index-label {
            font-weight: 600;
            color: #e0e0e0;
        }
        
        .h-index-value {
            color: #ffffff;
            font-weight: bold;
        }
        
        .h-index-expand {
            margin-top: 1rem;
            padding-top: 1rem;
            border-top: 1px solid rgba(255,255,255,0.1);
        }
        
        .h-index-toggle {
            font-size: 0.85rem;
            padding: 0.25rem 0.5rem;
        }
        
        .h-index-details {
            background-color: rgba(255,255,255,0.03);
            border-radius: 4px;
            padding: 0.75rem;
            border: 1px solid rgba(255,255,255,0.05);
            margin-top: 0.5rem;
            display: none;
        }
        
        .individual-h-index {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 0.25rem;
            font-size: 0.9rem;
        }
        
        .individual-h-index:last-child {
            margin-bottom: 0;
        }
        
        .author-name {
            color: #e0e0e0;
        }
        
        .author-name-link {
            color: #00d4aa;
            text-decoration: none;
        }
        
        .author-name-link:hover {
            color: #00ffcc;
            text-decoration: underline;
        }
        
        .author-h-value {
            color: #ffffff;
            font-weight: 600;
        }
        
        .llm-validation-summary {
            background-color: rgba(255,255,255,0.05);
            border-radius: 8px;
            padding: 1rem;
            border: 1px solid rgba(255,255,255,0.1);
        }
        
        .llm-validation-item {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 0.5rem;
        }
        
        .llm-validation-item:last-child {
            margin-bottom: 0;
        }
        
        .llm-topic-label {
            font-weight: 600;
            color: #e0e0e0;
        }
        
        .llm-status {
            font-weight: bold;
            font-size: 0.9rem;
        }
        
        .llm-highly-relevant {
            color: #28a745;
        }
        
        .llm-moderately-relevant {
            color: #17a2b8;
        }
        
        .llm-tangentially-relevant {
            color: #ffc107;
        }
        
        .llm-not-relevant {
            color: #dc3545;
        }
        
        .llm-not-relevant-asterisk {
            color: #dc3545;
            position: relative;
            cursor: help;
        }
        
        .llm-validation-tooltip {
            position: absolute;
            bottom: 100%;
            left: 50%;
            transform: translateX(-50%);
            background: #2d2d2d;
            color: #ffffff;
            padding: 0.5rem 0.75rem;
            border-radius: 4px;
            font-size: 0.8rem;
            white-space: nowrap;
            opacity: 0;
            visibility: hidden;
            transition: opacity 0.2s, visibility 0.2s;
            z-index: 1000;
            margin-bottom: 5px;
            border: 1px solid #404040;
        }
        
        .llm-validation-tooltip::after {
            content: '';
            position: absolute;
            top: 100%;
            left: 50%;
            transform: translateX(-50%);
            border: 5px solid transparent;
            border-top-color: #2d2d2d;
        }
        
        .llm-not-relevant-asterisk:hover .llm-validation-tooltip {
            opacity: 1;
            visibility: visible;
        }
        
        .llm-disabled {
            color: #6c757d;
        }
        
        .llm-buttons-row {
            margin-top: 1rem;
            padding-top: 1rem;
            border-top: 1px solid rgba(255,255,255,0.1);
            display: flex;
            gap: 0.5rem;
            flex-wrap: wrap;
        }
        
        .llm-toggle {
            font-size: 0.85rem;
            padding: 0.25rem 0.5rem;
        }
        
        .llm-details {
            background-color: rgba(255,255,255,0.03);
            border-radius: 4px;
            padding: 0.75rem;
            border: 1px solid rgba(255,255,255,0.05);
            margin-top: 1rem;
            display: none;
        }
        
        .llm-justification {
            margin-bottom: 0.75rem;
            font-size: 0.9rem;
            line-height: 1.4;
        }
        
        .llm-justification:last-child {
            margin-bottom: 0;
        }
        
        @media (max-width: 768px) {
            .paper-metrics-row {
                flex-direction: column;
                gap: 1rem;
            }
            .llm-scoring-row {
                flex-direction: column;
                align-items: flex-start;
                gap: 0.5rem;
            }
            .llm-scoring-left {
                width: 100%;
            }
            .llm-scoring-justification-btn {
                align-self: flex-start;
            }
        }
    </style>
</head>
<body>
    <div class="full-width-header">
        <div class="container">
            <div style="position: absolute; top: 1rem; left: 1rem;">
                <a href="index.html" class="main-nav-link">← Back to Home</a>
            </div>
            <div class="header-title-section">
                <h1 class="mb-3">Test Papers</h1>
                
                <p class="text-muted mb-0" id="paper-count">20 papers</p>
            </div>
        </div>
        <div class="controls-section">
            <div class="container">
                <div class="controls">
                    <div class="control-group">
                        <label for="sortBy" class="form-label mb-0">Sort by:</label>
                        <select id="sortBy" class="form-select form-select-sm">
                            <option value="recommendation_desc">Recommendation (Best First)</option>
                            <option value="recommendation_asc">Recommendation (Worst First)</option>
                            <option value="similarity_desc">Similarity score (Descending)</option>
                            <option value="similarity_asc">Similarity score (Ascending)</option>
                            <option value="title">Title</option>
                            <option value="arxiv_id">arXiv ID</option>
                            <option value="max_h_index_desc">Max H-index (Descending)</option>
                            <option value="max_h_index_asc">Max H-index (Ascending)</option>
                            <option value="avg_h_index_desc">Avg H-index (Descending)</option>
                            <option value="avg_h_index_asc">Avg H-index (Ascending)</option>
                        </select>
                    </div>
                    
                    <div class="control-group">
                        <label class="form-label mb-0">Filter by topics:</label>
                        <div style="display: flex; gap: 0.5rem; flex-wrap: wrap;">
                            
                            <label class="form-check-label" style="display: flex; align-items: center; gap: 0.25rem; cursor: pointer;">
                                <input type="checkbox" class="form-check-input topic-filter" value="RLHF" checked>
                                RLHF
                            </label>
                            
                            <label class="form-check-label" style="display: flex; align-items: center; gap: 0.25rem; cursor: pointer;">
                                <input type="checkbox" class="form-check-input topic-filter" value="Weak_supervision" checked>
                                Weak supervision
                            </label>
                            
                            <label class="form-check-label" style="display: flex; align-items: center; gap: 0.25rem; cursor: pointer;">
                                <input type="checkbox" class="form-check-input topic-filter" value="Diffusion_reasoning" checked>
                                Diffusion reasoning
                            </label>
                            
                            <label class="form-check-label" style="display: flex; align-items: center; gap: 0.25rem; cursor: pointer;">
                                <input type="checkbox" class="form-check-input topic-filter" value="Distributed_training" checked>
                                Distributed training
                            </label>
                            
                        </div>
                    </div>
                    
                    <div class="control-group">
                        <label class="form-label mb-0">LLM Validation:</label>
                        <div style="display: flex; gap: 0.5rem; flex-wrap: wrap;">
                            <label class="form-check-label" style="display: flex; align-items: center; gap: 0.25rem; cursor: pointer;">
                                <input type="checkbox" class="form-check-input llm-filter" value="yes" checked>
                                Yes
                            </label>
                            <label class="form-check-label" style="display: flex; align-items: center; gap: 0.25rem; cursor: pointer;">
                                <input type="checkbox" class="form-check-input llm-filter" value="no" checked>
                                No
                            </label>
                            <label class="form-check-label" style="display: flex; align-items: center; gap: 0.25rem; cursor: pointer;">
                                <input type="checkbox" class="form-check-input llm-filter" value="not_validated" checked>
                                Not Validated
                            </label>
                        </div>
                    </div>
                    
                    <div class="control-group">
                        <label class="form-label mb-0">H-Index Data:</label>
                        <div style="display: flex; gap: 0.5rem; flex-wrap: wrap;">
                            <label class="form-check-label" style="display: flex; align-items: center; gap: 0.25rem; cursor: pointer;">
                                <input type="checkbox" class="form-check-input h-index-filter" value="full" checked>
                                Full Data
                            </label>
                            <label class="form-check-label" style="display: flex; align-items: center; gap: 0.25rem; cursor: pointer;">
                                <input type="checkbox" class="form-check-input h-index-filter" value="partial" checked>
                                Partial Data
                            </label>
                            <label class="form-check-label" style="display: flex; align-items: center; gap: 0.25rem; cursor: pointer;">
                                <input type="checkbox" class="form-check-input h-index-filter" value="none" checked>
                                No Data
                            </label>
                        </div>
                    </div>
                    
                    <div class="control-group">
                        <label for="minScore" class="form-label mb-0">Min Score:</label>
                        <input type="number" id="minScore" class="form-control form-control-sm" 
                               step="0.01" min="0" max="1" value="0" style="width: 80px;">
                    </div>
                    
                    <div class="control-group">
                        <label for="maxScore" class="form-label mb-0">Max Score:</label>
                        <input type="number" id="maxScore" class="form-control form-control-sm" 
                               step="0.01" min="0" max="1" value="1" style="width: 80px;">
                    </div>
                    
                    <button id="resetFilters" class="btn btn-outline-light btn-sm">Reset</button>
                </div>
                
                <div class="filter-count-section">
                    <span id="filter-count" class="filter-count-display">
                        Showing 20/20 papers
                    </span>
                </div>
            </div>
        </div>
    </div>

    <div class="container">
        <div id="papers-container">
            
            <div class="paper-card" data-paper-index="0">
                <div class="paper-header">
                    <div class="paper-number">#1</div>
                    <h5 class="paper-title">
                        <a href="http://arxiv.org/abs/2402.07754" class="paper-link" target="_blank">
                            Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language
  Models
                        </a>
                    </h5>
                    <div class="paper-meta">
                        <strong>arXiv ID:</strong> 2402.07754 |
                        <strong>Published:</strong> 2024-02-12T16:23:28+00:00 |
                        
                        <strong>Highest Score:</strong> 0.753 Diffusion reasoning
                        
                    </div>
                </div>
                
                <div class="paper-body">
                    <div class="paper-abstract">
                        <strong>Abstract:</strong> Recently, diffusion models have garnered significant interest in the field of
text processing due to their many potential advantages compared to conventional
autoregressive models. In this work, we propose Diffusion-of-Thought (DoT), a
novel approach that integrates diffusion models with Chain-of-Thought, a
well-established technique for improving the reasoning ability of
autoregressive language models. In contrast to autoregressive language models
that make decisions in a left-to-right, token-by-token manner, DoT allows
reasoning steps to diffuse over time through a diffusion language model and
offers greater flexibility in trading-off computation for reasoning
performance. Our experimental results demonstrate the effectiveness of DoT in
multi-digit multiplication, boolean logic, and grade school math problems, with
a small diffusion model outperforming a much larger autoregressive model in
both efficiency and accuracy. In addition to that, DoT showcases promising
self-correction abilities and benefits from existing reasoning-enhancing
techniques like self-consistency decoding. Our findings contribute to the
understanding and development of reasoning with diffusion language models.
                    </div>
                    
                    
                    <div class="paper-categories">
                        <strong>Categories:</strong>
                        
                        <span class="category-tag">cs.CL</span>
                        
                        <span class="category-tag">cs.AI</span>
                        
                        <span class="category-tag">cs.LG</span>
                        
                    </div>
                    
                    
                    
                    <div class="similarity-summary">
                        <div class="llm-scoring-header">
                            <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600; display: inline;">LLM Scoring:</h6>
                            <button class="btn btn-sm btn-outline-light llm-scoring-toggle" 
                                    onclick="toggleLLMScoringJustifications('llm-scoring-0')">
                                Show Justification ▼
                            </button>
                        </div>
                        
                        <div class="llm-scoring-columns">
                            <!-- Recommendation Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Recommendation:</div>
                                
                                <div class="llm-scoring-value should-read">Should Read</div>
                                
                            </div>
                            
                            <!-- Novelty Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Novelty:</div>
                                
                                <div class="llm-scoring-value high">High</div>
                                
                            </div>
                            
                            <!-- Potential Impact Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Potential Impact:</div>
                                
                                <div class="llm-scoring-value high">High</div>
                                
                            </div>
                        </div>
                        
                        <!-- Unified Justifications Section -->
                        <div class="llm-scoring-justifications" id="llm-scoring-0" style="display: none;">
                            
                            <div class="llm-justification-item">
                                <strong>Recommendation:</strong> This paper is valuable for researchers and practitioners working on language models and reasoning techniques, as it offers innovative insights into diffusion models. However, as a preliminary study, it may not be essential for those outside the specific subfield of diffusion-based AI.
                            </div>
                            
                            
                            <div class="llm-justification-item">
                                <strong>Novelty:</strong> The paper introduces a truly new technique by adapting chain-of-thought reasoning to diffusion models, significantly advancing the state-of-the-art in reasoning for non-autoregressive language models. This integration represents a fresh approach that combines established ideas in a novel way to address limitations in existing models.
                            </div>
                            
                            
                            <div class="llm-justification-item">
                                <strong>Potential Impact:</strong> The work could influence future research and applications in diffusion models for language processing, potentially shifting paradigms away from autoregressive models by demonstrating superior efficiency and reasoning abilities. Its findings on outperforming larger models suggest broad applicability in AI subfields like natural language processing and machine learning.
                            </div>
                            
                        </div>
                    </div>
                    
                    
                    <div class="paper-metrics-row">
                        <div class="similarity-scores">
                            
                                <div class="similarity-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Similarity Scores:</h6>
                                    <div class="similarity-scores-content">
                                        
                                        <span class="similarity-label" data-topic="RLHF">RLHF:</span>
                                        <div class="similarity-right-column" data-topic="RLHF">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 36.1%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.361">0.361</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Weak_supervision">Weak supervision:</span>
                                        <div class="similarity-right-column" data-topic="Weak_supervision">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 31.4%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.314">0.314</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Diffusion_reasoning">Diffusion reasoning:</span>
                                        <div class="similarity-right-column" data-topic="Diffusion_reasoning">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 75.3%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.753">0.753</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Distributed_training">Distributed training:</span>
                                        <div class="similarity-right-column" data-topic="Distributed_training">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 38.0%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.380">0.380</span>
                                        </div>
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="llm-validation">
                            
                                <div class="llm-validation-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">LLM Validation:</h6>
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="RLHF">
                                                <span class="llm-topic-label">RLHF:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Weak_supervision">
                                                <span class="llm-topic-label">Weak supervision:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Diffusion_reasoning">
                                                <span class="llm-topic-label">Diffusion reasoning:</span>
                                                
                                                    
                                                        <span class="llm-status llm-highly-relevant">Highly Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Distributed_training">
                                                <span class="llm-topic-label">Distributed training:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                    
                                    <div class="llm-buttons-row">
                                        <button class="btn btn-sm btn-outline-light llm-toggle" 
                                                onclick="toggleLLMDetails('llm-details-0')">
                                            Show Justifications ▼
                                        </button>
                                    </div>
                                    
                                    <div class="llm-details" id="llm-details-0">
                                        <h6 style="font-size: 0.9rem; margin-bottom: 0.5rem;">LLM Justifications:</h6>
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>RLHF:</strong> below_threshold
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Weak supervision:</strong> below_threshold
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Diffusion reasoning:</strong> The paper's main contribution, Diffusion of Thoughts (DoT), directly adapts the iterative refinement process of diffusion models to enhance Chain-of-Thought reasoning for complex logical tasks. It treats the reasoning path as a dynamic entity that evolves over diffusion timesteps, enabling holistic correction and improvement, as evidenced by experiments on tasks like multi-digit multiplication and grade school math. This aligns precisely with the topic's definition of multi-step logical reasoning using diffusion models.
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Distributed training:</strong> below_threshold
                                            </div>
                                            
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="h-index-scores">
                            
                                <div class="h-index-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Author H-Index:</h6>
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Data found:</span>
                                        <span class="h-index-value">10/10 authors</span>
                                    </div>
                                    <div class="h-index-metric">
                                        <span class="h-index-label">H-index available:</span>
                                        <span class="h-index-value">10/10 found</span>
                                    </div>
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Highest:</span>
                                        <span class="h-index-value">16</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Average:</span>
                                        <span class="h-index-value">7.9</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Notable (H>5):</span>
                                        <span class="h-index-value">8</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Source:</span>
                                        <span class="h-index-value">Full Id</span>
                                    </div>
                                    
                                    
                                    
                                    <div class="h-index-expand">
                                        <button class="btn btn-sm btn-outline-light h-index-toggle" 
                                                onclick="toggleHIndexDetails('h-details-0')">
                                            Show Individual H-indices ▼
                                        </button>
                                        <div class="h-index-details" id="h-details-0">
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Jiacheng Ye</span>
                                                
                                                <span class="author-h-value">16</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Shansan Gong</span>
                                                
                                                <span class="author-h-value">10</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Liheng Chen</span>
                                                
                                                <span class="author-h-value">6</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Lin Zheng</span>
                                                
                                                <span class="author-h-value">6</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Jiahui Gao</span>
                                                
                                                <span class="author-h-value">13</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Han Shi</span>
                                                
                                                <span class="author-h-value">6</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Chuan Wu</span>
                                                
                                                <span class="author-h-value">5</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Zhenguo Li</span>
                                                
                                                <span class="author-h-value">6</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Wei Bi</span>
                                                
                                                <span class="author-h-value">4</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Lingpeng Kong</span>
                                                
                                                <span class="author-h-value">7</span>
                                            </div>
                                            
                                        </div>
                                    </div>
                                    
                                </div>
                            
                        </div>
                    </div>
                </div>
            </div>
            
            <div class="paper-card" data-paper-index="1">
                <div class="paper-header">
                    <div class="paper-number">#2</div>
                    <h5 class="paper-title">
                        <a href="http://arxiv.org/abs/2505.10446" class="paper-link" target="_blank">
                            Reinforcing the Diffusion Chain of Lateral Thought with Diffusion
  Language Models
                        </a>
                    </h5>
                    <div class="paper-meta">
                        <strong>arXiv ID:</strong> 2505.10446 |
                        <strong>Published:</strong> 2025-05-15T16:06:32+00:00 |
                        
                        <strong>Highest Score:</strong> 0.736 Diffusion reasoning
                        
                    </div>
                </div>
                
                <div class="paper-body">
                    <div class="paper-abstract">
                        <strong>Abstract:</strong> We introduce the Diffusion Chain of Lateral Thought (DCoLT), a reasoning
framework for diffusion language models. DCoLT treats each intermediate step in
the reverse diffusion process as a latent &quot;thinking&quot; action and optimizes the
entire reasoning trajectory to maximize the reward on the correctness of the
final answer with outcome-based Reinforcement Learning (RL). Unlike traditional
Chain-of-Thought (CoT) methods that follow a causal, linear thinking process,
DCoLT allows bidirectional, non-linear reasoning with no strict rule on
grammatical correctness amid its intermediate steps of thought. We implement
DCoLT on two representative Diffusion Language Models (DLMs). First, we choose
SEDD as a representative continuous-time discrete diffusion model, where its
concrete score derives a probabilistic policy to maximize the RL reward over
the entire sequence of intermediate diffusion steps. We further consider the
discrete-time masked diffusion language model -- LLaDA, and find that the order
to predict and unmask tokens plays an essential role to optimize its RL action
resulting from the ranking-based Unmasking Policy Module (UPM) defined by the
Plackett-Luce model. Experiments on both math and code generation tasks show
that using only public data and 16 H800 GPUs, DCoLT-reinforced DLMs outperform
other DLMs trained by SFT or RL or even both. Notably, DCoLT-reinforced LLaDA
boosts its reasoning accuracy by +9.8%, +5.7%, +11.4%, +19.5% on GSM8K, MATH,
MBPP, and HumanEval.
                    </div>
                    
                    
                    <div class="paper-categories">
                        <strong>Categories:</strong>
                        
                        <span class="category-tag">cs.CL</span>
                        
                    </div>
                    
                    
                    
                    <div class="similarity-summary">
                        <div class="llm-scoring-header">
                            <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600; display: inline;">LLM Scoring:</h6>
                            <button class="btn btn-sm btn-outline-light llm-scoring-toggle" 
                                    onclick="toggleLLMScoringJustifications('llm-scoring-1')">
                                Show Justification ▼
                            </button>
                        </div>
                        
                        <div class="llm-scoring-columns">
                            <!-- Recommendation Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Recommendation:</div>
                                
                                <div class="llm-scoring-value should-read">Should Read</div>
                                
                            </div>
                            
                            <!-- Novelty Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Novelty:</div>
                                
                                <div class="llm-scoring-value high">High</div>
                                
                            </div>
                            
                            <!-- Potential Impact Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Potential Impact:</div>
                                
                                <div class="llm-scoring-value moderate">Moderate</div>
                                
                            </div>
                        </div>
                        
                        <!-- Unified Justifications Section -->
                        <div class="llm-scoring-justifications" id="llm-scoring-1" style="display: none;">
                            
                            <div class="llm-justification-item">
                                <strong>Recommendation:</strong> This paper offers valuable innovations for researchers specifically working on diffusion language models and reasoning, providing practical insights and results that could enhance related studies.
                            </div>
                            
                            
                            <div class="llm-justification-item">
                                <strong>Novelty:</strong> The paper introduces a truly new framework, DCoLT, which combines diffusion models with reinforcement learning for non-linear reasoning, representing a significant advancement over traditional linear Chain-of-Thought methods.
                            </div>
                            
                            
                            <div class="llm-justification-item">
                                <strong>Potential Impact:</strong> The work is likely to be cited and built upon in the subfield of diffusion language models and reasoning tasks due to its demonstrated performance improvements, though its influence may be limited to specialized applications rather than widespread commercial or research domains.
                            </div>
                            
                        </div>
                    </div>
                    
                    
                    <div class="paper-metrics-row">
                        <div class="similarity-scores">
                            
                                <div class="similarity-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Similarity Scores:</h6>
                                    <div class="similarity-scores-content">
                                        
                                        <span class="similarity-label" data-topic="RLHF">RLHF:</span>
                                        <div class="similarity-right-column" data-topic="RLHF">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 45.8%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.458">0.458</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Weak_supervision">Weak supervision:</span>
                                        <div class="similarity-right-column" data-topic="Weak_supervision">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 38.4%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.384">0.384</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Diffusion_reasoning">Diffusion reasoning:</span>
                                        <div class="similarity-right-column" data-topic="Diffusion_reasoning">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 73.6%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.736">0.736</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Distributed_training">Distributed training:</span>
                                        <div class="similarity-right-column" data-topic="Distributed_training">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 39.3%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.393">0.393</span>
                                        </div>
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="llm-validation">
                            
                                <div class="llm-validation-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">LLM Validation:</h6>
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="RLHF">
                                                <span class="llm-topic-label">RLHF:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant">Not Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Weak_supervision">
                                                <span class="llm-topic-label">Weak supervision:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Diffusion_reasoning">
                                                <span class="llm-topic-label">Diffusion reasoning:</span>
                                                
                                                    
                                                        <span class="llm-status llm-highly-relevant">Highly Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Distributed_training">
                                                <span class="llm-topic-label">Distributed training:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                    
                                    <div class="llm-buttons-row">
                                        <button class="btn btn-sm btn-outline-light llm-toggle" 
                                                onclick="toggleLLMDetails('llm-details-1')">
                                            Show Justifications ▼
                                        </button>
                                    </div>
                                    
                                    <div class="llm-details" id="llm-details-1">
                                        <h6 style="font-size: 0.9rem; margin-bottom: 0.5rem;">LLM Justifications:</h6>
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>RLHF:</strong> The paper uses outcome-based reinforcement learning with a rule-based reward to optimize diffusion models, focusing on the correctness of final answers. It does not involve human feedback, a separate reward model trained on human-ranked data, or any alignment with human preferences, which are core to RLHF.
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Weak supervision:</strong> below_threshold
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Diffusion reasoning:</strong> The paper introduces DCoLT, a framework that adapts the reverse diffusion process in language models for multi-step logical reasoning, treating the entire reasoning trajectory as a single entity for optimization. This directly aligns with diffusion-based reasoning by enabling iterative refinement, non-linear thinking, and holistic correction for complex tasks like math and code generation.
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Distributed training:</strong> below_threshold
                                            </div>
                                            
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="h-index-scores">
                            
                                <div class="h-index-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Author H-Index:</h6>
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Data found:</span>
                                        <span class="h-index-value">5/5 authors</span>
                                    </div>
                                    <div class="h-index-metric">
                                        <span class="h-index-label">H-index available:</span>
                                        <span class="h-index-value">5/5 found</span>
                                    </div>
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Highest:</span>
                                        <span class="h-index-value">4</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Average:</span>
                                        <span class="h-index-value">2.4</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Notable (H>5):</span>
                                        <span class="h-index-value">0</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Source:</span>
                                        <span class="h-index-value">Full Id</span>
                                    </div>
                                    
                                    
                                    
                                    <div class="h-index-expand">
                                        <button class="btn btn-sm btn-outline-light h-index-toggle" 
                                                onclick="toggleHIndexDetails('h-details-1')">
                                            Show Individual H-indices ▼
                                        </button>
                                        <div class="h-index-details" id="h-details-1">
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Zemin Huang</span>
                                                
                                                <span class="author-h-value">3</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Zhiyang Chen</span>
                                                
                                                <span class="author-h-value">2</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Zijun Wang</span>
                                                
                                                <span class="author-h-value">1</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Tiancheng Li</span>
                                                
                                                <span class="author-h-value">2</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Guo-Jun Qi</span>
                                                
                                                <span class="author-h-value">4</span>
                                            </div>
                                            
                                        </div>
                                    </div>
                                    
                                </div>
                            
                        </div>
                    </div>
                </div>
            </div>
            
            <div class="paper-card" data-paper-index="2">
                <div class="paper-header">
                    <div class="paper-number">#3</div>
                    <h5 class="paper-title">
                        <a href="http://arxiv.org/abs/2502.13417" class="paper-link" target="_blank">
                            RLTHF: Targeted Human Feedback for LLM Alignment
                        </a>
                    </h5>
                    <div class="paper-meta">
                        <strong>arXiv ID:</strong> 2502.13417 |
                        <strong>Published:</strong> 2025-02-19T04:25:11+00:00 |
                        
                        <strong>Highest Score:</strong> 0.718 RLHF
                        
                    </div>
                </div>
                
                <div class="paper-body">
                    <div class="paper-abstract">
                        <strong>Abstract:</strong> Fine-tuning large language models (LLMs) to align with user preferences is
challenging due to the high cost of quality human annotations in Reinforcement
Learning from Human Feedback (RLHF) and the generalizability limitations of AI
Feedback. To address these challenges, we propose RLTHF, a human-AI hybrid
framework that combines LLM-based initial alignment with selective human
annotations to achieve full-human annotation alignment with minimal effort.
RLTHF identifies hard-to-annotate samples mislabeled by LLMs using a reward
model&#x27;s reward distribution and iteratively enhances alignment by integrating
strategic human corrections while leveraging LLM&#x27;s correctly labeled samples.
Evaluations on HH-RLHF and TL;DR datasets show that RLTHF reaches full-human
annotation-level alignment with only 6-7% of the human annotation effort.
Furthermore, models trained on RLTHF&#x27;s curated datasets for downstream tasks
outperform those trained on fully human-annotated datasets, underscoring the
effectiveness of RLTHF&#x27;s strategic data curation.
                    </div>
                    
                    
                    <div class="paper-categories">
                        <strong>Categories:</strong>
                        
                        <span class="category-tag">cs.CL</span>
                        
                        <span class="category-tag">cs.AI</span>
                        
                        <span class="category-tag">cs.LG</span>
                        
                    </div>
                    
                    
                    
                    <div class="similarity-summary">
                        <div class="llm-scoring-header">
                            <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600; display: inline;">LLM Scoring:</h6>
                            <button class="btn btn-sm btn-outline-light llm-scoring-toggle" 
                                    onclick="toggleLLMScoringJustifications('llm-scoring-2')">
                                Show Justification ▼
                            </button>
                        </div>
                        
                        <div class="llm-scoring-columns">
                            <!-- Recommendation Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Recommendation:</div>
                                
                                <div class="llm-scoring-value should-read">Should Read</div>
                                
                            </div>
                            
                            <!-- Novelty Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Novelty:</div>
                                
                                <div class="llm-scoring-value moderate">Moderate</div>
                                
                            </div>
                            
                            <!-- Potential Impact Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Potential Impact:</div>
                                
                                <div class="llm-scoring-value moderate">Moderate</div>
                                
                            </div>
                        </div>
                        
                        <!-- Unified Justifications Section -->
                        <div class="llm-scoring-justifications" id="llm-scoring-2" style="display: none;">
                            
                            <div class="llm-justification-item">
                                <strong>Recommendation:</strong> This paper provides valuable insights and methods for researchers working on LLM alignment and human-AI feedback, making it essential for those in the specific area but not broadly critical for the entire field.
                            </div>
                            
                            
                            <div class="llm-justification-item">
                                <strong>Novelty:</strong> The paper presents a clever combination of existing RLHF and RLAIF techniques by introducing targeted human feedback based on reward model analysis, offering a notable improvement in efficiency for LLM alignment without introducing an entirely new problem or architecture.
                            </div>
                            
                            
                            <div class="llm-justification-item">
                                <strong>Potential Impact:</strong> The work is likely to influence research and applications in LLM fine-tuning by reducing annotation costs, potentially leading to more efficient AI development practices within subfields like machine learning and natural language processing.
                            </div>
                            
                        </div>
                    </div>
                    
                    
                    <div class="paper-metrics-row">
                        <div class="similarity-scores">
                            
                                <div class="similarity-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Similarity Scores:</h6>
                                    <div class="similarity-scores-content">
                                        
                                        <span class="similarity-label" data-topic="RLHF">RLHF:</span>
                                        <div class="similarity-right-column" data-topic="RLHF">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 71.8%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.718">0.718</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Weak_supervision">Weak supervision:</span>
                                        <div class="similarity-right-column" data-topic="Weak_supervision">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 47.2%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.472">0.472</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Diffusion_reasoning">Diffusion reasoning:</span>
                                        <div class="similarity-right-column" data-topic="Diffusion_reasoning">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 40.9%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.409">0.409</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Distributed_training">Distributed training:</span>
                                        <div class="similarity-right-column" data-topic="Distributed_training">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 41.1%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.411">0.411</span>
                                        </div>
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="llm-validation">
                            
                                <div class="llm-validation-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">LLM Validation:</h6>
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="RLHF">
                                                <span class="llm-topic-label">RLHF:</span>
                                                
                                                    
                                                        <span class="llm-status llm-highly-relevant">Highly Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Weak_supervision">
                                                <span class="llm-topic-label">Weak supervision:</span>
                                                
                                                    
                                                        <span class="llm-status llm-moderately-relevant">Moderately Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Diffusion_reasoning">
                                                <span class="llm-topic-label">Diffusion reasoning:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant">Not Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Distributed_training">
                                                <span class="llm-topic-label">Distributed training:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant">Not Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                    
                                    <div class="llm-buttons-row">
                                        <button class="btn btn-sm btn-outline-light llm-toggle" 
                                                onclick="toggleLLMDetails('llm-details-2')">
                                            Show Justifications ▼
                                        </button>
                                    </div>
                                    
                                    <div class="llm-details" id="llm-details-2">
                                        <h6 style="font-size: 0.9rem; margin-bottom: 0.5rem;">LLM Justifications:</h6>
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>RLHF:</strong> The paper directly builds on RLHF by proposing RLTHF, a framework that enhances RLHF processes through targeted human feedback and reward models to align LLMs with human preferences. It addresses RLHF challenges like annotation costs, making it a core extension of the topic.
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Weak supervision:</strong> The paper uses LLM-generated labels as a noisy, programmatic source for initial annotations, which aligns with weak supervision by reducing reliance on perfect hand-labeled data. However, it focuses more on RLHF integration than pure weak supervision techniques.
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Diffusion reasoning:</strong> The paper does not involve diffusion models, iterative refinement for logical tasks, or Chain-of-Thought processes; it centers on RLHF and annotation strategies without any multi-step reasoning via diffusion.
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Distributed training:</strong> The paper does not discuss parallel computing, multi-node systems, or strategies for partitioning data/computation; it focuses solely on data annotation and alignment for LLMs.
                                            </div>
                                            
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="h-index-scores">
                            
                                <div class="h-index-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Author H-Index:</h6>
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Data found:</span>
                                        <span class="h-index-value">14/14 authors</span>
                                    </div>
                                    <div class="h-index-metric">
                                        <span class="h-index-label">H-index available:</span>
                                        <span class="h-index-value">14/14 found</span>
                                    </div>
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Highest:</span>
                                        <span class="h-index-value">6</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Average:</span>
                                        <span class="h-index-value">2.6</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Notable (H>5):</span>
                                        <span class="h-index-value">1</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Source:</span>
                                        <span class="h-index-value">Full Id</span>
                                    </div>
                                    
                                    
                                    
                                    <div class="h-index-expand">
                                        <button class="btn btn-sm btn-outline-light h-index-toggle" 
                                                onclick="toggleHIndexDetails('h-details-2')">
                                            Show Individual H-indices ▼
                                        </button>
                                        <div class="h-index-details" id="h-details-2">
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Yifei Xu</span>
                                                
                                                <span class="author-h-value">2</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Tusher Chakraborty</span>
                                                
                                                <span class="author-h-value">6</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Emre Kiciman</span>
                                                
                                                <span class="author-h-value">5</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Bibek Aryal</span>
                                                
                                                <span class="author-h-value">1</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Eduardo Rodrigues</span>
                                                
                                                <span class="author-h-value">1</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Srinagesh Sharma</span>
                                                
                                                <span class="author-h-value">1</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Roberto Estevão</span>
                                                
                                                <span class="author-h-value">2</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">M. A. D. L. Balaguer</span>
                                                
                                                <span class="author-h-value">5</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Jessica Wolk</span>
                                                
                                                <span class="author-h-value">1</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Rafael Padilha</span>
                                                
                                                <span class="author-h-value">2</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Leonardo Nunes</span>
                                                
                                                <span class="author-h-value">3</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Shobana Balakrishnan</span>
                                                
                                                <span class="author-h-value">1</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Songwu Lu</span>
                                                
                                                <span class="author-h-value">2</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Ranveer Chandra</span>
                                                
                                                <span class="author-h-value">4</span>
                                            </div>
                                            
                                        </div>
                                    </div>
                                    
                                </div>
                            
                        </div>
                    </div>
                </div>
            </div>
            
            <div class="paper-card" data-paper-index="3">
                <div class="paper-header">
                    <div class="paper-number">#4</div>
                    <h5 class="paper-title">
                        <a href="http://arxiv.org/abs/2504.03784" class="paper-link" target="_blank">
                            Robust Reinforcement Learning from Human Feedback for Large Language
  Models Fine-Tuning
                        </a>
                    </h5>
                    <div class="paper-meta">
                        <strong>arXiv ID:</strong> 2504.03784 |
                        <strong>Published:</strong> 2025-04-03T16:16:35+00:00 |
                        
                        <strong>Highest Score:</strong> 0.689 RLHF
                        
                    </div>
                </div>
                
                <div class="paper-body">
                    <div class="paper-abstract">
                        <strong>Abstract:</strong> Reinforcement learning from human feedback (RLHF) has emerged as a key
technique for aligning the output of large language models (LLMs) with human
preferences. To learn the reward function, most existing RLHF algorithms use
the Bradley-Terry model, which relies on assumptions about human preferences
that may not reflect the complexity and variability of real-world judgments. In
this paper, we propose a robust algorithm to enhance the performance of
existing approaches under such reward model misspecifications. Theoretically,
our algorithm reduces the variance of reward and policy estimators, leading to
improved regret bounds. Empirical evaluations on LLM benchmark datasets
demonstrate that the proposed algorithm consistently outperforms existing
methods, with 77-81% of responses being favored over baselines on the Anthropic
Helpful and Harmless dataset.
                    </div>
                    
                    
                    <div class="paper-categories">
                        <strong>Categories:</strong>
                        
                        <span class="category-tag">stat.ML</span>
                        
                        <span class="category-tag">cs.AI</span>
                        
                        <span class="category-tag">cs.LG</span>
                        
                    </div>
                    
                    
                    
                    <div class="similarity-summary">
                        <div class="llm-scoring-header">
                            <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600; display: inline;">LLM Scoring:</h6>
                            <button class="btn btn-sm btn-outline-light llm-scoring-toggle" 
                                    onclick="toggleLLMScoringJustifications('llm-scoring-3')">
                                Show Justification ▼
                            </button>
                        </div>
                        
                        <div class="llm-scoring-columns">
                            <!-- Recommendation Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Recommendation:</div>
                                
                                <div class="llm-scoring-value should-read">Should Read</div>
                                
                            </div>
                            
                            <!-- Novelty Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Novelty:</div>
                                
                                <div class="llm-scoring-value moderate">Moderate</div>
                                
                            </div>
                            
                            <!-- Potential Impact Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Potential Impact:</div>
                                
                                <div class="llm-scoring-value moderate">Moderate</div>
                                
                            </div>
                        </div>
                        
                        <!-- Unified Justifications Section -->
                        <div class="llm-scoring-justifications" id="llm-scoring-3" style="display: none;">
                            
                            <div class="llm-justification-item">
                                <strong>Recommendation:</strong> This paper is valuable for researchers specifically working on RLHF and LLM fine-tuning, offering theoretical and empirical insights into improving model robustness, though it may not be essential for those outside this niche.
                            </div>
                            
                            
                            <div class="llm-justification-item">
                                <strong>Novelty:</strong> The paper presents a notable improvement by introducing VRPO as a clever combination of existing RLHF techniques to handle reward model misspecifications, advancing the field without introducing an entirely new problem or architecture.
                            </div>
                            
                            
                            <div class="llm-justification-item">
                                <strong>Potential Impact:</strong> The work is likely to be cited and built upon in the subfield of LLM alignment and RLHF due to its practical enhancements in handling real-world preference complexities, potentially influencing future algorithms for more reliable AI systems.
                            </div>
                            
                        </div>
                    </div>
                    
                    
                    <div class="paper-metrics-row">
                        <div class="similarity-scores">
                            
                                <div class="similarity-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Similarity Scores:</h6>
                                    <div class="similarity-scores-content">
                                        
                                        <span class="similarity-label" data-topic="RLHF">RLHF:</span>
                                        <div class="similarity-right-column" data-topic="RLHF">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 68.9%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.689">0.689</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Weak_supervision">Weak supervision:</span>
                                        <div class="similarity-right-column" data-topic="Weak_supervision">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 43.4%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.434">0.434</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Diffusion_reasoning">Diffusion reasoning:</span>
                                        <div class="similarity-right-column" data-topic="Diffusion_reasoning">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 40.2%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.402">0.402</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Distributed_training">Distributed training:</span>
                                        <div class="similarity-right-column" data-topic="Distributed_training">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 41.6%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.416">0.416</span>
                                        </div>
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="llm-validation">
                            
                                <div class="llm-validation-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">LLM Validation:</h6>
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="RLHF">
                                                <span class="llm-topic-label">RLHF:</span>
                                                
                                                    
                                                        <span class="llm-status llm-highly-relevant">Highly Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Weak_supervision">
                                                <span class="llm-topic-label">Weak supervision:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant">Not Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Diffusion_reasoning">
                                                <span class="llm-topic-label">Diffusion reasoning:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant">Not Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Distributed_training">
                                                <span class="llm-topic-label">Distributed training:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant">Not Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                    
                                    <div class="llm-buttons-row">
                                        <button class="btn btn-sm btn-outline-light llm-toggle" 
                                                onclick="toggleLLMDetails('llm-details-3')">
                                            Show Justifications ▼
                                        </button>
                                    </div>
                                    
                                    <div class="llm-details" id="llm-details-3">
                                        <h6 style="font-size: 0.9rem; margin-bottom: 0.5rem;">LLM Justifications:</h6>
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>RLHF:</strong> The paper's main contribution is the development of a robust RLHF algorithm (VRPO) for fine-tuning LLMs, directly addressing challenges in aligning AI models with human preferences through human feedback. It builds on existing RLHF methods, analyzes reward models, and demonstrates empirical improvements, making it core to this topic.
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Weak supervision:</strong> The paper focuses on direct human feedback for RLHF, such as pairwise comparisons, rather than programmatically generating noisy labels from high-level sources, which is the essence of weak supervision.
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Diffusion reasoning:</strong> The paper does not involve diffusion models, iterative refinement for logical tasks, or multi-step reasoning processes; it is centered on RLHF and preference optimization for LLMs.
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Distributed training:</strong> The paper does not address parallel computing, multi-node setups, or strategies for partitioning data/computation; it is solely about improving RLHF algorithms algorithmically.
                                            </div>
                                            
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="h-index-scores">
                            
                                <div class="h-index-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Author H-Index:</h6>
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Data found:</span>
                                        <span class="h-index-value">5/5 authors</span>
                                    </div>
                                    <div class="h-index-metric">
                                        <span class="h-index-label">H-index available:</span>
                                        <span class="h-index-value">5/5 found</span>
                                    </div>
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Highest:</span>
                                        <span class="h-index-value">2</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Average:</span>
                                        <span class="h-index-value">1.2</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Notable (H>5):</span>
                                        <span class="h-index-value">0</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Source:</span>
                                        <span class="h-index-value">Title Search</span>
                                    </div>
                                    
                                    
                                    
                                    <div class="h-index-expand">
                                        <button class="btn btn-sm btn-outline-light h-index-toggle" 
                                                onclick="toggleHIndexDetails('h-details-3')">
                                            Show Individual H-indices ▼
                                        </button>
                                        <div class="h-index-details" id="h-details-3">
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Kai Ye</span>
                                                
                                                <span class="author-h-value">1</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Hongyi Zhou</span>
                                                
                                                <span class="author-h-value">1</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Jin Zhu</span>
                                                
                                                <span class="author-h-value">1</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Francesco Quinzan</span>
                                                
                                                <span class="author-h-value">1</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Chengchun Shi</span>
                                                
                                                <span class="author-h-value">2</span>
                                            </div>
                                            
                                        </div>
                                    </div>
                                    
                                </div>
                            
                        </div>
                    </div>
                </div>
            </div>
            
            <div class="paper-card" data-paper-index="4">
                <div class="paper-header">
                    <div class="paper-number">#5</div>
                    <h5 class="paper-title">
                        <a href="http://arxiv.org/abs/2012.01839" class="paper-link" target="_blank">
                            Distributed Training and Optimization Of Neural Networks
                        </a>
                    </h5>
                    <div class="paper-meta">
                        <strong>arXiv ID:</strong> 2012.01839 |
                        <strong>Published:</strong> 2020-12-03T11:18:46+00:00 |
                        
                        <strong>Highest Score:</strong> 0.685 Distributed training
                        
                    </div>
                </div>
                
                <div class="paper-body">
                    <div class="paper-abstract">
                        <strong>Abstract:</strong> Deep learning models are yielding increasingly better performances thanks to
multiple factors. To be successful, model may have large number of parameters
or complex architectures and be trained on large dataset. This leads to large
requirements on computing resource and turn around time, even more so when
hyper-parameter optimization is done (e.g search over model architectures).
While this is a challenge that goes beyond particle physics, we review the
various ways to do the necessary computations in parallel, and put it in the
context of high energy physics.
                    </div>
                    
                    
                    <div class="paper-categories">
                        <strong>Categories:</strong>
                        
                        <span class="category-tag">cs.LG</span>
                        
                    </div>
                    
                    
                    
                    <div class="similarity-summary">
                        <div class="llm-scoring-header">
                            <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600; display: inline;">LLM Scoring:</h6>
                            <button class="btn btn-sm btn-outline-light llm-scoring-toggle" 
                                    onclick="toggleLLMScoringJustifications('llm-scoring-4')">
                                Show Justification ▼
                            </button>
                        </div>
                        
                        <div class="llm-scoring-columns">
                            <!-- Recommendation Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Recommendation:</div>
                                
                                <div class="llm-scoring-value should-read">Should Read</div>
                                
                            </div>
                            
                            <!-- Novelty Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Novelty:</div>
                                
                                <div class="llm-scoring-value moderate">Moderate</div>
                                
                            </div>
                            
                            <!-- Potential Impact Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Potential Impact:</div>
                                
                                <div class="llm-scoring-value moderate">Moderate</div>
                                
                            </div>
                        </div>
                        
                        <!-- Unified Justifications Section -->
                        <div class="llm-scoring-justifications" id="llm-scoring-4" style="display: none;">
                            
                            <div class="llm-justification-item">
                                <strong>Recommendation:</strong> This paper is valuable for those specifically working on distributed training in high energy physics or similar domains, as it provides a useful overview and practical insights, but it is not essential for the broader machine learning community.
                            </div>
                            
                            
                            <div class="llm-justification-item">
                                <strong>Novelty:</strong> The paper presents a notable improvement by combining and adapting existing distributed training techniques to the specific context of high energy physics, making them more accessible for that field, though it does not introduce entirely new problems or architectures.
                            </div>
                            
                            
                            <div class="llm-justification-item">
                                <strong>Potential Impact:</strong> The work is likely to be cited and built upon by researchers in high energy physics and related subfields dealing with deep learning, as it offers practical guidance for accelerating training processes.
                            </div>
                            
                        </div>
                    </div>
                    
                    
                    <div class="paper-metrics-row">
                        <div class="similarity-scores">
                            
                                <div class="similarity-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Similarity Scores:</h6>
                                    <div class="similarity-scores-content">
                                        
                                        <span class="similarity-label" data-topic="RLHF">RLHF:</span>
                                        <div class="similarity-right-column" data-topic="RLHF">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 37.1%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.371">0.371</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Weak_supervision">Weak supervision:</span>
                                        <div class="similarity-right-column" data-topic="Weak_supervision">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 38.1%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.381">0.381</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Diffusion_reasoning">Diffusion reasoning:</span>
                                        <div class="similarity-right-column" data-topic="Diffusion_reasoning">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 36.4%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.364">0.364</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Distributed_training">Distributed training:</span>
                                        <div class="similarity-right-column" data-topic="Distributed_training">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 68.5%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.685">0.685</span>
                                        </div>
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="llm-validation">
                            
                                <div class="llm-validation-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">LLM Validation:</h6>
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="RLHF">
                                                <span class="llm-topic-label">RLHF:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Weak_supervision">
                                                <span class="llm-topic-label">Weak supervision:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Diffusion_reasoning">
                                                <span class="llm-topic-label">Diffusion reasoning:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Distributed_training">
                                                <span class="llm-topic-label">Distributed training:</span>
                                                
                                                    
                                                        <span class="llm-status llm-highly-relevant">Highly Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                    
                                    <div class="llm-buttons-row">
                                        <button class="btn btn-sm btn-outline-light llm-toggle" 
                                                onclick="toggleLLMDetails('llm-details-4')">
                                            Show Justifications ▼
                                        </button>
                                    </div>
                                    
                                    <div class="llm-details" id="llm-details-4">
                                        <h6 style="font-size: 0.9rem; margin-bottom: 0.5rem;">LLM Justifications:</h6>
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>RLHF:</strong> below_threshold
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Weak supervision:</strong> below_threshold
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Diffusion reasoning:</strong> below_threshold
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Distributed training:</strong> The paper's main contribution is a comprehensive review and guide to distributed training techniques for neural networks, including parameter distribution, data distribution, and model parallelism. These directly align with the topic's focus on parallel computing and multi-node machine learning, as they involve partitioning data, model architecture, and computations across multiple processors or nodes to accelerate training, particularly in contexts like high energy physics.
                                            </div>
                                            
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="h-index-scores">
                            
                                <div class="h-index-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Author H-Index:</h6>
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Data found:</span>
                                        <span class="h-index-value">2/2 authors</span>
                                    </div>
                                    <div class="h-index-metric">
                                        <span class="h-index-label">H-index available:</span>
                                        <span class="h-index-value">2/2 found</span>
                                    </div>
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Highest:</span>
                                        <span class="h-index-value">114</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Average:</span>
                                        <span class="h-index-value">66.0</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Notable (H>5):</span>
                                        <span class="h-index-value">2</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Source:</span>
                                        <span class="h-index-value">Full Id</span>
                                    </div>
                                    
                                    
                                    
                                    <div class="h-index-expand">
                                        <button class="btn btn-sm btn-outline-light h-index-toggle" 
                                                onclick="toggleHIndexDetails('h-details-4')">
                                            Show Individual H-indices ▼
                                        </button>
                                        <div class="h-index-details" id="h-details-4">
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">J. Vlimant</span>
                                                
                                                <span class="author-h-value">114</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Junqi Yin</span>
                                                
                                                <span class="author-h-value">18</span>
                                            </div>
                                            
                                        </div>
                                    </div>
                                    
                                </div>
                            
                        </div>
                    </div>
                </div>
            </div>
            
            <div class="paper-card" data-paper-index="5">
                <div class="paper-header">
                    <div class="paper-number">#6</div>
                    <h5 class="paper-title">
                        <a href="http://arxiv.org/abs/2504.12216" class="paper-link" target="_blank">
                            d1: Scaling Reasoning in Diffusion Large Language Models via
  Reinforcement Learning
                        </a>
                    </h5>
                    <div class="paper-meta">
                        <strong>arXiv ID:</strong> 2504.12216 |
                        <strong>Published:</strong> 2025-04-16T16:08:45+00:00 |
                        
                        <strong>Highest Score:</strong> 0.677 Diffusion reasoning
                        
                    </div>
                </div>
                
                <div class="paper-body">
                    <div class="paper-abstract">
                        <strong>Abstract:</strong> Recent large language models (LLMs) have demonstrated strong reasoning
capabilities that benefits from online reinforcement learning (RL). These
capabilities have primarily been demonstrated within the left-to-right
autoregressive (AR) generation paradigm. In contrast, non-autoregressive
paradigms based on diffusion generate text in a coarse-to-fine manner. Although
recent diffusion-based large language models (dLLMs) have achieved competitive
language modeling performance compared to their AR counterparts, it remains
unclear if dLLMs can also leverage recent advances in LLM reasoning. To this
end, we propose d1, a framework to adapt pre-trained masked dLLMs into
reasoning models via a combination of supervised finetuning (SFT) and RL.
Specifically, we develop and extend techniques to improve reasoning in
pretrained dLLMs: (a) we utilize a masked SFT technique to distill knowledge
and instill self-improvement behavior directly from existing datasets, and (b)
we introduce a novel critic-free, policy-gradient based RL algorithm called
diffu-GRPO, the first integration of policy gradient methods to masked dLLMs.
Through empirical studies, we investigate the performance of different
post-training recipes on multiple mathematical and planning benchmarks. We find
that d1 yields the best performance and significantly improves performance of a
state-of-the-art dLLM. Our code is released at
https://dllm-reasoning.github.io/.
                    </div>
                    
                    
                    <div class="paper-categories">
                        <strong>Categories:</strong>
                        
                        <span class="category-tag">cs.CL</span>
                        
                        <span class="category-tag">cs.LG</span>
                        
                    </div>
                    
                    
                    
                    <div class="similarity-summary">
                        <div class="llm-scoring-header">
                            <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600; display: inline;">LLM Scoring:</h6>
                            <button class="btn btn-sm btn-outline-light llm-scoring-toggle" 
                                    onclick="toggleLLMScoringJustifications('llm-scoring-5')">
                                Show Justification ▼
                            </button>
                        </div>
                        
                        <div class="llm-scoring-columns">
                            <!-- Recommendation Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Recommendation:</div>
                                
                                <div class="llm-scoring-value should-read">Should Read</div>
                                
                            </div>
                            
                            <!-- Novelty Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Novelty:</div>
                                
                                <div class="llm-scoring-value high">High</div>
                                
                            </div>
                            
                            <!-- Potential Impact Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Potential Impact:</div>
                                
                                <div class="llm-scoring-value moderate">Moderate</div>
                                
                            </div>
                        </div>
                        
                        <!-- Unified Justifications Section -->
                        <div class="llm-scoring-justifications" id="llm-scoring-5" style="display: none;">
                            
                            <div class="llm-justification-item">
                                <strong>Recommendation:</strong> This paper offers valuable insights and methods for researchers working on non-autoregressive LLMs and reasoning enhancements, making it worthwhile for those in the specific subfield, though not essential for the broader AI community.
                            </div>
                            
                            
                            <div class="llm-justification-item">
                                <strong>Novelty:</strong> The paper introduces a novel RL algorithm, diffu-GRPO, specifically adapted for masked dLLMs, which addresses a previously unexplored application of policy gradient methods to non-autoregressive models, representing a significant advancement in the field.
                            </div>
                            
                            
                            <div class="llm-justification-item">
                                <strong>Potential Impact:</strong> The work is likely to be cited and built upon in the subfield of diffusion-based LLMs and RL techniques, as it demonstrates practical improvements in reasoning tasks, though its influence may be limited to specific areas rather than widespread commercial applications.
                            </div>
                            
                        </div>
                    </div>
                    
                    
                    <div class="paper-metrics-row">
                        <div class="similarity-scores">
                            
                                <div class="similarity-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Similarity Scores:</h6>
                                    <div class="similarity-scores-content">
                                        
                                        <span class="similarity-label" data-topic="RLHF">RLHF:</span>
                                        <div class="similarity-right-column" data-topic="RLHF">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 46.1%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.461">0.461</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Weak_supervision">Weak supervision:</span>
                                        <div class="similarity-right-column" data-topic="Weak_supervision">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 37.8%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.378">0.378</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Diffusion_reasoning">Diffusion reasoning:</span>
                                        <div class="similarity-right-column" data-topic="Diffusion_reasoning">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 67.7%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.677">0.677</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Distributed_training">Distributed training:</span>
                                        <div class="similarity-right-column" data-topic="Distributed_training">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 41.7%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.417">0.417</span>
                                        </div>
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="llm-validation">
                            
                                <div class="llm-validation-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">LLM Validation:</h6>
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="RLHF">
                                                <span class="llm-topic-label">RLHF:</span>
                                                
                                                    
                                                        <span class="llm-status llm-tangentially-relevant">Tangentially Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Weak_supervision">
                                                <span class="llm-topic-label">Weak supervision:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Diffusion_reasoning">
                                                <span class="llm-topic-label">Diffusion reasoning:</span>
                                                
                                                    
                                                        <span class="llm-status llm-highly-relevant">Highly Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Distributed_training">
                                                <span class="llm-topic-label">Distributed training:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant">Not Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                    
                                    <div class="llm-buttons-row">
                                        <button class="btn btn-sm btn-outline-light llm-toggle" 
                                                onclick="toggleLLMDetails('llm-details-5')">
                                            Show Justifications ▼
                                        </button>
                                    </div>
                                    
                                    <div class="llm-details" id="llm-details-5">
                                        <h6 style="font-size: 0.9rem; margin-bottom: 0.5rem;">LLM Justifications:</h6>
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>RLHF:</strong> The paper uses reinforcement learning (RL) via diffu-GRPO to fine-tune dLLMs for reasoning tasks, involving reward signals for optimization. However, it does not specify the use of human feedback, a separate reward model trained on human-ranked data, or alignment with human preferences, focusing instead on general RL from benchmarks and datasets. Thus, it relates to RL but not the core elements of RLHF.
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Weak supervision:</strong> below_threshold
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Diffusion reasoning:</strong> The paper's main contribution is d1, a framework that adapts diffusion-based models (dLLMs) for reasoning tasks through iterative denoising and refinement processes, treating reasoning paths holistically across multiple steps for tasks like math and planning. This directly aligns with diffusion-based reasoning, as it enhances multi-step logical refinement in non-autoregressive models.
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Distributed training:</strong> The paper focuses on post-training techniques like SFT and RL for dLLMs, with no discussion of distributed training, parallel computing, multi-node setups, or strategies for partitioning data/computation across processors. Its contributions are centered on model adaptation for reasoning, not training acceleration methods.
                                            </div>
                                            
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="h-index-scores">
                            
                                <div class="h-index-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Author H-Index:</h6>
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Data found:</span>
                                        <span class="h-index-value">4/4 authors</span>
                                    </div>
                                    <div class="h-index-metric">
                                        <span class="h-index-label">H-index available:</span>
                                        <span class="h-index-value">4/4 found</span>
                                    </div>
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Highest:</span>
                                        <span class="h-index-value">10</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Average:</span>
                                        <span class="h-index-value">5.0</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Notable (H>5):</span>
                                        <span class="h-index-value">2</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Source:</span>
                                        <span class="h-index-value">Full Id</span>
                                    </div>
                                    
                                    
                                    
                                    <div class="h-index-expand">
                                        <button class="btn btn-sm btn-outline-light h-index-toggle" 
                                                onclick="toggleHIndexDetails('h-details-5')">
                                            Show Individual H-indices ▼
                                        </button>
                                        <div class="h-index-details" id="h-details-5">
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Siyan Zhao</span>
                                                
                                                <span class="author-h-value">6</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Devaansh Gupta</span>
                                                
                                                <span class="author-h-value">1</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Qinqing Zheng</span>
                                                
                                                <span class="author-h-value">10</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Aditya Grover</span>
                                                
                                                <span class="author-h-value">3</span>
                                            </div>
                                            
                                        </div>
                                    </div>
                                    
                                </div>
                            
                        </div>
                    </div>
                </div>
            </div>
            
            <div class="paper-card" data-paper-index="6">
                <div class="paper-header">
                    <div class="paper-number">#7</div>
                    <h5 class="paper-title">
                        <a href="http://arxiv.org/abs/2503.07025" class="paper-link" target="_blank">
                            Weak Supervision for Improved Precision in Search Systems
                        </a>
                    </h5>
                    <div class="paper-meta">
                        <strong>arXiv ID:</strong> 2503.07025 |
                        <strong>Published:</strong> 2025-03-10T08:06:30+00:00 |
                        
                        <strong>Highest Score:</strong> 0.674 Weak supervision
                        
                    </div>
                </div>
                
                <div class="paper-body">
                    <div class="paper-abstract">
                        <strong>Abstract:</strong> Labeled datasets are essential for modern search engines, which increasingly
rely on supervised learning methods like Learning to Rank and massive amounts
of data to power deep learning models. However, creating these datasets is both
time-consuming and costly, leading to the common use of user click and activity
logs as proxies for relevance. In this paper, we present a weak supervision
approach to infer the quality of query-document pairs and apply it within a
Learning to Rank framework to enhance the precision of a large-scale search
system.
                    </div>
                    
                    
                    <div class="paper-categories">
                        <strong>Categories:</strong>
                        
                        <span class="category-tag">cs.IR</span>
                        
                        <span class="category-tag">cs.AI</span>
                        
                        <span class="category-tag">cs.LG</span>
                        
                    </div>
                    
                    
                    
                    <div class="similarity-summary">
                        <div class="llm-scoring-header">
                            <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600; display: inline;">LLM Scoring:</h6>
                            <button class="btn btn-sm btn-outline-light llm-scoring-toggle" 
                                    onclick="toggleLLMScoringJustifications('llm-scoring-6')">
                                Show Justification ▼
                            </button>
                        </div>
                        
                        <div class="llm-scoring-columns">
                            <!-- Recommendation Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Recommendation:</div>
                                
                                <div class="llm-scoring-value should-read">Should Read</div>
                                
                            </div>
                            
                            <!-- Novelty Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Novelty:</div>
                                
                                <div class="llm-scoring-value moderate">Moderate</div>
                                
                            </div>
                            
                            <!-- Potential Impact Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Potential Impact:</div>
                                
                                <div class="llm-scoring-value moderate">Moderate</div>
                                
                            </div>
                        </div>
                        
                        <!-- Unified Justifications Section -->
                        <div class="llm-scoring-justifications" id="llm-scoring-6" style="display: none;">
                            
                            <div class="llm-justification-item">
                                <strong>Recommendation:</strong> This paper is valuable for researchers and practitioners working on search systems or weak supervision, as it offers actionable insights and a real-world deployment example that could inspire similar applications, making it worth reading for those in the specific area.
                            </div>
                            
                            
                            <div class="llm-justification-item">
                                <strong>Novelty:</strong> The paper presents a notable improvement by combining existing weak supervision techniques from Snorkel with a seed set of ground truth labels to refine heuristics, offering a new way to enhance label accuracy in industrial search systems without introducing a entirely novel paradigm.
                            </div>
                            
                            
                            <div class="llm-justification-item">
                                <strong>Potential Impact:</strong> The work is likely to be cited and built upon in subfields like information retrieval and machine learning, as it provides a practical, scalable solution for improving search precision in industrial applications, though its influence may be limited to specific domains rather than broadly transformative.
                            </div>
                            
                        </div>
                    </div>
                    
                    
                    <div class="paper-metrics-row">
                        <div class="similarity-scores">
                            
                                <div class="similarity-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Similarity Scores:</h6>
                                    <div class="similarity-scores-content">
                                        
                                        <span class="similarity-label" data-topic="RLHF">RLHF:</span>
                                        <div class="similarity-right-column" data-topic="RLHF">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 44.4%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.444">0.444</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Weak_supervision">Weak supervision:</span>
                                        <div class="similarity-right-column" data-topic="Weak_supervision">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 67.4%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.674">0.674</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Diffusion_reasoning">Diffusion reasoning:</span>
                                        <div class="similarity-right-column" data-topic="Diffusion_reasoning">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 35.9%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.359">0.359</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Distributed_training">Distributed training:</span>
                                        <div class="similarity-right-column" data-topic="Distributed_training">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 41.2%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.412">0.412</span>
                                        </div>
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="llm-validation">
                            
                                <div class="llm-validation-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">LLM Validation:</h6>
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="RLHF">
                                                <span class="llm-topic-label">RLHF:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant">Not Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Weak_supervision">
                                                <span class="llm-topic-label">Weak supervision:</span>
                                                
                                                    
                                                        <span class="llm-status llm-highly-relevant">Highly Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Diffusion_reasoning">
                                                <span class="llm-topic-label">Diffusion reasoning:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Distributed_training">
                                                <span class="llm-topic-label">Distributed training:</span>
                                                
                                                    
                                                        <span class="llm-status llm-moderately-relevant">Moderately Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                    
                                    <div class="llm-buttons-row">
                                        <button class="btn btn-sm btn-outline-light llm-toggle" 
                                                onclick="toggleLLMDetails('llm-details-6')">
                                            Show Justifications ▼
                                        </button>
                                    </div>
                                    
                                    <div class="llm-details" id="llm-details-6">
                                        <h6 style="font-size: 0.9rem; margin-bottom: 0.5rem;">LLM Justifications:</h6>
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>RLHF:</strong> The paper focuses on weak supervision for generating labels in a search system, using heuristics and a small set of ground truth labels, but does not involve reinforcement learning, reward models, or fine-tuning based on human preferences. There is no mention of RLHF elements like policy optimization or human-ranked data for rewards.
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Weak supervision:</strong> The paper's main contribution is a weak supervision approach that programmatically generates labels using heuristics and a seed set of ground truth data, aligning directly with the definition of training models from noisy or imprecise sources. It builds on methods like Snorkel to improve label quality for Learning to Rank in search systems.
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Diffusion reasoning:</strong> below_threshold
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Distributed training:</strong> The paper describes a distributed and scalable weak supervision solution, referencing techniques for aggregation and deployment in production, which touches on parallel computing aspects. However, it does not focus primarily on distributed training algorithms or multi-node optimizations for model training, making it secondary to the weak supervision core.
                                            </div>
                                            
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="h-index-scores">
                            
                                <div class="h-index-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Author H-Index:</h6>
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Data found:</span>
                                        <span class="h-index-value">1/1 authors</span>
                                    </div>
                                    <div class="h-index-metric">
                                        <span class="h-index-label">H-index available:</span>
                                        <span class="h-index-value">1/1 found</span>
                                    </div>
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Highest:</span>
                                        <span class="h-index-value">1</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Average:</span>
                                        <span class="h-index-value">1.0</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Notable (H>5):</span>
                                        <span class="h-index-value">0</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Source:</span>
                                        <span class="h-index-value">Full Id</span>
                                    </div>
                                    
                                    
                                    
                                    <div class="h-index-expand">
                                        <button class="btn btn-sm btn-outline-light h-index-toggle" 
                                                onclick="toggleHIndexDetails('h-details-6')">
                                            Show Individual H-indices ▼
                                        </button>
                                        <div class="h-index-details" id="h-details-6">
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Sriram Vasudevan</span>
                                                
                                                <span class="author-h-value">1</span>
                                            </div>
                                            
                                        </div>
                                    </div>
                                    
                                </div>
                            
                        </div>
                    </div>
                </div>
            </div>
            
            <div class="paper-card" data-paper-index="7">
                <div class="paper-header">
                    <div class="paper-number">#8</div>
                    <h5 class="paper-title">
                        <a href="http://arxiv.org/abs/2501.07727" class="paper-link" target="_blank">
                            Stronger Than You Think: Benchmarking Weak Supervision on Realistic
  Tasks
                        </a>
                    </h5>
                    <div class="paper-meta">
                        <strong>arXiv ID:</strong> 2501.07727 |
                        <strong>Published:</strong> 2025-01-13T22:29:31+00:00 |
                        
                        <strong>Highest Score:</strong> 0.668 Weak supervision
                        
                    </div>
                </div>
                
                <div class="paper-body">
                    <div class="paper-abstract">
                        <strong>Abstract:</strong> Weak supervision (WS) is a popular approach for label-efficient learning,
leveraging diverse sources of noisy but inexpensive weak labels to
automatically annotate training data. Despite its wide usage, WS and its
practical value are challenging to benchmark due to the many knobs in its
setup, including: data sources, labeling functions (LFs), aggregation
techniques (called label models), and end model pipelines. Existing evaluation
suites tend to be limited, focusing on particular components or specialized use
cases. Moreover, they often involve simplistic benchmark tasks or de-facto LF
sets that are suboptimally written, producing insights that may not generalize
to real-world settings. We address these limitations by introducing a new
benchmark, BOXWRENCH, designed to more accurately reflect real-world usages of
WS. This benchmark features tasks with (1) higher class cardinality and
imbalance, (2) notable domain expertise requirements, and (3) opportunities to
re-use LFs across parallel multilingual corpora. For all tasks, LFs are written
using a careful procedure aimed at mimicking real-world settings. In contrast
to existing WS benchmarks, we show that supervised learning requires
substantial amounts (1000+) of labeled examples to match WS in many settings.
                    </div>
                    
                    
                    <div class="paper-categories">
                        <strong>Categories:</strong>
                        
                        <span class="category-tag">cs.LG</span>
                        
                    </div>
                    
                    
                    
                    <div class="similarity-summary">
                        <div class="llm-scoring-header">
                            <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600; display: inline;">LLM Scoring:</h6>
                            <button class="btn btn-sm btn-outline-light llm-scoring-toggle" 
                                    onclick="toggleLLMScoringJustifications('llm-scoring-7')">
                                Show Justification ▼
                            </button>
                        </div>
                        
                        <div class="llm-scoring-columns">
                            <!-- Recommendation Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Recommendation:</div>
                                
                                <div class="llm-scoring-value should-read">Should Read</div>
                                
                            </div>
                            
                            <!-- Novelty Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Novelty:</div>
                                
                                <div class="llm-scoring-value high">High</div>
                                
                            </div>
                            
                            <!-- Potential Impact Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Potential Impact:</div>
                                
                                <div class="llm-scoring-value high">High</div>
                                
                            </div>
                        </div>
                        
                        <!-- Unified Justifications Section -->
                        <div class="llm-scoring-justifications" id="llm-scoring-7" style="display: none;">
                            
                            <div class="llm-justification-item">
                                <strong>Recommendation:</strong> This paper is valuable for researchers and practitioners in weak supervision and machine learning benchmarking, offering practical insights and a new benchmark that could enhance their work. While not essential for the entire field, it is highly relevant for those specifically addressing label-efficient learning.
                            </div>
                            
                            
                            <div class="llm-justification-item">
                                <strong>Novelty:</strong> The paper introduces a truly new benchmark with realistic tasks that significantly advances WS evaluation by addressing gaps in existing benchmarks, such as incorporating high-cardinality and imbalanced datasets. This represents a substantial innovation in assessing WS's real-world applicability, moving beyond simplistic prior setups.
                            </div>
                            
                            
                            <div class="llm-justification-item">
                                <strong>Potential Impact:</strong> The work could broadly influence future WS research and applications by providing a more accurate benchmarking framework, potentially leading to improved practices in label-efficient learning across various domains. Its findings challenge previous underestimations of WS, making it likely to be cited and built upon in the machine learning community.
                            </div>
                            
                        </div>
                    </div>
                    
                    
                    <div class="paper-metrics-row">
                        <div class="similarity-scores">
                            
                                <div class="similarity-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Similarity Scores:</h6>
                                    <div class="similarity-scores-content">
                                        
                                        <span class="similarity-label" data-topic="RLHF">RLHF:</span>
                                        <div class="similarity-right-column" data-topic="RLHF">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 41.1%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.411">0.411</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Weak_supervision">Weak supervision:</span>
                                        <div class="similarity-right-column" data-topic="Weak_supervision">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 66.8%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.668">0.668</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Diffusion_reasoning">Diffusion reasoning:</span>
                                        <div class="similarity-right-column" data-topic="Diffusion_reasoning">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 34.8%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.348">0.348</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Distributed_training">Distributed training:</span>
                                        <div class="similarity-right-column" data-topic="Distributed_training">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 40.5%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.405">0.405</span>
                                        </div>
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="llm-validation">
                            
                                <div class="llm-validation-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">LLM Validation:</h6>
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="RLHF">
                                                <span class="llm-topic-label">RLHF:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant">Not Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Weak_supervision">
                                                <span class="llm-topic-label">Weak supervision:</span>
                                                
                                                    
                                                        <span class="llm-status llm-highly-relevant">Highly Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Diffusion_reasoning">
                                                <span class="llm-topic-label">Diffusion reasoning:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Distributed_training">
                                                <span class="llm-topic-label">Distributed training:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant">Not Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                    
                                    <div class="llm-buttons-row">
                                        <button class="btn btn-sm btn-outline-light llm-toggle" 
                                                onclick="toggleLLMDetails('llm-details-7')">
                                            Show Justifications ▼
                                        </button>
                                    </div>
                                    
                                    <div class="llm-details" id="llm-details-7">
                                        <h6 style="font-size: 0.9rem; margin-bottom: 0.5rem;">LLM Justifications:</h6>
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>RLHF:</strong> The paper focuses on weak supervision for generating labels from noisy sources, with no mention of reinforcement learning, human feedback, reward models, or aligning AI models with human preferences.
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Weak supervision:</strong> The paper's main contribution is to weak supervision, introducing a new benchmark (BOXWRENCH) to evaluate its effectiveness in realistic tasks, discussing labeling functions, label models, and demonstrating its practical value for label-efficient learning.
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Diffusion reasoning:</strong> below_threshold
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Distributed training:</strong> The paper does not discuss distributed training, parallel computing, or multi-node systems; it centers on weak supervision techniques for label generation and benchmarking, without addressing data partitioning or computation acceleration across nodes.
                                            </div>
                                            
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="h-index-scores">
                            
                                <div class="h-index-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Author H-Index:</h6>
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Data found:</span>
                                        <span class="h-index-value">7/7 authors</span>
                                    </div>
                                    <div class="h-index-metric">
                                        <span class="h-index-label">H-index available:</span>
                                        <span class="h-index-value">7/7 found</span>
                                    </div>
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Highest:</span>
                                        <span class="h-index-value">17</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Average:</span>
                                        <span class="h-index-value">3.1</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Notable (H>5):</span>
                                        <span class="h-index-value">1</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Source:</span>
                                        <span class="h-index-value">Full Id</span>
                                    </div>
                                    
                                    
                                    
                                    <div class="h-index-expand">
                                        <button class="btn btn-sm btn-outline-light h-index-toggle" 
                                                onclick="toggleHIndexDetails('h-details-7')">
                                            Show Individual H-indices ▼
                                        </button>
                                        <div class="h-index-details" id="h-details-7">
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Tianyi Zhang</span>
                                                
                                                <span class="author-h-value">0</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Linrong Cai</span>
                                                
                                                <span class="author-h-value">0</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Jeffrey Li</span>
                                                
                                                <span class="author-h-value">0</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Nicholas Roberts</span>
                                                
                                                <span class="author-h-value">2</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Neel Guha</span>
                                                
                                                <span class="author-h-value">17</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Jinoh Lee</span>
                                                
                                                <span class="author-h-value">0</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Frederic Sala</span>
                                                
                                                <span class="author-h-value">3</span>
                                            </div>
                                            
                                        </div>
                                    </div>
                                    
                                </div>
                            
                        </div>
                    </div>
                </div>
            </div>
            
            <div class="paper-card" data-paper-index="8">
                <div class="paper-header">
                    <div class="paper-number">#9</div>
                    <h5 class="paper-title">
                        <a href="http://arxiv.org/abs/2503.09025" class="paper-link" target="_blank">
                            Aligning to What? Limits to RLHF Based Alignment
                        </a>
                    </h5>
                    <div class="paper-meta">
                        <strong>arXiv ID:</strong> 2503.09025 |
                        <strong>Published:</strong> 2025-03-12T03:24:44+00:00 |
                        
                        <strong>Highest Score:</strong> 0.626 RLHF
                        
                    </div>
                </div>
                
                <div class="paper-body">
                    <div class="paper-abstract">
                        <strong>Abstract:</strong> Reinforcement Learning from Human Feedback (RLHF) is increasingly used to
align large language models (LLMs) with human preferences. However, the
effectiveness of RLHF in addressing underlying biases remains unclear. This
study investigates the relationship between RLHF and both covert and overt
biases in LLMs, particularly focusing on biases against African Americans. We
applied various RLHF techniques (DPO, ORPO, and RLOO) to Llama 3 8B and
evaluated the covert and overt biases of the resulting models using
matched-guise probing and explicit bias testing. We performed additional tests
with DPO on different base models and datasets; among several implications, we
found that SFT before RLHF calcifies model biases. Additionally, we extend the
tools for measuring biases to multi-modal models. Through our experiments we
collect evidence that indicates that current alignment techniques are
inadequate for nebulous tasks such as mitigating covert biases, highlighting
the need for capable datasets, data curating techniques, or alignment tools.
                    </div>
                    
                    
                    <div class="paper-categories">
                        <strong>Categories:</strong>
                        
                        <span class="category-tag">cs.CL</span>
                        
                    </div>
                    
                    
                    
                    <div class="similarity-summary">
                        <div class="llm-scoring-header">
                            <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600; display: inline;">LLM Scoring:</h6>
                            <button class="btn btn-sm btn-outline-light llm-scoring-toggle" 
                                    onclick="toggleLLMScoringJustifications('llm-scoring-8')">
                                Show Justification ▼
                            </button>
                        </div>
                        
                        <div class="llm-scoring-columns">
                            <!-- Recommendation Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Recommendation:</div>
                                
                                <div class="llm-scoring-value should-read">Should Read</div>
                                
                            </div>
                            
                            <!-- Novelty Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Novelty:</div>
                                
                                <div class="llm-scoring-value moderate">Moderate</div>
                                
                            </div>
                            
                            <!-- Potential Impact Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Potential Impact:</div>
                                
                                <div class="llm-scoring-value moderate">Moderate</div>
                                
                            </div>
                        </div>
                        
                        <!-- Unified Justifications Section -->
                        <div class="llm-scoring-justifications" id="llm-scoring-8" style="display: none;">
                            
                            <div class="llm-justification-item">
                                <strong>Recommendation:</strong> This paper is valuable for researchers and practitioners focused on AI ethics, bias in LLMs, and alignment techniques, as it provides insightful empirical evidence on RLHF's shortcomings. However, it is not essential for those outside this niche, making it skippable for a general audience.
                            </div>
                            
                            
                            <div class="llm-justification-item">
                                <strong>Novelty:</strong> The paper presents a notable improvement by empirically examining the impact of RLHF on model biases, which has not been extensively studied, through clever combinations of existing techniques and new dataset curation. However, it builds on prior work in bias evaluation rather than introducing a entirely new problem or architecture.
                            </div>
                            
                            
                            <div class="llm-justification-item">
                                <strong>Potential Impact:</strong> The work is likely to influence research in AI alignment and bias mitigation within the subfield of LLMs, as it reveals critical limitations of RLHF that could guide future improvements. Nonetheless, its applicability is somewhat confined to specific ethical concerns in language models, limiting broader commercial or widespread adoption.
                            </div>
                            
                        </div>
                    </div>
                    
                    
                    <div class="paper-metrics-row">
                        <div class="similarity-scores">
                            
                                <div class="similarity-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Similarity Scores:</h6>
                                    <div class="similarity-scores-content">
                                        
                                        <span class="similarity-label" data-topic="RLHF">RLHF:</span>
                                        <div class="similarity-right-column" data-topic="RLHF">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 62.6%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.626">0.626</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Weak_supervision">Weak supervision:</span>
                                        <div class="similarity-right-column" data-topic="Weak_supervision">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 39.2%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.392">0.392</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Diffusion_reasoning">Diffusion reasoning:</span>
                                        <div class="similarity-right-column" data-topic="Diffusion_reasoning">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 37.4%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.374">0.374</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Distributed_training">Distributed training:</span>
                                        <div class="similarity-right-column" data-topic="Distributed_training">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 36.6%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.366">0.366</span>
                                        </div>
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="llm-validation">
                            
                                <div class="llm-validation-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">LLM Validation:</h6>
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="RLHF">
                                                <span class="llm-topic-label">RLHF:</span>
                                                
                                                    
                                                        <span class="llm-status llm-highly-relevant">Highly Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Weak_supervision">
                                                <span class="llm-topic-label">Weak supervision:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Diffusion_reasoning">
                                                <span class="llm-topic-label">Diffusion reasoning:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Distributed_training">
                                                <span class="llm-topic-label">Distributed training:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                    
                                    <div class="llm-buttons-row">
                                        <button class="btn btn-sm btn-outline-light llm-toggle" 
                                                onclick="toggleLLMDetails('llm-details-8')">
                                            Show Justifications ▼
                                        </button>
                                    </div>
                                    
                                    <div class="llm-details" id="llm-details-8">
                                        <h6 style="font-size: 0.9rem; margin-bottom: 0.5rem;">LLM Justifications:</h6>
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>RLHF:</strong> The paper's main contribution directly investigates the effectiveness of RLHF techniques (e.g., DPO, ORPO, and RLOO) in aligning LLMs with human preferences, specifically focusing on bias mitigation. It applies RLHF to models like Llama 3 8B, evaluates outcomes using human feedback-derived methods, and concludes that RLHF has limitations in addressing biases, aligning closely with the topic's definition of systems using human-ranked data for reinforcement learning-based fine-tuning.
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Weak supervision:</strong> below_threshold
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Diffusion reasoning:</strong> below_threshold
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Distributed training:</strong> below_threshold
                                            </div>
                                            
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="h-index-scores">
                            
                                <div class="h-index-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Author H-Index:</h6>
                                    <p class="text-muted">No H-index data available</p>
                                </div>
                            
                        </div>
                    </div>
                </div>
            </div>
            
            <div class="paper-card" data-paper-index="9">
                <div class="paper-header">
                    <div class="paper-number">#10</div>
                    <h5 class="paper-title">
                        <a href="http://arxiv.org/abs/2502.12366" class="paper-link" target="_blank">
                            ScriptoriumWS: A Code Generation Assistant for Weak Supervision
                        </a>
                    </h5>
                    <div class="paper-meta">
                        <strong>arXiv ID:</strong> 2502.12366 |
                        <strong>Published:</strong> 2025-02-17T23:07:14+00:00 |
                        
                        <strong>Highest Score:</strong> 0.621 Weak supervision
                        
                    </div>
                </div>
                
                <div class="paper-body">
                    <div class="paper-abstract">
                        <strong>Abstract:</strong> Weak supervision is a popular framework for overcoming the labeled data
bottleneck: the need to obtain labels for training data. In weak supervision,
multiple noisy-but-cheap sources are used to provide guesses of the label and
are aggregated to produce high-quality pseudolabels. These sources are often
expressed as small programs written by domain experts -- and so are expensive
to obtain. Instead, we argue for using code-generation models to act as coding
assistants for crafting weak supervision sources. We study prompting strategies
to maximize the quality of the generated sources, settling on a multi-tier
strategy that incorporates multiple types of information. We explore how to
best combine hand-written and generated sources. Using these insights, we
introduce ScriptoriumWS, a weak supervision system that, when compared to
hand-crafted sources, maintains accuracy and greatly improves coverage.
                    </div>
                    
                    
                    <div class="paper-categories">
                        <strong>Categories:</strong>
                        
                        <span class="category-tag">cs.LG</span>
                        
                    </div>
                    
                    
                    
                    <div class="similarity-summary">
                        <div class="llm-scoring-header">
                            <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600; display: inline;">LLM Scoring:</h6>
                            <button class="btn btn-sm btn-outline-light llm-scoring-toggle" 
                                    onclick="toggleLLMScoringJustifications('llm-scoring-9')">
                                Show Justification ▼
                            </button>
                        </div>
                        
                        <div class="llm-scoring-columns">
                            <!-- Recommendation Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Recommendation:</div>
                                
                                <div class="llm-scoring-value should-read">Should Read</div>
                                
                            </div>
                            
                            <!-- Novelty Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Novelty:</div>
                                
                                <div class="llm-scoring-value moderate">Moderate</div>
                                
                            </div>
                            
                            <!-- Potential Impact Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Potential Impact:</div>
                                
                                <div class="llm-scoring-value moderate">Moderate</div>
                                
                            </div>
                        </div>
                        
                        <!-- Unified Justifications Section -->
                        <div class="llm-scoring-justifications" id="llm-scoring-9" style="display: none;">
                            
                            <div class="llm-justification-item">
                                <strong>Recommendation:</strong> This paper is valuable for researchers and practitioners working on weak supervision, code generation, or data labeling techniques, as it provides actionable insights and a new system that could enhance their workflows. It is not essential for the broader machine learning community but offers specific benefits for those in related subfields.
                            </div>
                            
                            
                            <div class="llm-justification-item">
                                <strong>Novelty:</strong> The paper presents a notable improvement by cleverly combining code-generation models with programmatic weak supervision to automate labeling function creation, addressing the expense of manual coding without introducing an entirely new paradigm. While it builds on existing techniques like code generation and weak supervision, it innovates in their application to enhance efficiency and coverage.
                            </div>
                            
                            
                            <div class="llm-justification-item">
                                <strong>Potential Impact:</strong> The work is likely to be cited and built upon in the subfield of weak supervision and machine learning data labeling, as it offers practical methods to improve efficiency and scalability. However, its influence may be limited to specific applications rather than broadly transforming the field.
                            </div>
                            
                        </div>
                    </div>
                    
                    
                    <div class="paper-metrics-row">
                        <div class="similarity-scores">
                            
                                <div class="similarity-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Similarity Scores:</h6>
                                    <div class="similarity-scores-content">
                                        
                                        <span class="similarity-label" data-topic="RLHF">RLHF:</span>
                                        <div class="similarity-right-column" data-topic="RLHF">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 43.0%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.430">0.430</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Weak_supervision">Weak supervision:</span>
                                        <div class="similarity-right-column" data-topic="Weak_supervision">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 62.1%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.621">0.621</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Diffusion_reasoning">Diffusion reasoning:</span>
                                        <div class="similarity-right-column" data-topic="Diffusion_reasoning">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 42.4%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.424">0.424</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Distributed_training">Distributed training:</span>
                                        <div class="similarity-right-column" data-topic="Distributed_training">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 36.2%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.362">0.362</span>
                                        </div>
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="llm-validation">
                            
                                <div class="llm-validation-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">LLM Validation:</h6>
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="RLHF">
                                                <span class="llm-topic-label">RLHF:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant">Not Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Weak_supervision">
                                                <span class="llm-topic-label">Weak supervision:</span>
                                                
                                                    
                                                        <span class="llm-status llm-highly-relevant">Highly Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Diffusion_reasoning">
                                                <span class="llm-topic-label">Diffusion reasoning:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant">Not Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Distributed_training">
                                                <span class="llm-topic-label">Distributed training:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                    
                                    <div class="llm-buttons-row">
                                        <button class="btn btn-sm btn-outline-light llm-toggle" 
                                                onclick="toggleLLMDetails('llm-details-9')">
                                            Show Justifications ▼
                                        </button>
                                    </div>
                                    
                                    <div class="llm-details" id="llm-details-9">
                                        <h6 style="font-size: 0.9rem; margin-bottom: 0.5rem;">LLM Justifications:</h6>
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>RLHF:</strong> The paper focuses on code generation for weak supervision labeling functions and does not involve reinforcement learning, human feedback for training reward models, or aligning AI models with human preferences.
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Weak supervision:</strong> The paper's main contribution is developing ScriptoriumWS, a system that uses code-generation models to create labeling functions for weak supervision, directly addressing the generation of noisy labels from programmatic sources to improve training data efficiency.
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Diffusion reasoning:</strong> The paper does not involve diffusion models, iterative refinement processes, or multi-step logical reasoning; it instead centers on code generation for weak supervision tasks.
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Distributed training:</strong> below_threshold
                                            </div>
                                            
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="h-index-scores">
                            
                                <div class="h-index-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Author H-Index:</h6>
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Data found:</span>
                                        <span class="h-index-value">6/6 authors</span>
                                    </div>
                                    <div class="h-index-metric">
                                        <span class="h-index-label">H-index available:</span>
                                        <span class="h-index-value">6/6 found</span>
                                    </div>
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Highest:</span>
                                        <span class="h-index-value">8</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Average:</span>
                                        <span class="h-index-value">3.7</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Notable (H>5):</span>
                                        <span class="h-index-value">1</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Source:</span>
                                        <span class="h-index-value">Full Id</span>
                                    </div>
                                    
                                    
                                    
                                    <div class="h-index-expand">
                                        <button class="btn btn-sm btn-outline-light h-index-toggle" 
                                                onclick="toggleHIndexDetails('h-details-9')">
                                            Show Individual H-indices ▼
                                        </button>
                                        <div class="h-index-details" id="h-details-9">
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Tzu-Heng Huang</span>
                                                
                                                <span class="author-h-value">5</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Catherine Cao</span>
                                                
                                                <span class="author-h-value">2</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Spencer Schoenberg</span>
                                                
                                                <span class="author-h-value">2</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Harit Vishwakarma</span>
                                                
                                                <span class="author-h-value">8</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Nicholas Roberts</span>
                                                
                                                <span class="author-h-value">2</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Frederic Sala</span>
                                                
                                                <span class="author-h-value">3</span>
                                            </div>
                                            
                                        </div>
                                    </div>
                                    
                                </div>
                            
                        </div>
                    </div>
                </div>
            </div>
            
            <div class="paper-card" data-paper-index="10">
                <div class="paper-header">
                    <div class="paper-number">#11</div>
                    <h5 class="paper-title">
                        <a href="http://arxiv.org/abs/2501.05323" class="paper-link" target="_blank">
                            Distributed Learning and Inference Systems: A Networking Perspective
                        </a>
                    </h5>
                    <div class="paper-meta">
                        <strong>arXiv ID:</strong> 2501.05323 |
                        <strong>Published:</strong> 2025-01-09T15:48:29+00:00 |
                        
                        <strong>Highest Score:</strong> 0.594 Distributed training
                        
                    </div>
                </div>
                
                <div class="paper-body">
                    <div class="paper-abstract">
                        <strong>Abstract:</strong> Machine learning models have achieved, and in some cases surpassed,
human-level performance in various tasks, mainly through centralized training
of static models and the use of large models stored in centralized clouds for
inference. However, this centralized approach has several drawbacks, including
privacy concerns, high storage demands, a single point of failure, and
significant computing requirements. These challenges have driven interest in
developing alternative decentralized and distributed methods for AI training
and inference. Distribution introduces additional complexity, as it requires
managing multiple moving parts. To address these complexities and fill a gap in
the development of distributed AI systems, this work proposes a novel
framework, Data and Dynamics-Aware Inference and Training Networks (DA-ITN).
The different components of DA-ITN and their functions are explored, and the
associated challenges and research areas are highlighted.
                    </div>
                    
                    
                    <div class="paper-categories">
                        <strong>Categories:</strong>
                        
                        <span class="category-tag">cs.LG</span>
                        
                        <span class="category-tag">cs.NI</span>
                        
                    </div>
                    
                    
                    
                    <div class="similarity-summary">
                        <div class="llm-scoring-header">
                            <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600; display: inline;">LLM Scoring:</h6>
                            <button class="btn btn-sm btn-outline-light llm-scoring-toggle" 
                                    onclick="toggleLLMScoringJustifications('llm-scoring-10')">
                                Show Justification ▼
                            </button>
                        </div>
                        
                        <div class="llm-scoring-columns">
                            <!-- Recommendation Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Recommendation:</div>
                                
                                <div class="llm-scoring-value should-read">Should Read</div>
                                
                            </div>
                            
                            <!-- Novelty Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Novelty:</div>
                                
                                <div class="llm-scoring-value moderate">Moderate</div>
                                
                            </div>
                            
                            <!-- Potential Impact Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Potential Impact:</div>
                                
                                <div class="llm-scoring-value moderate">Moderate</div>
                                
                            </div>
                        </div>
                        
                        <!-- Unified Justifications Section -->
                        <div class="llm-scoring-justifications" id="llm-scoring-10" style="display: none;">
                            
                            <div class="llm-justification-item">
                                <strong>Recommendation:</strong> This paper is valuable for researchers specifically in distributed learning and networking due to its innovative framework and insights into decentralized AI challenges, but it is not essential for those outside this niche.
                            </div>
                            
                            
                            <div class="llm-justification-item">
                                <strong>Novelty:</strong> The paper presents a notable improvement by integrating existing decentralized AI techniques into a unified framework called DA-ITN, offering a clever combination to address gaps in distributed systems, though it does not introduce an entirely new problem or technique.
                            </div>
                            
                            
                            <div class="llm-justification-item">
                                <strong>Potential Impact:</strong> The work is likely to be cited and built upon in the subfield of distributed AI and networking, as DA-ITN provides a structured approach for future developments in areas like edge computing and federated learning.
                            </div>
                            
                        </div>
                    </div>
                    
                    
                    <div class="paper-metrics-row">
                        <div class="similarity-scores">
                            
                                <div class="similarity-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Similarity Scores:</h6>
                                    <div class="similarity-scores-content">
                                        
                                        <span class="similarity-label" data-topic="RLHF">RLHF:</span>
                                        <div class="similarity-right-column" data-topic="RLHF">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 41.5%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.415">0.415</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Weak_supervision">Weak supervision:</span>
                                        <div class="similarity-right-column" data-topic="Weak_supervision">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 41.8%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.418">0.418</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Diffusion_reasoning">Diffusion reasoning:</span>
                                        <div class="similarity-right-column" data-topic="Diffusion_reasoning">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 45.0%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.450">0.450</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Distributed_training">Distributed training:</span>
                                        <div class="similarity-right-column" data-topic="Distributed_training">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 59.4%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.594">0.594</span>
                                        </div>
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="llm-validation">
                            
                                <div class="llm-validation-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">LLM Validation:</h6>
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="RLHF">
                                                <span class="llm-topic-label">RLHF:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant">Not Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Weak_supervision">
                                                <span class="llm-topic-label">Weak supervision:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant">Not Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Diffusion_reasoning">
                                                <span class="llm-topic-label">Diffusion reasoning:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant">Not Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Distributed_training">
                                                <span class="llm-topic-label">Distributed training:</span>
                                                
                                                    
                                                        <span class="llm-status llm-highly-relevant">Highly Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                    
                                    <div class="llm-buttons-row">
                                        <button class="btn btn-sm btn-outline-light llm-toggle" 
                                                onclick="toggleLLMDetails('llm-details-10')">
                                            Show Justifications ▼
                                        </button>
                                    </div>
                                    
                                    <div class="llm-details" id="llm-details-10">
                                        <h6 style="font-size: 0.9rem; margin-bottom: 0.5rem;">LLM Justifications:</h6>
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>RLHF:</strong> The paper focuses on distributed and decentralized AI systems, proposing a framework for training and inference from a networking perspective, but it does not involve human feedback, reward models, or reinforcement learning techniques for aligning AI with human preferences.
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Weak supervision:</strong> The paper discusses distributed training and inference methods, such as federated learning, but it does not address programmatically generating labels from noisy sources or techniques for weak supervision in machine learning.
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Diffusion reasoning:</strong> The paper proposes a framework for distributed AI systems and mentions training and inference, but it does not involve diffusion models, iterative refinement for logical reasoning, or multi-step chain-of-thought processes.
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Distributed training:</strong> The paper's main contribution is a framework for distributed AI systems, including methods like federated learning and gossip learning, which directly align with distributed training, parallel computing, and multi-node machine learning for optimizing training across networked nodes.
                                            </div>
                                            
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="h-index-scores">
                            
                                <div class="h-index-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Author H-Index:</h6>
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Data found:</span>
                                        <span class="h-index-value">4/4 authors</span>
                                    </div>
                                    <div class="h-index-metric">
                                        <span class="h-index-label">H-index available:</span>
                                        <span class="h-index-value">4/4 found</span>
                                    </div>
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Highest:</span>
                                        <span class="h-index-value">7</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Average:</span>
                                        <span class="h-index-value">3.0</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Notable (H>5):</span>
                                        <span class="h-index-value">1</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Source:</span>
                                        <span class="h-index-value">Full Id</span>
                                    </div>
                                    
                                    
                                    
                                    <div class="h-index-expand">
                                        <button class="btn btn-sm btn-outline-light h-index-toggle" 
                                                onclick="toggleHIndexDetails('h-details-10')">
                                            Show Individual H-indices ▼
                                        </button>
                                        <div class="h-index-details" id="h-details-10">
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Hesham G. Moussa</span>
                                                
                                                <span class="author-h-value">7</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Arashmid Akhavain</span>
                                                
                                                <span class="author-h-value">3</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">S. M. Hosseini</span>
                                                
                                                <span class="author-h-value">1</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Bill McCormick</span>
                                                
                                                <span class="author-h-value">1</span>
                                            </div>
                                            
                                        </div>
                                    </div>
                                    
                                </div>
                            
                        </div>
                    </div>
                </div>
            </div>
            
            <div class="paper-card" data-paper-index="11">
                <div class="paper-header">
                    <div class="paper-number">#12</div>
                    <h5 class="paper-title">
                        <a href="http://arxiv.org/abs/2506.10911" class="paper-link" target="_blank">
                            NoLoCo: No-all-reduce Low Communication Training Method for Large Models
                        </a>
                    </h5>
                    <div class="paper-meta">
                        <strong>arXiv ID:</strong> 2506.10911 |
                        <strong>Published:</strong> 2025-06-12T17:23:23+00:00 |
                        
                        <strong>Highest Score:</strong> 0.565 Distributed training
                        
                    </div>
                </div>
                
                <div class="paper-body">
                    <div class="paper-abstract">
                        <strong>Abstract:</strong> Training large language models is generally done via optimization methods on
clusters containing tens of thousands of accelerators, communicating over a
high-bandwidth interconnect. Scaling up these clusters is expensive and can
become impractical, imposing limits on the size of models that can be trained.
Several recent studies have proposed training methods that are less
communication intensive, avoiding the need for a highly connected compute
cluster. These state-of-the-art low communication training methods still employ
a synchronization step for model parameters, which, when performed over all
model replicas, can become costly on a low-bandwidth network.
  In this work, we propose a novel optimization method, NoLoCo, that does not
explicitly synchronize all model parameters during training and, as a result,
does not require any collective communication. NoLoCo implicitly synchronizes
model weights via a novel variant of the Nesterov momentum optimizer by
partially averaging model weights with a randomly selected other one. We
provide both a theoretical convergence analysis for our proposed optimizer as
well as empirical results from language model training.
  We benchmark NoLoCo on a wide range of accelerator counts and model sizes,
between 125M to 6.8B parameters. Our method requires significantly less
communication overhead than fully sharded data parallel training or even widely
used low communication training method, DiLoCo. The synchronization step itself
is estimated to be one magnitude faster than the all-reduce used in DiLoCo for
few hundred accelerators training over the internet. We also do not have any
global blocking communication that reduces accelerator idling time. Compared to
DiLoCo, we also observe up to $4\%$ faster convergence rate with wide range of
model sizes and accelerator counts.
                    </div>
                    
                    
                    <div class="paper-categories">
                        <strong>Categories:</strong>
                        
                        <span class="category-tag">cs.LG</span>
                        
                    </div>
                    
                    
                    
                    <div class="similarity-summary">
                        <div class="llm-scoring-header">
                            <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600; display: inline;">LLM Scoring:</h6>
                            <button class="btn btn-sm btn-outline-light llm-scoring-toggle" 
                                    onclick="toggleLLMScoringJustifications('llm-scoring-11')">
                                Show Justification ▼
                            </button>
                        </div>
                        
                        <div class="llm-scoring-columns">
                            <!-- Recommendation Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Recommendation:</div>
                                
                                <div class="llm-scoring-value should-read">Should Read</div>
                                
                            </div>
                            
                            <!-- Novelty Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Novelty:</div>
                                
                                <div class="llm-scoring-value high">High</div>
                                
                            </div>
                            
                            <!-- Potential Impact Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Potential Impact:</div>
                                
                                <div class="llm-scoring-value moderate">Moderate</div>
                                
                            </div>
                        </div>
                        
                        <!-- Unified Justifications Section -->
                        <div class="llm-scoring-justifications" id="llm-scoring-11" style="display: none;">
                            
                            <div class="llm-justification-item">
                                <strong>Recommendation:</strong> This paper offers valuable insights and methods for researchers working on distributed training and large model optimization, making it worthwhile for those in the specific subfield. It is not essential for the broader audience outside of machine learning efficiency topics.
                            </div>
                            
                            
                            <div class="llm-justification-item">
                                <strong>Novelty:</strong> The paper introduces a truly new technique by proposing an optimization method that completely avoids collective communication, significantly advancing the state-of-the-art in low-communication training for large models.
                            </div>
                            
                            
                            <div class="llm-justification-item">
                                <strong>Potential Impact:</strong> The work is likely to be cited and built upon in the subfield of distributed machine learning, as it addresses practical challenges in scaling model training over low-bandwidth networks. However, its influence may be limited to specific applications rather than broader fields.
                            </div>
                            
                        </div>
                    </div>
                    
                    
                    <div class="paper-metrics-row">
                        <div class="similarity-scores">
                            
                                <div class="similarity-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Similarity Scores:</h6>
                                    <div class="similarity-scores-content">
                                        
                                        <span class="similarity-label" data-topic="RLHF">RLHF:</span>
                                        <div class="similarity-right-column" data-topic="RLHF">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 34.8%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.348">0.348</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Weak_supervision">Weak supervision:</span>
                                        <div class="similarity-right-column" data-topic="Weak_supervision">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 36.4%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.364">0.364</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Diffusion_reasoning">Diffusion reasoning:</span>
                                        <div class="similarity-right-column" data-topic="Diffusion_reasoning">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 37.3%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.373">0.373</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Distributed_training">Distributed training:</span>
                                        <div class="similarity-right-column" data-topic="Distributed_training">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 56.5%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.565">0.565</span>
                                        </div>
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="llm-validation">
                            
                                <div class="llm-validation-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">LLM Validation:</h6>
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="RLHF">
                                                <span class="llm-topic-label">RLHF:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Weak_supervision">
                                                <span class="llm-topic-label">Weak supervision:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Diffusion_reasoning">
                                                <span class="llm-topic-label">Diffusion reasoning:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Distributed_training">
                                                <span class="llm-topic-label">Distributed training:</span>
                                                
                                                    
                                                        <span class="llm-status llm-highly-relevant">Highly Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                    
                                    <div class="llm-buttons-row">
                                        <button class="btn btn-sm btn-outline-light llm-toggle" 
                                                onclick="toggleLLMDetails('llm-details-11')">
                                            Show Justifications ▼
                                        </button>
                                    </div>
                                    
                                    <div class="llm-details" id="llm-details-11">
                                        <h6 style="font-size: 0.9rem; margin-bottom: 0.5rem;">LLM Justifications:</h6>
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>RLHF:</strong> below_threshold
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Weak supervision:</strong> below_threshold
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Diffusion reasoning:</strong> below_threshold
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Distributed training:</strong> The paper's main contribution is a novel optimization method, NoLoCo, designed for distributed training of large models. It addresses key challenges in distributed training by reducing communication overhead through implicit synchronization and avoiding all-reduce operations, which directly aligns with topics like parallel computing and multi-node machine learning. The method involves partitioning computation across accelerators and focuses on accelerating training by minimizing network bottlenecks, making it a direct advancement in distributed training algorithms.
                                            </div>
                                            
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="h-index-scores">
                            
                                <div class="h-index-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Author H-Index:</h6>
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Data found:</span>
                                        <span class="h-index-value">5/5 authors</span>
                                    </div>
                                    <div class="h-index-metric">
                                        <span class="h-index-label">H-index available:</span>
                                        <span class="h-index-value">5/5 found</span>
                                    </div>
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Highest:</span>
                                        <span class="h-index-value">22</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Average:</span>
                                        <span class="h-index-value">5.2</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Notable (H>5):</span>
                                        <span class="h-index-value">1</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Source:</span>
                                        <span class="h-index-value">Full Id</span>
                                    </div>
                                    
                                    
                                    
                                    <div class="h-index-expand">
                                        <button class="btn btn-sm btn-outline-light h-index-toggle" 
                                                onclick="toggleHIndexDetails('h-details-11')">
                                            Show Individual H-indices ▼
                                        </button>
                                        <div class="h-index-details" id="h-details-11">
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">J. Kolehmainen</span>
                                                
                                                <span class="author-h-value">22</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Nikolay Blagoev</span>
                                                
                                                <span class="author-h-value">1</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">John Donaghy</span>
                                                
                                                <span class="author-h-value">1</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Ouguzhan Ersoy</span>
                                                
                                                <span class="author-h-value">2</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Christopher Nies</span>
                                                
                                                <span class="author-h-value">0</span>
                                            </div>
                                            
                                        </div>
                                    </div>
                                    
                                </div>
                            
                        </div>
                    </div>
                </div>
            </div>
            
            <div class="paper-card" data-paper-index="12">
                <div class="paper-header">
                    <div class="paper-number">#13</div>
                    <h5 class="paper-title">
                        <a href="http://arxiv.org/abs/2506.10908" class="paper-link" target="_blank">
                            Probably Approximately Correct Labels
                        </a>
                    </h5>
                    <div class="paper-meta">
                        <strong>arXiv ID:</strong> 2506.10908 |
                        <strong>Published:</strong> 2025-06-12T17:16:26+00:00 |
                        
                        <strong>Highest Score:</strong> 0.553 Weak supervision
                        
                    </div>
                </div>
                
                <div class="paper-body">
                    <div class="paper-abstract">
                        <strong>Abstract:</strong> Obtaining high-quality labeled datasets is often costly, requiring either
extensive human annotation or expensive experiments. We propose a method that
supplements such &quot;expert&quot; labels with AI predictions from pre-trained models to
construct labeled datasets more cost-effectively. Our approach results in
probably approximately correct labels: with high probability, the overall
labeling error is small. This solution enables rigorous yet efficient dataset
curation using modern AI models. We demonstrate the benefits of the methodology
through text annotation with large language models, image labeling with
pre-trained vision models, and protein folding analysis with AlphaFold.
                    </div>
                    
                    
                    <div class="paper-categories">
                        <strong>Categories:</strong>
                        
                        <span class="category-tag">stat.ML</span>
                        
                        <span class="category-tag">cs.LG</span>
                        
                    </div>
                    
                    
                    
                    <div class="similarity-summary">
                        <div class="llm-scoring-header">
                            <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600; display: inline;">LLM Scoring:</h6>
                            <button class="btn btn-sm btn-outline-light llm-scoring-toggle" 
                                    onclick="toggleLLMScoringJustifications('llm-scoring-12')">
                                Show Justification ▼
                            </button>
                        </div>
                        
                        <div class="llm-scoring-columns">
                            <!-- Recommendation Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Recommendation:</div>
                                
                                <div class="llm-scoring-value should-read">Should Read</div>
                                
                            </div>
                            
                            <!-- Novelty Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Novelty:</div>
                                
                                <div class="llm-scoring-value moderate">Moderate</div>
                                
                            </div>
                            
                            <!-- Potential Impact Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Potential Impact:</div>
                                
                                <div class="llm-scoring-value moderate">Moderate</div>
                                
                            </div>
                        </div>
                        
                        <!-- Unified Justifications Section -->
                        <div class="llm-scoring-justifications" id="llm-scoring-12" style="display: none;">
                            
                            <div class="llm-justification-item">
                                <strong>Recommendation:</strong> This paper offers valuable insights and methods for researchers working on data labeling and AI-assisted techniques, making it essential for those specifically in machine learning and statistical fields.
                            </div>
                            
                            
                            <div class="llm-justification-item">
                                <strong>Novelty:</strong> The paper presents a notable improvement by cleverly combining PAC learning principles with active learning techniques to efficiently label datasets, offering a new way to balance cost and accuracy without introducing entirely novel concepts.
                            </div>
                            
                            
                            <div class="llm-justification-item">
                                <strong>Potential Impact:</strong> The work is likely to be cited and built upon in subfields like machine learning and data annotation, as it addresses practical challenges in dataset curation and could enhance efficiency in various applications.
                            </div>
                            
                        </div>
                    </div>
                    
                    
                    <div class="paper-metrics-row">
                        <div class="similarity-scores">
                            
                                <div class="similarity-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Similarity Scores:</h6>
                                    <div class="similarity-scores-content">
                                        
                                        <span class="similarity-label" data-topic="RLHF">RLHF:</span>
                                        <div class="similarity-right-column" data-topic="RLHF">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 44.7%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.447">0.447</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Weak_supervision">Weak supervision:</span>
                                        <div class="similarity-right-column" data-topic="Weak_supervision">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 55.3%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.553">0.553</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Diffusion_reasoning">Diffusion reasoning:</span>
                                        <div class="similarity-right-column" data-topic="Diffusion_reasoning">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 35.7%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.357">0.357</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Distributed_training">Distributed training:</span>
                                        <div class="similarity-right-column" data-topic="Distributed_training">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 39.5%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.395">0.395</span>
                                        </div>
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="llm-validation">
                            
                                <div class="llm-validation-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">LLM Validation:</h6>
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="RLHF">
                                                <span class="llm-topic-label">RLHF:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant">Not Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Weak_supervision">
                                                <span class="llm-topic-label">Weak supervision:</span>
                                                
                                                    
                                                        <span class="llm-status llm-highly-relevant">Highly Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Diffusion_reasoning">
                                                <span class="llm-topic-label">Diffusion reasoning:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Distributed_training">
                                                <span class="llm-topic-label">Distributed training:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                    
                                    <div class="llm-buttons-row">
                                        <button class="btn btn-sm btn-outline-light llm-toggle" 
                                                onclick="toggleLLMDetails('llm-details-12')">
                                            Show Justifications ▼
                                        </button>
                                    </div>
                                    
                                    <div class="llm-details" id="llm-details-12">
                                        <h6 style="font-size: 0.9rem; margin-bottom: 0.5rem;">LLM Justifications:</h6>
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>RLHF:</strong> The paper focuses on creating labeled datasets by combining expert labels with AI predictions to minimize errors, without involving reinforcement learning or human feedback for model alignment. It does not train a reward model or use RL to fine-tune AI based on human preferences, which are core to RLHF.
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Weak supervision:</strong> The paper's main contribution involves using AI predictions as noisy or imprecise labels to supplement expert labels, enabling cost-effective dataset creation with guarantees on error rates. This directly aligns with weak supervision, which relies on programmatically generated, imperfect labels rather than fully hand-labeled data, as evidenced by the method's use of pre-trained models for labeling.
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Diffusion reasoning:</strong> below_threshold
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Distributed training:</strong> below_threshold
                                            </div>
                                            
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="h-index-scores">
                            
                                <div class="h-index-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Author H-Index:</h6>
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Data found:</span>
                                        <span class="h-index-value">3/3 authors</span>
                                    </div>
                                    <div class="h-index-metric">
                                        <span class="h-index-label">H-index available:</span>
                                        <span class="h-index-value">3/3 found</span>
                                    </div>
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Highest:</span>
                                        <span class="h-index-value">15</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Average:</span>
                                        <span class="h-index-value">6.7</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Notable (H>5):</span>
                                        <span class="h-index-value">1</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Source:</span>
                                        <span class="h-index-value">Full Id</span>
                                    </div>
                                    
                                    
                                    
                                    <div class="h-index-expand">
                                        <button class="btn btn-sm btn-outline-light h-index-toggle" 
                                                onclick="toggleHIndexDetails('h-details-12')">
                                            Show Individual H-indices ▼
                                        </button>
                                        <div class="h-index-details" id="h-details-12">
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Emmanuel J. Candes</span>
                                                
                                                <span class="author-h-value">5</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Andrew Ilyas</span>
                                                
                                                <span class="author-h-value">0</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Tijana Zrnic</span>
                                                
                                                <span class="author-h-value">15</span>
                                            </div>
                                            
                                        </div>
                                    </div>
                                    
                                </div>
                            
                        </div>
                    </div>
                </div>
            </div>
            
            <div class="paper-card" data-paper-index="13">
                <div class="paper-header">
                    <div class="paper-number">#14</div>
                    <h5 class="paper-title">
                        <a href="http://arxiv.org/abs/2506.10633" class="paper-link" target="_blank">
                            Anatomy-Grounded Weakly Supervised Prompt Tuning for Chest X-ray Latent
  Diffusion Models
                        </a>
                    </h5>
                    <div class="paper-meta">
                        <strong>arXiv ID:</strong> 2506.10633 |
                        <strong>Published:</strong> 2025-06-12T12:19:18+00:00 |
                        
                        <strong>Highest Score:</strong> 0.542 Diffusion reasoning
                        
                    </div>
                </div>
                
                <div class="paper-body">
                    <div class="paper-abstract">
                        <strong>Abstract:</strong> Latent Diffusion Models have shown remarkable results in text-guided image
synthesis in recent years. In the domain of natural (RGB) images, recent works
have shown that such models can be adapted to various vision-language
downstream tasks with little to no supervision involved. On the contrary,
text-to-image Latent Diffusion Models remain relatively underexplored in the
field of medical imaging, primarily due to limited data availability (e.g., due
to privacy concerns). In this work, focusing on the chest X-ray modality, we
first demonstrate that a standard text-conditioned Latent Diffusion Model has
not learned to align clinically relevant information in free-text radiology
reports with the corresponding areas of the given scan. Then, to alleviate this
issue, we propose a fine-tuning framework to improve multi-modal alignment in a
pre-trained model such that it can be efficiently repurposed for downstream
tasks such as phrase grounding. Our method sets a new state-of-the-art on a
standard benchmark dataset (MS-CXR), while also exhibiting robust performance
on out-of-distribution data (VinDr-CXR). Our code will be made publicly
available.
                    </div>
                    
                    
                    <div class="paper-categories">
                        <strong>Categories:</strong>
                        
                        <span class="category-tag">cs.CV</span>
                        
                    </div>
                    
                    
                    
                    <div class="similarity-summary">
                        <div class="llm-scoring-header">
                            <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600; display: inline;">LLM Scoring:</h6>
                            <button class="btn btn-sm btn-outline-light llm-scoring-toggle" 
                                    onclick="toggleLLMScoringJustifications('llm-scoring-13')">
                                Show Justification ▼
                            </button>
                        </div>
                        
                        <div class="llm-scoring-columns">
                            <!-- Recommendation Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Recommendation:</div>
                                
                                <div class="llm-scoring-value should-read">Should Read</div>
                                
                            </div>
                            
                            <!-- Novelty Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Novelty:</div>
                                
                                <div class="llm-scoring-value moderate">Moderate</div>
                                
                            </div>
                            
                            <!-- Potential Impact Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Potential Impact:</div>
                                
                                <div class="llm-scoring-value moderate">Moderate</div>
                                
                            </div>
                        </div>
                        
                        <!-- Unified Justifications Section -->
                        <div class="llm-scoring-justifications" id="llm-scoring-13" style="display: none;">
                            
                            <div class="llm-justification-item">
                                <strong>Recommendation:</strong> This paper is valuable for researchers in medical AI and vision-language models, as it offers innovative fine-tuning methods that could improve downstream tasks, making it worth reading for those specifically interested in the topic.
                            </div>
                            
                            
                            <div class="llm-justification-item">
                                <strong>Novelty:</strong> The paper presents a notable improvement by cleverly combining existing techniques, such as clinical entity recognition and prompt tuning, to address image-text alignment in medical imaging, though it builds on prior works rather than introducing a entirely new problem or architecture.
                            </div>
                            
                            
                            <div class="llm-justification-item">
                                <strong>Potential Impact:</strong> The work is likely to be cited and built upon in the subfield of biomedical vision-language processing, particularly for enhancing diffusion models in medical applications, due to its practical approach and demonstrated performance gains.
                            </div>
                            
                        </div>
                    </div>
                    
                    
                    <div class="paper-metrics-row">
                        <div class="similarity-scores">
                            
                                <div class="similarity-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Similarity Scores:</h6>
                                    <div class="similarity-scores-content">
                                        
                                        <span class="similarity-label" data-topic="RLHF">RLHF:</span>
                                        <div class="similarity-right-column" data-topic="RLHF">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 38.0%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.380">0.380</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Weak_supervision">Weak supervision:</span>
                                        <div class="similarity-right-column" data-topic="Weak_supervision">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 41.0%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.410">0.410</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Diffusion_reasoning">Diffusion reasoning:</span>
                                        <div class="similarity-right-column" data-topic="Diffusion_reasoning">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 54.2%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.542">0.542</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Distributed_training">Distributed training:</span>
                                        <div class="similarity-right-column" data-topic="Distributed_training">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 33.1%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.331">0.331</span>
                                        </div>
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="llm-validation">
                            
                                <div class="llm-validation-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">LLM Validation:</h6>
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="RLHF">
                                                <span class="llm-topic-label">RLHF:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Weak_supervision">
                                                <span class="llm-topic-label">Weak supervision:</span>
                                                
                                                    
                                                        <span class="llm-status llm-highly-relevant">Highly Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Diffusion_reasoning">
                                                <span class="llm-topic-label">Diffusion reasoning:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant">Not Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Distributed_training">
                                                <span class="llm-topic-label">Distributed training:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                    
                                    <div class="llm-buttons-row">
                                        <button class="btn btn-sm btn-outline-light llm-toggle" 
                                                onclick="toggleLLMDetails('llm-details-13')">
                                            Show Justifications ▼
                                        </button>
                                    </div>
                                    
                                    <div class="llm-details" id="llm-details-13">
                                        <h6 style="font-size: 0.9rem; margin-bottom: 0.5rem;">LLM Justifications:</h6>
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>RLHF:</strong> below_threshold
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Weak supervision:</strong> The paper's main contribution involves a weakly supervised fine-tuning framework that derives supervision signals from free-text radiology reports using a pre-trained clinical entity recognition model and a small set of anatomical annotations. This aligns directly with weak supervision, as it programmatically generates labels from high-level, noisy, or imprecise sources (e.g., unstructured reports) without relying on perfectly hand-labeled data, enabling efficient model training.
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Diffusion reasoning:</strong> The paper uses Latent Diffusion Models for image-text alignment and synthesis in medical imaging, focusing on fine-tuning for tasks like phrase grounding. However, it does not involve adapting the diffusion process for multi-step logical reasoning, chain-of-thought correction, or solving complex logical tasks; it is centered on visual generation and alignment, not reasoning.
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Distributed training:</strong> below_threshold
                                            </div>
                                            
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="h-index-scores">
                            
                                <div class="h-index-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Author H-Index:</h6>
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Data found:</span>
                                        <span class="h-index-value">5/5 authors</span>
                                    </div>
                                    <div class="h-index-metric">
                                        <span class="h-index-label">H-index available:</span>
                                        <span class="h-index-value">5/5 found</span>
                                    </div>
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Highest:</span>
                                        <span class="h-index-value">48</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Average:</span>
                                        <span class="h-index-value">10.8</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Notable (H>5):</span>
                                        <span class="h-index-value">1</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Source:</span>
                                        <span class="h-index-value">Full Id</span>
                                    </div>
                                    
                                    
                                    
                                    <div class="h-index-expand">
                                        <button class="btn btn-sm btn-outline-light h-index-toggle" 
                                                onclick="toggleHIndexDetails('h-details-13')">
                                            Show Individual H-indices ▼
                                        </button>
                                        <div class="h-index-details" id="h-details-13">
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Konstantinos Vilouras</span>
                                                
                                                <span class="author-h-value">2</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Ilias Stogiannidis</span>
                                                
                                                <span class="author-h-value">0</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Junyu Yan</span>
                                                
                                                <span class="author-h-value">1</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Alison Q. O'Neil</span>
                                                
                                                <span class="author-h-value">3</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">S. Tsaftaris</span>
                                                
                                                <span class="author-h-value">48</span>
                                            </div>
                                            
                                        </div>
                                    </div>
                                    
                                </div>
                            
                        </div>
                    </div>
                </div>
            </div>
            
            <div class="paper-card" data-paper-index="14">
                <div class="paper-header">
                    <div class="paper-number">#15</div>
                    <h5 class="paper-title">
                        <a href="http://arxiv.org/abs/2502.07750" class="paper-link" target="_blank">
                            PFedDST: Personalized Federated Learning with Decentralized Selection
  Training
                        </a>
                    </h5>
                    <div class="paper-meta">
                        <strong>arXiv ID:</strong> 2502.07750 |
                        <strong>Published:</strong> 2025-02-11T18:25:48+00:00 |
                        
                        <strong>Highest Score:</strong> 0.503 Distributed training
                        
                    </div>
                </div>
                
                <div class="paper-body">
                    <div class="paper-abstract">
                        <strong>Abstract:</strong> Distributed Learning (DL) enables the training of machine learning models
across multiple devices, yet it faces challenges like non-IID data
distributions and device capability disparities, which can impede training
efficiency. Communication bottlenecks further complicate traditional Federated
Learning (FL) setups. To mitigate these issues, we introduce the Personalized
Federated Learning with Decentralized Selection Training (PFedDST) framework.
PFedDST enhances model training by allowing devices to strategically evaluate
and select peers based on a comprehensive communication score. This score
integrates loss, task similarity, and selection frequency, ensuring optimal
peer connections. This selection strategy is tailored to increase local
personalization and promote beneficial peer collaborations to strengthen the
stability and efficiency of the training process. Our experiments demonstrate
that PFedDST not only enhances model accuracy but also accelerates convergence.
This approach outperforms state-of-the-art methods in handling data
heterogeneity, delivering both faster and more effective training in diverse
and decentralized systems.
                    </div>
                    
                    
                    <div class="paper-categories">
                        <strong>Categories:</strong>
                        
                        <span class="category-tag">cs.LG</span>
                        
                        <span class="category-tag">cs.AI</span>
                        
                    </div>
                    
                    
                    
                    <div class="similarity-summary">
                        <div class="llm-scoring-header">
                            <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600; display: inline;">LLM Scoring:</h6>
                            <button class="btn btn-sm btn-outline-light llm-scoring-toggle" 
                                    onclick="toggleLLMScoringJustifications('llm-scoring-14')">
                                Show Justification ▼
                            </button>
                        </div>
                        
                        <div class="llm-scoring-columns">
                            <!-- Recommendation Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Recommendation:</div>
                                
                                <div class="llm-scoring-value should-read">Should Read</div>
                                
                            </div>
                            
                            <!-- Novelty Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Novelty:</div>
                                
                                <div class="llm-scoring-value moderate">Moderate</div>
                                
                            </div>
                            
                            <!-- Potential Impact Column -->
                            <div class="llm-scoring-column">
                                <div class="llm-scoring-label">Potential Impact:</div>
                                
                                <div class="llm-scoring-value moderate">Moderate</div>
                                
                            </div>
                        </div>
                        
                        <!-- Unified Justifications Section -->
                        <div class="llm-scoring-justifications" id="llm-scoring-14" style="display: none;">
                            
                            <div class="llm-justification-item">
                                <strong>Recommendation:</strong> This paper is valuable for researchers and practitioners in federated learning due to its innovative peer selection strategy and demonstrated performance gains in heterogeneous environments. However, it is not essential for those outside this specific area, making it a targeted rather than mandatory read.
                            </div>
                            
                            
                            <div class="llm-justification-item">
                                <strong>Novelty:</strong> The paper presents a notable improvement by combining existing federated learning concepts with a new scoring strategy for peer selection, effectively addressing data heterogeneity in a decentralized setting. While it builds on prior work, it introduces a clever integration that advances personalization without creating an entirely new paradigm.
                            </div>
                            
                            
                            <div class="llm-justification-item">
                                <strong>Potential Impact:</strong> The work is likely to influence research in personalized and decentralized federated learning by providing a more efficient method for handling data heterogeneity and communication challenges. Its specific focus on practical improvements may lead to citations and adaptations within this subfield, though its broader applicability remains limited.
                            </div>
                            
                        </div>
                    </div>
                    
                    
                    <div class="paper-metrics-row">
                        <div class="similarity-scores">
                            
                                <div class="similarity-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Similarity Scores:</h6>
                                    <div class="similarity-scores-content">
                                        
                                        <span class="similarity-label" data-topic="RLHF">RLHF:</span>
                                        <div class="similarity-right-column" data-topic="RLHF">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 40.7%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.407">0.407</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Weak_supervision">Weak supervision:</span>
                                        <div class="similarity-right-column" data-topic="Weak_supervision">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 34.8%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.348">0.348</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Diffusion_reasoning">Diffusion reasoning:</span>
                                        <div class="similarity-right-column" data-topic="Diffusion_reasoning">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 34.7%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.347">0.347</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Distributed_training">Distributed training:</span>
                                        <div class="similarity-right-column" data-topic="Distributed_training">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 50.3%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.503">0.503</span>
                                        </div>
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="llm-validation">
                            
                                <div class="llm-validation-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">LLM Validation:</h6>
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="RLHF">
                                                <span class="llm-topic-label">RLHF:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant">Not Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Weak_supervision">
                                                <span class="llm-topic-label">Weak supervision:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Diffusion_reasoning">
                                                <span class="llm-topic-label">Diffusion reasoning:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Distributed_training">
                                                <span class="llm-topic-label">Distributed training:</span>
                                                
                                                    
                                                        <span class="llm-status llm-highly-relevant">Highly Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                    
                                    <div class="llm-buttons-row">
                                        <button class="btn btn-sm btn-outline-light llm-toggle" 
                                                onclick="toggleLLMDetails('llm-details-14')">
                                            Show Justifications ▼
                                        </button>
                                    </div>
                                    
                                    <div class="llm-details" id="llm-details-14">
                                        <h6 style="font-size: 0.9rem; margin-bottom: 0.5rem;">LLM Justifications:</h6>
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>RLHF:</strong> The paper focuses on Personalized Federated Learning and decentralized training strategies, with no mention of human feedback, reward models, or reinforcement learning techniques. It deals solely with automated peer selection and model aggregation in distributed settings.
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Weak supervision:</strong> below_threshold
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Diffusion reasoning:</strong> below_threshold
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Distributed training:</strong> The paper's main contribution, PFedDST, involves distributed training across multiple devices, addressing challenges like data heterogeneity, communication efficiency, and parallel computing in federated learning. It directly aligns with distributed training by partitioning data and computation across nodes and optimizing multi-node interactions.
                                            </div>
                                            
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="h-index-scores">
                            
                                <div class="h-index-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Author H-Index:</h6>
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Data found:</span>
                                        <span class="h-index-value">5/5 authors</span>
                                    </div>
                                    <div class="h-index-metric">
                                        <span class="h-index-label">H-index available:</span>
                                        <span class="h-index-value">5/5 found</span>
                                    </div>
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Highest:</span>
                                        <span class="h-index-value">3</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Average:</span>
                                        <span class="h-index-value">1.0</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Notable (H>5):</span>
                                        <span class="h-index-value">0</span>
                                    </div>
                                    
                                    
                                    <div class="h-index-metric">
                                        <span class="h-index-label">Source:</span>
                                        <span class="h-index-value">Full Id</span>
                                    </div>
                                    
                                    
                                    
                                    <div class="h-index-expand">
                                        <button class="btn btn-sm btn-outline-light h-index-toggle" 
                                                onclick="toggleHIndexDetails('h-details-14')">
                                            Show Individual H-indices ▼
                                        </button>
                                        <div class="h-index-details" id="h-details-14">
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Mengchen Fan</span>
                                                
                                                <span class="author-h-value">1</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Keren Li</span>
                                                
                                                <span class="author-h-value">1</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Tianyun Zhang</span>
                                                
                                                <span class="author-h-value">0</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Qing Tian</span>
                                                
                                                <span class="author-h-value">0</span>
                                            </div>
                                            
                                            <div class="individual-h-index">
                                                
                                                <span class="author-name">Baocheng Geng</span>
                                                
                                                <span class="author-h-value">3</span>
                                            </div>
                                            
                                        </div>
                                    </div>
                                    
                                </div>
                            
                        </div>
                    </div>
                </div>
            </div>
            
            <div class="paper-card" data-paper-index="15">
                <div class="paper-header">
                    <div class="paper-number">#16</div>
                    <h5 class="paper-title">
                        <a href="http://arxiv.org/abs/2410.21842" class="paper-link" target="_blank">
                            Diffusion as Reasoning: Enhancing Object Navigation via Diffusion Model
  Conditioned on LLM-based Object-Room Knowledge
                        </a>
                    </h5>
                    <div class="paper-meta">
                        <strong>arXiv ID:</strong> 2410.21842 |
                        <strong>Published:</strong> 2024-10-29T08:10:06+00:00 |
                        
                        <strong>Highest Score:</strong> 0.654 Diffusion reasoning
                        
                    </div>
                </div>
                
                <div class="paper-body">
                    <div class="paper-abstract">
                        <strong>Abstract:</strong> The Object Navigation (ObjectNav) task aims to guide an agent to locate
target objects in unseen environments using partial observations. Prior
approaches have employed location prediction paradigms to achieve long-term
goal reasoning, yet these methods often struggle to effectively integrate
contextual relation reasoning. Alternatively, map completion-based paradigms
predict long-term goals by generating semantic maps of unexplored areas.
However, existing methods in this category fail to fully leverage known
environmental information, resulting in suboptimal map quality that requires
further improvement. In this work, we propose a novel approach to enhancing the
ObjectNav task, by training a diffusion model to learn the statistical
distribution patterns of objects in semantic maps, and using the map of the
explored regions during navigation as the condition to generate the map of the
unknown regions, thereby realizing the long-term goal reasoning of the target
object, i.e., diffusion as reasoning (DAR). Meanwhile, we propose the Room
Guidance method, which leverages commonsense knowledge derived from large
language models (LLMs) to guide the diffusion model in generating room-aware
object distributions. Based on the generated map in the unknown region, the
agent sets the predicted location of the target as the goal and moves towards
it. Experiments on Gibson and MP3D show the effectiveness of our method.
                    </div>
                    
                    
                    <div class="paper-categories">
                        <strong>Categories:</strong>
                        
                        <span class="category-tag">cs.CV</span>
                        
                        <span class="category-tag">cs.AI</span>
                        
                    </div>
                    
                    
                    
                    <div class="similarity-summary">
                        <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">LLM Scoring:</h6>
                        <p class="text-muted" style="text-align: left;">No LLM Scoring available. (No Highly Relevant Topics)</p>
                    </div>
                    
                    
                    <div class="paper-metrics-row">
                        <div class="similarity-scores">
                            
                                <div class="similarity-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Similarity Scores:</h6>
                                    <div class="similarity-scores-content">
                                        
                                        <span class="similarity-label" data-topic="RLHF">RLHF:</span>
                                        <div class="similarity-right-column" data-topic="RLHF">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 38.9%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.389">0.389</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Weak_supervision">Weak supervision:</span>
                                        <div class="similarity-right-column" data-topic="Weak_supervision">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 35.8%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.358">0.358</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Diffusion_reasoning">Diffusion reasoning:</span>
                                        <div class="similarity-right-column" data-topic="Diffusion_reasoning">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 65.4%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.654">0.654</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Distributed_training">Distributed training:</span>
                                        <div class="similarity-right-column" data-topic="Distributed_training">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 35.4%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.354">0.354</span>
                                        </div>
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="llm-validation">
                            
                                <div class="llm-validation-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">LLM Validation:</h6>
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="RLHF">
                                                <span class="llm-topic-label">RLHF:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Weak_supervision">
                                                <span class="llm-topic-label">Weak supervision:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Diffusion_reasoning">
                                                <span class="llm-topic-label">Diffusion reasoning:</span>
                                                
                                                    
                                                        <span class="llm-status llm-moderately-relevant">Moderately Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Distributed_training">
                                                <span class="llm-topic-label">Distributed training:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                    
                                    <div class="llm-buttons-row">
                                        <button class="btn btn-sm btn-outline-light llm-toggle" 
                                                onclick="toggleLLMDetails('llm-details-15')">
                                            Show Justifications ▼
                                        </button>
                                    </div>
                                    
                                    <div class="llm-details" id="llm-details-15">
                                        <h6 style="font-size: 0.9rem; margin-bottom: 0.5rem;">LLM Justifications:</h6>
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>RLHF:</strong> below_threshold
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Weak supervision:</strong> below_threshold
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Diffusion reasoning:</strong> The paper uses a diffusion model for generating semantic maps in Object Navigation, framing it as "diffusion as reasoning" to predict long-term goals through iterative denoising. This involves multi-step refinement, which aligns somewhat with the topic's emphasis on iterative processes for complex tasks. However, the application focuses on spatial and probabilistic generation rather than explicit multi-step logical reasoning or treating a chain-of-thought as a holistic entity, making it only moderately relevant.
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Distributed training:</strong> below_threshold
                                            </div>
                                            
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="h-index-scores">
                            
                                <div class="h-index-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Author H-Index:</h6>
                                    <p class="text-muted">No H-index data available</p>
                                </div>
                            
                        </div>
                    </div>
                </div>
            </div>
            
            <div class="paper-card" data-paper-index="16">
                <div class="paper-header">
                    <div class="paper-number">#17</div>
                    <h5 class="paper-title">
                        <a href="http://arxiv.org/abs/2506.10943" class="paper-link" target="_blank">
                            Self-Adapting Language Models
                        </a>
                    </h5>
                    <div class="paper-meta">
                        <strong>arXiv ID:</strong> 2506.10943 |
                        <strong>Published:</strong> 2025-06-12T17:48:13+00:00 |
                        
                        <strong>Highest Score:</strong> 0.462 Diffusion reasoning
                        
                    </div>
                </div>
                
                <div class="paper-body">
                    <div class="paper-abstract">
                        <strong>Abstract:</strong> Large language models (LLMs) are powerful but static; they lack mechanisms to
adapt their weights in response to new tasks, knowledge, or examples. We
introduce Self-Adapting LLMs (SEAL), a framework that enables LLMs to
self-adapt by generating their own finetuning data and update directives. Given
a new input, the model produces a self-edit-a generation that may restructure
the information in different ways, specify optimization hyperparameters, or
invoke tools for data augmentation and gradient-based updates. Through
supervised finetuning (SFT), these self-edits result in persistent weight
updates, enabling lasting adaptation. To train the model to produce effective
self-edits, we use a reinforcement learning loop with the downstream
performance of the updated model as the reward signal. Unlike prior approaches
that rely on separate adaptation modules or auxiliary networks, SEAL directly
uses the model&#x27;s own generation to control its adaptation process. Experiments
on knowledge incorporation and few-shot generalization show that SEAL is a
promising step toward language models capable of self-directed adaptation. Our
website and code is available at https://jyopari.github.io/posts/seal.
                    </div>
                    
                    
                    <div class="paper-categories">
                        <strong>Categories:</strong>
                        
                        <span class="category-tag">cs.LG</span>
                        
                    </div>
                    
                    
                    
                    <div class="similarity-summary">
                        <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">LLM Scoring:</h6>
                        <p class="text-muted" style="text-align: left;">No LLM Scoring available. (No Highly Relevant Topics)</p>
                    </div>
                    
                    
                    <div class="paper-metrics-row">
                        <div class="similarity-scores">
                            
                                <div class="similarity-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Similarity Scores:</h6>
                                    <div class="similarity-scores-content">
                                        
                                        <span class="similarity-label" data-topic="RLHF">RLHF:</span>
                                        <div class="similarity-right-column" data-topic="RLHF">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 44.6%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.446">0.446</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Weak_supervision">Weak supervision:</span>
                                        <div class="similarity-right-column" data-topic="Weak_supervision">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 42.6%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.426">0.426</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Diffusion_reasoning">Diffusion reasoning:</span>
                                        <div class="similarity-right-column" data-topic="Diffusion_reasoning">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 46.2%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.462">0.462</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Distributed_training">Distributed training:</span>
                                        <div class="similarity-right-column" data-topic="Distributed_training">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 38.0%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.380">0.380</span>
                                        </div>
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="llm-validation">
                            
                                <div class="llm-validation-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">LLM Validation:</h6>
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="RLHF">
                                                <span class="llm-topic-label">RLHF:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant">Not Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Weak_supervision">
                                                <span class="llm-topic-label">Weak supervision:</span>
                                                
                                                    
                                                        <span class="llm-status llm-moderately-relevant">Moderately Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Diffusion_reasoning">
                                                <span class="llm-topic-label">Diffusion reasoning:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant">Not Relevant</span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Distributed_training">
                                                <span class="llm-topic-label">Distributed training:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                    
                                    <div class="llm-buttons-row">
                                        <button class="btn btn-sm btn-outline-light llm-toggle" 
                                                onclick="toggleLLMDetails('llm-details-16')">
                                            Show Justifications ▼
                                        </button>
                                    </div>
                                    
                                    <div class="llm-details" id="llm-details-16">
                                        <h6 style="font-size: 0.9rem; margin-bottom: 0.5rem;">LLM Justifications:</h6>
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>RLHF:</strong> The paper uses a reinforcement learning loop where rewards are based on the model's downstream task performance, not human feedback. RLHF specifically requires training a reward model from human-ranked data, which is absent here, making the paper's approach fundamentally different.
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Weak supervision:</strong> The paper involves the model generating its own finetuning data and directives programmatically, which aligns with weak supervision's use of noisy or high-level sources for data creation. However, the primary focus is on self-adaptation via reinforcement learning, not on weak supervision as a core technique for label generation.
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Diffusion reasoning:</strong> The paper does not involve diffusion models, iterative refinement processes, or multi-step logical reasoning as described in diffusion-based approaches. It focuses on reinforcement learning for self-adaptation in LLMs, with no components related to diffusion or holistic chain-of-thought correction.
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Distributed training:</strong> below_threshold
                                            </div>
                                            
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="h-index-scores">
                            
                                <div class="h-index-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Author H-Index:</h6>
                                    <p class="text-muted">No H-index data available</p>
                                </div>
                            
                        </div>
                    </div>
                </div>
            </div>
            
            <div class="paper-card" data-paper-index="17">
                <div class="paper-header">
                    <div class="paper-number">#18</div>
                    <h5 class="paper-title">
                        <a href="http://arxiv.org/abs/2506.10570" class="paper-link" target="_blank">
                            6G Infrastructures for Edge AI: An Analytical Perspective
                        </a>
                    </h5>
                    <div class="paper-meta">
                        <strong>arXiv ID:</strong> 2506.10570 |
                        <strong>Published:</strong> 2025-06-12T10:59:08+00:00 |
                        
                        <strong>Highest Score:</strong> 0.395 Distributed training
                        
                    </div>
                </div>
                
                <div class="paper-body">
                    <div class="paper-abstract">
                        <strong>Abstract:</strong> The convergence of Artificial Intelligence (AI) and the Internet of Things
has accelerated the development of distributed, network-sensitive applications,
necessitating ultra-low latency, high throughput, and real-time processing
capabilities. While 5G networks represent a significant technological
milestone, their ability to support AI-driven edge applications remains
constrained by performance gaps observed in real-world deployments. This paper
addresses these limitations and highlights critical advancements needed to
realize a robust and scalable 6G ecosystem optimized for AI applications.
Furthermore, we conduct an empirical evaluation of 5G network infrastructure in
central Europe, with latency measurements ranging from 61 ms to 110 ms across
different close geographical areas. These values exceed the requirements of
latency-critical AI applications by approximately 270%, revealing significant
shortcomings in current deployments. Building on these findings, we propose a
set of recommendations to bridge the gap between existing 5G performance and
the requirements of next-generation AI applications.
                    </div>
                    
                    
                    <div class="paper-categories">
                        <strong>Categories:</strong>
                        
                        <span class="category-tag">cs.DC</span>
                        
                    </div>
                    
                    
                    
                    <div class="similarity-summary">
                        <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">LLM Scoring:</h6>
                        <p class="text-muted" style="text-align: left;">No LLM Scoring available. (No Highly Relevant Topics)</p>
                    </div>
                    
                    
                    <div class="paper-metrics-row">
                        <div class="similarity-scores">
                            
                                <div class="similarity-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Similarity Scores:</h6>
                                    <div class="similarity-scores-content">
                                        
                                        <span class="similarity-label" data-topic="RLHF">RLHF:</span>
                                        <div class="similarity-right-column" data-topic="RLHF">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 31.4%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.314">0.314</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Weak_supervision">Weak supervision:</span>
                                        <div class="similarity-right-column" data-topic="Weak_supervision">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 29.3%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.293">0.293</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Diffusion_reasoning">Diffusion reasoning:</span>
                                        <div class="similarity-right-column" data-topic="Diffusion_reasoning">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 31.9%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.319">0.319</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Distributed_training">Distributed training:</span>
                                        <div class="similarity-right-column" data-topic="Distributed_training">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 39.5%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.395">0.395</span>
                                        </div>
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="llm-validation">
                            
                                <div class="llm-validation-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">LLM Validation:</h6>
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="RLHF">
                                                <span class="llm-topic-label">RLHF:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Weak_supervision">
                                                <span class="llm-topic-label">Weak supervision:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Diffusion_reasoning">
                                                <span class="llm-topic-label">Diffusion reasoning:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Distributed_training">
                                                <span class="llm-topic-label">Distributed training:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                    
                                    <div class="llm-buttons-row">
                                        <button class="btn btn-sm btn-outline-light llm-toggle" 
                                                onclick="toggleLLMDetails('llm-details-17')">
                                            Show Justifications ▼
                                        </button>
                                    </div>
                                    
                                    <div class="llm-details" id="llm-details-17">
                                        <h6 style="font-size: 0.9rem; margin-bottom: 0.5rem;">LLM Justifications:</h6>
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>RLHF:</strong> below_threshold
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Weak supervision:</strong> below_threshold
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Diffusion reasoning:</strong> below_threshold
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Distributed training:</strong> below_threshold
                                            </div>
                                            
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="h-index-scores">
                            
                                <div class="h-index-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Author H-Index:</h6>
                                    <p class="text-muted">No H-index data available</p>
                                </div>
                            
                        </div>
                    </div>
                </div>
            </div>
            
            <div class="paper-card" data-paper-index="18">
                <div class="paper-header">
                    <div class="paper-number">#19</div>
                    <h5 class="paper-title">
                        <a href="http://arxiv.org/abs/2506.10820" class="paper-link" target="_blank">
                            A Combined Parallel-in-time Direct Inverse (ParaDIn)-Parareal Method for
  Nonlinear Differential Equations
                        </a>
                    </h5>
                    <div class="paper-meta">
                        <strong>arXiv ID:</strong> 2506.10820 |
                        <strong>Published:</strong> 2025-06-12T15:38:56+00:00 |
                        
                        <strong>Highest Score:</strong> 0.354 Distributed training
                        
                    </div>
                </div>
                
                <div class="paper-body">
                    <div class="paper-abstract">
                        <strong>Abstract:</strong> As has been shown in our previous work, the parallel-in-time direct inverse
(ParaDIn) method introduced by Yamaleev and Paudel in (arXiv: 2406.00878v1,
2024) imposes some constraint on the maximum number of time levels, $N_t$, that
can be integrated in parallel. To circumvent this problem and further increase
the speedup, we combine the ParaDIn method with the Parareal algorithm to
efficiently parallelize the first-order time derivative term in nonlinear
partial differential equations discretized by the method of lines. The main
idea of the proposed approach is to use a block-Jacobi preconditioner, so that
each block is solved by using the ParaDIn method. To accelerate the convergence
of Jacobi iterations, we use the Parareal method which can be interpreted as a
two-level multigrid method in time. In contrast to the conventional Parareal
algorithm whose coarse grid correction step is performed sequentially, both the
coarse- and fine-grid propagators in the proposed approach are implemented in
parallel by using the ParaDIn method, thus significantly increasing the
parallel performance of the combined algorithm. Numerical results show that the
new combined ParaDIn-Parareal method provides the speedup of up to 124 on 480
computing cores as compared with the sequential first-order implicit backward
difference (BDF1) scheme for the 2-D nonlinear heat and Burgers equations with
both smooth and discontinuous solutions.
                    </div>
                    
                    
                    <div class="paper-categories">
                        <strong>Categories:</strong>
                        
                        <span class="category-tag">math.NA</span>
                        
                        <span class="category-tag">cs.NA</span>
                        
                    </div>
                    
                    
                    
                    <div class="similarity-summary">
                        <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">LLM Scoring:</h6>
                        <p class="text-muted" style="text-align: left;">No LLM Scoring available. (No Highly Relevant Topics)</p>
                    </div>
                    
                    
                    <div class="paper-metrics-row">
                        <div class="similarity-scores">
                            
                                <div class="similarity-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Similarity Scores:</h6>
                                    <div class="similarity-scores-content">
                                        
                                        <span class="similarity-label" data-topic="RLHF">RLHF:</span>
                                        <div class="similarity-right-column" data-topic="RLHF">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 19.6%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.196">0.196</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Weak_supervision">Weak supervision:</span>
                                        <div class="similarity-right-column" data-topic="Weak_supervision">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 20.0%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.200">0.200</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Diffusion_reasoning">Diffusion reasoning:</span>
                                        <div class="similarity-right-column" data-topic="Diffusion_reasoning">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 32.0%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.320">0.320</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Distributed_training">Distributed training:</span>
                                        <div class="similarity-right-column" data-topic="Distributed_training">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 35.4%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.354">0.354</span>
                                        </div>
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="llm-validation">
                            
                                <div class="llm-validation-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">LLM Validation:</h6>
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="RLHF">
                                                <span class="llm-topic-label">RLHF:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Weak_supervision">
                                                <span class="llm-topic-label">Weak supervision:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Diffusion_reasoning">
                                                <span class="llm-topic-label">Diffusion reasoning:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Distributed_training">
                                                <span class="llm-topic-label">Distributed training:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                    
                                    <div class="llm-buttons-row">
                                        <button class="btn btn-sm btn-outline-light llm-toggle" 
                                                onclick="toggleLLMDetails('llm-details-18')">
                                            Show Justifications ▼
                                        </button>
                                    </div>
                                    
                                    <div class="llm-details" id="llm-details-18">
                                        <h6 style="font-size: 0.9rem; margin-bottom: 0.5rem;">LLM Justifications:</h6>
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>RLHF:</strong> below_threshold
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Weak supervision:</strong> below_threshold
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Diffusion reasoning:</strong> below_threshold
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Distributed training:</strong> below_threshold
                                            </div>
                                            
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="h-index-scores">
                            
                                <div class="h-index-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Author H-Index:</h6>
                                    <p class="text-muted">No H-index data available</p>
                                </div>
                            
                        </div>
                    </div>
                </div>
            </div>
            
            <div class="paper-card" data-paper-index="19">
                <div class="paper-header">
                    <div class="paper-number">#20</div>
                    <h5 class="paper-title">
                        <a href="http://arxiv.org/abs/2506.10397" class="paper-link" target="_blank">
                            Bug Classification in Quantum Software: A Rule-Based Framework and Its
  Evaluation
                        </a>
                    </h5>
                    <div class="paper-meta">
                        <strong>arXiv ID:</strong> 2506.10397 |
                        <strong>Published:</strong> 2025-06-12T06:42:10+00:00 |
                        
                        <strong>Highest Score:</strong> 0.333 Weak supervision
                        
                    </div>
                </div>
                
                <div class="paper-body">
                    <div class="paper-abstract">
                        <strong>Abstract:</strong> Accurate classification of software bugs is essential for improving software
quality. This paper presents a rule-based automated framework for classifying
issues in quantum software repositories by bug type, category, severity, and
impacted quality attributes, with additional focus on quantum-specific bug
types. The framework applies keyword and heuristic-based techniques tailored to
quantum computing. To assess its reliability, we manually classified a
stratified sample of 4,984 issues from a dataset of 12,910 issues across 36
Qiskit repositories. Automated classifications were compared with ground truth
using accuracy, precision, recall, and F1-score. The framework achieved up to
85.21% accuracy, with F1-scores ranging from 0.7075 (severity) to 0.8393
(quality attribute). Statistical validation via paired t-tests and Cohen&#x27;s
Kappa showed substantial to almost perfect agreement for bug type (k = 0.696),
category (k = 0.826), quality attribute (k = 0.818), and quantum-specific bug
type (k = 0.712). Severity classification showed slight agreement (k = 0.162),
suggesting room for improvement. Large-scale analysis revealed that classical
bugs dominate (67.2%), with quantum-specific bugs at 27.3%. Frequent bug
categories included compatibility, functional, and quantum-specific defects,
while usability, maintainability, and interoperability were the most impacted
quality attributes. Most issues (93.7%) were low severity; only 4.3% were
critical. A detailed review of 1,550 quantum-specific bugs showed that over
half involved quantum circuit-level problems, followed by gate errors and
hardware-related issues.
                    </div>
                    
                    
                    <div class="paper-categories">
                        <strong>Categories:</strong>
                        
                        <span class="category-tag">cs.SE</span>
                        
                        <span class="category-tag">cs.CY</span>
                        
                        <span class="category-tag">cs.DC</span>
                        
                    </div>
                    
                    
                    
                    <div class="similarity-summary">
                        <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">LLM Scoring:</h6>
                        <p class="text-muted" style="text-align: left;">No LLM Scoring available. (No Highly Relevant Topics)</p>
                    </div>
                    
                    
                    <div class="paper-metrics-row">
                        <div class="similarity-scores">
                            
                                <div class="similarity-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Similarity Scores:</h6>
                                    <div class="similarity-scores-content">
                                        
                                        <span class="similarity-label" data-topic="RLHF">RLHF:</span>
                                        <div class="similarity-right-column" data-topic="RLHF">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 27.8%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.278">0.278</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Weak_supervision">Weak supervision:</span>
                                        <div class="similarity-right-column" data-topic="Weak_supervision">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 33.3%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.333">0.333</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Diffusion_reasoning">Diffusion reasoning:</span>
                                        <div class="similarity-right-column" data-topic="Diffusion_reasoning">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 29.4%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.294">0.294</span>
                                        </div>
                                        
                                        <span class="similarity-label" data-topic="Distributed_training">Distributed training:</span>
                                        <div class="similarity-right-column" data-topic="Distributed_training">
                                            <div class="similarity-bar">
                                                <div class="similarity-bar-fill" style="width: 30.7%"></div>
                                            </div>
                                            <span class="similarity-value" data-original-score="0.307">0.307</span>
                                        </div>
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="llm-validation">
                            
                                <div class="llm-validation-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">LLM Validation:</h6>
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="RLHF">
                                                <span class="llm-topic-label">RLHF:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Weak_supervision">
                                                <span class="llm-topic-label">Weak supervision:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Diffusion_reasoning">
                                                <span class="llm-topic-label">Diffusion reasoning:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                        
                                            
                                            <div class="llm-validation-item" data-topic="Distributed_training">
                                                <span class="llm-topic-label">Distributed training:</span>
                                                
                                                    
                                                        <span class="llm-status llm-not-relevant-asterisk">
                                                            Not Relevant*
                                                            <div class="llm-validation-tooltip">
                                                                Topic similarity score below 0.4, hence deemed not relevant
                                                            </div>
                                                        </span>
                                                    
                                                
                                            </div>
                                        
                                    
                                    
                                    <div class="llm-buttons-row">
                                        <button class="btn btn-sm btn-outline-light llm-toggle" 
                                                onclick="toggleLLMDetails('llm-details-19')">
                                            Show Justifications ▼
                                        </button>
                                    </div>
                                    
                                    <div class="llm-details" id="llm-details-19">
                                        <h6 style="font-size: 0.9rem; margin-bottom: 0.5rem;">LLM Justifications:</h6>
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>RLHF:</strong> below_threshold
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Weak supervision:</strong> below_threshold
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Diffusion reasoning:</strong> below_threshold
                                            </div>
                                            
                                        
                                            
                                            <div class="llm-justification">
                                                <strong>Distributed training:</strong> below_threshold
                                            </div>
                                            
                                        
                                    </div>
                                </div>
                            
                        </div>
                        
                        <div class="h-index-scores">
                            
                                <div class="h-index-summary">
                                    <h6 style="margin-bottom: 1rem; color: #ffffff; font-weight: 600;">Author H-Index:</h6>
                                    <p class="text-muted">No H-index data available</p>
                                </div>
                            
                        </div>
                    </div>
                </div>
            </div>
            
        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
    <script>
        function toggleLLMScoringJustifications(id) {
            const element = document.getElementById(id);
            const button = document.querySelector(`[onclick="toggleLLMScoringJustifications('${id}')"]`);
            
            if (element.style.display === 'none' || element.style.display === '') {
                element.style.display = 'block';
                button.innerHTML = 'Hide Justification ▲';
            } else {
                element.style.display = 'none';
                button.innerHTML = 'Show Justification ▼';
            }
        }
        
        function toggleJustification(id) {
            const element = document.getElementById(id);
            const button = element.previousElementSibling;
            
            if (element.style.display === 'none' || element.style.display === '') {
                element.style.display = 'block';
                button.innerHTML = 'Hide Justification ▲';
            } else {
                element.style.display = 'none';
                button.innerHTML = 'Show Justification ▼';
            }
        }
        
        function toggleLLMDetails(id) {
            const element = document.getElementById(id);
            const button = element.previousElementSibling.querySelector('.llm-toggle');
            
            if (element.style.display === 'none' || element.style.display === '') {
                element.style.display = 'block';
                button.innerHTML = 'Hide Justifications ▲';
            } else {
                element.style.display = 'none';
                button.innerHTML = 'Show Justifications ▼';
            }
        }
        
        function toggleHIndexDetails(id) {
            const element = document.getElementById(id);
            const button = element.previousElementSibling;
            
            if (element.style.display === 'none' || element.style.display === '') {
                element.style.display = 'block';
                button.innerHTML = 'Hide Individual H-indices ▲';
            } else {
                element.style.display = 'none';
                button.innerHTML = 'Show Individual H-indices ▼';
            }
        }
        
        // Basic filtering and sorting functionality
        const papers = [{"abstract": "Recently, diffusion models have garnered significant interest in the field of\ntext processing due to their many potential advantages compared to conventional\nautoregressive models. In this work, we propose Diffusion-of-Thought (DoT), a\nnovel approach that integrates diffusion models with Chain-of-Thought, a\nwell-established technique for improving the reasoning ability of\nautoregressive language models. In contrast to autoregressive language models\nthat make decisions in a left-to-right, token-by-token manner, DoT allows\nreasoning steps to diffuse over time through a diffusion language model and\noffers greater flexibility in trading-off computation for reasoning\nperformance. Our experimental results demonstrate the effectiveness of DoT in\nmulti-digit multiplication, boolean logic, and grade school math problems, with\na small diffusion model outperforming a much larger autoregressive model in\nboth efficiency and accuracy. In addition to that, DoT showcases promising\nself-correction abilities and benefits from existing reasoning-enhancing\ntechniques like self-consistency decoding. Our findings contribute to the\nunderstanding and development of reasoning with diffusion language models.", "arxiv_id": "2402.07754", "arxiv_url": "http://arxiv.org/abs/2402.07754", "author_h_indices": {"author_h_indexes": [{"h_index": 16, "name": "Jiacheng Ye", "semantic_scholar_url": null}, {"h_index": 10, "name": "Shansan Gong", "semantic_scholar_url": null}, {"h_index": 6, "name": "Liheng Chen", "semantic_scholar_url": null}, {"h_index": 6, "name": "Lin Zheng", "semantic_scholar_url": null}, {"h_index": 13, "name": "Jiahui Gao", "semantic_scholar_url": null}, {"h_index": 6, "name": "Han Shi", "semantic_scholar_url": null}, {"h_index": 5, "name": "Chuan Wu", "semantic_scholar_url": null}, {"h_index": 6, "name": "Zhenguo Li", "semantic_scholar_url": null}, {"h_index": 4, "name": "Wei Bi", "semantic_scholar_url": null}, {"h_index": 7, "name": "Lingpeng Kong", "semantic_scholar_url": null}], "authors_with_h_index_count": 10, "average_h_index": 7.9, "h_index_fetch_method": "full_id", "highest_h_index": 16, "notable_authors_count": 8, "success": true, "total_authors": 10}, "authors": ["Jiacheng Ye", "Shansan Gong", "Liheng Chen", "Lin Zheng", "Jiahui Gao", "Han Shi", "Chuan Wu", "Xin Jiang", "Zhenguo Li", "Wei Bi", "Lingpeng Kong"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "embedding_completed": true, "h_index_completed": true, "highest_score": 0.753, "highest_similarity_topic": "Diffusion_reasoning", "id": "2402.07754", "llm_scoring_completed": true, "llm_validation": {"Diffusion_reasoning": {"justification": "The paper\u0027s main contribution, Diffusion of Thoughts (DoT), directly adapts the iterative refinement process of diffusion models to enhance Chain-of-Thought reasoning for complex logical tasks. It treats the reasoning path as a dynamic entity that evolves over diffusion timesteps, enabling holistic correction and improvement, as evidenced by experiments on tasks like multi-digit multiplication and grade school math. This aligns precisely with the topic\u0027s definition of multi-step logical reasoning using diffusion models.", "llm_relevant": "Highly Relevant", "validated": true}, "Distributed_training": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}, "RLHF": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}, "Weak_supervision": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}}, "llm_validation_completed": true, "published": "2024-02-12T16:23:28+00:00", "scores": {"Diffusion_reasoning": 0.753, "Distributed_training": 0.38, "RLHF": 0.361, "Weak_supervision": 0.314}, "scores_data": {"impact": "High", "impact_justification": "The work could influence future research and applications in diffusion models for language processing, potentially shifting paradigms away from autoregressive models by demonstrating superior efficiency and reasoning abilities. Its findings on outperforming larger models suggest broad applicability in AI subfields like natural language processing and machine learning.", "novelty": "High", "novelty_justification": "The paper introduces a truly new technique by adapting chain-of-thought reasoning to diffusion models, significantly advancing the state-of-the-art in reasoning for non-autoregressive language models. This integration represents a fresh approach that combines established ideas in a novel way to address limitations in existing models.", "recommendation": "Should Read", "recommendation_justification": "This paper is valuable for researchers and practitioners working on language models and reasoning techniques, as it offers innovative insights into diffusion models. However, as a preliminary study, it may not be essential for those outside the specific subfield of diffusion-based AI.", "summary": "The paper introduces Diffusion-of-Thought (DoT), a novel method that integrates chain-of-thought reasoning with diffusion language models to enhance reasoning capabilities, allowing for parallel processing of reasoning steps over time and offering flexibility in computation-performance trade-offs. The methodology involves progressively updating latent variables in hidden space, using classifier-free guidance, training-time sampling for self-correction, and adapting conditional ODE solvers for faster inference; key findings demonstrate DoT\u0027s superior efficiency and accuracy on tasks like multi-digit multiplication, boolean logic, and grade school math problems, where a smaller diffusion model outperforms a larger autoregressive model, and it benefits from techniques like self-consistency decoding."}, "title": "Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language\n  Models"}, {"abstract": "We introduce the Diffusion Chain of Lateral Thought (DCoLT), a reasoning\nframework for diffusion language models. DCoLT treats each intermediate step in\nthe reverse diffusion process as a latent \u0026quot;thinking\u0026quot; action and optimizes the\nentire reasoning trajectory to maximize the reward on the correctness of the\nfinal answer with outcome-based Reinforcement Learning (RL). Unlike traditional\nChain-of-Thought (CoT) methods that follow a causal, linear thinking process,\nDCoLT allows bidirectional, non-linear reasoning with no strict rule on\ngrammatical correctness amid its intermediate steps of thought. We implement\nDCoLT on two representative Diffusion Language Models (DLMs). First, we choose\nSEDD as a representative continuous-time discrete diffusion model, where its\nconcrete score derives a probabilistic policy to maximize the RL reward over\nthe entire sequence of intermediate diffusion steps. We further consider the\ndiscrete-time masked diffusion language model -- LLaDA, and find that the order\nto predict and unmask tokens plays an essential role to optimize its RL action\nresulting from the ranking-based Unmasking Policy Module (UPM) defined by the\nPlackett-Luce model. Experiments on both math and code generation tasks show\nthat using only public data and 16 H800 GPUs, DCoLT-reinforced DLMs outperform\nother DLMs trained by SFT or RL or even both. Notably, DCoLT-reinforced LLaDA\nboosts its reasoning accuracy by +9.8%, +5.7%, +11.4%, +19.5% on GSM8K, MATH,\nMBPP, and HumanEval.", "arxiv_id": "2505.10446", "arxiv_url": "http://arxiv.org/abs/2505.10446", "author_h_indices": {"author_h_indexes": [{"h_index": 3, "name": "Zemin Huang", "semantic_scholar_url": null}, {"h_index": 2, "name": "Zhiyang Chen", "semantic_scholar_url": null}, {"h_index": 1, "name": "Zijun Wang", "semantic_scholar_url": null}, {"h_index": 2, "name": "Tiancheng Li", "semantic_scholar_url": null}, {"h_index": 4, "name": "Guo-Jun Qi", "semantic_scholar_url": null}], "authors_with_h_index_count": 5, "average_h_index": 2.4, "h_index_fetch_method": "full_id", "highest_h_index": 4, "notable_authors_count": 0, "success": true, "total_authors": 5}, "authors": ["Zemin Huang", "Zhiyang Chen", "Zijun Wang", "Tiancheng Li", "Guo-Jun Qi"], "categories": ["cs.CL"], "embedding_completed": true, "h_index_completed": true, "highest_score": 0.736, "highest_similarity_topic": "Diffusion_reasoning", "id": "2505.10446", "llm_scoring_completed": true, "llm_validation": {"Diffusion_reasoning": {"justification": "The paper introduces DCoLT, a framework that adapts the reverse diffusion process in language models for multi-step logical reasoning, treating the entire reasoning trajectory as a single entity for optimization. This directly aligns with diffusion-based reasoning by enabling iterative refinement, non-linear thinking, and holistic correction for complex tasks like math and code generation.", "llm_relevant": "Highly Relevant", "validated": true}, "Distributed_training": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}, "RLHF": {"justification": "The paper uses outcome-based reinforcement learning with a rule-based reward to optimize diffusion models, focusing on the correctness of final answers. It does not involve human feedback, a separate reward model trained on human-ranked data, or any alignment with human preferences, which are core to RLHF.", "llm_relevant": "Not Relevant", "validated": true}, "Weak_supervision": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}}, "llm_validation_completed": true, "published": "2025-05-15T16:06:32+00:00", "scores": {"Diffusion_reasoning": 0.736, "Distributed_training": 0.393, "RLHF": 0.458, "Weak_supervision": 0.384}, "scores_data": {"impact": "Moderate", "impact_justification": "The work is likely to be cited and built upon in the subfield of diffusion language models and reasoning tasks due to its demonstrated performance improvements, though its influence may be limited to specialized applications rather than widespread commercial or research domains.", "novelty": "High", "novelty_justification": "The paper introduces a truly new framework, DCoLT, which combines diffusion models with reinforcement learning for non-linear reasoning, representing a significant advancement over traditional linear Chain-of-Thought methods.", "recommendation": "Should Read", "recommendation_justification": "This paper offers valuable innovations for researchers specifically working on diffusion language models and reasoning, providing practical insights and results that could enhance related studies.", "summary": "The paper introduces the Diffusion Chain of Lateral Thought (DCoLT), a novel reasoning framework for diffusion language models that enables bidirectional, non-linear thinking by treating intermediate diffusion steps as latent actions optimized via reinforcement learning to maximize the accuracy of final answers. By implementing DCoLT on models like SEDD (continuous-time) and LLaDA (discrete-time), the authors demonstrate significant performance improvements on math and code generation tasks, such as achieving up to +19.5% accuracy gains on benchmarks like GSM8K, MATH, MBPP, and HumanEval, using only public data and modest computational resources."}, "title": "Reinforcing the Diffusion Chain of Lateral Thought with Diffusion\n  Language Models"}, {"abstract": "Fine-tuning large language models (LLMs) to align with user preferences is\nchallenging due to the high cost of quality human annotations in Reinforcement\nLearning from Human Feedback (RLHF) and the generalizability limitations of AI\nFeedback. To address these challenges, we propose RLTHF, a human-AI hybrid\nframework that combines LLM-based initial alignment with selective human\nannotations to achieve full-human annotation alignment with minimal effort.\nRLTHF identifies hard-to-annotate samples mislabeled by LLMs using a reward\nmodel\u0026#x27;s reward distribution and iteratively enhances alignment by integrating\nstrategic human corrections while leveraging LLM\u0026#x27;s correctly labeled samples.\nEvaluations on HH-RLHF and TL;DR datasets show that RLTHF reaches full-human\nannotation-level alignment with only 6-7% of the human annotation effort.\nFurthermore, models trained on RLTHF\u0026#x27;s curated datasets for downstream tasks\noutperform those trained on fully human-annotated datasets, underscoring the\neffectiveness of RLTHF\u0026#x27;s strategic data curation.", "arxiv_id": "2502.13417", "arxiv_url": "http://arxiv.org/abs/2502.13417", "author_h_indices": {"author_h_indexes": [{"h_index": 2, "name": "Yifei Xu", "semantic_scholar_url": null}, {"h_index": 6, "name": "Tusher Chakraborty", "semantic_scholar_url": null}, {"h_index": 5, "name": "Emre Kiciman", "semantic_scholar_url": null}, {"h_index": 1, "name": "Bibek Aryal", "semantic_scholar_url": null}, {"h_index": 1, "name": "Eduardo Rodrigues", "semantic_scholar_url": null}, {"h_index": 1, "name": "Srinagesh Sharma", "semantic_scholar_url": null}, {"h_index": 2, "name": "Roberto Estev\u00e3o", "semantic_scholar_url": null}, {"h_index": 5, "name": "M. A. D. L. Balaguer", "semantic_scholar_url": null}, {"h_index": 1, "name": "Jessica Wolk", "semantic_scholar_url": null}, {"h_index": 2, "name": "Rafael Padilha", "semantic_scholar_url": null}, {"h_index": 3, "name": "Leonardo Nunes", "semantic_scholar_url": null}, {"h_index": 1, "name": "Shobana Balakrishnan", "semantic_scholar_url": null}, {"h_index": 2, "name": "Songwu Lu", "semantic_scholar_url": null}, {"h_index": 4, "name": "Ranveer Chandra", "semantic_scholar_url": null}], "authors_with_h_index_count": 14, "average_h_index": 2.5714285714285716, "h_index_fetch_method": "full_id", "highest_h_index": 6, "notable_authors_count": 1, "success": true, "total_authors": 14}, "authors": ["Yifei Xu", "Tusher Chakraborty", "Emre K\u0131c\u0131man", "Bibek Aryal", "Eduardo Rodrigues", "Srinagesh Sharma", "Roberto Estevao", "Maria Angels de Luis Balaguer", "Jessica Wolk", "Rafael Padilha", "Leonardo Nunes", "Shobana Balakrishnan", "Songwu Lu", "Ranveer Chandra"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "embedding_completed": true, "h_index_completed": true, "highest_score": 0.718, "highest_similarity_topic": "RLHF", "id": "2502.13417", "llm_scoring_completed": true, "llm_validation": {"Diffusion_reasoning": {"justification": "The paper does not involve diffusion models, iterative refinement for logical tasks, or Chain-of-Thought processes; it centers on RLHF and annotation strategies without any multi-step reasoning via diffusion.", "llm_relevant": "Not Relevant", "validated": true}, "Distributed_training": {"justification": "The paper does not discuss parallel computing, multi-node systems, or strategies for partitioning data/computation; it focuses solely on data annotation and alignment for LLMs.", "llm_relevant": "Not Relevant", "validated": true}, "RLHF": {"justification": "The paper directly builds on RLHF by proposing RLTHF, a framework that enhances RLHF processes through targeted human feedback and reward models to align LLMs with human preferences. It addresses RLHF challenges like annotation costs, making it a core extension of the topic.", "llm_relevant": "Highly Relevant", "validated": true}, "Weak_supervision": {"justification": "The paper uses LLM-generated labels as a noisy, programmatic source for initial annotations, which aligns with weak supervision by reducing reliance on perfect hand-labeled data. However, it focuses more on RLHF integration than pure weak supervision techniques.", "llm_relevant": "Moderately Relevant", "validated": true}}, "llm_validation_completed": true, "published": "2025-02-19T04:25:11+00:00", "scores": {"Diffusion_reasoning": 0.409, "Distributed_training": 0.411, "RLHF": 0.718, "Weak_supervision": 0.472}, "scores_data": {"impact": "Moderate", "impact_justification": "The work is likely to influence research and applications in LLM fine-tuning by reducing annotation costs, potentially leading to more efficient AI development practices within subfields like machine learning and natural language processing.", "novelty": "Moderate", "novelty_justification": "The paper presents a clever combination of existing RLHF and RLAIF techniques by introducing targeted human feedback based on reward model analysis, offering a notable improvement in efficiency for LLM alignment without introducing an entirely new problem or architecture.", "recommendation": "Should Read", "recommendation_justification": "This paper provides valuable insights and methods for researchers working on LLM alignment and human-AI feedback, making it essential for those in the specific area but not broadly critical for the entire field.", "summary": "The paper introduces RLTHF, a hybrid framework for aligning large language models (LLMs) with user preferences by combining initial LLM-based annotations with targeted human feedback on hard-to-annotate samples. It uses a reward model\u0027s distribution to identify potential errors, iteratively refines the dataset with minimal human effort, and demonstrates that RLTHF achieves full-human annotation quality using only 6-7% of the annotations, while models trained on its curated datasets outperform those on fully human-annotated ones in downstream tasks."}, "title": "RLTHF: Targeted Human Feedback for LLM Alignment"}, {"abstract": "Reinforcement learning from human feedback (RLHF) has emerged as a key\ntechnique for aligning the output of large language models (LLMs) with human\npreferences. To learn the reward function, most existing RLHF algorithms use\nthe Bradley-Terry model, which relies on assumptions about human preferences\nthat may not reflect the complexity and variability of real-world judgments. In\nthis paper, we propose a robust algorithm to enhance the performance of\nexisting approaches under such reward model misspecifications. Theoretically,\nour algorithm reduces the variance of reward and policy estimators, leading to\nimproved regret bounds. Empirical evaluations on LLM benchmark datasets\ndemonstrate that the proposed algorithm consistently outperforms existing\nmethods, with 77-81% of responses being favored over baselines on the Anthropic\nHelpful and Harmless dataset.", "arxiv_id": "2504.03784", "arxiv_url": "http://arxiv.org/abs/2504.03784", "author_h_indices": {"author_h_indexes": [{"h_index": 1, "name": "Kai Ye", "semantic_scholar_url": null}, {"h_index": 1, "name": "Hongyi Zhou", "semantic_scholar_url": null}, {"h_index": 1, "name": "Jin Zhu", "semantic_scholar_url": null}, {"h_index": 1, "name": "Francesco Quinzan", "semantic_scholar_url": null}, {"h_index": 2, "name": "Chengchun Shi", "semantic_scholar_url": null}], "authors_with_h_index_count": 5, "average_h_index": 1.2, "h_index_fetch_method": "title_search", "highest_h_index": 2, "notable_authors_count": 0, "success": true, "total_authors": 5}, "authors": ["Kai Ye", "Hongyi Zhou", "Jin Zhu", "Francesco Quinzan", "Chengchun Shi"], "categories": ["stat.ML", "cs.AI", "cs.LG"], "embedding_completed": true, "h_index_completed": true, "highest_score": 0.689, "highest_similarity_topic": "RLHF", "id": "2504.03784", "llm_scoring_completed": true, "llm_validation": {"Diffusion_reasoning": {"justification": "The paper does not involve diffusion models, iterative refinement for logical tasks, or multi-step reasoning processes; it is centered on RLHF and preference optimization for LLMs.", "llm_relevant": "Not Relevant", "validated": true}, "Distributed_training": {"justification": "The paper does not address parallel computing, multi-node setups, or strategies for partitioning data/computation; it is solely about improving RLHF algorithms algorithmically.", "llm_relevant": "Not Relevant", "validated": true}, "RLHF": {"justification": "The paper\u0027s main contribution is the development of a robust RLHF algorithm (VRPO) for fine-tuning LLMs, directly addressing challenges in aligning AI models with human preferences through human feedback. It builds on existing RLHF methods, analyzes reward models, and demonstrates empirical improvements, making it core to this topic.", "llm_relevant": "Highly Relevant", "validated": true}, "Weak_supervision": {"justification": "The paper focuses on direct human feedback for RLHF, such as pairwise comparisons, rather than programmatically generating noisy labels from high-level sources, which is the essence of weak supervision.", "llm_relevant": "Not Relevant", "validated": true}}, "llm_validation_completed": true, "published": "2025-04-03T16:16:35+00:00", "scores": {"Diffusion_reasoning": 0.402, "Distributed_training": 0.416, "RLHF": 0.689, "Weak_supervision": 0.434}, "scores_data": {"impact": "Moderate", "impact_justification": "The work is likely to be cited and built upon in the subfield of LLM alignment and RLHF due to its practical enhancements in handling real-world preference complexities, potentially influencing future algorithms for more reliable AI systems.", "novelty": "Moderate", "novelty_justification": "The paper presents a notable improvement by introducing VRPO as a clever combination of existing RLHF techniques to handle reward model misspecifications, advancing the field without introducing an entirely new problem or architecture.", "recommendation": "Should Read", "recommendation_justification": "This paper is valuable for researchers specifically working on RLHF and LLM fine-tuning, offering theoretical and empirical insights into improving model robustness, though it may not be essential for those outside this niche.", "summary": "This paper introduces Variance-Reduced Preference Optimization (VRPO), a robust framework for Reinforcement Learning from Human Feedback (RLHF) in fine-tuning large language models, addressing limitations in traditional reward models like the Bradley-Terry model by handling misspecifications such as intransitive preferences and context dependence. The methodology leverages a known reference policy and an auxiliary preference model to reduce variance and mean squared error in estimators, leading to improved regret bounds and policy performance; empirical evaluations on datasets like Anthropic Helpful and Harmless demonstrate superior results, with 77-81% of responses preferred over baselines."}, "title": "Robust Reinforcement Learning from Human Feedback for Large Language\n  Models Fine-Tuning"}, {"abstract": "Deep learning models are yielding increasingly better performances thanks to\nmultiple factors. To be successful, model may have large number of parameters\nor complex architectures and be trained on large dataset. This leads to large\nrequirements on computing resource and turn around time, even more so when\nhyper-parameter optimization is done (e.g search over model architectures).\nWhile this is a challenge that goes beyond particle physics, we review the\nvarious ways to do the necessary computations in parallel, and put it in the\ncontext of high energy physics.", "arxiv_id": "2012.01839", "arxiv_url": "http://arxiv.org/abs/2012.01839", "author_h_indices": {"author_h_indexes": [{"h_index": 114, "name": "J. Vlimant", "semantic_scholar_url": null}, {"h_index": 18, "name": "Junqi Yin", "semantic_scholar_url": null}], "authors_with_h_index_count": 2, "average_h_index": 66.0, "h_index_fetch_method": "full_id", "highest_h_index": 114, "notable_authors_count": 2, "success": true, "total_authors": 2}, "authors": ["Jean-Roch Vlimant", "Junqi Yin"], "categories": ["cs.LG"], "embedding_completed": true, "h_index_completed": true, "highest_score": 0.685, "highest_similarity_topic": "Distributed_training", "id": "2012.01839", "llm_scoring_completed": true, "llm_validation": {"Diffusion_reasoning": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}, "Distributed_training": {"justification": "The paper\u0027s main contribution is a comprehensive review and guide to distributed training techniques for neural networks, including parameter distribution, data distribution, and model parallelism. These directly align with the topic\u0027s focus on parallel computing and multi-node machine learning, as they involve partitioning data, model architecture, and computations across multiple processors or nodes to accelerate training, particularly in contexts like high energy physics.", "llm_relevant": "Highly Relevant", "validated": true}, "RLHF": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}, "Weak_supervision": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}}, "llm_validation_completed": true, "published": "2020-12-03T11:18:46+00:00", "scores": {"Diffusion_reasoning": 0.364, "Distributed_training": 0.685, "RLHF": 0.371, "Weak_supervision": 0.381}, "scores_data": {"impact": "Moderate", "impact_justification": "The work is likely to be cited and built upon by researchers in high energy physics and related subfields dealing with deep learning, as it offers practical guidance for accelerating training processes.", "novelty": "Moderate", "novelty_justification": "The paper presents a notable improvement by combining and adapting existing distributed training techniques to the specific context of high energy physics, making them more accessible for that field, though it does not introduce entirely new problems or architectures.", "recommendation": "Should Read", "recommendation_justification": "This paper is valuable for those specifically working on distributed training in high energy physics or similar domains, as it provides a useful overview and practical insights, but it is not essential for the broader machine learning community.", "summary": "This paper reviews and discusses strategies for distributed training and optimization of neural networks, particularly in the context of high energy physics, to address challenges posed by large models, datasets, and computing constraints. It outlines key methodologies such as parameter distribution, data distribution, model parallelism, and hyper-parameter optimization, providing a practical guide to reduce training times and facilitate the development of complex models, while highlighting the limitations in HEP environments like budget constraints on hardware."}, "title": "Distributed Training and Optimization Of Neural Networks"}, {"abstract": "Recent large language models (LLMs) have demonstrated strong reasoning\ncapabilities that benefits from online reinforcement learning (RL). These\ncapabilities have primarily been demonstrated within the left-to-right\nautoregressive (AR) generation paradigm. In contrast, non-autoregressive\nparadigms based on diffusion generate text in a coarse-to-fine manner. Although\nrecent diffusion-based large language models (dLLMs) have achieved competitive\nlanguage modeling performance compared to their AR counterparts, it remains\nunclear if dLLMs can also leverage recent advances in LLM reasoning. To this\nend, we propose d1, a framework to adapt pre-trained masked dLLMs into\nreasoning models via a combination of supervised finetuning (SFT) and RL.\nSpecifically, we develop and extend techniques to improve reasoning in\npretrained dLLMs: (a) we utilize a masked SFT technique to distill knowledge\nand instill self-improvement behavior directly from existing datasets, and (b)\nwe introduce a novel critic-free, policy-gradient based RL algorithm called\ndiffu-GRPO, the first integration of policy gradient methods to masked dLLMs.\nThrough empirical studies, we investigate the performance of different\npost-training recipes on multiple mathematical and planning benchmarks. We find\nthat d1 yields the best performance and significantly improves performance of a\nstate-of-the-art dLLM. Our code is released at\nhttps://dllm-reasoning.github.io/.", "arxiv_id": "2504.12216", "arxiv_url": "http://arxiv.org/abs/2504.12216", "author_h_indices": {"author_h_indexes": [{"h_index": 6, "name": "Siyan Zhao", "semantic_scholar_url": null}, {"h_index": 1, "name": "Devaansh Gupta", "semantic_scholar_url": null}, {"h_index": 10, "name": "Qinqing Zheng", "semantic_scholar_url": null}, {"h_index": 3, "name": "Aditya Grover", "semantic_scholar_url": null}], "authors_with_h_index_count": 4, "average_h_index": 5.0, "h_index_fetch_method": "full_id", "highest_h_index": 10, "notable_authors_count": 2, "success": true, "total_authors": 4}, "authors": ["Siyan Zhao", "Devaansh Gupta", "Qinqing Zheng", "Aditya Grover"], "categories": ["cs.CL", "cs.LG"], "embedding_completed": true, "h_index_completed": true, "highest_score": 0.677, "highest_similarity_topic": "Diffusion_reasoning", "id": "2504.12216", "llm_scoring_completed": true, "llm_validation": {"Diffusion_reasoning": {"justification": "The paper\u0027s main contribution is d1, a framework that adapts diffusion-based models (dLLMs) for reasoning tasks through iterative denoising and refinement processes, treating reasoning paths holistically across multiple steps for tasks like math and planning. This directly aligns with diffusion-based reasoning, as it enhances multi-step logical refinement in non-autoregressive models.", "llm_relevant": "Highly Relevant", "validated": true}, "Distributed_training": {"justification": "The paper focuses on post-training techniques like SFT and RL for dLLMs, with no discussion of distributed training, parallel computing, multi-node setups, or strategies for partitioning data/computation across processors. Its contributions are centered on model adaptation for reasoning, not training acceleration methods.", "llm_relevant": "Not Relevant", "validated": true}, "RLHF": {"justification": "The paper uses reinforcement learning (RL) via diffu-GRPO to fine-tune dLLMs for reasoning tasks, involving reward signals for optimization. However, it does not specify the use of human feedback, a separate reward model trained on human-ranked data, or alignment with human preferences, focusing instead on general RL from benchmarks and datasets. Thus, it relates to RL but not the core elements of RLHF.", "llm_relevant": "Tangentially Relevant", "validated": true}, "Weak_supervision": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}}, "llm_validation_completed": true, "published": "2025-04-16T16:08:45+00:00", "scores": {"Diffusion_reasoning": 0.677, "Distributed_training": 0.417, "RLHF": 0.461, "Weak_supervision": 0.378}, "scores_data": {"impact": "Moderate", "impact_justification": "The work is likely to be cited and built upon in the subfield of diffusion-based LLMs and RL techniques, as it demonstrates practical improvements in reasoning tasks, though its influence may be limited to specific areas rather than widespread commercial applications.", "novelty": "High", "novelty_justification": "The paper introduces a novel RL algorithm, diffu-GRPO, specifically adapted for masked dLLMs, which addresses a previously unexplored application of policy gradient methods to non-autoregressive models, representing a significant advancement in the field.", "recommendation": "Should Read", "recommendation_justification": "This paper offers valuable insights and methods for researchers working on non-autoregressive LLMs and reasoning enhancements, making it worthwhile for those in the specific subfield, though not essential for the broader AI community.", "summary": "The paper introduces d1, a two-stage framework to enhance reasoning capabilities in diffusion large language models (dLLMs) by first applying supervised finetuning (SFT) to distill knowledge from datasets and then using a novel reinforcement learning algorithm, diffu-GRPO, adapted for masked dLLMs. Through experiments on mathematical and planning benchmarks, d1 significantly outperforms baseline dLLMs and other variants, demonstrating substantial improvements in reasoning performance and paving the way for RL applications in non-autoregressive models."}, "title": "d1: Scaling Reasoning in Diffusion Large Language Models via\n  Reinforcement Learning"}, {"abstract": "Labeled datasets are essential for modern search engines, which increasingly\nrely on supervised learning methods like Learning to Rank and massive amounts\nof data to power deep learning models. However, creating these datasets is both\ntime-consuming and costly, leading to the common use of user click and activity\nlogs as proxies for relevance. In this paper, we present a weak supervision\napproach to infer the quality of query-document pairs and apply it within a\nLearning to Rank framework to enhance the precision of a large-scale search\nsystem.", "arxiv_id": "2503.07025", "arxiv_url": "http://arxiv.org/abs/2503.07025", "author_h_indices": {"author_h_indexes": [{"h_index": 1, "name": "Sriram Vasudevan", "semantic_scholar_url": null}], "authors_with_h_index_count": 1, "average_h_index": 1.0, "h_index_fetch_method": "full_id", "highest_h_index": 1, "notable_authors_count": 0, "success": true, "total_authors": 1}, "authors": ["Sriram Vasudevan"], "categories": ["cs.IR", "cs.AI", "cs.LG"], "embedding_completed": true, "h_index_completed": true, "highest_score": 0.674, "highest_similarity_topic": "Weak_supervision", "id": "2503.07025", "llm_scoring_completed": true, "llm_validation": {"Diffusion_reasoning": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}, "Distributed_training": {"justification": "The paper describes a distributed and scalable weak supervision solution, referencing techniques for aggregation and deployment in production, which touches on parallel computing aspects. However, it does not focus primarily on distributed training algorithms or multi-node optimizations for model training, making it secondary to the weak supervision core.", "llm_relevant": "Moderately Relevant", "validated": true}, "RLHF": {"justification": "The paper focuses on weak supervision for generating labels in a search system, using heuristics and a small set of ground truth labels, but does not involve reinforcement learning, reward models, or fine-tuning based on human preferences. There is no mention of RLHF elements like policy optimization or human-ranked data for rewards.", "llm_relevant": "Not Relevant", "validated": true}, "Weak_supervision": {"justification": "The paper\u0027s main contribution is a weak supervision approach that programmatically generates labels using heuristics and a seed set of ground truth data, aligning directly with the definition of training models from noisy or imprecise sources. It builds on methods like Snorkel to improve label quality for Learning to Rank in search systems.", "llm_relevant": "Highly Relevant", "validated": true}}, "llm_validation_completed": true, "published": "2025-03-10T08:06:30+00:00", "scores": {"Diffusion_reasoning": 0.359, "Distributed_training": 0.412, "RLHF": 0.444, "Weak_supervision": 0.674}, "scores_data": {"impact": "Moderate", "impact_justification": "The work is likely to be cited and built upon in subfields like information retrieval and machine learning, as it provides a practical, scalable solution for improving search precision in industrial applications, though its influence may be limited to specific domains rather than broadly transformative.", "novelty": "Moderate", "novelty_justification": "The paper presents a notable improvement by combining existing weak supervision techniques from Snorkel with a seed set of ground truth labels to refine heuristics, offering a new way to enhance label accuracy in industrial search systems without introducing a entirely novel paradigm.", "recommendation": "Should Read", "recommendation_justification": "This paper is valuable for researchers and practitioners working on search systems or weak supervision, as it offers actionable insights and a real-world deployment example that could inspire similar applications, making it worth reading for those in the specific area.", "summary": "The paper addresses the challenges of creating high-quality labeled datasets for search systems by proposing a weak supervision approach that combines Subject Matter Expert (SME)-authored heuristics with a small seed set of ground truth labels to generate scalable training data. This method is integrated into a Learning to Rank framework, resulting in significant precision improvements when deployed in a large-scale job search system, thereby mitigating issues like reliance on noisy user activity logs and the Matthew Effect."}, "title": "Weak Supervision for Improved Precision in Search Systems"}, {"abstract": "Weak supervision (WS) is a popular approach for label-efficient learning,\nleveraging diverse sources of noisy but inexpensive weak labels to\nautomatically annotate training data. Despite its wide usage, WS and its\npractical value are challenging to benchmark due to the many knobs in its\nsetup, including: data sources, labeling functions (LFs), aggregation\ntechniques (called label models), and end model pipelines. Existing evaluation\nsuites tend to be limited, focusing on particular components or specialized use\ncases. Moreover, they often involve simplistic benchmark tasks or de-facto LF\nsets that are suboptimally written, producing insights that may not generalize\nto real-world settings. We address these limitations by introducing a new\nbenchmark, BOXWRENCH, designed to more accurately reflect real-world usages of\nWS. This benchmark features tasks with (1) higher class cardinality and\nimbalance, (2) notable domain expertise requirements, and (3) opportunities to\nre-use LFs across parallel multilingual corpora. For all tasks, LFs are written\nusing a careful procedure aimed at mimicking real-world settings. In contrast\nto existing WS benchmarks, we show that supervised learning requires\nsubstantial amounts (1000+) of labeled examples to match WS in many settings.", "arxiv_id": "2501.07727", "arxiv_url": "http://arxiv.org/abs/2501.07727", "author_h_indices": {"author_h_indexes": [{"h_index": 0, "name": "Tianyi Zhang", "semantic_scholar_url": null}, {"h_index": 0, "name": "Linrong Cai", "semantic_scholar_url": null}, {"h_index": 0, "name": "Jeffrey Li", "semantic_scholar_url": null}, {"h_index": 2, "name": "Nicholas Roberts", "semantic_scholar_url": null}, {"h_index": 17, "name": "Neel Guha", "semantic_scholar_url": null}, {"h_index": 0, "name": "Jinoh Lee", "semantic_scholar_url": null}, {"h_index": 3, "name": "Frederic Sala", "semantic_scholar_url": null}], "authors_with_h_index_count": 7, "average_h_index": 3.142857142857143, "h_index_fetch_method": "full_id", "highest_h_index": 17, "notable_authors_count": 1, "success": true, "total_authors": 7}, "authors": ["Tianyi Zhang", "Linrong Cai", "Jeffrey Li", "Nicholas Roberts", "Neel Guha", "Jinoh Lee", "Frederic Sala"], "categories": ["cs.LG"], "embedding_completed": true, "h_index_completed": true, "highest_score": 0.668, "highest_similarity_topic": "Weak_supervision", "id": "2501.07727", "llm_scoring_completed": true, "llm_validation": {"Diffusion_reasoning": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}, "Distributed_training": {"justification": "The paper does not discuss distributed training, parallel computing, or multi-node systems; it centers on weak supervision techniques for label generation and benchmarking, without addressing data partitioning or computation acceleration across nodes.", "llm_relevant": "Not Relevant", "validated": true}, "RLHF": {"justification": "The paper focuses on weak supervision for generating labels from noisy sources, with no mention of reinforcement learning, human feedback, reward models, or aligning AI models with human preferences.", "llm_relevant": "Not Relevant", "validated": true}, "Weak_supervision": {"justification": "The paper\u0027s main contribution is to weak supervision, introducing a new benchmark (BOXWRENCH) to evaluate its effectiveness in realistic tasks, discussing labeling functions, label models, and demonstrating its practical value for label-efficient learning.", "llm_relevant": "Highly Relevant", "validated": true}}, "llm_validation_completed": true, "published": "2025-01-13T22:29:31+00:00", "scores": {"Diffusion_reasoning": 0.348, "Distributed_training": 0.405, "RLHF": 0.411, "Weak_supervision": 0.668}, "scores_data": {"impact": "High", "impact_justification": "The work could broadly influence future WS research and applications by providing a more accurate benchmarking framework, potentially leading to improved practices in label-efficient learning across various domains. Its findings challenge previous underestimations of WS, making it likely to be cited and built upon in the machine learning community.", "novelty": "High", "novelty_justification": "The paper introduces a truly new benchmark with realistic tasks that significantly advances WS evaluation by addressing gaps in existing benchmarks, such as incorporating high-cardinality and imbalanced datasets. This represents a substantial innovation in assessing WS\u0027s real-world applicability, moving beyond simplistic prior setups.", "recommendation": "Should Read", "recommendation_justification": "This paper is valuable for researchers and practitioners in weak supervision and machine learning benchmarking, offering practical insights and a new benchmark that could enhance their work. While not essential for the entire field, it is highly relevant for those specifically addressing label-efficient learning.", "summary": "The paper introduces BOXWRENCH, a new benchmark for evaluating weak supervision (WS) in realistic settings, addressing limitations in existing benchmarks by featuring tasks with high class cardinality, imbalance, domain expertise requirements, and multilingual LF reuse opportunities. It employs a careful procedure for designing labeling functions (LFs), improves upon existing ones, and demonstrates through experiments on five text-classification tasks that WS often outperforms supervised learning, which requires over 1000 labeled examples to match WS performance in many cases, highlighting WS\u0027s practical advantages."}, "title": "Stronger Than You Think: Benchmarking Weak Supervision on Realistic\n  Tasks"}, {"abstract": "Reinforcement Learning from Human Feedback (RLHF) is increasingly used to\nalign large language models (LLMs) with human preferences. However, the\neffectiveness of RLHF in addressing underlying biases remains unclear. This\nstudy investigates the relationship between RLHF and both covert and overt\nbiases in LLMs, particularly focusing on biases against African Americans. We\napplied various RLHF techniques (DPO, ORPO, and RLOO) to Llama 3 8B and\nevaluated the covert and overt biases of the resulting models using\nmatched-guise probing and explicit bias testing. We performed additional tests\nwith DPO on different base models and datasets; among several implications, we\nfound that SFT before RLHF calcifies model biases. Additionally, we extend the\ntools for measuring biases to multi-modal models. Through our experiments we\ncollect evidence that indicates that current alignment techniques are\ninadequate for nebulous tasks such as mitigating covert biases, highlighting\nthe need for capable datasets, data curating techniques, or alignment tools.", "arxiv_id": "2503.09025", "arxiv_url": "http://arxiv.org/abs/2503.09025", "author_h_indices": {"authors_with_h_index_count": 0, "average_h_index": null, "highest_h_index": null, "notable_authors_count": 0, "success": false, "total_authors": 0}, "authors": ["Logan Barnhart", "Reza Akbarian Bafghi", "Stephen Becker", "Maziar Raissi"], "categories": ["cs.CL"], "embedding_completed": true, "h_index_completed": false, "highest_score": 0.626, "highest_similarity_topic": "RLHF", "id": "2503.09025", "llm_scoring_completed": true, "llm_validation": {"Diffusion_reasoning": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}, "Distributed_training": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}, "RLHF": {"justification": "The paper\u0027s main contribution directly investigates the effectiveness of RLHF techniques (e.g., DPO, ORPO, and RLOO) in aligning LLMs with human preferences, specifically focusing on bias mitigation. It applies RLHF to models like Llama 3 8B, evaluates outcomes using human feedback-derived methods, and concludes that RLHF has limitations in addressing biases, aligning closely with the topic\u0027s definition of systems using human-ranked data for reinforcement learning-based fine-tuning.", "llm_relevant": "Highly Relevant", "validated": true}, "Weak_supervision": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}}, "llm_validation_completed": true, "published": "2025-03-12T03:24:44+00:00", "scores": {"Diffusion_reasoning": 0.374, "Distributed_training": 0.366, "RLHF": 0.626, "Weak_supervision": 0.392}, "scores_data": {"impact": "Moderate", "impact_justification": "The work is likely to influence research in AI alignment and bias mitigation within the subfield of LLMs, as it reveals critical limitations of RLHF that could guide future improvements. Nonetheless, its applicability is somewhat confined to specific ethical concerns in language models, limiting broader commercial or widespread adoption.", "novelty": "Moderate", "novelty_justification": "The paper presents a notable improvement by empirically examining the impact of RLHF on model biases, which has not been extensively studied, through clever combinations of existing techniques and new dataset curation. However, it builds on prior work in bias evaluation rather than introducing a entirely new problem or architecture.", "recommendation": "Should Read", "recommendation_justification": "This paper is valuable for researchers and practitioners focused on AI ethics, bias in LLMs, and alignment techniques, as it provides insightful empirical evidence on RLHF\u0027s shortcomings. However, it is not essential for those outside this niche, making it skippable for a general audience.", "summary": "This paper investigates the limitations of Reinforcement Learning from Human Feedback (RLHF) in aligning large language models (LLMs) with human preferences, particularly in mitigating covert and overt biases against African Americans. The authors apply RLHF techniques such as DPO, ORPO, and RLOO to models like Llama 3 8B, evaluate biases using matched-guise probing and explicit testing, and extend bias measurement to multi-modal models, finding that RLHF fails to effectively reduce covert biases, with supervised fine-tuning potentially calcifying them, and highlighting the need for improved alignment strategies."}, "title": "Aligning to What? Limits to RLHF Based Alignment"}, {"abstract": "Weak supervision is a popular framework for overcoming the labeled data\nbottleneck: the need to obtain labels for training data. In weak supervision,\nmultiple noisy-but-cheap sources are used to provide guesses of the label and\nare aggregated to produce high-quality pseudolabels. These sources are often\nexpressed as small programs written by domain experts -- and so are expensive\nto obtain. Instead, we argue for using code-generation models to act as coding\nassistants for crafting weak supervision sources. We study prompting strategies\nto maximize the quality of the generated sources, settling on a multi-tier\nstrategy that incorporates multiple types of information. We explore how to\nbest combine hand-written and generated sources. Using these insights, we\nintroduce ScriptoriumWS, a weak supervision system that, when compared to\nhand-crafted sources, maintains accuracy and greatly improves coverage.", "arxiv_id": "2502.12366", "arxiv_url": "http://arxiv.org/abs/2502.12366", "author_h_indices": {"author_h_indexes": [{"h_index": 5, "name": "Tzu-Heng Huang", "semantic_scholar_url": null}, {"h_index": 2, "name": "Catherine Cao", "semantic_scholar_url": null}, {"h_index": 2, "name": "Spencer Schoenberg", "semantic_scholar_url": null}, {"h_index": 8, "name": "Harit Vishwakarma", "semantic_scholar_url": null}, {"h_index": 2, "name": "Nicholas Roberts", "semantic_scholar_url": null}, {"h_index": 3, "name": "Frederic Sala", "semantic_scholar_url": null}], "authors_with_h_index_count": 6, "average_h_index": 3.6666666666666665, "h_index_fetch_method": "full_id", "highest_h_index": 8, "notable_authors_count": 1, "success": true, "total_authors": 6}, "authors": ["Tzu-Heng Huang", "Catherine Cao", "Spencer Schoenberg", "Harit Vishwakarma", "Nicholas Roberts", "Frederic Sala"], "categories": ["cs.LG"], "embedding_completed": true, "h_index_completed": true, "highest_score": 0.621, "highest_similarity_topic": "Weak_supervision", "id": "2502.12366", "llm_scoring_completed": true, "llm_validation": {"Diffusion_reasoning": {"justification": "The paper does not involve diffusion models, iterative refinement processes, or multi-step logical reasoning; it instead centers on code generation for weak supervision tasks.", "llm_relevant": "Not Relevant", "validated": true}, "Distributed_training": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}, "RLHF": {"justification": "The paper focuses on code generation for weak supervision labeling functions and does not involve reinforcement learning, human feedback for training reward models, or aligning AI models with human preferences.", "llm_relevant": "Not Relevant", "validated": true}, "Weak_supervision": {"justification": "The paper\u0027s main contribution is developing ScriptoriumWS, a system that uses code-generation models to create labeling functions for weak supervision, directly addressing the generation of noisy labels from programmatic sources to improve training data efficiency.", "llm_relevant": "Highly Relevant", "validated": true}}, "llm_validation_completed": true, "published": "2025-02-17T23:07:14+00:00", "scores": {"Diffusion_reasoning": 0.424, "Distributed_training": 0.362, "RLHF": 0.43, "Weak_supervision": 0.621}, "scores_data": {"impact": "Moderate", "impact_justification": "The work is likely to be cited and built upon in the subfield of weak supervision and machine learning data labeling, as it offers practical methods to improve efficiency and scalability. However, its influence may be limited to specific applications rather than broadly transforming the field.", "novelty": "Moderate", "novelty_justification": "The paper presents a notable improvement by cleverly combining code-generation models with programmatic weak supervision to automate labeling function creation, addressing the expense of manual coding without introducing an entirely new paradigm. While it builds on existing techniques like code generation and weak supervision, it innovates in their application to enhance efficiency and coverage.", "recommendation": "Should Read", "recommendation_justification": "This paper is valuable for researchers and practitioners working on weak supervision, code generation, or data labeling techniques, as it provides actionable insights and a new system that could enhance their workflows. It is not essential for the broader machine learning community but offers specific benefits for those in related subfields.", "summary": "The paper introduces ScriptoriumWS, a system that utilizes code-generation models to automatically create labeling functions for programmatic weak supervision, aiming to reduce the reliance on manually written code by domain experts. By exploring various prompting strategies and combining generated and hand-written functions, the authors demonstrate that ScriptoriumWS achieves significantly higher data coverage\u2014such as improving from 40.5% to 100% on the SMS dataset and from 25.8% to 100% on the Spouse dataset\u2014while maintaining accuracy and enhancing downstream model performance by up to 5.0% in F1 scores."}, "title": "ScriptoriumWS: A Code Generation Assistant for Weak Supervision"}, {"abstract": "Machine learning models have achieved, and in some cases surpassed,\nhuman-level performance in various tasks, mainly through centralized training\nof static models and the use of large models stored in centralized clouds for\ninference. However, this centralized approach has several drawbacks, including\nprivacy concerns, high storage demands, a single point of failure, and\nsignificant computing requirements. These challenges have driven interest in\ndeveloping alternative decentralized and distributed methods for AI training\nand inference. Distribution introduces additional complexity, as it requires\nmanaging multiple moving parts. To address these complexities and fill a gap in\nthe development of distributed AI systems, this work proposes a novel\nframework, Data and Dynamics-Aware Inference and Training Networks (DA-ITN).\nThe different components of DA-ITN and their functions are explored, and the\nassociated challenges and research areas are highlighted.", "arxiv_id": "2501.05323", "arxiv_url": "http://arxiv.org/abs/2501.05323", "author_h_indices": {"author_h_indexes": [{"h_index": 7, "name": "Hesham G. Moussa", "semantic_scholar_url": null}, {"h_index": 3, "name": "Arashmid Akhavain", "semantic_scholar_url": null}, {"h_index": 1, "name": "S. M. Hosseini", "semantic_scholar_url": null}, {"h_index": 1, "name": "Bill McCormick", "semantic_scholar_url": null}], "authors_with_h_index_count": 4, "average_h_index": 3.0, "h_index_fetch_method": "full_id", "highest_h_index": 7, "notable_authors_count": 1, "success": true, "total_authors": 4}, "authors": ["Hesham G. Moussa", "Arashmid Akhavain", "S. Maryam Hosseini", "Bill McCormick"], "categories": ["cs.LG", "cs.NI"], "embedding_completed": true, "h_index_completed": true, "highest_score": 0.594, "highest_similarity_topic": "Distributed_training", "id": "2501.05323", "llm_scoring_completed": true, "llm_validation": {"Diffusion_reasoning": {"justification": "The paper proposes a framework for distributed AI systems and mentions training and inference, but it does not involve diffusion models, iterative refinement for logical reasoning, or multi-step chain-of-thought processes.", "llm_relevant": "Not Relevant", "validated": true}, "Distributed_training": {"justification": "The paper\u0027s main contribution is a framework for distributed AI systems, including methods like federated learning and gossip learning, which directly align with distributed training, parallel computing, and multi-node machine learning for optimizing training across networked nodes.", "llm_relevant": "Highly Relevant", "validated": true}, "RLHF": {"justification": "The paper focuses on distributed and decentralized AI systems, proposing a framework for training and inference from a networking perspective, but it does not involve human feedback, reward models, or reinforcement learning techniques for aligning AI with human preferences.", "llm_relevant": "Not Relevant", "validated": true}, "Weak_supervision": {"justification": "The paper discusses distributed training and inference methods, such as federated learning, but it does not address programmatically generating labels from noisy sources or techniques for weak supervision in machine learning.", "llm_relevant": "Not Relevant", "validated": true}}, "llm_validation_completed": true, "published": "2025-01-09T15:48:29+00:00", "scores": {"Diffusion_reasoning": 0.45, "Distributed_training": 0.594, "RLHF": 0.415, "Weak_supervision": 0.418}, "scores_data": {"impact": "Moderate", "impact_justification": "The work is likely to be cited and built upon in the subfield of distributed AI and networking, as DA-ITN provides a structured approach for future developments in areas like edge computing and federated learning.", "novelty": "Moderate", "novelty_justification": "The paper presents a notable improvement by integrating existing decentralized AI techniques into a unified framework called DA-ITN, offering a clever combination to address gaps in distributed systems, though it does not introduce an entirely new problem or technique.", "recommendation": "Should Read", "recommendation_justification": "This paper is valuable for researchers specifically in distributed learning and networking due to its innovative framework and insights into decentralized AI challenges, but it is not essential for those outside this niche.", "summary": "This paper examines the limitations of centralized machine learning systems, such as privacy risks, high computational costs, and single points of failure, and advocates for decentralized alternatives to enhance scalability and efficiency. It introduces a novel framework called Data and Dynamics-Aware Inference and Training Networks (DA-ITN), which optimizes the \"model-follow-data\" paradigm by managing interactions between distributed data, models, and compute resources across networked nodes, while outlining its components, a practical example, potential implementations, and future research challenges."}, "title": "Distributed Learning and Inference Systems: A Networking Perspective"}, {"abstract": "Training large language models is generally done via optimization methods on\nclusters containing tens of thousands of accelerators, communicating over a\nhigh-bandwidth interconnect. Scaling up these clusters is expensive and can\nbecome impractical, imposing limits on the size of models that can be trained.\nSeveral recent studies have proposed training methods that are less\ncommunication intensive, avoiding the need for a highly connected compute\ncluster. These state-of-the-art low communication training methods still employ\na synchronization step for model parameters, which, when performed over all\nmodel replicas, can become costly on a low-bandwidth network.\n  In this work, we propose a novel optimization method, NoLoCo, that does not\nexplicitly synchronize all model parameters during training and, as a result,\ndoes not require any collective communication. NoLoCo implicitly synchronizes\nmodel weights via a novel variant of the Nesterov momentum optimizer by\npartially averaging model weights with a randomly selected other one. We\nprovide both a theoretical convergence analysis for our proposed optimizer as\nwell as empirical results from language model training.\n  We benchmark NoLoCo on a wide range of accelerator counts and model sizes,\nbetween 125M to 6.8B parameters. Our method requires significantly less\ncommunication overhead than fully sharded data parallel training or even widely\nused low communication training method, DiLoCo. The synchronization step itself\nis estimated to be one magnitude faster than the all-reduce used in DiLoCo for\nfew hundred accelerators training over the internet. We also do not have any\nglobal blocking communication that reduces accelerator idling time. Compared to\nDiLoCo, we also observe up to $4\\%$ faster convergence rate with wide range of\nmodel sizes and accelerator counts.", "arxiv_id": "2506.10911", "arxiv_url": "http://arxiv.org/abs/2506.10911", "author_h_indices": {"author_h_indexes": [{"h_index": 22, "name": "J. Kolehmainen", "semantic_scholar_url": null}, {"h_index": 1, "name": "Nikolay Blagoev", "semantic_scholar_url": null}, {"h_index": 1, "name": "John Donaghy", "semantic_scholar_url": null}, {"h_index": 2, "name": "Ouguzhan Ersoy", "semantic_scholar_url": null}, {"h_index": 0, "name": "Christopher Nies", "semantic_scholar_url": null}], "authors_with_h_index_count": 5, "average_h_index": 5.2, "h_index_fetch_method": "full_id", "highest_h_index": 22, "notable_authors_count": 1, "success": true, "total_authors": 5}, "authors": ["Jari Kolehmainen", "Nikolay Blagoev", "John Donaghy", "O\u011fuzhan Ersoy", "Christopher Nies"], "categories": ["cs.LG"], "embedding_completed": true, "h_index_completed": true, "highest_score": 0.565, "highest_similarity_topic": "Distributed_training", "id": "2506.10911", "llm_scoring_completed": true, "llm_validation": {"Diffusion_reasoning": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}, "Distributed_training": {"justification": "The paper\u0027s main contribution is a novel optimization method, NoLoCo, designed for distributed training of large models. It addresses key challenges in distributed training by reducing communication overhead through implicit synchronization and avoiding all-reduce operations, which directly aligns with topics like parallel computing and multi-node machine learning. The method involves partitioning computation across accelerators and focuses on accelerating training by minimizing network bottlenecks, making it a direct advancement in distributed training algorithms.", "llm_relevant": "Highly Relevant", "validated": true}, "RLHF": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}, "Weak_supervision": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}}, "llm_validation_completed": true, "published": "2025-06-12T17:23:23+00:00", "scores": {"Diffusion_reasoning": 0.373, "Distributed_training": 0.565, "RLHF": 0.348, "Weak_supervision": 0.364}, "scores_data": {"impact": "Moderate", "impact_justification": "The work is likely to be cited and built upon in the subfield of distributed machine learning, as it addresses practical challenges in scaling model training over low-bandwidth networks. However, its influence may be limited to specific applications rather than broader fields.", "novelty": "High", "novelty_justification": "The paper introduces a truly new technique by proposing an optimization method that completely avoids collective communication, significantly advancing the state-of-the-art in low-communication training for large models.", "recommendation": "Should Read", "recommendation_justification": "This paper offers valuable insights and methods for researchers working on distributed training and large model optimization, making it worthwhile for those in the specific subfield. It is not essential for the broader audience outside of machine learning efficiency topics.", "summary": "The paper introduces NoLoCo, a novel optimization method for training large language models that eliminates explicit all-reduce synchronization by implicitly averaging model weights with randomly selected peers using a modified Nesterov momentum optimizer. Through theoretical convergence analysis and empirical benchmarks on models from 125M to 6.8B parameters, the authors demonstrate that NoLoCo reduces communication overhead, achieves up to 4% faster convergence than methods like DiLoCo, and improves efficiency in low-bandwidth distributed training environments."}, "title": "NoLoCo: No-all-reduce Low Communication Training Method for Large Models"}, {"abstract": "Obtaining high-quality labeled datasets is often costly, requiring either\nextensive human annotation or expensive experiments. We propose a method that\nsupplements such \u0026quot;expert\u0026quot; labels with AI predictions from pre-trained models to\nconstruct labeled datasets more cost-effectively. Our approach results in\nprobably approximately correct labels: with high probability, the overall\nlabeling error is small. This solution enables rigorous yet efficient dataset\ncuration using modern AI models. We demonstrate the benefits of the methodology\nthrough text annotation with large language models, image labeling with\npre-trained vision models, and protein folding analysis with AlphaFold.", "arxiv_id": "2506.10908", "arxiv_url": "http://arxiv.org/abs/2506.10908", "author_h_indices": {"author_h_indexes": [{"h_index": 5, "name": "Emmanuel J. Candes", "semantic_scholar_url": null}, {"h_index": 0, "name": "Andrew Ilyas", "semantic_scholar_url": null}, {"h_index": 15, "name": "Tijana Zrnic", "semantic_scholar_url": null}], "authors_with_h_index_count": 3, "average_h_index": 6.666666666666667, "h_index_fetch_method": "full_id", "highest_h_index": 15, "notable_authors_count": 1, "success": true, "total_authors": 3}, "authors": ["Emmanuel J. Cand\u00e8s", "Andrew Ilyas", "Tijana Zrnic"], "categories": ["stat.ML", "cs.LG"], "embedding_completed": true, "h_index_completed": true, "highest_score": 0.553, "highest_similarity_topic": "Weak_supervision", "id": "2506.10908", "llm_scoring_completed": true, "llm_validation": {"Diffusion_reasoning": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}, "Distributed_training": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}, "RLHF": {"justification": "The paper focuses on creating labeled datasets by combining expert labels with AI predictions to minimize errors, without involving reinforcement learning or human feedback for model alignment. It does not train a reward model or use RL to fine-tune AI based on human preferences, which are core to RLHF.", "llm_relevant": "Not Relevant", "validated": true}, "Weak_supervision": {"justification": "The paper\u0027s main contribution involves using AI predictions as noisy or imprecise labels to supplement expert labels, enabling cost-effective dataset creation with guarantees on error rates. This directly aligns with weak supervision, which relies on programmatically generated, imperfect labels rather than fully hand-labeled data, as evidenced by the method\u0027s use of pre-trained models for labeling.", "llm_relevant": "Highly Relevant", "validated": true}}, "llm_validation_completed": true, "published": "2025-06-12T17:16:26+00:00", "scores": {"Diffusion_reasoning": 0.357, "Distributed_training": 0.395, "RLHF": 0.447, "Weak_supervision": 0.553}, "scores_data": {"impact": "Moderate", "impact_justification": "The work is likely to be cited and built upon in subfields like machine learning and data annotation, as it addresses practical challenges in dataset curation and could enhance efficiency in various applications.", "novelty": "Moderate", "novelty_justification": "The paper presents a notable improvement by cleverly combining PAC learning principles with active learning techniques to efficiently label datasets, offering a new way to balance cost and accuracy without introducing entirely novel concepts.", "recommendation": "Should Read", "recommendation_justification": "This paper offers valuable insights and methods for researchers working on data labeling and AI-assisted techniques, making it essential for those specifically in machine learning and statistical fields.", "summary": "This paper introduces a method called Probably Approximately Correct (PAC) labeling, which aims to create high-quality labeled datasets by combining expensive expert labels with cheap AI predictions, minimizing costs while ensuring that the overall labeling error is at most a specified \u03b5 with probability at least 1-\u03b4. The methodology involves querying experts only for instances where AI models are uncertain, and it is demonstrated through applications in text annotation, image labeling, and protein folding analysis, providing guarantees on error rates and significant cost savings."}, "title": "Probably Approximately Correct Labels"}, {"abstract": "Latent Diffusion Models have shown remarkable results in text-guided image\nsynthesis in recent years. In the domain of natural (RGB) images, recent works\nhave shown that such models can be adapted to various vision-language\ndownstream tasks with little to no supervision involved. On the contrary,\ntext-to-image Latent Diffusion Models remain relatively underexplored in the\nfield of medical imaging, primarily due to limited data availability (e.g., due\nto privacy concerns). In this work, focusing on the chest X-ray modality, we\nfirst demonstrate that a standard text-conditioned Latent Diffusion Model has\nnot learned to align clinically relevant information in free-text radiology\nreports with the corresponding areas of the given scan. Then, to alleviate this\nissue, we propose a fine-tuning framework to improve multi-modal alignment in a\npre-trained model such that it can be efficiently repurposed for downstream\ntasks such as phrase grounding. Our method sets a new state-of-the-art on a\nstandard benchmark dataset (MS-CXR), while also exhibiting robust performance\non out-of-distribution data (VinDr-CXR). Our code will be made publicly\navailable.", "arxiv_id": "2506.10633", "arxiv_url": "http://arxiv.org/abs/2506.10633", "author_h_indices": {"author_h_indexes": [{"h_index": 2, "name": "Konstantinos Vilouras", "semantic_scholar_url": null}, {"h_index": 0, "name": "Ilias Stogiannidis", "semantic_scholar_url": null}, {"h_index": 1, "name": "Junyu Yan", "semantic_scholar_url": null}, {"h_index": 3, "name": "Alison Q. O\u0027Neil", "semantic_scholar_url": null}, {"h_index": 48, "name": "S. Tsaftaris", "semantic_scholar_url": null}], "authors_with_h_index_count": 5, "average_h_index": 10.8, "h_index_fetch_method": "full_id", "highest_h_index": 48, "notable_authors_count": 1, "success": true, "total_authors": 5}, "authors": ["Konstantinos Vilouras", "Ilias Stogiannidis", "Junyu Yan", "Alison Q. O\u0027Neil", "Sotirios A. Tsaftaris"], "categories": ["cs.CV"], "embedding_completed": true, "h_index_completed": true, "highest_score": 0.542, "highest_similarity_topic": "Diffusion_reasoning", "id": "2506.10633", "llm_scoring_completed": true, "llm_validation": {"Diffusion_reasoning": {"justification": "The paper uses Latent Diffusion Models for image-text alignment and synthesis in medical imaging, focusing on fine-tuning for tasks like phrase grounding. However, it does not involve adapting the diffusion process for multi-step logical reasoning, chain-of-thought correction, or solving complex logical tasks; it is centered on visual generation and alignment, not reasoning.", "llm_relevant": "Not Relevant", "validated": true}, "Distributed_training": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}, "RLHF": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}, "Weak_supervision": {"justification": "The paper\u0027s main contribution involves a weakly supervised fine-tuning framework that derives supervision signals from free-text radiology reports using a pre-trained clinical entity recognition model and a small set of anatomical annotations. This aligns directly with weak supervision, as it programmatically generates labels from high-level, noisy, or imprecise sources (e.g., unstructured reports) without relying on perfectly hand-labeled data, enabling efficient model training.", "llm_relevant": "Highly Relevant", "validated": true}}, "llm_validation_completed": true, "published": "2025-06-12T12:19:18+00:00", "scores": {"Diffusion_reasoning": 0.542, "Distributed_training": 0.331, "RLHF": 0.38, "Weak_supervision": 0.41}, "scores_data": {"impact": "Moderate", "impact_justification": "The work is likely to be cited and built upon in the subfield of biomedical vision-language processing, particularly for enhancing diffusion models in medical applications, due to its practical approach and demonstrated performance gains.", "novelty": "Moderate", "novelty_justification": "The paper presents a notable improvement by cleverly combining existing techniques, such as clinical entity recognition and prompt tuning, to address image-text alignment in medical imaging, though it builds on prior works rather than introducing a entirely new problem or architecture.", "recommendation": "Should Read", "recommendation_justification": "This paper is valuable for researchers in medical AI and vision-language models, as it offers innovative fine-tuning methods that could improve downstream tasks, making it worth reading for those specifically interested in the topic.", "summary": "This paper addresses the misalignment between text descriptions in radiology reports and corresponding regions in chest X-ray images within Latent Diffusion Models (LDMs), proposing a weakly supervised fine-tuning framework that uses a pre-trained clinical entity recognition model and minimal anatomical annotations to derive supervision signals and update anatomy token embeddings for better multi-modal alignment. The methodology improves phrase grounding by steering cross-attention activations to relevant anatomical areas, achieving a new state-of-the-art on the MS-CXR benchmark and demonstrating robust performance on out-of-distribution data like VinDr-CXR, thus enhancing the applicability of LDMs in medical imaging tasks with limited supervision."}, "title": "Anatomy-Grounded Weakly Supervised Prompt Tuning for Chest X-ray Latent\n  Diffusion Models"}, {"abstract": "Distributed Learning (DL) enables the training of machine learning models\nacross multiple devices, yet it faces challenges like non-IID data\ndistributions and device capability disparities, which can impede training\nefficiency. Communication bottlenecks further complicate traditional Federated\nLearning (FL) setups. To mitigate these issues, we introduce the Personalized\nFederated Learning with Decentralized Selection Training (PFedDST) framework.\nPFedDST enhances model training by allowing devices to strategically evaluate\nand select peers based on a comprehensive communication score. This score\nintegrates loss, task similarity, and selection frequency, ensuring optimal\npeer connections. This selection strategy is tailored to increase local\npersonalization and promote beneficial peer collaborations to strengthen the\nstability and efficiency of the training process. Our experiments demonstrate\nthat PFedDST not only enhances model accuracy but also accelerates convergence.\nThis approach outperforms state-of-the-art methods in handling data\nheterogeneity, delivering both faster and more effective training in diverse\nand decentralized systems.", "arxiv_id": "2502.07750", "arxiv_url": "http://arxiv.org/abs/2502.07750", "author_h_indices": {"author_h_indexes": [{"h_index": 1, "name": "Mengchen Fan", "semantic_scholar_url": null}, {"h_index": 1, "name": "Keren Li", "semantic_scholar_url": null}, {"h_index": 0, "name": "Tianyun Zhang", "semantic_scholar_url": null}, {"h_index": 0, "name": "Qing Tian", "semantic_scholar_url": null}, {"h_index": 3, "name": "Baocheng Geng", "semantic_scholar_url": null}], "authors_with_h_index_count": 5, "average_h_index": 1.0, "h_index_fetch_method": "full_id", "highest_h_index": 3, "notable_authors_count": 0, "success": true, "total_authors": 5}, "authors": ["Mengchen Fan", "Keren Li", "Tianyun Zhang", "Qing Tian", "Baocheng Geng"], "categories": ["cs.LG", "cs.AI"], "embedding_completed": true, "h_index_completed": true, "highest_score": 0.503, "highest_similarity_topic": "Distributed_training", "id": "2502.07750", "llm_scoring_completed": true, "llm_validation": {"Diffusion_reasoning": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}, "Distributed_training": {"justification": "The paper\u0027s main contribution, PFedDST, involves distributed training across multiple devices, addressing challenges like data heterogeneity, communication efficiency, and parallel computing in federated learning. It directly aligns with distributed training by partitioning data and computation across nodes and optimizing multi-node interactions.", "llm_relevant": "Highly Relevant", "validated": true}, "RLHF": {"justification": "The paper focuses on Personalized Federated Learning and decentralized training strategies, with no mention of human feedback, reward models, or reinforcement learning techniques. It deals solely with automated peer selection and model aggregation in distributed settings.", "llm_relevant": "Not Relevant", "validated": true}, "Weak_supervision": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}}, "llm_validation_completed": true, "published": "2025-02-11T18:25:48+00:00", "scores": {"Diffusion_reasoning": 0.347, "Distributed_training": 0.503, "RLHF": 0.407, "Weak_supervision": 0.348}, "scores_data": {"impact": "Moderate", "impact_justification": "The work is likely to influence research in personalized and decentralized federated learning by providing a more efficient method for handling data heterogeneity and communication challenges. Its specific focus on practical improvements may lead to citations and adaptations within this subfield, though its broader applicability remains limited.", "novelty": "Moderate", "novelty_justification": "The paper presents a notable improvement by combining existing federated learning concepts with a new scoring strategy for peer selection, effectively addressing data heterogeneity in a decentralized setting. While it builds on prior work, it introduces a clever integration that advances personalization without creating an entirely new paradigm.", "recommendation": "Should Read", "recommendation_justification": "This paper is valuable for researchers and practitioners in federated learning due to its innovative peer selection strategy and demonstrated performance gains in heterogeneous environments. However, it is not essential for those outside this specific area, making it a targeted rather than mandatory read.", "summary": "The PFedDST framework addresses challenges in federated learning by introducing a decentralized peer selection mechanism, where devices evaluate and select collaborators based on a communication score incorporating loss, task similarity, and selection frequency to enhance personalization and efficiency. This approach allows for strategic model aggregation and local updates, with experiments demonstrating improved accuracy, faster convergence, and superior handling of data heterogeneity compared to existing methods."}, "title": "PFedDST: Personalized Federated Learning with Decentralized Selection\n  Training"}, {"abstract": "The Object Navigation (ObjectNav) task aims to guide an agent to locate\ntarget objects in unseen environments using partial observations. Prior\napproaches have employed location prediction paradigms to achieve long-term\ngoal reasoning, yet these methods often struggle to effectively integrate\ncontextual relation reasoning. Alternatively, map completion-based paradigms\npredict long-term goals by generating semantic maps of unexplored areas.\nHowever, existing methods in this category fail to fully leverage known\nenvironmental information, resulting in suboptimal map quality that requires\nfurther improvement. In this work, we propose a novel approach to enhancing the\nObjectNav task, by training a diffusion model to learn the statistical\ndistribution patterns of objects in semantic maps, and using the map of the\nexplored regions during navigation as the condition to generate the map of the\nunknown regions, thereby realizing the long-term goal reasoning of the target\nobject, i.e., diffusion as reasoning (DAR). Meanwhile, we propose the Room\nGuidance method, which leverages commonsense knowledge derived from large\nlanguage models (LLMs) to guide the diffusion model in generating room-aware\nobject distributions. Based on the generated map in the unknown region, the\nagent sets the predicted location of the target as the goal and moves towards\nit. Experiments on Gibson and MP3D show the effectiveness of our method.", "arxiv_id": "2410.21842", "arxiv_url": "http://arxiv.org/abs/2410.21842", "author_h_indices": {"authors_with_h_index_count": 0, "average_h_index": null, "highest_h_index": null, "notable_authors_count": 0, "success": false, "total_authors": 0}, "authors": ["Yiming Ji", "Kaijie Yun", "Yang Liu", "Zhengpu Wang", "Boyu Ma", "Zongwu Xie", "Hong Liu"], "categories": ["cs.CV", "cs.AI"], "embedding_completed": true, "h_index_completed": false, "highest_score": 0.654, "highest_similarity_topic": "Diffusion_reasoning", "id": "2410.21842", "llm_scoring_completed": false, "llm_validation": {"Diffusion_reasoning": {"justification": "The paper uses a diffusion model for generating semantic maps in Object Navigation, framing it as \"diffusion as reasoning\" to predict long-term goals through iterative denoising. This involves multi-step refinement, which aligns somewhat with the topic\u0027s emphasis on iterative processes for complex tasks. However, the application focuses on spatial and probabilistic generation rather than explicit multi-step logical reasoning or treating a chain-of-thought as a holistic entity, making it only moderately relevant.", "llm_relevant": "Moderately Relevant", "validated": true}, "Distributed_training": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}, "RLHF": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}, "Weak_supervision": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}}, "llm_validation_completed": true, "published": "2024-10-29T08:10:06+00:00", "scores": {"Diffusion_reasoning": 0.654, "Distributed_training": 0.354, "RLHF": 0.389, "Weak_supervision": 0.358}, "scores_data": {}, "title": "Diffusion as Reasoning: Enhancing Object Navigation via Diffusion Model\n  Conditioned on LLM-based Object-Room Knowledge"}, {"abstract": "Large language models (LLMs) are powerful but static; they lack mechanisms to\nadapt their weights in response to new tasks, knowledge, or examples. We\nintroduce Self-Adapting LLMs (SEAL), a framework that enables LLMs to\nself-adapt by generating their own finetuning data and update directives. Given\na new input, the model produces a self-edit-a generation that may restructure\nthe information in different ways, specify optimization hyperparameters, or\ninvoke tools for data augmentation and gradient-based updates. Through\nsupervised finetuning (SFT), these self-edits result in persistent weight\nupdates, enabling lasting adaptation. To train the model to produce effective\nself-edits, we use a reinforcement learning loop with the downstream\nperformance of the updated model as the reward signal. Unlike prior approaches\nthat rely on separate adaptation modules or auxiliary networks, SEAL directly\nuses the model\u0026#x27;s own generation to control its adaptation process. Experiments\non knowledge incorporation and few-shot generalization show that SEAL is a\npromising step toward language models capable of self-directed adaptation. Our\nwebsite and code is available at https://jyopari.github.io/posts/seal.", "arxiv_id": "2506.10943", "arxiv_url": "http://arxiv.org/abs/2506.10943", "author_h_indices": {"authors_with_h_index_count": 0, "average_h_index": null, "highest_h_index": null, "notable_authors_count": 0, "success": false, "total_authors": 0}, "authors": ["Adam Zweiger", "Jyothish Pari", "Han Guo", "Ekin Aky\u00fcrek", "Yoon Kim", "Pulkit Agrawal"], "categories": ["cs.LG"], "embedding_completed": true, "h_index_completed": false, "highest_score": 0.462, "highest_similarity_topic": "Diffusion_reasoning", "id": "2506.10943", "llm_scoring_completed": false, "llm_validation": {"Diffusion_reasoning": {"justification": "The paper does not involve diffusion models, iterative refinement processes, or multi-step logical reasoning as described in diffusion-based approaches. It focuses on reinforcement learning for self-adaptation in LLMs, with no components related to diffusion or holistic chain-of-thought correction.", "llm_relevant": "Not Relevant", "validated": true}, "Distributed_training": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}, "RLHF": {"justification": "The paper uses a reinforcement learning loop where rewards are based on the model\u0027s downstream task performance, not human feedback. RLHF specifically requires training a reward model from human-ranked data, which is absent here, making the paper\u0027s approach fundamentally different.", "llm_relevant": "Not Relevant", "validated": true}, "Weak_supervision": {"justification": "The paper involves the model generating its own finetuning data and directives programmatically, which aligns with weak supervision\u0027s use of noisy or high-level sources for data creation. However, the primary focus is on self-adaptation via reinforcement learning, not on weak supervision as a core technique for label generation.", "llm_relevant": "Moderately Relevant", "validated": true}}, "llm_validation_completed": true, "published": "2025-06-12T17:48:13+00:00", "scores": {"Diffusion_reasoning": 0.462, "Distributed_training": 0.38, "RLHF": 0.446, "Weak_supervision": 0.426}, "scores_data": {}, "title": "Self-Adapting Language Models"}, {"abstract": "The convergence of Artificial Intelligence (AI) and the Internet of Things\nhas accelerated the development of distributed, network-sensitive applications,\nnecessitating ultra-low latency, high throughput, and real-time processing\ncapabilities. While 5G networks represent a significant technological\nmilestone, their ability to support AI-driven edge applications remains\nconstrained by performance gaps observed in real-world deployments. This paper\naddresses these limitations and highlights critical advancements needed to\nrealize a robust and scalable 6G ecosystem optimized for AI applications.\nFurthermore, we conduct an empirical evaluation of 5G network infrastructure in\ncentral Europe, with latency measurements ranging from 61 ms to 110 ms across\ndifferent close geographical areas. These values exceed the requirements of\nlatency-critical AI applications by approximately 270%, revealing significant\nshortcomings in current deployments. Building on these findings, we propose a\nset of recommendations to bridge the gap between existing 5G performance and\nthe requirements of next-generation AI applications.", "arxiv_id": "2506.10570", "arxiv_url": "http://arxiv.org/abs/2506.10570", "author_h_indices": {"authors_with_h_index_count": 0, "average_h_index": null, "highest_h_index": null, "notable_authors_count": 0, "success": false, "total_authors": 0}, "authors": ["Kurt Horvath", "Shpresa Tuda", "Blerta Idrizi", "Stojan Kitanov", "Fisnik Doko", "Dragi Kimovski"], "categories": ["cs.DC"], "embedding_completed": true, "h_index_completed": false, "highest_score": 0.395, "highest_similarity_topic": "Distributed_training", "id": "2506.10570", "llm_scoring_completed": false, "llm_validation": {"Diffusion_reasoning": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}, "Distributed_training": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}, "RLHF": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}, "Weak_supervision": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}}, "llm_validation_completed": true, "published": "2025-06-12T10:59:08+00:00", "scores": {"Diffusion_reasoning": 0.319, "Distributed_training": 0.395, "RLHF": 0.314, "Weak_supervision": 0.293}, "scores_data": {}, "title": "6G Infrastructures for Edge AI: An Analytical Perspective"}, {"abstract": "As has been shown in our previous work, the parallel-in-time direct inverse\n(ParaDIn) method introduced by Yamaleev and Paudel in (arXiv: 2406.00878v1,\n2024) imposes some constraint on the maximum number of time levels, $N_t$, that\ncan be integrated in parallel. To circumvent this problem and further increase\nthe speedup, we combine the ParaDIn method with the Parareal algorithm to\nefficiently parallelize the first-order time derivative term in nonlinear\npartial differential equations discretized by the method of lines. The main\nidea of the proposed approach is to use a block-Jacobi preconditioner, so that\neach block is solved by using the ParaDIn method. To accelerate the convergence\nof Jacobi iterations, we use the Parareal method which can be interpreted as a\ntwo-level multigrid method in time. In contrast to the conventional Parareal\nalgorithm whose coarse grid correction step is performed sequentially, both the\ncoarse- and fine-grid propagators in the proposed approach are implemented in\nparallel by using the ParaDIn method, thus significantly increasing the\nparallel performance of the combined algorithm. Numerical results show that the\nnew combined ParaDIn-Parareal method provides the speedup of up to 124 on 480\ncomputing cores as compared with the sequential first-order implicit backward\ndifference (BDF1) scheme for the 2-D nonlinear heat and Burgers equations with\nboth smooth and discontinuous solutions.", "arxiv_id": "2506.10820", "arxiv_url": "http://arxiv.org/abs/2506.10820", "author_h_indices": {"authors_with_h_index_count": 0, "average_h_index": null, "highest_h_index": null, "notable_authors_count": 0, "success": false, "total_authors": 0}, "authors": ["Subhash Paudel", "Nail K. Yamaleev"], "categories": ["math.NA", "cs.NA"], "embedding_completed": true, "h_index_completed": false, "highest_score": 0.354, "highest_similarity_topic": "Distributed_training", "id": "2506.10820", "llm_scoring_completed": false, "llm_validation": {"Diffusion_reasoning": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}, "Distributed_training": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}, "RLHF": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}, "Weak_supervision": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}}, "llm_validation_completed": true, "published": "2025-06-12T15:38:56+00:00", "scores": {"Diffusion_reasoning": 0.32, "Distributed_training": 0.354, "RLHF": 0.196, "Weak_supervision": 0.2}, "scores_data": {}, "title": "A Combined Parallel-in-time Direct Inverse (ParaDIn)-Parareal Method for\n  Nonlinear Differential Equations"}, {"abstract": "Accurate classification of software bugs is essential for improving software\nquality. This paper presents a rule-based automated framework for classifying\nissues in quantum software repositories by bug type, category, severity, and\nimpacted quality attributes, with additional focus on quantum-specific bug\ntypes. The framework applies keyword and heuristic-based techniques tailored to\nquantum computing. To assess its reliability, we manually classified a\nstratified sample of 4,984 issues from a dataset of 12,910 issues across 36\nQiskit repositories. Automated classifications were compared with ground truth\nusing accuracy, precision, recall, and F1-score. The framework achieved up to\n85.21% accuracy, with F1-scores ranging from 0.7075 (severity) to 0.8393\n(quality attribute). Statistical validation via paired t-tests and Cohen\u0026#x27;s\nKappa showed substantial to almost perfect agreement for bug type (k = 0.696),\ncategory (k = 0.826), quality attribute (k = 0.818), and quantum-specific bug\ntype (k = 0.712). Severity classification showed slight agreement (k = 0.162),\nsuggesting room for improvement. Large-scale analysis revealed that classical\nbugs dominate (67.2%), with quantum-specific bugs at 27.3%. Frequent bug\ncategories included compatibility, functional, and quantum-specific defects,\nwhile usability, maintainability, and interoperability were the most impacted\nquality attributes. Most issues (93.7%) were low severity; only 4.3% were\ncritical. A detailed review of 1,550 quantum-specific bugs showed that over\nhalf involved quantum circuit-level problems, followed by gate errors and\nhardware-related issues.", "arxiv_id": "2506.10397", "arxiv_url": "http://arxiv.org/abs/2506.10397", "author_h_indices": {"authors_with_h_index_count": 0, "average_h_index": null, "highest_h_index": null, "notable_authors_count": 0, "success": false, "total_authors": 0}, "authors": ["Mir Mohammad Yousuf", "Shabir Ahmad Sofi"], "categories": ["cs.SE", "cs.CY", "cs.DC"], "embedding_completed": true, "h_index_completed": false, "highest_score": 0.333, "highest_similarity_topic": "Weak_supervision", "id": "2506.10397", "llm_scoring_completed": false, "llm_validation": {"Diffusion_reasoning": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}, "Distributed_training": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}, "RLHF": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}, "Weak_supervision": {"justification": "below_threshold", "llm_relevant": "not_validated", "validated": true}}, "llm_validation_completed": true, "published": "2025-06-12T06:42:10+00:00", "scores": {"Diffusion_reasoning": 0.294, "Distributed_training": 0.307, "RLHF": 0.278, "Weak_supervision": 0.333}, "scores_data": {}, "title": "Bug Classification in Quantum Software: A Rule-Based Framework and Its\n  Evaluation"}];
        let filteredPapers = [...papers];
        
        function updateDisplay() {
            const container = document.getElementById('papers-container');
            const filterCount = document.getElementById('filter-count');
            
            filterCount.textContent = `Showing ${filteredPapers.length}/${papers.length} papers`;
            
            // Show/hide paper cards
            const cards = container.querySelectorAll('.paper-card');
            cards.forEach((card, index) => {
                const isVisible = filteredPapers.some(p => papers.indexOf(p) === index);
                card.style.display = isVisible ? 'block' : 'none';
            });
        }
        
        function applyFilters() {
            const selectedTopics = Array.from(document.querySelectorAll('.topic-filter:checked')).map(cb => cb.value);
            const selectedLLM = Array.from(document.querySelectorAll('.llm-filter:checked')).map(cb => cb.value);
            const selectedHIndex = Array.from(document.querySelectorAll('.h-index-filter:checked')).map(cb => cb.value);
            const minScore = parseFloat(document.getElementById('minScore').value) || 0;
            const maxScore = parseFloat(document.getElementById('maxScore').value) || 1;
            
            filteredPapers = papers.filter(paper => {
                // Topic filter
                if (selectedTopics.length > 0 && paper.scores) {
                    const hasSelectedTopic = selectedTopics.some(topic => 
                        paper.scores.hasOwnProperty(topic) && 
                        paper.scores[topic] >= minScore && 
                        paper.scores[topic] <= maxScore
                    );
                    if (!hasSelectedTopic) return false;
                }
                
                return true;
            });
            
            updateDisplay();
        }
        
        // Event listeners
        document.addEventListener('DOMContentLoaded', function() {
            document.querySelectorAll('.topic-filter, .llm-filter, .h-index-filter').forEach(cb => {
                cb.addEventListener('change', applyFilters);
            });
            
            document.getElementById('minScore').addEventListener('input', applyFilters);
            document.getElementById('maxScore').addEventListener('input', applyFilters);
            
            document.getElementById('resetFilters').addEventListener('click', function() {
                document.querySelectorAll('.topic-filter, .llm-filter, .h-index-filter').forEach(cb => cb.checked = true);
                document.getElementById('minScore').value = 0;
                document.getElementById('maxScore').value = 1;
                applyFilters();
            });
        });
    </script>
</body>
</html>