<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Research Feed -- 02 October 2025</title>
    
    <!-- Favicon and Apple Touch Icons -->
    <link rel="icon" type="image/png" href="/favicon.png">
    <link rel="apple-touch-icon" href="/apple-touch-icon.png">
    <link rel="apple-touch-icon-precomposed" href="/apple-touch-icon-precomposed.png">
    
    <!-- Google Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@400;700&family=Space+Mono:wght@400;700&display=swap" rel="stylesheet">
    
    <!-- KaTeX CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" integrity="sha384-GvrOXuhMATgEsSwCs4smul74iXGOixntILdUW9XmUC6+HX0sLNAK3q71HotJqlAn" crossorigin="anonymous">
    
    <!-- Tailwind CSS CDN -->
    <script src="https://cdn.tailwindcss.com"></script>
    
    <!-- Custom Tailwind Configuration -->
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    fontFamily: {
                        'heading': ['Space Grotesk', 'Inter', 'system-ui', 'sans-serif'],
                        'body': ['Space Mono', 'Fira Code', 'Consolas', 'monospace'],
                    },
                    
                    fontSize: {
                            // 4px increments with responsive scaling
                            'xs': 'clamp(0.5rem, 1vw, 0.625rem)',     // 8-10px
                            'sm': 'clamp(0.625rem, 1.2vw, 0.75rem)',  // 10-12px
                            'md': 'clamp(0.75rem, 1.4vw, 0.875rem)',  // 12-14px
                            'lg': 'clamp(0.875rem, 1.6vw, 1rem)',     // 14-16px
                            'xl': 'clamp(1rem, 1.8vw, 1.125rem)',     // 16-18px
                            '2xl': 'clamp(1.125rem, 2vw, 1.25rem)',   // 18-20px
                            '3xl': 'clamp(1.25rem, 2.2vw, 1.375rem)', // 20-22px
                            '4xl': 'clamp(1.375rem, 2.4vw, 1.5rem)',  // 22-24px
                            '5xl': 'clamp(1.5rem, 2.6vw, 1.625rem)',  // 24-26px
                            '6xl': 'clamp(1.625rem, 2.8vw, 1.75rem)', // 26-28px
                            '7xl': 'clamp(1.75rem, 3vw, 1.875rem)',   // 28-30px
                            '8xl': 'clamp(1.875rem, 3.2vw, 2rem)',    // 30-32px
                            '9xl': 'clamp(2rem, 3.4vw, 2.125rem)',    // 32-34px
                        },

                    colors: {
                        neutral: {
                            10: '#f5f2e7',
                            20: '#e5e5e5',
                            40: '#a3a3a3',
                            60: '#525252',
                            70: '#404040',
                            90: '#171717',
                            100: '#f5f2e7',
                            200: '#dad7cd',
                            300: '#bebcb3',
                            400: '#a2a199',
                            500: '#86857f',
                            600: '#6b6a65',
                            700: '#4f4e4b',
                            900: '#171717',
                        },
                        // Status colors with 70% opacity
                        status: {
                            green: 'rgba(22, 104, 52, 0.7)',     // #166834 with 70% opacity
                            blue: 'rgba(40, 100, 156, 0.7)',     // #28649C with 70% opacity
                            orange: 'rgba(234, 147, 0, 0.7)',    // #EA9300 with 70% opacity
                            red: 'rgba(129, 12, 12, 0.7)',       // #810C0C with 70% opacity
                        },
                        bar: {
                            raw: 'rgba(107, 106, 101, 0.7)',       // #6B6A65 with 70% opacity
                            normalized: 'rgba(107, 106, 101, 0.7)' // #6B6A65 with 70% opacity
                        }
                    },
                    
                    spacing: {
                        '2xs': 'clamp(0.125rem, 0.5vw, 0.25rem)', // 2-4px
                        'xs': 'clamp(0.25rem, 1vw, 0.5rem)',    // 4-8px
                        'sm': 'clamp(0.5rem, 1.5vw, 0.75rem)',  // 8-12px
                        'md': 'clamp(0.75rem, 2vw, 1rem)',      // 12-16px
                        'lg': 'clamp(1rem, 2.5vw, 1.5rem)',     // 16-24px
                        'xl': 'clamp(1.5rem, 3vw, 2rem)',       // 24-32px
                        '2xl': 'clamp(2rem, 4vw, 3rem)',        // 32-48px
                        '3xl': 'clamp(3rem, 6vw, 4rem)',        // 48-64px
                        '4xl': 'clamp(4rem, 8vw, 5rem)',        // 64-80px
                        '5xl': 'clamp(5rem, 10vw, 6rem)',       // 80-96px
                        '6xl': 'clamp(6rem, 12vw, 7rem)',       // 96-112px
                        
                        // Mobile-specific spacing
                        'mobile-header': '5px',                  // 5px for mobile header padding
                        
                        // Card-specific spacing
                        'card-gap': '20px',                      // 20px gap for card info grid
                        
                        // Tag-specific spacing
                        'tag-x': '8px',                          // 8px horizontal padding for tags
                        'tag-y': '4px',                          // 4px vertical padding for tags
                    },
                    
                    screens: {
                        'mobile': '480px',
                        'tablet': '768px',
                        'desktop': '1024px',
                        'wide': '1440px',
                    },
                }
            }
        }
    </script>
    
    <!-- Custom CSS for additional styles -->
    <style>
        /* Focus states */
        .nav-button:focus-visible {
            outline: 2px solid #86857f;
            outline-offset: 2px;
        }
        
        .pagination-square:focus-visible {
            outline: 2px solid #86857f;
            outline-offset: 2px;
        }
        
        .pagination-arrow:focus-visible {
            outline: 2px solid #86857f;
            outline-offset: 2px;
        }
        
        .pagination-arrow {
            transition: background-color 0.2s ease, opacity 0.2s ease;
        }
        
        .pagination-arrow.disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }
        
        .pagination-arrow.disabled:hover {
            background-color: transparent;
        }
        
        /* Fix for multiline text padding in author and category spans */
        .metadata-tag {
            box-decoration-break: clone;
            -webkit-box-decoration-break: clone;
        }
        
        /* Sidebar styling */
        #mobile-sidebar {
            backdrop-filter: blur(4px);
            /* Move scrollbar to left side */
            direction: rtl;
        }
        
        #mobile-sidebar > div {
            /* Reset text direction inside sidebar */
            direction: ltr;
        }
        
        #desktop-sidebar {
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);
            /* Move scrollbar to left side */
            direction: rtl;
        }
        
        #desktop-sidebar > div {
            /* Reset text direction inside sidebar */
            direction: ltr;
        }
        
        /* Mobile main container transition */
        #mobile-main-container {
            transition: transform 300ms ease-in-out;
        }
        
        /* Prevent scrolling when any sidebar is open */
        body.no-scroll {
            overflow: hidden;
        }
        
        /* Dropdown positioning */
        .dropdown-up {
            bottom: 100% !important;
            top: auto !important;
        }
        
        .dropdown-down {
            top: 100% !important;
            bottom: auto !important;
        }
        
        /* Mobile active states */
        @media (hover: none) {
            /* Remove button animation */
        }
        
        /* Font fallbacks */
        .font-mono {
            font-family: 'Space Mono', 'Fira Code', 'Consolas', monospace;
        }
        
        /* Paper title link styling */
        .paper-title-link {
            color: inherit;
            text-decoration: none;
            transition: text-decoration 0.2s ease;
        }
        
        .paper-title-link:hover {
            text-decoration: underline;
        }
        
        /* Abstract text styling */
        .abstract-text {
            transition: all 0.3s ease-in-out;
        }

        /* KaTeX styling customization */
        .katex {
            font-size: 1em !important;
            line-height: inherit !important;
        }
        
        /* Inline math styling */
        .katex-display {
            margin: 0.5em 0 !important;
            text-align: left !important;
        }
        
        /* Make KaTeX blend with our color scheme */
        .katex .base {
            color: inherit;
        }
        
        /* Ensure KaTeX math doesn't break responsive design */
        .katex-display > .katex {
            max-width: 100%;
            overflow-x: auto;
            overflow-y: hidden;
        }
        
        /* Prevent double tap to zoom on mobile - Global */
        * {
            touch-action: manipulation;
        }
        
        /* Prevent double tap to zoom on mobile - Specific elements (keeping for compatibility) */
        .button, .interactive-element {
            touch-action: manipulation;
        }
        
        /* Research Feed button hover effect */
        .research-feed-button:hover {
            background-color: #4f4e4b !important; /* bg-neutral-700 */
            color: #f5f2e7 !important; /* text-neutral-10 */
        }
        
        /* Custom checkbox styling */
        .custom-checkbox {
            position: relative;
            display: inline-flex;
            align-items: center;
        }
        
        .custom-checkbox input[type="checkbox"] {
            opacity: 0;
            position: absolute;
            width: 0;
            height: 0;
        }
        
        .custom-checkbox label {
            display: inline-block;
            width: 20px;
            height: 20px;
            background-color: #86857f; /* bg-neutral-500 */
            border: 2px solid #f5f2e7; /* border-neutral-100 */
            border-radius: 4px; /* rounded corners */
            cursor: pointer;
            transition: background-color 0.2s ease, border-color 0.2s ease;
            flex-shrink: 0;
        }
        
        .custom-checkbox input[type="checkbox"]:checked + label {
            background-color: #f5f2e7; /* bg-neutral-100 */
            border-color: #f5f2e7;
        }
        
        .custom-checkbox input[type="checkbox"]:checked + label::after {
            content: '';
            position: absolute;
            left: 6px;
            top: 2px;
            width: 6px;
            height: 10px;
            border: solid #86857f;
            border-width: 0 2px 2px 0;
            transform: rotate(45deg);
        }
        
        /* H-Index range section styling */
        .hindex-range-section {
            transition: opacity 0.2s ease;
        }
        
        .hindex-range-section.disabled {
            opacity: 0.5;
        }
        
        .hindex-range-section.disabled input {
            cursor: not-allowed !important;
        }
        
        .hindex-range-section.disabled input:hover {
            background-color: #6b6a65 !important; /* Keep original bg when disabled */
        }
        
        /* Override any Tailwind hover effects on disabled inputs */
        .hindex-range-section.disabled input.bg-neutral-600:hover {
            background-color: #6b6a65 !important;
        }
        
        /* Advanced filter dropdowns disabled state */
        .opacity-50 {
            opacity: 0.5 !important;
        }
        
        .cursor-not-allowed {
            cursor: not-allowed !important;
        }
    </style>
</head>

<body class="bg-neutral-100 min-h-screen">
    <!-- Mobile Layout (visible < 768px) -->
    <div class="flex flex-col tablet:hidden" id="mobile-main-container">
        <!-- Mobile Header -->
        <header class="bg-neutral-100 w-full flex items-center px-xs pt-xl pb-md relative">
            <!-- Menu Button - Positioned absolutely within header -->
            <button id="mobile-menu-btn" class="absolute top-1/4 left-xs transform -translate-y-1/2 z-10 nav-button w-12 h-12 bg-transparent flex items-center justify-center button" aria-label="Open Menu" onclick="toggleMobileMenu()">
                <svg width="24" height="18" viewBox="0 0 24 18" xmlns="http://www.w3.org/2000/svg">
                    <rect x="0" y="0" width="24" height="5" fill="#4F4E4B"/>
                    <rect x="0" y="6.5" width="24" height="5" fill="#4F4E4B"/>
                    <rect x="0" y="13" width="24" height="5" fill="#4F4E4B"/>
                </svg>
            </button>
            
            <!-- Center: Page info (full width since menu button is positioned absolutely) -->
            <div class="w-full flex flex-col items-center justify-center text-center">
                <h1 class="text-neutral-70 font-heading font-bold text-lg mb-md" id="page-title-mobile">
                    Papers Published on 02 October 2025
                </h1>
                
                <!-- Mobile Pagination -->
                <div class="flex items-center gap-sm mb-md">
                    <!-- Previous Arrow -->
                    <button id="mobile-prev-btn" class="pagination-arrow w-8 h-8 bg-transparent text-neutral-70 flex items-center justify-center hover:bg-neutral-300 cursor-pointer" onclick="goToPage(currentPage - 1)">
                        <span class="font-heading font-bold text-sm">‹</span>
                    </button>
                    
                    <!-- Page Numbers Container -->
                    <div class="flex gap-sm" id="mobile-pagination-numbers">
                        <!-- Page numbers will be populated by JavaScript -->
                    </div>
                    
                    <!-- Next Arrow -->
                    <button id="mobile-next-btn" class="pagination-arrow w-8 h-8 bg-transparent text-neutral-70 flex items-center justify-center hover:bg-neutral-300 cursor-pointer" onclick="goToPage(currentPage + 1)">
                        <span class="font-heading font-bold text-sm">›</span>
                    </button>
                </div>
                
                <!-- Mobile Paper Count -->
                <p id="mobile-main-paper-count" class="text-neutral-60 font-heading font-bold text-lg">
                    Showing 0 / 0 papers
                </p>
            </div>
        </header>
        
        <!-- Mobile Content Area -->
        <main class="bg-neutral-100 min-h-screen">
            <div class="max-w-[500px] mx-auto">
                <!-- Mobile Papers Grid -->
                <div class="flex flex-col gap-3xl" id="mobile-papers">
                    <!-- Paper cards will be populated by JavaScript -->
                </div>
            </div>
        </main>
        
        <!-- Mobile Footer -->
        <footer class="py-xl px-lg bg-neutral-200">
            <div class="flex flex-col items-center justify-center text-center">
                <!-- Mobile Footer Pagination -->
                <div class="flex items-center gap-sm">
                    <!-- Previous Arrow -->
                    <button id="mobile-footer-prev-btn" class="pagination-arrow w-8 h-8 bg-transparent text-neutral-70 flex items-center justify-center hover:bg-neutral-300 cursor-pointer" onclick="goToPage(currentPage - 1)">
                        <span class="font-heading font-bold text-sm">‹</span>
                    </button>
                    
                    <!-- Page Numbers Container -->
                    <div class="flex gap-sm" id="mobile-footer-pagination-numbers">
                        <!-- Page numbers will be populated by JavaScript -->
                    </div>
                    
                    <!-- Next Arrow -->
                    <button id="mobile-footer-next-btn" class="pagination-arrow w-8 h-8 bg-transparent text-neutral-70 flex items-center justify-center hover:bg-neutral-300 cursor-pointer" onclick="goToPage(currentPage + 1)">
                        <span class="font-heading font-bold text-sm">›</span>
                    </button>
                </div>
            </div>
        </footer>
    </div>
    
    <!-- Mobile Sidebar -->
    <div id="mobile-sidebar" class="fixed inset-y-0 left-0 z-50 tablet:hidden bg-neutral-100 transition-transform duration-300 ease-in-out overflow-y-auto" style="width: 100vw; transform: translateX(-100%);">
        <div class="w-full h-full flex flex-col">
            <!-- Mobile Sidebar Header -->
            <div class="flex items-center justify-between pt-lg pr-lg pb-sm pl-lg">
                <!-- Left: Research Feed Home Button -->
                <div>
                    <a href="index.html" class="research-feed-button text-center px-tag-x py-sm bg-neutral-600 transition-colors duration-200">
                        <span class="text-neutral-10 font-heading font-bold text-2xl">Research Feed</span>
                    </a>
                </div>
                
                <!-- Right: Menu Button -->
                <button id="mobile-close-btn" class="nav-button w-12 h-12 bg-transparent flex items-center justify-center button" aria-label="Close Menu" onclick="closeMobileMenu()">
                    <svg width="24" height="18" viewBox="0 0 24 18" xmlns="http://www.w3.org/2000/svg">
                        <rect x="0" y="0" width="24" height="5" fill="#4F4E4B"/>
                        <rect x="0" y="6.5" width="24" height="5" fill="#4F4E4B"/>
                        <rect x="0" y="13" width="24" height="5" fill="#4F4E4B"/>
                    </svg>
                </button>
            </div>
            
            <!-- Mobile Sidebar Content -->
            <div class="flex-1 pt-sm px-lg pb-6xl">
                <div class="flex flex-col gap-lg gap-lg">
                    <!-- Section 1: Paper Count -->
                    <div class="bg-transparent text-left">
                        <span class="text-neutral-70 font-heading font-bold text-2xl" id="mobile-paper-count">
                            Showing: 0/0 Papers
                        </span>
                    </div>
                    
                    <!-- Section 2: Quick Filters -->
                    <div class="flex flex-col gap-sm">
                        <h3 class="text-neutral-60 font-heading font-bold text-2xl text-left bg-transparent">Quick Filters</h3>
                        <button id="mobile-quick-must-read" class="w-full py-tag-y font-heading font-bold text-xl text-neutral-10 bg-neutral-500 hover:bg-neutral-600" onclick="applyQuickFilter('must-read')">Must Read</button>
                        <button id="mobile-quick-should-read" class="w-full py-tag-y font-heading font-bold text-xl text-neutral-10 bg-neutral-500 hover:bg-neutral-600" onclick="applyQuickFilter('should-read')">Should Read</button>
                        <button id="mobile-quick-rlhf" class="w-full py-tag-y font-heading font-bold text-xl text-neutral-10 bg-neutral-500 hover:bg-neutral-600" onclick="applyQuickFilter('rlhf')">RLHF</button>
                        <button id="mobile-quick-weak-supervision" class="w-full py-tag-y font-heading font-bold text-xl text-neutral-10 bg-neutral-500 hover:bg-neutral-600" onclick="applyQuickFilter('weak-supervision')">Weak Supervision</button>
                        <button id="mobile-quick-diffusion-reasoning" class="w-full py-tag-y font-heading font-bold text-xl text-neutral-10 bg-neutral-500 hover:bg-neutral-600" onclick="applyQuickFilter('diffusion-reasoning')">Diffusion Reasoning</button>
                        <button id="mobile-quick-distributed-training" class="w-full py-tag-y font-heading font-bold text-xl text-neutral-10 bg-neutral-500 hover:bg-neutral-600" onclick="applyQuickFilter('distributed-training')">Distributed Training</button>
                        <button id="mobile-quick-datasets" class="w-full py-tag-y font-heading font-bold text-xl text-neutral-10 bg-neutral-500 hover:bg-neutral-600" onclick="applyQuickFilter('datasets')">Datasets</button>
                        <button id="mobile-quick-reset" class="w-full py-tag-y font-heading font-bold text-xl text-neutral-10 bg-neutral-500 hover:bg-neutral-600" onclick="applyQuickFilter('reset')">Reset To Default</button>
                    </div>
                    
                    <!-- Section 3: Advanced Filters -->
                    <div class="flex flex-col gap-sm">
                        <h3 class="text-neutral-60 font-heading font-bold text-2xl text-left bg-transparent">Advanced Filters</h3>
                        <!-- Scoring Filter Dropdown -->
                        <div class="relative">
                            <button id="mobile-scoring-btn" class="w-full py-tag-y font-heading font-bold text-xl text-neutral-10 bg-neutral-500 text-left px-tag-x hover:bg-neutral-600" onclick="toggleMobileScoringDropdown()">
                                <span class="font-bold">Scoring:</span> <span class="font-normal">All Selected</span> <span class="text-base">▼</span>
                            </button>
                            <div id="mobile-scoring-dropdown" class="hidden absolute top-full left-0 w-full bg-neutral-700 z-50 p-md">
                                <div class="flex flex-col gap-md">
                                    <!-- Section 1: Has Scoring and Summary Checkbox -->
                                    <div class="flex items-center gap-md">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="mobile-scoring-has" checked>
                                            <label for="mobile-scoring-has"></label>
                                        </div>
                                        <label for="mobile-scoring-has" class="text-neutral-10 text-xl font-heading cursor-pointer">Completed</label>
                                    </div>
                                    
                                    <!-- Section 2: Does not have Scoring and Summary Checkbox -->
                                    <div class="flex items-center gap-md">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="mobile-scoring-no" checked>
                                            <label for="mobile-scoring-no"></label>
                                        </div>
                                        <label for="mobile-scoring-no" class="text-neutral-10 text-xl font-heading cursor-pointer">Not relevant enough</label>
                                    </div>
                                    
                                    <!-- Section 3: Apply Filter Button -->
                                    <button class="w-full py-tag-y font-heading font-bold text-lg text-neutral-60 bg-neutral-300 hover:bg-neutral-500 hover:text-neutral-10 transition-colors" onclick="applyScoringFilter()">
                                        Apply Filter
                                    </button>
                                </div>
                            </div>
                        </div>
                        <!-- Recommendation Filter Dropdown -->
                        <div class="relative">
                            <button id="mobile-recommendation-btn" class="w-full py-tag-y font-heading font-bold text-xl text-neutral-10 bg-neutral-500 text-left px-tag-x hover:bg-neutral-600" onclick="toggleMobileRecommendationDropdown()">
                                <span class="font-bold">Recommendation:</span> <span class="font-normal">All Selected</span> <span class="text-base">▼</span>
                            </button>
                            <div id="mobile-recommendation-dropdown" class="hidden absolute top-full left-0 w-full bg-neutral-700 z-50 p-md">
                                <div class="flex flex-col gap-md">
                                    <!-- Must Read Checkbox -->
                                    <div class="flex items-center gap-md">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="mobile-recommendation-must" checked>
                                            <label for="mobile-recommendation-must"></label>
                                        </div>
                                        <label for="mobile-recommendation-must" class="text-neutral-10 text-xl font-heading cursor-pointer">Must Read</label>
                                    </div>
                                    
                                    <!-- Should Read Checkbox -->
                                    <div class="flex items-center gap-md">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="mobile-recommendation-should" checked>
                                            <label for="mobile-recommendation-should"></label>
                                        </div>
                                        <label for="mobile-recommendation-should" class="text-neutral-10 text-xl font-heading cursor-pointer">Should Read</label>
                                    </div>
                                    
                                    <!-- Can Skip Checkbox -->
                                    <div class="flex items-center gap-md">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="mobile-recommendation-skip" checked>
                                            <label for="mobile-recommendation-skip"></label>
                                        </div>
                                        <label for="mobile-recommendation-skip" class="text-neutral-10 text-xl font-heading cursor-pointer">Can Skip</label>
                                    </div>
                                    
                                    <!-- Ignore Checkbox -->
                                    <div class="flex items-center gap-md">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="mobile-recommendation-ignore" checked>
                                            <label for="mobile-recommendation-ignore"></label>
                                        </div>
                                        <label for="mobile-recommendation-ignore" class="text-neutral-10 text-xl font-heading cursor-pointer">Ignore</label>
                                    </div>
                                    
                                    <!-- Apply Filter Button -->
                                    <button class="w-full py-tag-y font-heading font-bold text-lg text-neutral-60 bg-neutral-300 hover:bg-neutral-500 hover:text-neutral-10 transition-colors" onclick="applyRecommendationFilter()">
                                        Apply Filter
                                    </button>
                                </div>
                            </div>
                        </div>
                        <!-- Novelty Filter Dropdown -->
                        <div class="relative">
                            <button id="mobile-novelty-btn" class="w-full py-tag-y font-heading font-bold text-xl text-neutral-10 bg-neutral-500 text-left px-tag-x hover:bg-neutral-600" onclick="toggleMobileNoveltyDropdown()">
                                <span class="font-bold">Novelty:</span> <span class="font-normal">All Selected</span> <span class="text-base">▼</span>
                            </button>
                            <div id="mobile-novelty-dropdown" class="hidden absolute top-full left-0 w-full bg-neutral-700 z-50 p-md">
                                <div class="flex flex-col gap-md">
                                    <!-- High Checkbox -->
                                    <div class="flex items-center gap-md">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="mobile-novelty-high" checked>
                                            <label for="mobile-novelty-high"></label>
                                        </div>
                                        <label for="mobile-novelty-high" class="text-neutral-10 text-xl font-heading cursor-pointer">High</label>
                                    </div>
                                    
                                    <!-- Moderate Checkbox -->
                                    <div class="flex items-center gap-md">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="mobile-novelty-moderate" checked>
                                            <label for="mobile-novelty-moderate"></label>
                                        </div>
                                        <label for="mobile-novelty-moderate" class="text-neutral-10 text-xl font-heading cursor-pointer">Moderate</label>
                                    </div>
                                    
                                    <!-- Low Checkbox -->
                                    <div class="flex items-center gap-md">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="mobile-novelty-low" checked>
                                            <label for="mobile-novelty-low"></label>
                                        </div>
                                        <label for="mobile-novelty-low" class="text-neutral-10 text-xl font-heading cursor-pointer">Low</label>
                                    </div>
                                    
                                    <!-- None Checkbox -->
                                    <div class="flex items-center gap-md">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="mobile-novelty-none" checked>
                                            <label for="mobile-novelty-none"></label>
                                        </div>
                                        <label for="mobile-novelty-none" class="text-neutral-10 text-xl font-heading cursor-pointer">None</label>
                                    </div>
                                    
                                    <!-- Apply Filter Button -->
                                    <button class="w-full py-tag-y font-heading font-bold text-lg text-neutral-60 bg-neutral-300 hover:bg-neutral-500 hover:text-neutral-10 transition-colors" onclick="applyNoveltyFilter()">
                                        Apply Filter
                                    </button>
                                </div>
                            </div>
                        </div>
                        <!-- Potential Impact Filter Dropdown -->
                        <div class="relative">
                            <button id="mobile-impact-btn" class="w-full py-tag-y font-heading font-bold text-xl text-neutral-10 bg-neutral-500 text-left px-tag-x hover:bg-neutral-600" onclick="toggleMobileImpactDropdown()">
                                <span class="font-bold">Potential Impact:</span> <span class="font-normal">All Selected</span> <span class="text-base">▼</span>
                            </button>
                            <div id="mobile-impact-dropdown" class="hidden absolute top-full left-0 w-full bg-neutral-700 z-50 p-md">
                                <div class="flex flex-col gap-md">
                                    <!-- High Checkbox -->
                                    <div class="flex items-center gap-md">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="mobile-impact-high" checked>
                                            <label for="mobile-impact-high"></label>
                                        </div>
                                        <label for="mobile-impact-high" class="text-neutral-10 text-xl font-heading cursor-pointer">High</label>
                                    </div>
                                    
                                    <!-- Moderate Checkbox -->
                                    <div class="flex items-center gap-md">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="mobile-impact-moderate" checked>
                                            <label for="mobile-impact-moderate"></label>
                                        </div>
                                        <label for="mobile-impact-moderate" class="text-neutral-10 text-xl font-heading cursor-pointer">Moderate</label>
                                    </div>
                                    
                                    <!-- Low Checkbox -->
                                    <div class="flex items-center gap-md">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="mobile-impact-low" checked>
                                            <label for="mobile-impact-low"></label>
                                        </div>
                                        <label for="mobile-impact-low" class="text-neutral-10 text-lg font-heading cursor-pointer">Low</label>
                                    </div>
                                    
                                    <!-- Negligible Checkbox -->
                                    <div class="flex items-center gap-md">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="mobile-impact-negligible" checked>
                                            <label for="mobile-impact-negligible"></label>
                                        </div>
                                        <label for="mobile-impact-negligible" class="text-neutral-10 text-xl font-heading cursor-pointer">Negligible</label>
                                    </div>
                                    
                                    <!-- Apply Filter Button -->
                                    <button class="w-full py-tag-y font-heading font-bold text-lg text-neutral-60 bg-neutral-300 hover:bg-neutral-500 hover:text-neutral-10 transition-colors" onclick="applyImpactFilter()">
                                        Apply Filter
                                    </button>
                                </div>
                            </div>
                        </div>
                        <!-- Relevance Filter Dropdown -->
                        <div class="relative">
                            <button id="mobile-relevance-btn" class="w-full py-tag-y font-heading font-bold text-xl text-neutral-10 bg-neutral-500 text-left px-tag-x hover:bg-neutral-600" onclick="toggleMobileRelevanceDropdown()">
                                <span class="font-bold">Relevance:</span> <span class="font-normal">All Selected</span> <span class="text-base">▼</span>
                            </button>
                            <div id="mobile-relevance-dropdown" class="hidden absolute top-full left-0 w-full bg-neutral-700 z-50 p-md">
                                <div class="flex flex-col gap-md">
                                    <!-- Highly Relevant Checkbox -->
                                    <div class="flex items-center gap-md">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="mobile-relevance-highly" checked>
                                            <label for="mobile-relevance-highly"></label>
                                        </div>
                                        <label for="mobile-relevance-highly" class="text-neutral-10 text-xl font-heading cursor-pointer">Highly Relevant</label>
                                    </div>
                                    
                                    <!-- Moderately Relevant Checkbox -->
                                    <div class="flex items-center gap-md">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="mobile-relevance-moderately" checked>
                                            <label for="mobile-relevance-moderately"></label>
                                        </div>
                                        <label for="mobile-relevance-moderately" class="text-neutral-10 text-xl font-heading cursor-pointer">Moderately Relevant</label>
                                    </div>
                                    
                                    <!-- Tangentially Relevant Checkbox -->
                                    <div class="flex items-center gap-md">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="mobile-relevance-tangentially" checked>
                                            <label for="mobile-relevance-tangentially"></label>
                                        </div>
                                        <label for="mobile-relevance-tangentially" class="text-neutral-10 text-xl font-heading cursor-pointer">Tangentially Relevant</label>
                                    </div>
                                    
                                    <!-- Not Relevant Checkbox -->
                                    <div class="flex items-center gap-md">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="mobile-relevance-not" checked>
                                            <label for="mobile-relevance-not"></label>
                                        </div>
                                        <label for="mobile-relevance-not" class="text-neutral-10 text-xl font-heading cursor-pointer">Not Relevant</label>
                                    </div>
                                    
                                    <!-- Apply Filter Button -->
                                    <button class="w-full py-tag-y font-heading font-bold text-lg text-neutral-60 bg-neutral-300 hover:bg-neutral-500 hover:text-neutral-10 transition-colors" onclick="applyRelevanceFilter()">
                                        Apply Filter
                                    </button>
                                </div>
                            </div>
                        </div>
                        
                        <!-- Topic Filter Dropdown -->
                        <div class="relative">
                            <button id="mobile-topic-btn" class="w-full py-tag-y font-heading font-bold text-xl text-neutral-10 bg-neutral-500 text-left px-tag-x hover:bg-neutral-600" onclick="toggleMobileTopicDropdown()">
                                <span class="font-bold">Topics:</span> <span class="font-normal">All Selected</span> <span class="text-base">▼</span>
                            </button>
                            <div id="mobile-topic-dropdown" class="hidden absolute top-full left-0 w-full bg-neutral-700 z-50 p-md">
                                <div class="flex flex-col gap-md">
                                    <!-- RLHF Checkbox -->
                                    <div class="flex items-center gap-md">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="mobile-topic-rlhf" checked>
                                            <label for="mobile-topic-rlhf"></label>
                                        </div>
                                        <label for="mobile-topic-rlhf" class="text-neutral-10 text-xl font-heading cursor-pointer">RLHF</label>
                                    </div>
                                    
                                    <!-- Weak Supervision Checkbox -->
                                    <div class="flex items-center gap-md">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="mobile-topic-weak-supervision" checked>
                                            <label for="mobile-topic-weak-supervision"></label>
                                        </div>
                                        <label for="mobile-topic-weak-supervision" class="text-neutral-10 text-xl font-heading cursor-pointer">Weak Supervision</label>
                                    </div>
                                    
                                    <!-- Diffusion Reasoning Checkbox -->
                                    <div class="flex items-center gap-md">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="mobile-topic-diffusion-reasoning" checked>
                                            <label for="mobile-topic-diffusion-reasoning"></label>
                                        </div>
                                        <label for="mobile-topic-diffusion-reasoning" class="text-neutral-10 text-xl font-heading cursor-pointer">Diffusion Reasoning</label>
                                    </div>
                                    
                                    <!-- Distributed Training Checkbox -->
                                    <div class="flex items-center gap-md">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="mobile-topic-distributed-training" checked>
                                            <label for="mobile-topic-distributed-training"></label>
                                        </div>
                                        <label for="mobile-topic-distributed-training" class="text-neutral-10 text-xl font-heading cursor-pointer">Distributed Training</label>
                                    </div>
                                    
                                    <!-- Datasets Checkbox -->
                                    <div class="flex items-center gap-md">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="mobile-topic-datasets" checked>
                                            <label for="mobile-topic-datasets"></label>
                                        </div>
                                        <label for="mobile-topic-datasets" class="text-neutral-10 text-xl font-heading cursor-pointer">Datasets</label>
                                    </div>
                                    
                                    <!-- Apply Filter Button -->
                                    <button class="w-full py-tag-y font-heading font-bold text-lg text-neutral-60 bg-neutral-300 hover:bg-neutral-500 hover:text-neutral-10 transition-colors" onclick="applyTopicFilter()">
                                        Apply Filter
                                    </button>
                                </div>
                            </div>
                        </div>
                        
                        <!-- H-Index Filter Dropdown -->
                        <div class="relative">
                            <button id="mobile-hindex-btn" class="w-full py-tag-y font-heading font-bold text-xl text-neutral-10 bg-neutral-500 text-left px-tag-x hover:bg-neutral-600" onclick="toggleMobileHIndexDropdown()">
                                H-index: All Selected <span class="text-lg">▼</span>
                            </button>
                            <div id="mobile-hindex-dropdown" class="hidden absolute top-full left-0 w-full bg-neutral-700 z-50 p-md">
                                <div class="flex flex-col gap-lg">
                                    <!-- Section 1: H-Index Found Checkbox -->
                                    <div class="flex items-center gap-md">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="mobile-hindex-found" checked onchange="toggleHIndexRanges()">
                                            <label for="mobile-hindex-found"></label>
                                        </div>
                                        <label for="mobile-hindex-found" class="text-neutral-10 text-xl font-heading cursor-pointer">H-Index Found</label>
                                    </div>
                                    
                                    <!-- Section 2: H-Index Not Found Checkbox -->
                                    <div class="flex items-center gap-md">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="mobile-hindex-not-found" checked>
                                            <label for="mobile-hindex-not-found"></label>
                                        </div>
                                        <label for="mobile-hindex-not-found" class="text-neutral-10 text-xl font-heading cursor-pointer">H-Index Not Found</label>
                                    </div>
                                    
                                    <!-- Section 3: Highest H-Index Range -->
                                    <div id="mobile-highest-range" class="hindex-range-section">
                                        <div class="text-neutral-10 text-lg font-heading mb-2xs">Highest H-Index Range:</div>
                                        <div class="flex items-center gap-xs">
                                            <span class="text-neutral-10 text-lg font-heading">Min:</span>
                                            <input type="number" id="mobile-highest-min" min="0" max="1000" value="0" class="bg-neutral-600 text-neutral-10 px-2xs py-2xs text-lg font-heading w-16 rounded">
                                            <span class="text-neutral-10 text-lg font-heading">-</span>
                                            <span class="text-neutral-10 text-lg font-heading">Max:</span>
                                            <input type="number" id="mobile-highest-max" min="0" max="1000" value="1000" class="bg-neutral-600 text-neutral-10 px-2xs py-2xs text-lg font-heading w-16 rounded">
                                        </div>
                                    </div>
                                    
                                    <!-- Section 4: Average H-Index Range -->
                                    <div id="mobile-average-range" class="hindex-range-section">
                                        <div class="text-neutral-10 text-lg font-heading mb-2xs">Average H-Index Range:</div>
                                        <div class="flex items-center gap-xs">
                                            <span class="text-neutral-10 text-lg font-heading">Min:</span>
                                            <input type="number" id="mobile-average-min" min="0" max="1000" value="0" class="bg-neutral-600 text-neutral-10 px-2xs py-2xs text-lg font-heading w-16 rounded">
                                            <span class="text-neutral-10 text-lg font-heading">-</span>
                                            <span class="text-neutral-10 text-lg font-heading">Max:</span>
                                            <input type="number" id="mobile-average-max" min="0" max="1000" value="1000" class="bg-neutral-600 text-neutral-10 px-2xs py-2xs text-lg font-heading w-16 rounded">
                                        </div>
                                    </div>
                                    
                                    <!-- Section 5: Apply Filter Button -->
                                    <button class="w-full py-tag-y font-heading font-bold text-lg text-neutral-60 bg-neutral-300 hover:bg-neutral-500 hover:text-neutral-10 transition-colors" onclick="applyHIndexFilter()">
                                        Apply Filter
                                    </button>
                                </div>
                            </div>
                        </div>
                        
                        <!-- Sort By Dropdown -->
                        <div class="relative">
                            <button id="mobile-sort-btn" class="w-full py-tag-y font-heading font-bold text-xl text-neutral-10 bg-neutral-500 text-left px-tag-x hover:bg-neutral-600" onclick="toggleMobileSortDropdown()">
                                <span class="font-bold">Sort By:</span> <span id="mobile-sort-text" class="font-normal">Recommendation (Best First)</span> <span class="text-base">▼</span>
                            </button>
                            <div id="mobile-sort-dropdown" class="hidden absolute top-full left-0 w-full bg-neutral-700 z-50 py-xs">
                                <div class="flex flex-col gap-xs">
                                    <button class="w-full py-tag-y font-heading text-xl text-neutral-10 hover:bg-neutral-600 text-left px-tag-x" onclick="changeSortAndClose('recommend_best')">Recommendation (Best First)</button>
                                    <button class="w-full py-tag-y font-heading text-xl text-neutral-10 hover:bg-neutral-600 text-left px-tag-x" onclick="changeSortAndClose('recommend_worst')">Recommendation (Worst First)</button>
                                    <button class="w-full py-tag-y font-heading text-xl text-neutral-10 hover:bg-neutral-600 text-left px-tag-x" onclick="changeSortAndClose('relevance_high')">Relevance (Highest to Lowest)</button>
                                    <button class="w-full py-tag-y font-heading text-xl text-neutral-10 hover:bg-neutral-600 text-left px-tag-x" onclick="changeSortAndClose('relevance_low')">Relevance (Lowest to Highest)</button>
                                    <button class="w-full py-tag-y font-heading text-xl text-neutral-10 hover:bg-neutral-600 text-left px-tag-x" onclick="changeSortAndClose('highest_hindex_asc')">Highest H-Index (Ascending)</button>
                                    <button class="w-full py-tag-y font-heading text-xl text-neutral-10 hover:bg-neutral-600 text-left px-tag-x" onclick="changeSortAndClose('highest_hindex_desc')">Highest H-Index (Descending)</button>
                                    <button class="w-full py-tag-y font-heading text-xl text-neutral-10 hover:bg-neutral-600 text-left px-tag-x" onclick="changeSortAndClose('average_hindex_asc')">Average H-Index (Ascending)</button>
                                    <button class="w-full py-tag-y font-heading text-xl text-neutral-10 hover:bg-neutral-600 text-left px-tag-x" onclick="changeSortAndClose('average_hindex_desc')">Average H-Index (Descending)</button>
                                    <button class="w-full py-tag-y font-heading text-xl text-neutral-10 hover:bg-neutral-600 text-left px-tag-x" onclick="changeSortAndClose('id_asc')">arXiv ID (Ascending)</button>
                                    <button class="w-full py-tag-y font-heading text-xl text-neutral-10 hover:bg-neutral-600 text-left px-tag-x" onclick="changeSortAndClose('id_desc')">arXiv ID (Descending)</button>
                                    <button class="w-full py-tag-y font-heading text-xl text-neutral-10 hover:bg-neutral-600 text-left px-tag-x" onclick="changeSortAndClose('title_az')">Title (A-Z)</button>
                                    <button class="w-full py-tag-y font-heading text-xl text-neutral-10 hover:bg-neutral-600 text-left px-tag-x" onclick="changeSortAndClose('title_za')">Title (Z-A)</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    
    <!-- Desktop Sidebar Overlay -->
    <div id="desktop-sidebar-overlay" class="hidden tablet:block fixed inset-0 bg-black bg-opacity-50 z-30 opacity-0 pointer-events-none transition-opacity duration-300 ease-in-out" onclick="closeDesktopMenu()"></div>
    
    <!-- Desktop Sidebar -->
    <div id="desktop-sidebar" class="hidden tablet:block fixed inset-y-0 left-0 z-40 bg-neutral-200 transition-transform duration-300 ease-in-out overflow-y-auto" style="width: 500px; transform: translateX(-100%);">
        <div class="w-full h-full flex flex-col">
            <!-- Desktop Sidebar Header -->
            <div class="flex items-center justify-between pt-lg pr-lg pb-sm pl-lg">
                <!-- Left: Research Feed Home Button -->
                <div>
                    <a href="index.html" class="research-feed-button text-center px-tag-x py-sm bg-neutral-600 transition-colors duration-200">
                        <span class="text-neutral-10 font-heading font-bold text-2xl">Research Feed</span>
                    </a>
                </div>
                
                <!-- Right: Menu Button -->
                <button id="desktop-close-btn" class="nav-button bg-transparent flex items-center justify-center button" 
                        style="width: clamp(3rem, 6vw, 3.125rem); height: clamp(3rem, 6vw, 3.125rem);" 
                        aria-label="Close Menu" onclick="closeDesktopMenu()">
                    <svg width="24" height="18" viewBox="0 0 24 18" xmlns="http://www.w3.org/2000/svg">
                        <rect x="0" y="0" width="24" height="5" fill="#4F4E4B"/>
                        <rect x="0" y="6.5" width="24" height="5" fill="#4F4E4B"/>
                        <rect x="0" y="13" width="24" height="5" fill="#4F4E4B"/>
                    </svg>
                </button>
            </div>
            
            <!-- Desktop Sidebar Content -->
            <div class="flex-1 px-lg pt-lg pb-6xl">
                <div class="flex flex-col gap-lg">
                    <!-- Section 1: Paper Count -->
                    <div class="bg-transparent">
                        <span class="text-neutral-70 font-heading text-xl font-bold" id="desktop-paper-count">
                            Showing: 0/0 Papers
                        </span>
                    </div>
                    
                    <!-- Section 2: Quick Filters -->
                    <div class="flex flex-col gap-xs">
                        <h3 class="text-neutral-60 font-heading font-bold text-2xl text-left bg-transparent">Quick Filters</h3>
                        <button id="desktop-quick-must-read" class="w-full py-tag-y font-heading font-bold text-lg text-neutral-10 bg-neutral-500 hover:bg-neutral-600" onclick="applyQuickFilter('must-read')">Must Read</button>
                        <button id="desktop-quick-should-read" class="w-full py-tag-y font-heading font-bold text-lg text-neutral-10 bg-neutral-500 hover:bg-neutral-600" onclick="applyQuickFilter('should-read')">Should Read</button>
                        <button id="desktop-quick-rlhf" class="w-full py-tag-y font-heading font-bold text-lg text-neutral-10 bg-neutral-500 hover:bg-neutral-600" onclick="applyQuickFilter('rlhf')">RLHF</button>
                        <button id="desktop-quick-weak-supervision" class="w-full py-tag-y font-heading font-bold text-lg text-neutral-10 bg-neutral-500 hover:bg-neutral-600" onclick="applyQuickFilter('weak-supervision')">Weak Supervision</button>
                        <button id="desktop-quick-diffusion-reasoning" class="w-full py-tag-y font-heading font-bold text-lg text-neutral-10 bg-neutral-500 hover:bg-neutral-600" onclick="applyQuickFilter('diffusion-reasoning')">Diffusion Reasoning</button>
                        <button id="desktop-quick-distributed-training" class="w-full py-tag-y font-heading font-bold text-lg text-neutral-10 bg-neutral-500 hover:bg-neutral-600" onclick="applyQuickFilter('distributed-training')">Distributed Training</button>
                        <button id="desktop-quick-datasets" class="w-full py-tag-y font-heading font-bold text-lg text-neutral-10 bg-neutral-500 hover:bg-neutral-600" onclick="applyQuickFilter('datasets')">Datasets</button>
                        <button id="desktop-quick-reset" class="w-full py-tag-y font-heading font-bold text-lg text-neutral-10 bg-neutral-500 hover:bg-neutral-600" onclick="applyQuickFilter('reset')">Reset To Default</button>
                    </div>
                    
                    <!-- Section 3: Advanced Filters -->
                    <div class="flex flex-col gap-xs">
                        <h3 class="text-neutral-60 font-heading font-bold text-2xl text-left bg-transparent">Advanced Filters</h3>
                        <!-- Scoring Filter Dropdown -->
                        <div class="relative">
                            <button id="desktop-scoring-btn" class="w-full py-tag-y font-heading font-bold text-lg text-neutral-10 bg-neutral-500 text-left px-tag-x hover:bg-neutral-600" onclick="toggleDesktopScoringDropdown()">
                                <span class="font-bold">Scoring:</span> <span class="font-normal">All Selected</span> <span class="text-sm">▼</span>
                            </button>
                            <div id="desktop-scoring-dropdown" class="hidden absolute top-full left-0 w-full bg-neutral-700 z-50 p-md">
                                <div class="flex flex-col gap-xs">
                                    <!-- Section 1: Has Scoring and Summary Checkbox -->
                                    <div class="flex items-center gap-xs">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="desktop-scoring-has" checked>
                                            <label for="desktop-scoring-has"></label>
                                        </div>
                                        <label for="desktop-scoring-has" class="text-neutral-10 text-lg font-heading cursor-pointer">Completed</label>
                                    </div>
                                    
                                    <!-- Section 2: Does not have Scoring and Summary Checkbox -->
                                    <div class="flex items-center gap-xs">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="desktop-scoring-no" checked>
                                            <label for="desktop-scoring-no"></label>
                                        </div>
                                        <label for="desktop-scoring-no" class="text-neutral-10 text-lg font-heading cursor-pointer">Not relevant enough</label>
                                    </div>
                                    
                                    <!-- Section 3: Apply Filter Button -->
                                    <button class="w-full py-tag-y font-heading font-bold text-lg text-neutral-60 bg-neutral-300 hover:bg-neutral-500 hover:text-neutral-10 transition-colors" onclick="applyScoringFilter()">
                                        Apply Filter
                                    </button>
                                </div>
                            </div>
                        </div>
                        <!-- Recommendation Filter Dropdown -->
                        <div class="relative">
                            <button id="desktop-recommendation-btn" class="w-full py-tag-y font-heading font-bold text-lg text-neutral-10 bg-neutral-500 text-left px-tag-x hover:bg-neutral-600" onclick="toggleDesktopRecommendationDropdown()">
                                <span class="font-bold">Recommendation:</span> <span class="font-normal">All Selected</span> <span class="text-sm">▼</span>
                            </button>
                            <div id="desktop-recommendation-dropdown" class="hidden absolute top-full left-0 w-full bg-neutral-700 z-50 p-md">
                                <div class="flex flex-col gap-xs">
                                    <!-- Must Read Checkbox -->
                                    <div class="flex items-center gap-xs">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="desktop-recommendation-must" checked>
                                            <label for="desktop-recommendation-must"></label>
                                        </div>
                                        <label for="desktop-recommendation-must" class="text-neutral-10 text-lg font-heading cursor-pointer">Must Read</label>
                                    </div>
                                    
                                    <!-- Should Read Checkbox -->
                                    <div class="flex items-center gap-xs">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="desktop-recommendation-should" checked>
                                            <label for="desktop-recommendation-should"></label>
                                        </div>
                                        <label for="desktop-recommendation-should" class="text-neutral-10 text-lg font-heading cursor-pointer">Should Read</label>
                                    </div>
                                    
                                    <!-- Can Skip Checkbox -->
                                    <div class="flex items-center gap-xs">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="desktop-recommendation-skip" checked>
                                            <label for="desktop-recommendation-skip"></label>
                                        </div>
                                        <label for="desktop-recommendation-skip" class="text-neutral-10 text-lg font-heading cursor-pointer">Can Skip</label>
                                    </div>
                                    
                                    <!-- Ignore Checkbox -->
                                    <div class="flex items-center gap-xs">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="desktop-recommendation-ignore" checked>
                                            <label for="desktop-recommendation-ignore"></label>
                                        </div>
                                        <label for="desktop-recommendation-ignore" class="text-neutral-10 text-lg font-heading cursor-pointer">Ignore</label>
                                    </div>
                                    
                                    <!-- Apply Filter Button -->
                                    <button class="w-full py-tag-y font-heading font-bold text-lg text-neutral-60 bg-neutral-300 hover:bg-neutral-500 hover:text-neutral-10 transition-colors" onclick="applyRecommendationFilter()">
                                        Apply Filter
                                    </button>
                                </div>
                            </div>
                        </div>
                        <!-- Novelty Filter Dropdown -->
                        <div class="relative">
                            <button id="desktop-novelty-btn" class="w-full py-tag-y font-heading font-bold text-lg text-neutral-10 bg-neutral-500 text-left px-tag-x hover:bg-neutral-600" onclick="toggleDesktopNoveltyDropdown()">
                                <span class="font-bold">Novelty:</span> <span class="font-normal">All Selected</span> <span class="text-sm">▼</span>
                            </button>
                            <div id="desktop-novelty-dropdown" class="hidden absolute top-full left-0 w-full bg-neutral-700 z-50 p-md">
                                <div class="flex flex-col gap-xs">
                                    <!-- High Checkbox -->
                                    <div class="flex items-center gap-xs">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="desktop-novelty-high" checked>
                                            <label for="desktop-novelty-high"></label>
                                        </div>
                                        <label for="desktop-novelty-high" class="text-neutral-10 text-lg font-heading cursor-pointer">High</label>
                                    </div>
                                    
                                    <!-- Moderate Checkbox -->
                                    <div class="flex items-center gap-xs">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="desktop-novelty-moderate" checked>
                                            <label for="desktop-novelty-moderate"></label>
                                        </div>
                                        <label for="desktop-novelty-moderate" class="text-neutral-10 text-lg font-heading cursor-pointer">Moderate</label>
                                    </div>
                                    
                                    <!-- Low Checkbox -->
                                    <div class="flex items-center gap-xs">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="desktop-novelty-low" checked>
                                            <label for="desktop-novelty-low"></label>
                                        </div>
                                        <label for="desktop-novelty-low" class="text-neutral-10 text-lg font-heading cursor-pointer">Low</label>
                                    </div>
                                    
                                    <!-- None Checkbox -->
                                    <div class="flex items-center gap-xs">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="desktop-novelty-none" checked>
                                            <label for="desktop-novelty-none"></label>
                                        </div>
                                        <label for="desktop-novelty-none" class="text-neutral-10 text-lg font-heading cursor-pointer">None</label>
                                    </div>
                                    
                                    <!-- Apply Filter Button -->
                                    <button class="w-full py-tag-y font-heading font-bold text-lg text-neutral-60 bg-neutral-300 hover:bg-neutral-500 hover:text-neutral-10 transition-colors" onclick="applyNoveltyFilter()">
                                        Apply Filter
                                    </button>
                                </div>
                            </div>
                        </div>
                        <!-- Potential Impact Filter Dropdown -->
                        <div class="relative">
                            <button id="desktop-impact-btn" class="w-full py-tag-y font-heading font-bold text-lg text-neutral-10 bg-neutral-500 text-left px-tag-x hover:bg-neutral-600" onclick="toggleDesktopImpactDropdown()">
                                <span class="font-bold">Potential Impact:</span> <span class="font-normal">All Selected</span> <span class="text-sm">▼</span>
                            </button>
                            <div id="desktop-impact-dropdown" class="hidden absolute top-full left-0 w-full bg-neutral-700 z-50 p-md">
                                <div class="flex flex-col gap-xs">
                                    <!-- High Checkbox -->
                                    <div class="flex items-center gap-xs">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="desktop-impact-high" checked>
                                            <label for="desktop-impact-high"></label>
                                        </div>
                                        <label for="desktop-impact-high" class="text-neutral-10 text-lg font-heading cursor-pointer">High</label>
                                    </div>
                                    
                                    <!-- Moderate Checkbox -->
                                    <div class="flex items-center gap-xs">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="desktop-impact-moderate" checked>
                                            <label for="desktop-impact-moderate"></label>
                                        </div>
                                        <label for="desktop-impact-moderate" class="text-neutral-10 text-lg font-heading cursor-pointer">Moderate</label>
                                    </div>
                                    
                                    <!-- Low Checkbox -->
                                    <div class="flex items-center gap-xs">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="desktop-impact-low" checked>
                                            <label for="desktop-impact-low"></label>
                                        </div>
                                        <label for="desktop-impact-low" class="text-neutral-10 text-lg font-heading cursor-pointer">Low</label>
                                    </div>
                                    
                                    <!-- Negligible Checkbox -->
                                    <div class="flex items-center gap-xs">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="desktop-impact-negligible" checked>
                                            <label for="desktop-impact-negligible"></label>
                                        </div>
                                        <label for="desktop-impact-negligible" class="text-neutral-10 text-lg font-heading cursor-pointer">Negligible</label>
                                    </div>
                                    
                                    <!-- Apply Filter Button -->
                                    <button class="w-full py-tag-y font-heading font-bold text-lg text-neutral-60 bg-neutral-300 hover:bg-neutral-500 hover:text-neutral-10 transition-colors" onclick="applyImpactFilter()">
                                        Apply Filter
                                    </button>
                                </div>
                            </div>
                        </div>
                        <!-- Relevance Filter Dropdown -->
                        <div class="relative">
                            <button id="desktop-relevance-btn" class="w-full py-tag-y font-heading font-bold text-lg text-neutral-10 bg-neutral-500 text-left px-tag-x hover:bg-neutral-600" onclick="toggleDesktopRelevanceDropdown()">
                                <span class="font-bold">Relevance:</span> <span class="font-normal">All Selected</span> <span class="text-sm">▼</span>
                            </button>
                            <div id="desktop-relevance-dropdown" class="hidden absolute top-full left-0 w-full bg-neutral-700 z-50 p-md">
                                <div class="flex flex-col gap-xs">
                                    <!-- Highly Relevant Checkbox -->
                                    <div class="flex items-center gap-xs">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="desktop-relevance-highly" checked>
                                            <label for="desktop-relevance-highly"></label>
                                        </div>
                                        <label for="desktop-relevance-highly" class="text-neutral-10 text-lg font-heading cursor-pointer">Highly Relevant</label>
                                    </div>
                                    
                                    <!-- Moderately Relevant Checkbox -->
                                    <div class="flex items-center gap-xs">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="desktop-relevance-moderately" checked>
                                            <label for="desktop-relevance-moderately"></label>
                                        </div>
                                        <label for="desktop-relevance-moderately" class="text-neutral-10 text-lg font-heading cursor-pointer">Moderately Relevant</label>
                                    </div>
                                    
                                    <!-- Tangentially Relevant Checkbox -->
                                    <div class="flex items-center gap-xs">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="desktop-relevance-tangentially" checked>
                                            <label for="desktop-relevance-tangentially"></label>
                                        </div>
                                        <label for="desktop-relevance-tangentially" class="text-neutral-10 text-lg font-heading cursor-pointer">Tangentially Relevant</label>
                                    </div>
                                    
                                    <!-- Not Relevant Checkbox -->
                                    <div class="flex items-center gap-xs">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="desktop-relevance-not" checked>
                                            <label for="desktop-relevance-not"></label>
                                        </div>
                                        <label for="desktop-relevance-not" class="text-neutral-10 text-lg font-heading cursor-pointer">Not Relevant</label>
                                    </div>
                                    
                                    <!-- Apply Filter Button -->
                                    <button class="w-full py-tag-y font-heading font-bold text-lg text-neutral-60 bg-neutral-300 hover:bg-neutral-500 hover:text-neutral-10 transition-colors" onclick="applyRelevanceFilter()">
                                        Apply Filter
                                    </button>
                                </div>
                            </div>
                        </div>
                        
                        <!-- Topic Filter Dropdown -->
                        <div class="relative">
                            <button id="desktop-topic-btn" class="w-full py-tag-y font-heading font-bold text-lg text-neutral-10 bg-neutral-500 text-left px-tag-x hover:bg-neutral-600" onclick="toggleDesktopTopicDropdown()">
                                <span class="font-bold">Topics:</span> <span class="font-normal">All Selected</span> <span class="text-sm">▼</span>
                            </button>
                            <div id="desktop-topic-dropdown" class="hidden absolute top-full left-0 w-full bg-neutral-700 z-50 p-md">
                                <div class="flex flex-col gap-xs">
                                    <!-- RLHF Checkbox -->
                                    <div class="flex items-center gap-xs">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="desktop-topic-rlhf" checked>
                                            <label for="desktop-topic-rlhf"></label>
                                        </div>
                                        <label for="desktop-topic-rlhf" class="text-neutral-10 text-lg font-heading cursor-pointer">RLHF</label>
                                    </div>
                                    
                                    <!-- Weak Supervision Checkbox -->
                                    <div class="flex items-center gap-xs">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="desktop-topic-weak-supervision" checked>
                                            <label for="desktop-topic-weak-supervision"></label>
                                        </div>
                                        <label for="desktop-topic-weak-supervision" class="text-neutral-10 text-lg font-heading cursor-pointer">Weak Supervision</label>
                                    </div>
                                    
                                    <!-- Diffusion Reasoning Checkbox -->
                                    <div class="flex items-center gap-xs">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="desktop-topic-diffusion-reasoning" checked>
                                            <label for="desktop-topic-diffusion-reasoning"></label>
                                        </div>
                                        <label for="desktop-topic-diffusion-reasoning" class="text-neutral-10 text-lg font-heading cursor-pointer">Diffusion Reasoning</label>
                                    </div>
                                    
                                    <!-- Distributed Training Checkbox -->
                                    <div class="flex items-center gap-xs">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="desktop-topic-distributed-training" checked>
                                            <label for="desktop-topic-distributed-training"></label>
                                        </div>
                                        <label for="desktop-topic-distributed-training" class="text-neutral-10 text-lg font-heading cursor-pointer">Distributed Training</label>
                                    </div>
                                    
                                    <!-- Datasets Checkbox -->
                                    <div class="flex items-center gap-xs">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="desktop-topic-datasets" checked>
                                            <label for="desktop-topic-datasets"></label>
                                        </div>
                                        <label for="desktop-topic-datasets" class="text-neutral-10 text-lg font-heading cursor-pointer">Datasets</label>
                                    </div>
                                    
                                    <!-- Apply Filter Button -->
                                    <button class="w-full py-tag-y font-heading font-bold text-lg text-neutral-60 bg-neutral-300 hover:bg-neutral-500 hover:text-neutral-10 transition-colors" onclick="applyTopicFilter()">
                                        Apply Filter
                                    </button>
                                </div>
                            </div>
                        </div>
                        
                        <!-- H-Index Filter Dropdown -->
                        <div class="relative">
                            <button id="desktop-hindex-btn" class="w-full py-tag-y font-heading font-bold text-lg text-neutral-10 bg-neutral-500 text-left px-tag-x hover:bg-neutral-600" onclick="toggleDesktopHIndexDropdown()">
                                H-index: All Selected <span class="text-md">▼</span>
                            </button>
                            <div id="desktop-hindex-dropdown" class="hidden absolute top-full left-0 w-full bg-neutral-700 z-50 p-md">
                                <div class="flex flex-col gap-lg">
                                    <!-- Section 1: H-Index Found Checkbox -->
                                    <div class="flex items-center gap-xs">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="desktop-hindex-found" checked onchange="toggleHIndexRanges()">
                                            <label for="desktop-hindex-found"></label>
                                        </div>
                                        <label for="desktop-hindex-found" class="text-neutral-10 text-lg font-heading cursor-pointer">H-Index Found</label>
                                    </div>
                                    
                                    <!-- Section 2: H-Index Not Found Checkbox -->
                                    <div class="flex items-center gap-xs">
                                        <div class="custom-checkbox">
                                            <input type="checkbox" id="desktop-hindex-not-found" checked>
                                            <label for="desktop-hindex-not-found"></label>
                                        </div>
                                        <label for="desktop-hindex-not-found" class="text-neutral-10 text-lg font-heading cursor-pointer">H-Index Not Found</label>
                                    </div>
                                    
                                    <!-- Section 3: Highest H-Index Range -->
                                    <div id="desktop-highest-range" class="hindex-range-section">
                                        <div class="text-neutral-10 text-lg font-heading mb-2xs">Highest H-Index Range:</div>
                                        <div class="flex items-center gap-xs">
                                            <span class="text-neutral-10 text-lg font-heading">Min:</span>
                                            <input type="number" id="desktop-highest-min" min="0" max="1000" value="0" class="bg-neutral-600 text-neutral-10 px-2xs py-2xs text-lg font-heading w-16 rounded">
                                            <span class="text-neutral-10 text-lg font-heading">-</span>
                                            <span class="text-neutral-10 text-lg font-heading">Max:</span>
                                            <input type="number" id="desktop-highest-max" min="0" max="1000" value="1000" class="bg-neutral-600 text-neutral-10 px-2xs py-2xs text-lg font-heading w-16 rounded">
                                        </div>
                                    </div>
                                    
                                    <!-- Section 4: Average H-Index Range -->
                                    <div id="desktop-average-range" class="hindex-range-section">
                                        <div class="text-neutral-10 text-lg font-heading mb-2xs">Average H-Index Range:</div>
                                        <div class="flex items-center gap-xs">
                                            <span class="text-neutral-10 text-lg font-heading">Min:</span>
                                            <input type="number" id="desktop-average-min" min="0" max="1000" value="0" class="bg-neutral-600 text-neutral-10 px-2xs py-2xs text-lg font-heading w-16 rounded">
                                            <span class="text-neutral-10 text-lg font-heading">-</span>
                                            <span class="text-neutral-10 text-lg font-heading">Max:</span>
                                            <input type="number" id="desktop-average-max" min="0" max="1000" value="1000" class="bg-neutral-600 text-neutral-10 px-2xs py-2xs text-lg font-heading w-16 rounded">
                                        </div>
                                    </div>
                                    
                                    <!-- Section 5: Apply Filter Button -->
                                    <button class="w-full py-tag-y font-heading font-bold text-lg text-neutral-60 bg-neutral-300 hover:bg-neutral-500 hover:text-neutral-10 transition-colors" onclick="applyHIndexFilter()">
                                        Apply Filter
                                    </button>
                                </div>
                            </div>
                        </div>
                        
                        <!-- Sort By Dropdown -->
                        <div class="relative">
                            <button id="desktop-sort-btn" class="w-full py-tag-y font-heading font-bold text-lg text-neutral-10 bg-neutral-500 text-left px-tag-x hover:bg-neutral-600" onclick="toggleDesktopSortDropdown()">
                                <span class="font-bold">Sort By:</span> <span id="desktop-sort-text" class="font-normal">Recommendation (Best First)</span> <span class="text-sm">▼</span>
                            </button>
                            <div id="desktop-sort-dropdown" class="hidden absolute top-full left-0 w-full bg-neutral-700 z-50">
                                <div class="flex flex-col gap-xs">
                                    <button class="w-full py-tag-y font-heading text-lg text-neutral-10 hover:bg-neutral-600 text-left px-tag-x" onclick="changeSortAndClose('recommend_best')">Recommendation (Best First)</button>
                                    <button class="w-full py-tag-y font-heading text-lg text-neutral-10 hover:bg-neutral-600 text-left px-tag-x" onclick="changeSortAndClose('recommend_worst')">Recommendation (Worst First)</button>
                                    <button class="w-full py-tag-y font-heading text-lg text-neutral-10 hover:bg-neutral-600 text-left px-tag-x" onclick="changeSortAndClose('relevance_high')">Relevance (Highest to Lowest)</button>
                                    <button class="w-full py-tag-y font-heading text-lg text-neutral-10 hover:bg-neutral-600 text-left px-tag-x" onclick="changeSortAndClose('relevance_low')">Relevance (Lowest to Highest)</button>
                                    <button class="w-full py-tag-y font-heading text-lg text-neutral-10 hover:bg-neutral-600 text-left px-tag-x" onclick="changeSortAndClose('highest_hindex_asc')">Highest H-Index (Ascending)</button>
                                    <button class="w-full py-tag-y font-heading text-lg text-neutral-10 hover:bg-neutral-600 text-left px-tag-x" onclick="changeSortAndClose('highest_hindex_desc')">Highest H-Index (Descending)</button>
                                    <button class="w-full py-tag-y font-heading text-lg text-neutral-10 hover:bg-neutral-600 text-left px-tag-x" onclick="changeSortAndClose('average_hindex_asc')">Average H-Index (Ascending)</button>
                                    <button class="w-full py-tag-y font-heading text-lg text-neutral-10 hover:bg-neutral-600 text-left px-tag-x" onclick="changeSortAndClose('average_hindex_desc')">Average H-Index (Descending)</button>
                                    <button class="w-full py-tag-y font-heading text-lg text-neutral-10 hover:bg-neutral-600 text-left px-tag-x" onclick="changeSortAndClose('id_asc')">arXiv ID (Ascending)</button>
                                    <button class="w-full py-tag-y font-heading text-lg text-neutral-10 hover:bg-neutral-600 text-left px-tag-x" onclick="changeSortAndClose('id_desc')">arXiv ID (Descending)</button>
                                    <button class="w-full py-tag-y font-heading text-lg text-neutral-10 hover:bg-neutral-600 text-left px-tag-x" onclick="changeSortAndClose('title_az')">Title (A-Z)</button>
                                    <button class="w-full py-tag-y font-heading text-lg text-neutral-10 hover:bg-neutral-600 text-left px-tag-x" onclick="changeSortAndClose('title_za')">Title (Z-A)</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    
    <!-- Desktop Layout (visible ≥ 768px) -->
    <div class="hidden tablet:block">
        <!-- Desktop Header -->
        <header class="bg-neutral-200 w-full flex items-center px-lg pt-xl pb-md relative">
            <!-- Menu Button - Positioned absolutely within header -->
            <button id="desktop-menu-btn" class="absolute top-1/2 left-lg transform -translate-y-1/2 z-10 nav-button bg-transparent flex items-center justify-center button" 
                    style="width: clamp(3rem, 6vw, 3.125rem); height: clamp(3rem, 6vw, 3.125rem);" 
                    aria-label="Open Menu" onclick="toggleDesktopMenu()">
                <svg width="24" height="18" viewBox="0 0 24 18" xmlns="http://www.w3.org/2000/svg">
                    <rect x="0" y="0" width="24" height="5" fill="#4F4E4B"/>
                    <rect x="0" y="6.5" width="24" height="5" fill="#4F4E4B"/>
                    <rect x="0" y="13" width="24" height="5" fill="#4F4E4B"/>
                </svg>
            </button>
            
            <!-- Center: Page info (full width since menu button is positioned absolutely) -->
            <div class="w-full flex flex-col items-center justify-center text-center">
                <h1 class="text-neutral-70 font-heading font-bold text-4xl mb-md" id="page-title-desktop">
                    Papers Published on 02 October 2025
                </h1>
                
                <!-- Desktop Pagination -->
                <div class="flex items-center mb-md" style="gap: clamp(0.5rem, 1vw, 0.75rem);">
                    <!-- Previous Arrow -->
                    <button id="desktop-prev-btn" class="pagination-arrow bg-transparent text-neutral-70 flex items-center justify-center hover:bg-neutral-300 cursor-pointer" 
                            style="width: clamp(1.5rem, 3vw, 1.875rem); height: clamp(1.5rem, 3vw, 1.875rem);" onclick="goToPage(currentPage - 1)">
                        <span class="font-heading font-bold text-md">‹</span>
                    </button>
                    
                    <!-- Page Numbers Container -->
                    <div class="flex" style="gap: clamp(0.5rem, 1vw, 0.75rem);" id="desktop-pagination-numbers">
                        <!-- Page numbers will be populated by JavaScript -->
                    </div>
                    
                    <!-- Next Arrow -->
                    <button id="desktop-next-btn" class="pagination-arrow bg-transparent text-neutral-70 flex items-center justify-center hover:bg-neutral-300 cursor-pointer" 
                            style="width: clamp(1.5rem, 3vw, 1.875rem); height: clamp(1.5rem, 3vw, 1.875rem);" onclick="goToPage(currentPage + 1)">
                        <span class="font-heading font-bold text-md">›</span>
                    </button>
                </div>
                
                <!-- Desktop Paper Count -->
                <p id="desktop-main-paper-count" class="text-neutral-60 font-heading font-bold text-xl">
                    Showing 0 / 0 papers
                </p>
            </div>
        </header>
        
        <!-- Desktop Content Area -->
        <main class="px-xl py-2xl min-h-screen">
            <div class="max-w-[1400px] mx-auto">
                <!-- Desktop Papers Grid -->
                <div class="flex flex-col gap-3xl" id="desktop-papers">
                    <!-- Paper cards will be populated by JavaScript -->
                </div>
            </div>
        </main>
        
        <!-- Desktop Footer -->
        <footer class="py-xl bg-neutral-200">
            <div class="flex flex-col items-center justify-center text-center">
                <!-- Desktop Footer Pagination -->
                <div class="flex items-center" style="gap: clamp(0.5rem, 1vw, 0.75rem);">
                    <!-- Previous Arrow -->
                    <button id="desktop-footer-prev-btn" class="pagination-arrow bg-transparent text-neutral-70 flex items-center justify-center hover:bg-neutral-300 cursor-pointer" 
                            style="width: clamp(1.5rem, 3vw, 1.875rem); height: clamp(1.5rem, 3vw, 1.875rem);" onclick="goToPage(currentPage - 1)">
                        <span class="font-heading font-bold text-md">‹</span>
                    </button>
                    
                    <!-- Page Numbers Container -->
                    <div class="flex" style="gap: clamp(0.5rem, 1vw, 0.75rem);" id="desktop-footer-pagination-numbers">
                        <!-- Page numbers will be populated by JavaScript -->
                    </div>
                    
                    <!-- Next Arrow -->
                    <button id="desktop-footer-next-btn" class="pagination-arrow bg-transparent text-neutral-70 flex items-center justify-center hover:bg-neutral-300 cursor-pointer" 
                            style="width: clamp(1.5rem, 3vw, 1.875rem); height: clamp(1.5rem, 3vw, 1.875rem);" onclick="goToPage(currentPage + 1)">
                        <span class="font-heading font-bold text-md">›</span>
                    </button>
                </div>
            </div>
        </footer>
    </div>

    <!-- Embedded Paper Data - This will be populated by the builder script -->
    <script>
        // This JSON structure will be injected by the builder script
        // Expected structure:
        // {
        //   "papers": [
        //     {
        //       "id": "2407.xxxxx",
        //       "title": "Paper title with possible LaTeX: $\\alpha$ notation",
        //       "authors": ["Author 1", "Author 2"],
        //       "categories": ["cs.LG", "cs.AI"],
        //       "abstract": "Abstract text with possible LaTeX notation",
        //       "published_date": "2025-07-15",
        //       "arxiv_url": "https://arxiv.org/abs/2407.xxxxx",
        //       "pdf_url": "https://arxiv.org/pdf/2407.xxxxx.pdf",
        //       "summary": "AI generated summary",
        //       "recommendation_score": "Must Read",
        //       "recommendation_justification": "Justification text",
        //       "novelty_score": "High",
        //       "novelty_justification": "Novelty justification",
        //       "impact_score": "High", 
        //       "impact_justification": "Impact justification",
        //       "rlhf_score": 0.85,
        //       "weak_supervision_score": 0.72,
        //       "diffusion_reasoning_score": 0.15,
        //       "distributed_training_score": 0.05,
        //       "datasets_score": 0.92,
        //       "rlhf_relevance": "Highly Relevant",
        //       "weak_supervision_relevance": "Moderately Relevant", 
        //       "diffusion_reasoning_relevance": "Not Relevant",
        //       "distributed_training_relevance": "Not Relevant",
        //       "datasets_relevance": "Highly Relevant",
        //       "rlhf_justification": "Relevance justification text",
        //       "weak_supervision_justification": "Relevance justification text",
        //       "diffusion_reasoning_justification": "below_threshold",
        //       "distributed_training_justification": "below_threshold", 
        //       "datasets_justification": "Relevance justification text",
        //       "h_index_status": "completed",
        //       "semantic_scholar_url": "https://www.semanticscholar.org/...",
        //       "total_authors": 3,
        //       "authors_found": 2,
        //       "highest_h_index": 45,
        //       "average_h_index": 28.5,
        //       "notable_authors_count": 2,
        //       "author_h_indexes": [
        //         {"name": "Author 1", "h_index": 45, "profile_url": "https://..."},
        //         {"name": "Author 2", "h_index": 12, "profile_url": "https://..."}
        //       ],
        //       "llm_score_status": "completed" // or "not_relevant_enough"
        //     }
        //   ],
        //   "total_papers": 25,
        //   "date": "2025-07-15"
        // }
        const PAPER_DATA = {
  "papers": [
    {
      "id": "2510.01528",
      "title": "Towards Interpretable and Inference-Optimal COT Reasoning with Sparse\n  Autoencoder-Guided Generation",
      "authors": [
        "Daniel Zhao",
        "Abhilash Shankarampeta",
        "Lanxiang Hu",
        "Tajana Rosing",
        "Hao Zhang"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "We propose a novel method that leverages sparse autoencoders (SAEs) and\nclustering techniques to analyze the internal token representations of large\nlanguage models (LLMs) and guide generations in mathematical reasoning tasks.\nOur approach first trains an SAE to generate sparse vector representations for\ntraining tokens, then applies k-means clustering to construct a graph where\nvertices represent token clusters and weighted edges capture sequential token\ntransitions. Using this graph, we define an edge-weight based reward function\nto quantify adherence to established reasoning traces, thereby identifying\nexploitative reasoning trajectories. Additionally, we measure generation\ndiversity from clustering to assess the extent of exploration. Our findings\nindicate that balancing both exploitation and exploration is crucial for\nachieving high accuracy in mathematical reasoning tasks. During generation, the\nSAE can serve as a scalable reward model to guide generations, ensuring a\nbalanced trade-off between exploitation and exploration. This prevents extreme\nbehaviors in either direction, ultimately fostering a higher-quality reasoning\nprocess in LLMs.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01528v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01528v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.418,
      "weak_supervision_score": 0.374,
      "diffusion_reasoning_score": 0.609,
      "distributed_training_score": 0.378,
      "datasets_score": 0.335,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Tangentially Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper discusses using a reward model in the context of reinforcement learning for LLMs, such as guiding generations and balancing exploitation and exploration, which relates to RL concepts. However, it employs an unsupervised method with sparse autoencoders and clustering, without involving human feedback or human-ranked data, which is a core requirement for RLHF. Thus, it is only indirectly connected.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on using sparse autoencoders and clustering to guide mathematical reasoning in LLMs, including building graphs and defining rewards, but it does not involve diffusion models, iterative refinement processes, or any adaptation of diffusion techniques for multi-step logical reasoning.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01530",
      "title": "LOGicalThought: Logic-Based Ontological Grounding of LLMs for\n  High-Assurance Reasoning",
      "authors": [
        "Navapat Nananukul",
        "Yue Zhang",
        "Ryan Lee",
        "Eric Boxer",
        "Jonathan May",
        "Vibhav Giridhar Gogate",
        "Jay Pujara",
        "Mayank Kejriwal"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "High-assurance reasoning, particularly in critical domains such as law and\nmedicine, requires conclusions that are accurate, verifiable, and explicitly\ngrounded in evidence. This reasoning relies on premises codified from rules,\nstatutes, and contracts, inherently involving defeasible or non-monotonic logic\ndue to numerous exceptions, where the introduction of a single fact can\ninvalidate general rules, posing significant challenges. While large language\nmodels (LLMs) excel at processing natural language, their capabilities in\nstandard inference tasks do not translate to the rigorous reasoning required\nover high-assurance text guidelines. Core reasoning challenges within such\ntexts often manifest specific logical structures involving negation,\nimplication, and, most critically, defeasible rules and exceptions. In this\npaper, we propose a novel neurosymbolically-grounded architecture called\nLOGicalThought (LogT) that uses an advanced logical language and reasoner in\nconjunction with an LLM to construct a dual symbolic graph context and\nlogic-based context. These two context representations transform the problem\nfrom inference over long-form guidelines into a compact grounded evaluation.\nEvaluated on four multi-domain benchmarks against four baselines, LogT improves\noverall performance by 11.84% across all LLMs. Performance improves\nsignificantly across all three modes of reasoning: by up to +10.2% on negation,\n+13.2% on implication, and +5.5% on defeasible reasoning compared to the\nstrongest baseline.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01530v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01530v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.423,
      "weak_supervision_score": 0.375,
      "diffusion_reasoning_score": 0.554,
      "distributed_training_score": 0.317,
      "datasets_score": 0.326,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on a neurosymbolic architecture for logical reasoning in LLMs, emphasizing ontological grounding and defeasible logic, without any mention of reinforcement learning, human feedback, reward models, or fine-tuning based on human preferences.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper proposes a neurosymbolic approach using symbolic graphs and logic programs for reasoning, but it does not involve diffusion models, iterative refinement processes, or treating Chain-of-Thought as a holistically corrected entity over multiple steps.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01531",
      "title": "Information Seeking for Robust Decision Making under Partial\n  Observability",
      "authors": [
        "Djengo Cyun-Jyun Fang",
        "Tsung-Wei Ke"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)",
        "cs.CL (Computation and Language)",
        "cs.RO (Robotics)"
      ],
      "abstract": "Explicit information seeking is essential to human problem-solving in\npractical environments characterized by incomplete information and noisy\ndynamics. When the true environmental state is not directly observable, humans\nseek information to update their internal dynamics and inform future\ndecision-making. Although existing Large Language Model (LLM) planning agents\nhave addressed observational uncertainty, they often overlook discrepancies\nbetween their internal dynamics and the actual environment. We introduce\nInformation Seeking Decision Planner (InfoSeeker), an LLM decision-making\nframework that integrates task-oriented planning with information seeking to\nalign internal dynamics and make optimal decisions under uncertainty in both\nagent observations and environmental dynamics. InfoSeeker prompts an LLM to\nactively gather information by planning actions to validate its understanding,\ndetect environmental changes, or test hypotheses before generating or revising\ntask-oriented plans. To evaluate InfoSeeker, we introduce a novel benchmark\nsuite featuring partially observable environments with incomplete observations\nand uncertain dynamics. Experiments demonstrate that InfoSeeker achieves a 74%\nabsolute performance gain over prior methods without sacrificing sample\nefficiency. Moreover, InfoSeeker generalizes across LLMs and outperforms\nbaselines on established benchmarks such as robotic manipulation and web\nnavigation. These findings underscore the importance of tightly integrating\nplanning and information seeking for robust behavior in partially observable\nenvironments. The project page is available at https://infoseekerllm.github.io",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01531v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01531v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.458,
      "weak_supervision_score": 0.423,
      "diffusion_reasoning_score": 0.465,
      "distributed_training_score": 0.318,
      "datasets_score": 0.322,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "Not Relevant",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on an LLM-based framework for decision-making under uncertainty, emphasizing planning and information seeking, but does not involve training models with human feedback, reward models, or reinforcement learning based on human preferences.",
      "weak_supervision_justification": "The paper introduces a decision-making framework and benchmarks using LLMs, but it does not discuss training models with programmatically generated labels from noisy sources or any form of weak supervision techniques.",
      "diffusion_reasoning_justification": "The paper describes LLM-based planning with information seeking, which involves multi-step reasoning, but it does not incorporate diffusion models, iterative refinement processes, or treat reasoning paths as entities for holistic correction as defined in diffusion-based reasoning.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01532",
      "title": "MATCH: Multi-faceted Adaptive Topo-Consistency for Semi-Supervised\n  Histopathology Segmentation",
      "authors": [
        "Meilong Xu",
        "Xiaoling Hu",
        "Shahira Abousamra",
        "Chen Li",
        "Chao Chen"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "In semi-supervised segmentation, capturing meaningful semantic structures\nfrom unlabeled data is essential. This is particularly challenging in\nhistopathology image analysis, where objects are densely distributed. To\naddress this issue, we propose a semi-supervised segmentation framework\ndesigned to robustly identify and preserve relevant topological features. Our\nmethod leverages multiple perturbed predictions obtained through stochastic\ndropouts and temporal training snapshots, enforcing topological consistency\nacross these varied outputs. This consistency mechanism helps distinguish\nbiologically meaningful structures from transient and noisy artifacts. A key\nchallenge in this process is to accurately match the corresponding topological\nfeatures across the predictions in the absence of ground truth. To overcome\nthis, we introduce a novel matching strategy that integrates spatial overlap\nwith global structural alignment, minimizing discrepancies among predictions.\nExtensive experiments demonstrate that our approach effectively reduces\ntopological errors, resulting in more robust and accurate segmentations\nessential for reliable downstream analysis. Code is available at\n\\href{https://github.com/Melon-Xu/MATCH}{https://github.com/Melon-Xu/MATCH}.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01532v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01532v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.306,
      "weak_supervision_score": 0.374,
      "diffusion_reasoning_score": 0.335,
      "distributed_training_score": 0.325,
      "datasets_score": 0.302,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01540",
      "title": "Towards Better Optimization For Listwise Preference in Diffusion Models",
      "authors": [
        "Jiamu Bai",
        "Xin Yu",
        "Meilong Xu",
        "Weitao Lu",
        "Xin Pan",
        "Kiwan Maeng",
        "Daniel Kifer",
        "Jian Wang",
        "Yu Wang"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Reinforcement learning from human feedback (RLHF) has proven effectiveness\nfor aligning text-to-image (T2I) diffusion models with human preferences.\nAlthough Direct Preference Optimization (DPO) is widely adopted for its\ncomputational efficiency and avoidance of explicit reward modeling, its\napplications to diffusion models have primarily relied on pairwise preferences.\nThe precise optimization of listwise preferences remains largely unaddressed.\nIn practice, human feedback on image preferences often contains implicit ranked\ninformation, which conveys more precise human preferences than pairwise\ncomparisons. In this work, we propose Diffusion-LPO, a simple and effective\nframework for Listwise Preference Optimization in diffusion models with\nlistwise data. Given a caption, we aggregate user feedback into a ranked list\nof images and derive a listwise extension of the DPO objective under the\nPlackett-Luce model. Diffusion-LPO enforces consistency across the entire\nranking by encouraging each sample to be preferred over all of its lower-ranked\nalternatives. We empirically demonstrate the effectiveness of Diffusion-LPO\nacross various tasks, including text-to-image generation, image editing, and\npersonalized preference alignment. Diffusion-LPO consistently outperforms\npairwise DPO baselines on visual quality and preference alignment.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01540v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01540v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.511,
      "weak_supervision_score": 0.389,
      "diffusion_reasoning_score": 0.55,
      "distributed_training_score": 0.357,
      "datasets_score": 0.332,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Highly Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper directly builds on RLHF by adapting Direct Preference Optimization (DPO) for diffusion models, using human feedback to align models with preferences. It proposes Diffusion-LPO as an extension, which incorporates human-ranked data to fine-tune models, aligning with RLHF's core principles of using human preferences for optimization.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on optimizing diffusion models for text-to-image generation and preference alignment, without any adaptation of diffusion processes for multi-step logical reasoning or solving complex logical tasks as defined in the topic.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "completed",
      "summary": "The paper, titled \"Towards Better Optimization For Listwise Preference in Diffusion Models,\" addresses the limitations of pairwise preference optimization in text-to-image diffusion models by proposing Diffusion-LPO, a framework that extends Direct Preference Optimization (DPO) to handle listwise preferences using the Plackett-Luce model. By aggregating user feedback into ranked lists of images and enforcing consistency across the entire ranking, Diffusion-LPO improves alignment with human preferences, demonstrating superior performance over pairwise DPO baselines in tasks such as text-to-image generation, image editing, and personalized alignment, with empirical results showing up to 12% higher win rates on datasets like Pick-a-Pic.",
      "novelty_score": "Moderate",
      "novelty_justification": "The paper presents a notable improvement by extending DPO to listwise preferences, offering a clever adaptation of existing techniques to better capture ranked human feedback without introducing entirely new problems or architectures. While it advances the state-of-the-art in preference optimization for diffusion models, it primarily builds on established methods rather than introducing a groundbreaking innovation.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to be cited and built upon in the subfield of diffusion models and human preference alignment, as it provides a practical enhancement for improving AI-generated content quality. However, its influence may be limited to specific applications in computer vision rather than broadly across all AI research or commercial domains.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper represents a strong, valuable contribution to preference optimization in diffusion models, offering insights and empirical evidence that could benefit researchers in generative AI. It is essential for those working in computer vision and text-to-image synthesis to be aware of this advancement, though not universally critical for all audiences.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/27f6531af74b0aee04a572884d908421f03881ad",
      "total_authors": 9,
      "authors_found": 8,
      "highest_h_index": 13,
      "average_h_index": 1.625,
      "notable_authors_count": 1,
      "author_h_indexes": [
        {
          "name": "Jiamu Bai",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2384406213"
        },
        {
          "name": "Xin Yu",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2384788227"
        },
        {
          "name": "Meilong Xu",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383467484"
        },
        {
          "name": "Weitao Lu",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2384458457"
        },
        {
          "name": "Xin Pan",
          "h_index": null,
          "profile_url": null
        },
        {
          "name": "Kiwan Maeng",
          "h_index": 13,
          "profile_url": "https://www.semanticscholar.org/author/10995410"
        },
        {
          "name": "Daniel Kifer",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383308972"
        },
        {
          "name": "Jian Wang",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2384060938"
        },
        {
          "name": "Yu Wang",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2384008233"
        }
      ]
    },
    {
      "id": "2510.01544",
      "title": "Step-Aware Policy Optimization for Reasoning in Diffusion Large Language\n  Models",
      "authors": [
        "Shaoan Xie",
        "Lingjing Kong",
        "Xiangchen Song",
        "Xinshuai Dong",
        "Guangyi Chen",
        "Eric P. Xing",
        "Kun Zhang"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Diffusion language models (dLLMs) offer a promising, non-autoregressive\nparadigm for text generation, yet training them for complex reasoning remains a\nkey challenge. Current reinforcement learning approaches often rely on sparse,\noutcome-based rewards, which can reinforce flawed reasoning paths that lead to\ncoincidentally correct answers. We argue that this stems from a fundamental\nmismatch with the natural structure of reasoning. We first propose a\ntheoretical framework that formalizes complex problem solving as a hierarchical\nselection process, where an intractable global constraint is decomposed into a\nseries of simpler, localized logical steps. This framework provides a\nprincipled foundation for algorithm design, including theoretical insights into\nthe identifiability of this latent reasoning structure. Motivated by this\ntheory, we identify unstructured refinement -- a failure mode where a model's\niterative steps do not contribute meaningfully to the solution -- as a core\ndeficiency in existing methods. We then introduce Step-Aware Policy\nOptimization (SAPO), a novel RL algorithm that aligns the dLLM's denoising\nprocess with the latent reasoning hierarchy. By using a process-based reward\nfunction that encourages incremental progress, SAPO guides the model to learn\nstructured, coherent reasoning paths. Our empirical results show that this\nprincipled approach significantly improves performance on challenging reasoning\nbenchmarks and enhances the interpretability of the generation process.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01544v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01544v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.456,
      "weak_supervision_score": 0.386,
      "diffusion_reasoning_score": 0.674,
      "distributed_training_score": 0.376,
      "datasets_score": 0.311,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Highly Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on Step-Aware Policy Optimization (SAPO), an RL algorithm using process-based rewards derived from task performance, not human feedback. It does not involve training a reward model on human-ranked data or aligning with human preferences, which are core to RLHF.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper's main contribution, SAPO, directly adapts the iterative refinement process of diffusion models (dLLMs) for complex, multi-step logical reasoning. It treats the reasoning path as a holistic entity that is refined over steps, aligning with the topic's definition of diffusion-based reasoning.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "completed",
      "summary": "This paper addresses the challenges in training diffusion language models (dLLMs) for complex reasoning by proposing a theoretical framework that formalizes reasoning as a hierarchical selection process, highlighting the identifiability of latent logical structures. It introduces Step-Aware Policy Optimization (SAPO), a reinforcement learning algorithm that employs process-based rewards to align the model's denoising steps with this hierarchy, resulting in improved performance on reasoning benchmarks and enhanced interpretability of generated paths.",
      "novelty_score": "High",
      "novelty_justification": "The paper introduces a novel theoretical framework for hierarchical reasoning and a new RL algorithm (SAPO) that significantly advances training methods for dLLMs by addressing unstructured refinement issues. This represents a true innovation in handling complex problem-solving in non-autoregressive models.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to be cited and built upon in the subfield of diffusion models and language model reasoning, as it offers practical improvements in performance and interpretability. However, its influence may remain confined to specific AI applications rather than broadly transforming the field.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper provides valuable theoretical insights and empirical improvements in dLLM training, making it important for researchers focused on AI reasoning, though it is not essential for those outside this niche. It represents a strong contribution worth considering for its methodological advancements.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/ffd3feff3f8ccf86ead4dafee3be6f55035dfe6e",
      "total_authors": 7,
      "authors_found": 7,
      "highest_h_index": 16,
      "average_h_index": 5.714285714285714,
      "notable_authors_count": 2,
      "author_h_indexes": [
        {
          "name": "Shaoan Xie",
          "h_index": 16,
          "profile_url": "https://www.semanticscholar.org/author/25106675"
        },
        {
          "name": "Lingjing Kong",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2324899900"
        },
        {
          "name": "Xiangchen Song",
          "h_index": 5,
          "profile_url": "https://www.semanticscholar.org/author/2262495949"
        },
        {
          "name": "Xinshuai Dong",
          "h_index": 5,
          "profile_url": "https://www.semanticscholar.org/author/2262501910"
        },
        {
          "name": "Guan-Hong Chen",
          "h_index": 11,
          "profile_url": "https://www.semanticscholar.org/author/2155315836"
        },
        {
          "name": "Eric P.Xing",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383310512"
        },
        {
          "name": "Kun Zhang",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2372757363"
        }
      ]
    },
    {
      "id": "2510.01545",
      "title": "Predictive Preference Learning from Human Interventions",
      "authors": [
        "Haoyuan Cai",
        "Zhenghao Peng",
        "Bolei Zhou"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)",
        "cs.RO (Robotics)"
      ],
      "abstract": "Learning from human involvement aims to incorporate the human subject to\nmonitor and correct agent behavior errors. Although most interactive imitation\nlearning methods focus on correcting the agent's action at the current state,\nthey do not adjust its actions in future states, which may be potentially more\nhazardous. To address this, we introduce Predictive Preference Learning from\nHuman Interventions (PPL), which leverages the implicit preference signals\ncontained in human interventions to inform predictions of future rollouts. The\nkey idea of PPL is to bootstrap each human intervention into L future time\nsteps, called the preference horizon, with the assumption that the agent\nfollows the same action and the human makes the same intervention in the\npreference horizon. By applying preference optimization on these future states,\nexpert corrections are propagated into the safety-critical regions where the\nagent is expected to explore, significantly improving learning efficiency and\nreducing human demonstrations needed. We evaluate our approach with experiments\non both autonomous driving and robotic manipulation benchmarks and demonstrate\nits efficiency and generality. Our theoretical analysis further shows that\nselecting an appropriate preference horizon L balances coverage of risky states\nwith label correctness, thereby bounding the algorithmic optimality gap. Demo\nand code are available at: https://metadriverse.github.io/ppl",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01545v2",
      "pdf_url": "http://arxiv.org/pdf/2510.01545v2",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.57,
      "weak_supervision_score": 0.423,
      "diffusion_reasoning_score": 0.365,
      "distributed_training_score": 0.36,
      "datasets_score": 0.317,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Highly Relevant",
      "weak_supervision_relevance": "Tangentially Relevant",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper's main contribution, Predictive Preference Learning from Human Interventions (PPL), directly involves learning from human feedback by using interventions as implicit preference signals to optimize agent behavior, similar to RLHF. It employs preference optimization on predicted trajectories, akin to training a reward model from human-ranked data and fine-tuning via reinforcement learning, as seen in references to RL from Human Feedback in the introduction. This alignment with human preferences to improve policy learning makes it highly relevant to RLHF.",
      "weak_supervision_justification": "The paper involves bootstrapping human interventions into future states to generate additional preference signals, which could introduce noisy or imprecise labels, somewhat resembling weak supervision. However, the core focus is on interactive imitation learning with direct human input rather than programmatically generating labels from high-level sources, making it only tangentially related and not a primary aspect of the method.",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "completed",
      "summary": "The paper introduces Predictive Preference Learning from Human Interventions (PPL), a novel algorithm for interactive imitation learning that uses trajectory predictions to forecast an agent's future states and visualize them for human supervisors, enabling proactive interventions. By bootstrapping human interventions into future time steps via preference optimization, PPL improves learning efficiency, reduces the need for demonstrations, and enhances safety in tasks like autonomous driving and robotic manipulation, as validated through experiments on benchmarks such as MetaDrive and Robosuite, along with theoretical analysis showing bounded optimality gaps.",
      "novelty_score": "Moderate",
      "novelty_justification": "The paper presents a notable improvement by combining trajectory prediction and preference learning in interactive imitation learning, effectively addressing the limitation of prior methods that only correct current states. While it builds on existing ideas, it introduces a new way to propagate corrections to future states, advancing efficiency without creating an entirely new paradigm.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to be cited and built upon in subfields like robotics and autonomous driving, as it enhances safety and efficiency in human-in-the-loop learning. However, its influence may remain confined to specific applications rather than broadly transforming the field.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper provides a strong, practical contribution to interactive imitation learning with clear benefits in efficiency and safety, making it valuable for researchers in AI and robotics. While not essential for all, it offers insights that could inform ongoing work in human-agent interactions.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/949b38448641e2db90865743b714fdecbf221a7b",
      "total_authors": 3,
      "authors_found": 2,
      "highest_h_index": 16,
      "average_h_index": 10.5,
      "notable_authors_count": 1,
      "author_h_indexes": [
        {
          "name": "Haoyuan Cai",
          "h_index": null,
          "profile_url": null
        },
        {
          "name": "Zhenghao Peng",
          "h_index": 16,
          "profile_url": "https://www.semanticscholar.org/author/46216016"
        },
        {
          "name": "Bolei Zhou",
          "h_index": 5,
          "profile_url": "https://www.semanticscholar.org/author/2261182340"
        }
      ]
    },
    {
      "id": "2510.01546",
      "title": "Growing Visual Generative Capacity for Pre-Trained MLLMs",
      "authors": [
        "Hanyu Wang",
        "Jiaming Han",
        "Ziyan Yang",
        "Qi Zhao",
        "Shanchuan Lin",
        "Xiangyu Yue",
        "Abhinav Shrivastava",
        "Zhenheng Yang",
        "Hao Chen"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "Multimodal large language models (MLLMs) extend the success of language\nmodels to visual understanding, and recent efforts have sought to build unified\nMLLMs that support both understanding and generation. However, constructing\nsuch models remains challenging: hybrid approaches combine continuous\nembeddings with diffusion or flow-based objectives, producing high-quality\nimages but breaking the autoregressive paradigm, while pure autoregressive\napproaches unify text and image prediction over discrete visual tokens but\noften face trade-offs between semantic alignment and pixel-level fidelity. In\nthis work, we present Bridge, a pure autoregressive unified MLLM that augments\npre-trained visual understanding models with generative ability through a\nMixture-of-Transformers architecture, enabling both image understanding and\ngeneration within a single next-token prediction framework. To further improve\nvisual generation fidelity, we propose a semantic-to-pixel discrete\nrepresentation that integrates compact semantic tokens with fine-grained pixel\ntokens, achieving strong language alignment and precise description of visual\ndetails with only a 7.9% increase in sequence length. Extensive experiments\nacross diverse multimodal benchmarks demonstrate that Bridge achieves\ncompetitive or superior results in both understanding and generation\nbenchmarks, while requiring less training data and reduced training time\ncompared to prior unified MLLMs.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01546v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01546v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.358,
      "weak_supervision_score": 0.366,
      "diffusion_reasoning_score": 0.491,
      "distributed_training_score": 0.368,
      "datasets_score": 0.308,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on pure autoregressive unified MLLMs for visual understanding and generation, using next-token prediction and discrete tokens. It mentions diffusion-based methods in hybrid approaches as a contrast but does not adapt diffusion for multi-step logical reasoning or chain-of-thought processes. Therefore, the paper lacks any components related to diffusion-based reasoning.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01547",
      "title": "Robust Classification of Oral Cancer with Limited Training Data",
      "authors": [
        "Akshay Bhagwan Sonawane",
        "Lena D. Swamikannan",
        "Lakshman Tamil"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "Oral cancer ranks among the most prevalent cancers globally, with a\nparticularly high mortality rate in regions lacking adequate healthcare access.\nEarly diagnosis is crucial for reducing mortality; however, challenges persist\ndue to limited oral health programs, inadequate infrastructure, and a shortage\nof healthcare practitioners. Conventional deep learning models, while\npromising, often rely on point estimates, leading to overconfidence and reduced\nreliability. Critically, these models require large datasets to mitigate\noverfitting and ensure generalizability, an unrealistic demand in settings with\nlimited training data. To address these issues, we propose a hybrid model that\ncombines a convolutional neural network (CNN) with Bayesian deep learning for\noral cancer classification using small training sets. This approach employs\nvariational inference to enhance reliability through uncertainty\nquantification. The model was trained on photographic color images captured by\nsmartphones and evaluated on three distinct test datasets. The proposed method\nachieved 94% accuracy on a test dataset with a distribution similar to that of\nthe training data, comparable to traditional CNN performance. Notably, for\nreal-world photographic image data, despite limitations and variations\ndiffering from the training dataset, the proposed model demonstrated superior\ngeneralizability, achieving 88% accuracy on diverse datasets compared to 72.94%\nfor traditional CNNs, even with a smaller dataset. Confidence analysis revealed\nthat the model exhibits low uncertainty (high confidence) for correctly\nclassified samples and high uncertainty (low confidence) for misclassified\nsamples. These results underscore the effectiveness of Bayesian inference in\ndata-scarce environments in enhancing early oral cancer diagnosis by improving\nmodel reliability and generalizability.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01547v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01547v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.319,
      "weak_supervision_score": 0.403,
      "diffusion_reasoning_score": 0.328,
      "distributed_training_score": 0.351,
      "datasets_score": 0.346,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "Not Relevant",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "The paper's main contribution is the development of a hybrid CNN-Bayesian deep learning model for oral cancer classification with limited training data, focusing on uncertainty quantification and generalizability. It does not involve weak supervision techniques, such as programmatically generating labels from high-level, noisy, or imprecise sources. Instead, it relies on existing small datasets of annotated images, making it unrelated to weak supervision.",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01552",
      "title": "POLAR: Automating Cyber Threat Prioritization through LLM-Powered\n  Assessment",
      "authors": [
        "Luoxi Tang",
        "Yuqiao Meng",
        "Ankita Patra",
        "Weicheng Ma",
        "Muchao Ye",
        "Zhaohan Xi"
      ],
      "categories": [
        "cs.CR (Cryptography and Security)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Large Language Models (LLMs) are intensively used to assist security analysts\nin counteracting the rapid exploitation of cyber threats, wherein LLMs offer\ncyber threat intelligence (CTI) to support vulnerability assessment and\nincident response. While recent work has shown that LLMs can support a wide\nrange of CTI tasks such as threat analysis, vulnerability detection, and\nintrusion defense, significant performance gaps persist in practical\ndeployments. In this paper, we investigate the intrinsic vulnerabilities of\nLLMs in CTI, focusing on challenges that arise from the nature of the threat\nlandscape itself rather than the model architecture. Using large-scale\nevaluations across multiple CTI benchmarks and real-world threat reports, we\nintroduce a novel categorization methodology that integrates stratification,\nautoregressive refinement, and human-in-the-loop supervision to reliably\nanalyze failure instances. Through extensive experiments and human inspections,\nwe reveal three fundamental vulnerabilities: spurious correlations,\ncontradictory knowledge, and constrained generalization, that limit LLMs in\neffectively supporting CTI. Subsequently, we provide actionable insights for\ndesigning more robust LLM-powered CTI systems to facilitate future research.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01552v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01552v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.455,
      "weak_supervision_score": 0.415,
      "diffusion_reasoning_score": 0.414,
      "distributed_training_score": 0.383,
      "datasets_score": 0.351,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Tangentially Relevant",
      "weak_supervision_relevance": "Not Relevant",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper mentions \"human-in-the-loop supervision\" for analyzing failure instances and refining evaluations, which involves human feedback. However, it does not describe using this feedback to train a reward model or fine-tune the LLM via reinforcement learning, as required for RLHF. Thus, it is only tangentially related through the general use of human oversight.",
      "weak_supervision_justification": "The paper focuses on using pre-existing LLMs for cyber threat prioritization and evaluation on real-world data, but it does not discuss training models with programmatically generated, noisy, or imprecise labels. There is no indication of weak supervision techniques being employed.",
      "diffusion_reasoning_justification": "The paper describes an autoregressive refinement process in its methodology for categorizing and analyzing threats, but it does not involve diffusion models or iterative refinement of a 'Chain-of-Thought' as a holistic entity. There is no mention of adapting diffusion processes for logical reasoning tasks.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01555",
      "title": "Rethinking KL Regularization in RLHF: From Value Estimation to Gradient\n  Optimization",
      "authors": [
        "Kezhao Liu",
        "Jason Klein Liu",
        "Mingtao Chen",
        "Yiming Liu"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) leverages a\nKullback-Leibler (KL) divergence loss to stabilize training and prevent\noverfitting. However, in methods such as GRPO, its implementation may be guided\nby principles from numerical value estimation-a practice that overlooks the\nterm's functional role as an optimization loss. To analyze this issue, we\nestablish a unified framework that connects two seemingly distinct\nimplementation styles: using the mathematical term $k_n$ as a detached\ncoefficient for the policy's score function ('$k_n$ in reward') or as a direct\nloss function through which gradients are propagated ('$k_n$ as loss'). We show\nthat the latter can always be analyzed via an equivalent gradient coefficient\nin the former, unifying the two perspectives. Through this framework, we prove\nthat the conventional '$k_1$ in reward' (like in PPO) is the principled loss\nfor Reverse KL (RKL) regularization. We further establish a key finding: under\non-policy conditions, the '$k_2$ as loss' formulation is, in fact,\ngradient-equivalent to '$k_1$ in reward'. This equivalence, first proven in our\nwork, identifies both as the theoretically sound implementations of the RKL\nobjective. In contrast, we show that the recently adopted '$k_3$ as loss' (like\nin GRPO) is merely a first-order, biased approximation of the principled loss.\nFurthermore, we argue that common off-policy implementations of '$k_n$ as loss'\nmethods are biased due to neglected importance sampling, and we propose a\nprincipled correction. Our findings provide a comprehensive, gradient-based\nrationale for choosing and correctly implementing KL regularization, paving the\nway for more robust and effective RLHF systems.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01555v2",
      "pdf_url": "http://arxiv.org/pdf/2510.01555v2",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.525,
      "weak_supervision_score": 0.338,
      "diffusion_reasoning_score": 0.365,
      "distributed_training_score": 0.347,
      "datasets_score": 0.218,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Highly Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper's main contribution focuses on improving KL regularization in RLHF, a key technique for aligning AI models with human preferences. It analyzes implementations in RLHF methods like GRPO and PPO, provides a unified framework for gradient optimization, and proposes corrections for biases, directly advancing RLHF systems as defined in the topic.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "completed",
      "summary": "This paper reexamines the use of Kullback-Leibler (KL) regularization in Reinforcement Learning from Human Feedback (RLHF) by shifting focus from numerical value estimation to gradient-based optimization, establishing a unified framework to analyze different implementation styles of KL loss. Through theoretical analysis and proofs, the authors demonstrate that conventional implementations like 'k1 in reward' and 'k2 as loss' are gradient-equivalent and principled for Reverse KL regularization, while alternatives such as 'k3 as loss' (used in methods like GRPO) are biased approximations; they also propose corrections for off-policy implementations to enhance stability and effectiveness in RLHF training.",
      "novelty_score": "High",
      "novelty_justification": "The paper introduces a novel gradient-centric framework for analyzing KL regularization in RLHF, proving new equivalences and identifying biases in existing methods, which significantly advances the theoretical understanding and state-of-the-art in AI training techniques.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to influence future research in RLHF by providing theoretical insights and practical corrections that could improve model training stability, though its impact may be confined to specific subfields like machine learning for LLMs.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper offers valuable theoretical contributions and practical guidance for researchers in AI and RLHF, making it a strong and insightful read that enhances understanding of optimization techniques, though it may not be essential for all audiences.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/0451059a51e04456d20e5bd0b1005392ca2aae34",
      "total_authors": 4,
      "authors_found": 4,
      "highest_h_index": 2,
      "average_h_index": 1.25,
      "notable_authors_count": 0,
      "author_h_indexes": [
        {
          "name": "Kezhao Liu",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2297821127"
        },
        {
          "name": "Jason Klein Liu",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383381611"
        },
        {
          "name": "Mingtao Chen",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2383375507"
        },
        {
          "name": "Yiming Liu",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2297811661"
        }
      ]
    },
    {
      "id": "2510.01559",
      "title": "Consistent Assistant Domains Transformer for Source-free Domain\n  Adaptation",
      "authors": [
        "Renrong Shao",
        "Wei Zhang",
        "Kangyang Luo",
        "Qin Li",
        "and Jun Wang"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Source-free domain adaptation (SFDA) aims to address the challenge of\nadapting to a target domain without accessing the source domain directly.\nHowever, due to the inaccessibility of source domain data, deterministic\ninvariable features cannot be obtained. Current mainstream methods primarily\nfocus on evaluating invariant features in the target domain that closely\nresemble those in the source domain, subsequently aligning the target domain\nwith the source domain. However, these methods are susceptible to hard samples\nand influenced by domain bias. In this paper, we propose a Consistent Assistant\nDomains Transformer for SFDA, abbreviated as CADTrans, which solves the issue\nby constructing invariable feature representations of domain consistency.\nConcretely, we develop an assistant domain module for CADTrans to obtain\ndiversified representations from the intermediate aggregated global attentions,\nwhich addresses the limitation of existing methods in adequately representing\ndiversity. Based on assistant and target domains, invariable feature\nrepresentations are obtained by multiple consistent strategies, which can be\nused to distinguish easy and hard samples. Finally, to align the hard samples\nto the corresponding easy samples, we construct a conditional multi-kernel max\nmean discrepancy (CMK-MMD) strategy to distinguish between samples of the same\ncategory and those of different categories. Extensive experiments are conducted\non various benchmarks such as Office-31, Office-Home, VISDA-C, and\nDomainNet-126, proving the significant performance improvements achieved by our\nproposed approaches. Code is available at\nhttps://github.com/RoryShao/CADTrans.git.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01559v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01559v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.335,
      "weak_supervision_score": 0.384,
      "diffusion_reasoning_score": 0.378,
      "distributed_training_score": 0.37,
      "datasets_score": 0.353,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01569",
      "title": "InvThink: Towards AI Safety via Inverse Reasoning",
      "authors": [
        "Yubin Kim",
        "Taehan Kim",
        "Eugene Park",
        "Chunjong Park",
        "Cynthia Breazeal",
        "Daniel McDuff",
        "Hae Won Park"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)",
        "cs.CL (Computation and Language)"
      ],
      "abstract": "We present InvThink, a simple yet powerful approach that gives large language\nmodels (LLMs) the capability of inverse thinking: reasoning through failure\nmodes before generating responses. Unlike existing safety alignment methods\nthat optimize directly for safe response, InvThink instructs models to 1)\nenumerate potential harms, 2) analyze their consequences, and 3) generate safe\noutputs that proactively avoid these risks. Our method reveals three key\nfindings: (i) safety improvements show stronger scaling with model size\ncompared to existing safety methods. (ii) InvThink mitigates safety tax; by\ntraining models to systematically consider failure modes, it preserves general\nreasoning capabilities on standard benchmarks. (iii) beyond general safety\ntasks, InvThink excels in high-stakes domains including external-facing\n(medicine, finance, law) and agentic (blackmail, murder) risk scenarios,\nachieving up to 15.7% reduction in harmful responses compared to baseline\nmethods like SafetyPrompt. We further implement InvThink via supervised\nfine-tuning, and reinforcement learning across three LLM families. These\nresults suggest that inverse reasoning provides a scalable and generalizable\npath toward safer, more capable language models.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01569v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01569v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.515,
      "weak_supervision_score": 0.391,
      "diffusion_reasoning_score": 0.509,
      "distributed_training_score": 0.374,
      "datasets_score": 0.309,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Tangentially Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper mentions using reinforcement learning (e.g., GRPO with safety rewards) to refine models for safety, which is related to RLHF as it involves optimization based on rewards. However, it does not explicitly describe training a separate reward model on human-ranked data or relying on human feedback, focusing instead on automated safety rewards and inverse reasoning. Thus, it touches on reinforcement learning concepts but does not fully align with the core definition of RLHF.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper's main contribution, InvThink, involves inverse reasoning, supervised fine-tuning, and reinforcement learning for safety in LLMs, with no mention of diffusion models, iterative refinement processes, or treating reasoning paths as entities for holistic correction. It does not adapt diffusion techniques for multi-step logical tasks, making it unrelated to this topic.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01571",
      "title": "From Supervision to Exploration: What Does Protein Language Model Learn\n  During Reinforcement Learning?",
      "authors": [
        "Hanqun Cao",
        "Hongrui Zhang",
        "Junde Xu",
        "Zhou Zhang",
        "Lingdong Shen",
        "Minghao Sun",
        "Ge Liu",
        "Jinbo Xu",
        "Wu-Jun Li",
        "Jinren Ni",
        "Cesar de la Fuente-Nunez",
        "Tianfan Fu",
        "Yejin Choi",
        "Pheng-Ann Heng",
        "Fang Wu"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Protein language models (PLMs) have advanced computational protein science\nthrough large-scale pretraining and scalable architectures. In parallel,\nreinforcement learning (RL) has broadened exploration and enabled precise\nmulti-objective optimization in protein design. Yet whether RL can push PLMs\nbeyond their pretraining priors to uncover latent sequence-structure-function\nrules remains unclear. We address this by pairing RL with PLMs across four\ndomains: antimicrobial peptide design, kinase variant optimization, antibody\nengineering, and inverse folding. Using diverse RL algorithms and model\nclasses, we ask if RL improves sampling efficiency and, more importantly, if it\nreveals capabilities not captured by supervised learning. Across benchmarks, RL\nconsistently boosts success rates and sample efficiency. Performance follows a\nthree-factor interaction: task headroom, reward fidelity, and policy capacity\njointly determine gains. When rewards are accurate and informative, policies\nhave sufficient capacity, and tasks leave room beyond supervised baselines,\nimprovements scale; when rewards are noisy or capacity is constrained, gains\nsaturate despite exploration. This view yields practical guidance for RL in\nprotein design: prioritize reward modeling and calibration before scaling\npolicy size, match algorithm and regularization strength to task difficulty,\nand allocate capacity where marginal gains are largest. Implementation is\navailable at https://github.com/chq1155/RL-PLM.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01571v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01571v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.517,
      "weak_supervision_score": 0.423,
      "diffusion_reasoning_score": 0.44,
      "distributed_training_score": 0.398,
      "datasets_score": 0.306,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "Tangentially Relevant",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on using reinforcement learning (RL) with protein language models for protein design, emphasizing reward modeling based on computational or biological objectives, not human feedback. There is no mention of training a reward model on human-ranked data or aligning models with human preferences, which are core to RLHF. Thus, the paper's contributions do not align with RLHF.",
      "weak_supervision_justification": "The paper involves protein language models (PLMs) pretrained on large-scale datasets, which may implicitly use weakly supervised methods like self-supervision. However, the main contribution centers on RL for optimization, not on weak supervision techniques for label generation or model training. This makes it only loosely connected to the topic.",
      "diffusion_reasoning_justification": "The paper discusses RL algorithms like PPO and Monte Carlo tree search for protein design, focusing on exploration and optimization, but does not involve diffusion models, iterative refinement for logical reasoning, or treating reasoning paths as entities for correction. There is no component related to multi-step logical reasoning via diffusion processes.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01574",
      "title": "Synthetic Prefixes to Mitigate Bias in Real-Time Neural Query\n  Autocomplete",
      "authors": [
        "Adithya Rajan",
        "Xiaoyu Liu",
        "Prateek Verma",
        "Vibhu Arora"
      ],
      "categories": [
        "cs.IR (Information Retrieval)",
        "cs.AI (Artificial Intelligence)",
        "cs.CL (Computation and Language)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "We introduce a data-centric approach for mitigating presentation bias in\nreal-time neural query autocomplete systems through the use of synthetic\nprefixes. These prefixes are generated from complete user queries collected\nduring regular search sessions where autocomplete was not active. This allows\nus to enrich the training data for learning to rank models with more diverse\nand less biased examples. This method addresses the inherent bias in engagement\nsignals collected from live query autocomplete interactions, where model\nsuggestions influence user behavior. Our neural ranker is optimized for\nreal-time deployment under strict latency constraints and incorporates a rich\nset of features, including query popularity, seasonality, fuzzy match scores,\nand contextual signals such as department affinity, device type, and vertical\nalignment with previous user queries. To support efficient training, we\nintroduce a task-specific simplification of the listwise loss, reducing\ncomputational complexity from $O(n^2)$ to $O(n)$ by leveraging the query\nautocomplete structure of having only one ground-truth selection per prefix.\nDeployed in a large-scale e-commerce setting, our system demonstrates\nstatistically significant improvements in user engagement, as measured by mean\nreciprocal rank and related metrics. Our findings show that synthetic prefixes\nnot only improve generalization but also provide a scalable path toward bias\nmitigation in other low-latency ranking tasks, including related searches and\nquery recommendations.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01574v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01574v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.419,
      "weak_supervision_score": 0.416,
      "diffusion_reasoning_score": 0.361,
      "distributed_training_score": 0.356,
      "datasets_score": 0.357,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "Highly Relevant",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on data augmentation with synthetic prefixes to mitigate bias in a neural query autocomplete system and trains a learning-to-rank model using user engagement logs. It does not involve training a separate reward model on human-ranked data or using reinforcement learning to fine-tune the main model, which are core elements of RLHF.",
      "weak_supervision_justification": "The paper's main contribution involves programmatically generating synthetic prefixes from complete user queries to create augmented training data, which aligns with weak supervision by using noisy or imprecise sources (e.g., search session logs) to produce labels without relying on hand-labeled data. This approach reduces bias and enriches the dataset for training a neural ranker.",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "completed",
      "summary": "This paper introduces a data-centric approach to mitigate presentation bias in real-time neural query autocomplete systems by generating synthetic prefixes from complete user queries collected during non-autocomplete search sessions, thereby enriching training data for a neural learning-to-rank model. The methodology incorporates contextual features like query popularity and device type, employs a simplified listwise loss for efficient training under latency constraints, and demonstrates significant improvements in user engagement metrics, such as a over 1% increase in mean reciprocal rank, when deployed in a large-scale e-commerce environment.",
      "novelty_score": "Moderate",
      "novelty_justification": "The paper presents a notable improvement by introducing synthetic prefixes as a clever data augmentation strategy to address presentation bias in query autocomplete, combining existing ideas in a new way to enhance training data diversity. While bias mitigation is not entirely novel, this specific application to real-time systems advances the state-of-the-art in neural ranking models.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to be cited and built upon in subfields like information retrieval and AI due to its practical deployment and demonstrated improvements in user engagement. However, its influence may be limited to specific applications in low-latency ranking tasks rather than broader commercial or research domains.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper provides a strong, valuable contribution to bias mitigation in neural query systems, offering practical insights and empirical results that are relevant for researchers in AI and information retrieval. It is significant but not essential for those outside its specific subfield.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/e585ee2f05c6a9884d93464ba0401de8faecbf72",
      "total_authors": 4,
      "authors_found": 4,
      "highest_h_index": 1,
      "average_h_index": 0.25,
      "notable_authors_count": 0,
      "author_h_indexes": [
        {
          "name": "Adithya Rajan",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2360660048"
        },
        {
          "name": "Xiaoyu Liu",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2230083039"
        },
        {
          "name": "Prateek Verma",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383303873"
        },
        {
          "name": "Vibhu Arora",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383311113"
        }
      ]
    },
    {
      "id": "2510.01576",
      "title": "Guiding Multimodal Large Language Models with Blind and Low Vision\n  People Visual Questions for Proactive Visual Interpretations",
      "authors": [
        "Ricardo Gonzalez Penuela",
        "Felipe Arias-Russi",
        "Victor Capriles"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.AI (Artificial Intelligence)",
        "cs.HC (Human-Computer Interaction)"
      ],
      "abstract": "Multimodal large language models (MLLMs) have been integrated into visual\ninterpretation applications to support Blind and Low Vision (BLV) users because\nof their accuracy and ability to provide rich, human-like interpretations.\nHowever, these applications often default to comprehensive, lengthy\ndescriptions regardless of context. This leads to inefficient exchanges, as\nusers must go through irrelevant details rather than receiving the specific\ninformation they are likely to seek. To deliver more contextually-relevant\ninformation, we developed a system that draws on historical BLV users\nquestions. When given an image, our system identifies similar past visual\ncontexts from the VizWiz-LF dataset and uses the associated questions to guide\nthe MLLM generate descriptions more relevant to BLV users. An evaluation with\nthree human labelers who revised 92 context-aware and context-free descriptions\nshowed that context-aware descriptions anticipated and answered users'\nquestions in 76.1% of cases (70 out of 92) and were preferred in 54.4% of\ncomparisons (50 out of 92). Our paper reviews, and data analysis are publicly\navailable in a Github repository at\nhttps://github.com/rgonzalezp/guiding-multimodal-large-language-models-with-blind-and-low-vision-people-visual-questions .",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01576v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01576v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.461,
      "weak_supervision_score": 0.415,
      "diffusion_reasoning_score": 0.424,
      "distributed_training_score": 0.312,
      "datasets_score": 0.376,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "Tangentially Relevant",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on using historical user questions to guide MLLM descriptions via retrieval and prompting, without any mention of training a reward model, fine-tuning with reinforcement learning, or aligning the model using human-ranked data. Human feedback is used only for evaluation, not for model training or optimization.",
      "weak_supervision_justification": "The paper utilizes the VizWiz-LF dataset, which contains real user questions as a form of noisy or high-level labels, to inform MLLM guidance. However, it does not involve training a model with programmatically generated labels; instead, it focuses on retrieval for prompting, which is not the core of weak supervision techniques.",
      "diffusion_reasoning_justification": "The paper describes a system for generating context-aware descriptions using retrieval and MLLMs, with no reference to diffusion models, iterative refinement of reasoning paths, or multi-step logical reasoning processes. It lacks any components related to diffusion-based approaches.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01581",
      "title": "Think Right: Learning to Mitigate Under-Over Thinking via Adaptive,\n  Attentive Compression",
      "authors": [
        "Joykirat Singh",
        "Justin Chih-Yao Chen",
        "Archiki Prasad",
        "Elias Stengel-Eskin",
        "Akshay Nambi",
        "Mohit Bansal"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)",
        "cs.CL (Computation and Language)"
      ],
      "abstract": "Recent thinking models solve complex reasoning tasks by scaling test-time\ncompute, but this scaling must be allocated in line with task difficulty. On\none hand, short reasoning (underthinking) leads to errors on harder problems\nthat require extended reasoning steps; but, excessively long reasoning\n(overthinking) can be token-inefficient, generating unnecessary steps even\nafter reaching a correct intermediate solution. We refer to this as\nunder-adaptivity, where the model fails to modulate its response length\nappropriately given problems of varying difficulty. To address under-adaptivity\nand strike a balance between under- and overthinking, we propose TRAAC (Think\nRight with Adaptive, Attentive Compression), an online post-training RL method\nthat leverages the model's self-attention over a long reasoning trajectory to\nidentify important steps and prune redundant ones. TRAAC also estimates\ndifficulty and incorporates it into training rewards, thereby learning to\nallocate reasoning budget commensurate with example difficulty. Our approach\nimproves accuracy, reduces reasoning steps, and enables adaptive thinking\ncompared to base models and other RL baselines. Across a variety of tasks\n(AIME, AMC, GPQA-D, BBEH), TRAAC (Qwen3-4B) achieves an average absolute\naccuracy gain of 8.4% with a relative reduction in reasoning length of 36.8%\ncompared to the base model, and a 7.9% accuracy gain paired with a 29.4% length\ndrop compared to the best RL baseline. TRAAC also shows strong generalization:\nalthough our models are trained on math datasets, they show accuracy and\nefficiency gains on out-of-distribution non-math datasets like GPQA-D, BBEH,\nand OptimalThinkingBench. Our analysis further verifies that TRAAC provides\nfine-grained adjustments to thinking budget based on difficulty and that a\ncombination of task-difficulty calibration and attention-based compression\nyields gains across diverse tasks.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01581v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01581v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.438,
      "weak_supervision_score": 0.374,
      "diffusion_reasoning_score": 0.546,
      "distributed_training_score": 0.399,
      "datasets_score": 0.293,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper describes an RL-based method (TRAAC) using algorithmic rewards based on accuracy, efficiency, and task difficulty, without involving human-ranked data or a separate reward model trained on human preferences. Thus, it does not align with the definition of RLHF.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on an RL method with attention-based compression for reasoning tasks, but it does not involve diffusion models, iterative refinement processes, or treating Chain-of-Thought as a holistically corrected entity. There is no component related to diffusion-based approaches.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01582",
      "title": "ImageNet-Think-250K: A Large-Scale Synthetic Dataset for Multimodal\n  Reasoning for Vision Language Models",
      "authors": [
        "Krishna Teja Chitty-Venkata",
        "Murali Emani"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "We develop ImageNet-Think, a multimodal reasoning dataset designed to aid the\ndevelopment of Vision Language Models (VLMs) with explicit reasoning\ncapabilities. Our dataset is built on 250,000 images from ImageNet21k dataset,\nproviding structured thinking tokens and corresponding answers. Our synthetic\ndataset is generated by two state-of-the-art VLMs: GLM-4.1V-9B-Thinking and\nKimi-VL-A3B-Thinking-2506. Each image is accompanied by two pairs of\nthinking-answer sequences, creating a resource for training and evaluating\nmultimodal reasoning models. We capture the step-by-step reasoning process of\nVLMs and the final descriptive answers. Our goal with this dataset is to enable\nthe development of more robust VLMs while contributing to the broader\nunderstanding of multimodal reasoning mechanisms. The dataset and evaluation\nbenchmarks will be publicly available to aid research in reasoning/thinking\nmultimodal VLMs.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01582v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01582v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.344,
      "weak_supervision_score": 0.362,
      "diffusion_reasoning_score": 0.539,
      "distributed_training_score": 0.357,
      "datasets_score": 0.458,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "Highly Relevant",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on creating a synthetic dataset for multimodal reasoning using Vision Language Models (VLMs) like GLM-4.1V-Thinking and Kimi-VL-Thinking, but it does not involve diffusion-based methods. There is no mention of iterative refinement processes, chain-of-thought as a holistic entity, or adapting diffusion models for logical tasks, making it unrelated to this topic.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "The paper's main contribution is the introduction of a new large-scale dataset, ImageNet-Think-250K, including its creation methodology, generation using VLMs, and benchmarking for multimodal reasoning. This directly aligns with research on dataset creation, analysis, and evaluation for AI applications.",
      "llm_score_status": "completed",
      "summary": "The paper introduces ImageNet-Think-250K, a large-scale synthetic dataset derived from 250,000 images in the ImageNet-21k dataset, designed to enhance the reasoning capabilities of Vision Language Models (VLMs) by providing explicit thinking tokens and answers. Using two state-of-the-art VLMs, GLM-4.1V-9B-Thinking and Kimi-VL-A3B-Thinking-2506, the authors generate pairs of reasoning sequences and final answers for each image, aiming to address the limitations of existing datasets that lack intermediate reasoning steps; key contributions include the dataset's scale, diversity from multi-model generation, and accompanying benchmarks for evaluating reasoning VLMs.",
      "novelty_score": "Moderate",
      "novelty_justification": "The paper presents a notable improvement by creating a large-scale dataset with explicit reasoning annotations from multiple models, extending existing multimodal datasets in a new way, though it does not introduce a fundamentally new problem or technique.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to be cited and utilized within the subfield of multimodal reasoning for VLMs, as it provides a valuable resource for training and evaluation, but its influence may remain confined to specific research areas rather than broader applications.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper represents a strong contribution by offering a new dataset that could advance VLM development, making it essential for researchers focused on multimodal reasoning to be aware of and potentially use.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/72ec9f0595507a0c3d1a10c39a7b878e3400c081",
      "total_authors": 2,
      "authors_found": 2,
      "highest_h_index": 18,
      "average_h_index": 12.5,
      "notable_authors_count": 2,
      "author_h_indexes": [
        {
          "name": "Krishna Teja Chitty-Venkata",
          "h_index": 7,
          "profile_url": "https://www.semanticscholar.org/author/1418875123"
        },
        {
          "name": "M. Emani",
          "h_index": 18,
          "profile_url": "https://www.semanticscholar.org/author/2157261"
        }
      ]
    },
    {
      "id": "2510.01586",
      "title": "AdvEvo-MARL: Shaping Internalized Safety through Adversarial\n  Co-Evolution in Multi-Agent Reinforcement Learning",
      "authors": [
        "Zhenyu Pan",
        "Yiting Zhang",
        "Zhuo Liu",
        "Yolo Yunlong Tang",
        "Zeliang Zhang",
        "Haozheng Luo",
        "Yuwei Han",
        "Jianshu Zhang",
        "Dennis Wu",
        "Hong-Yu Chen",
        "Haoran Lu",
        "Haoyang Fang",
        "Manling Li",
        "Chenliang Xu",
        "Philip S. Yu",
        "Han Liu"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "LLM-based multi-agent systems excel at planning, tool use, and role\ncoordination, but their openness and interaction complexity also expose them to\njailbreak, prompt-injection, and adversarial collaboration. Existing defenses\nfall into two lines: (i) self-verification that asks each agent to pre-filter\nunsafe instructions before execution, and (ii) external guard modules that\npolice behaviors. The former often underperforms because a standalone agent\nlacks sufficient capacity to detect cross-agent unsafe chains and\ndelegation-induced risks; the latter increases system overhead and creates a\nsingle-point-of-failure-once compromised, system-wide safety collapses, and\nadding more guards worsens cost and complexity. To solve these challenges, we\npropose AdvEvo-MARL, a co-evolutionary multi-agent reinforcement learning\nframework that internalizes safety into task agents. Rather than relying on\nexternal guards, AdvEvo-MARL jointly optimizes attackers (which synthesize\nevolving jailbreak prompts) and defenders (task agents trained to both\naccomplish their duties and resist attacks) in adversarial learning\nenvironments. To stabilize learning and foster cooperation, we introduce a\npublic baseline for advantage estimation: agents within the same functional\ngroup share a group-level mean-return baseline, enabling lower-variance updates\nand stronger intra-group coordination. Across representative attack scenarios,\nAdvEvo-MARL consistently keeps attack-success rate (ASR) below 20%, whereas\nbaselines reach up to 38.33%, while preserving-and sometimes improving-task\naccuracy (up to +3.67% on reasoning tasks). These results show that safety and\nutility can be jointly improved without relying on extra guard agents or added\nsystem overhead.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01586v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01586v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.437,
      "weak_supervision_score": 0.354,
      "diffusion_reasoning_score": 0.36,
      "distributed_training_score": 0.363,
      "datasets_score": 0.292,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper proposes AdvEvo-MARL, a multi-agent reinforcement learning framework for internalizing safety through adversarial co-evolution, but it does not involve human feedback. Specifically, it lacks elements of RLHF such as training a separate reward model on human-ranked data or fine-tuning based on human preferences. Instead, the framework relies on adversarial environments and supervised fine-tuning with curated prompts, making it unrelated to RLHF.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01588",
      "title": "Enhancing Noise Robustness of Parkinson's Disease Telemonitoring via\n  Contrastive Feature Augmentation",
      "authors": [
        "Ziming Tang",
        "Chengbin Hou",
        "Tianyu Zhang",
        "Bangxu Tian",
        "Jinbao Wang",
        "Hairong Lv"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Parkinson's disease (PD) is one of the most common neurodegenerative\ndisorder. PD telemonitoring emerges as a novel assessment modality enabling\nself-administered at-home tests of Unified Parkinson's Disease Rating Scale\n(UPDRS) scores, enhancing accessibility for PD patients. However, three types\nof noise would occur during measurements: (1) patient-induced measurement\ninaccuracies, (2) environmental noise, and (3) data packet loss during\ntransmission, resulting in higher prediction errors. To address these\nchallenges, NoRo, a noise-robust UPDRS prediction framework is proposed. First,\nthe original speech features are grouped into ordered bins, based on the\ncontinuous values of a selected feature, to construct contrastive pairs.\nSecond, the contrastive pairs are employed to train a multilayer perceptron\nencoder for generating noise-robust features. Finally, these features are\nconcatenated with the original features as the augmented features, which are\nthen fed into the UPDRS prediction models. Notably, we further introduces a\nnovel evaluation approach with customizable noise injection module, and\nextensive experiments show that NoRo can successfully enhance the noise\nrobustness of UPDRS prediction across various downstream prediction models\nunder different noisy environments.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01588v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01588v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.394,
      "weak_supervision_score": 0.417,
      "diffusion_reasoning_score": 0.354,
      "distributed_training_score": 0.369,
      "datasets_score": 0.331,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "Moderately Relevant",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "The paper employs Contrastive Learning (CL) to generate noise-robust features by programmatically creating contrastive pairs from feature bins, which aligns with weak supervision as it uses automatically derived supervisory signals from data rather than hand-labeled data. However, the primary focus is on enhancing noise robustness for Parkinson's Disease prediction, not explicitly on weak supervision techniques, making it moderately relevant rather than central.",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "completed",
      "summary": "This paper addresses the challenges of noise in Parkinson's Disease (PD) telemonitoring, particularly patient-induced inaccuracies, environmental noise, and data transmission losses, by introducing NoRo, a noise-robust framework for predicting Unified Parkinson's Disease Rating Scale (UPDRS) scores. The methodology involves grouping speech features into ordered bins, using contrastive learning with a multilayer perceptron encoder to generate noise-robust features, and concatenating these with original features for input into downstream prediction models; experiments demonstrate that NoRo significantly reduces prediction errors by up to 40% in various noisy environments, validated through a customizable noise injection evaluation approach.",
      "novelty_score": "Moderate",
      "novelty_justification": "The paper presents a clever combination of contrastive learning and feature augmentation to address noise robustness in PD telemonitoring, which is a new application of existing techniques to a specific problem. While it advances the state-of-the-art in this niche area, it does not introduce entirely new concepts like a groundbreaking architecture.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to influence research and applications in AI for healthcare, particularly PD telemonitoring, by providing a practical framework that could be built upon or adopted in similar noisy data scenarios. However, its impact is confined to specific subfields rather than having broad, widespread effects across all AI or medical domains.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "The paper delivers a valuable, practical contribution to machine learning in healthcare by enhancing noise robustness in PD monitoring, with open-source code and empirical evidence, making it essential for researchers in AI and medical diagnostics. While not revolutionary, it addresses a timely and relevant issue effectively.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/06251417a1d19ea4a77dbbd8fe2daace9a9c4876",
      "total_authors": 6,
      "authors_found": 6,
      "highest_h_index": 3,
      "average_h_index": 1.0,
      "notable_authors_count": 0,
      "author_h_indexes": [
        {
          "name": "Ziming Tang",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2385449422"
        },
        {
          "name": "Chengbin Hou",
          "h_index": 3,
          "profile_url": "https://www.semanticscholar.org/author/2296632735"
        },
        {
          "name": "Tianyu Zhang",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383461031"
        },
        {
          "name": "Bangxu Tian",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383303519"
        },
        {
          "name": "Jinbao Wang",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383415282"
        },
        {
          "name": "Hairong Lv",
          "h_index": 3,
          "profile_url": "https://www.semanticscholar.org/author/2261175635"
        }
      ]
    },
    {
      "id": "2510.01600",
      "title": "A Comparison of Independent and Joint Fine-tuning Strategies for\n  Retrieval-Augmented Generation",
      "authors": [
        "Neal Gregory Lawton",
        "Alfy Samuel",
        "Anoop Kumar",
        "Daben Liu"
      ],
      "categories": [
        "cs.CL (Computation and Language)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "A Comparison of Independent and Joint Fine-tuning Strategies for\nRetrieval-Augmented Generation Download PDF Neal Gregory Lawton, Alfy Samuel,\nAnoop Kumar, Daben Liu Published: 20 Aug 2025, Retrieval augmented generation\n(RAG) is a popular framework for question answering that is powered by two\nlarge language models (LLMs): an embedding model that retrieves context\ndocuments from a database that are relevant to a given question, and a\ngenerator model that uses the retrieved context to generate an answer to the\nquestion. Both the embedding and generator models can be fine-tuned to increase\nperformance of a RAG pipeline on a new task, but multiple fine-tuning\nstrategies exist with different costs and benefits. In this paper, we evaluate\nand compare several RAG fine-tuning strategies, including independent, joint,\nand two-phase fine-tuning. In our experiments, we observe that all of these\nstrategies achieve about equal improvement in EM and F1 generation quality\nmetrics, although they have significantly different computational costs. We\nconclude the optimal fine-tuning strategy to use depends on whether the\ntraining dataset includes context labels and whether a grid search over the\nlearning rates for the embedding and generator models is required.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01600v2",
      "pdf_url": "http://arxiv.org/pdf/2510.01600v2",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.42,
      "weak_supervision_score": 0.372,
      "diffusion_reasoning_score": 0.457,
      "distributed_training_score": 0.389,
      "datasets_score": 0.354,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on fine-tuning strategies for Retrieval-Augmented Generation (RAG) using supervised methods on labeled datasets, without any mention of human feedback, reward models, or reinforcement learning techniques. It does not involve aligning models with human preferences through RLHF.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper evaluates fine-tuning strategies for RAG, which involves retrieval and generation with LLMs, but it does not incorporate diffusion models, iterative refinement processes, or multi-step logical reasoning for complex tasks as defined. There is no component for holistically correcting a 'Chain-of-Thought' entity.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01606",
      "title": "Bridging Collaborative Filtering and Large Language Models with Dynamic\n  Alignment, Multimodal Fusion and Evidence-grounded Explanations",
      "authors": [
        "Bo Ma",
        "LuYao Liu",
        "Simon Lau",
        "Chandler Yuan",
        "and XueY Cui",
        "Rosie Zhang"
      ],
      "categories": [
        "cs.IR (Information Retrieval)",
        "cs.AI (Artificial Intelligence)",
        "cs.CL (Computation and Language)"
      ],
      "abstract": "Recent research has explored using Large Language Models for recommendation\ntasks by transforming user interaction histories and item metadata into text\nprompts, then having the LLM produce rankings or recommendations. A promising\napproach involves connecting collaborative filtering knowledge to LLM\nrepresentations through compact adapter networks, which avoids expensive\nfine-tuning while preserving the strengths of both components. Yet several\nchallenges persist in practice: collaborative filtering models often use static\nsnapshots that miss rapidly changing user preferences; many real-world items\ncontain rich visual and audio content beyond textual descriptions; and current\nsystems struggle to provide trustworthy explanations backed by concrete\nevidence. Our work introduces \\model{}, a framework that tackles these\nlimitations through three key innovations. We develop an online adaptation\nmechanism that continuously incorporates new user interactions through\nlightweight modules, avoiding the need to retrain large models. We create a\nunified representation that seamlessly combines collaborative signals with\nvisual and audio features, handling cases where some modalities may be\nunavailable. Finally, we design an explanation system that grounds\nrecommendations in specific collaborative patterns and item attributes,\nproducing natural language rationales users can verify. Our approach maintains\nthe efficiency of frozen base models while adding minimal computational\noverhead, making it practical for real-world deployment.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01606v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01606v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.476,
      "weak_supervision_score": 0.392,
      "diffusion_reasoning_score": 0.505,
      "distributed_training_score": 0.37,
      "datasets_score": 0.371,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on bridging collaborative filtering and large language models using adapters, multimodal fusion, and adaptive mechanisms, but it does not involve training a reward model on human-ranked data or using reinforcement learning to fine-tune models based on human feedback.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper does not incorporate diffusion models or iterative refinement processes for multi-step logical reasoning; it primarily addresses recommendation systems through collaborative filtering, LLMs, and multimodal integration without any mention of treating Chain-of-Thought as a holistically corrected entity.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01607",
      "title": "ActiveUMI: Robotic Manipulation with Active Perception from Robot-Free\n  Human Demonstrations",
      "authors": [
        "Qiyuan Zeng",
        "Chengmeng Li",
        "Jude St. John",
        "Zhongyi Zhou",
        "Junjie Wen",
        "Guorui Feng",
        "Yichen Zhu",
        "Yi Xu"
      ],
      "categories": [
        "cs.RO (Robotics)",
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "We present ActiveUMI, a framework for a data collection system that transfers\nin-the-wild human demonstrations to robots capable of complex bimanual\nmanipulation. ActiveUMI couples a portable VR teleoperation kit with sensorized\ncontrollers that mirror the robot's end-effectors, bridging human-robot\nkinematics via precise pose alignment. To ensure mobility and data quality, we\nintroduce several key techniques, including immersive 3D model rendering, a\nself-contained wearable computer, and efficient calibration methods.\nActiveUMI's defining feature is its capture of active, egocentric perception.\nBy recording an operator's deliberate head movements via a head-mounted\ndisplay, our system learns the crucial link between visual attention and\nmanipulation. We evaluate ActiveUMI on six challenging bimanual tasks. Policies\ntrained exclusively on ActiveUMI data achieve an average success rate of 70\\%\non in-distribution tasks and demonstrate strong generalization, retaining a\n56\\% success rate when tested on novel objects and in new environments. Our\nresults demonstrate that portable data collection systems, when coupled with\nlearned active perception, provide an effective and scalable pathway toward\ncreating generalizable and highly capable real-world robot policies.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01607v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01607v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.399,
      "weak_supervision_score": 0.404,
      "diffusion_reasoning_score": 0.335,
      "distributed_training_score": 0.339,
      "datasets_score": 0.337,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "Not Relevant",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "The paper's main contribution is a framework for collecting high-quality, precise human demonstrations via VR teleoperation to train robot policies, emphasizing active perception and embodiment alignment. It relies on direct human inputs for supervision, which are calibrated and aligned for accuracy, rather than programmatically generating labels from high-level, noisy, or imprecise sources. Weak supervision typically involves using indirect or noisy labeling methods, which is not a feature of this work.",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01608",
      "title": "NPN: Non-Linear Projections of the Null-Space for Imaging Inverse\n  Problems",
      "authors": [
        "Roman Jacome",
        "Romario Gualdrón-Hurtado",
        "Leon Suarez",
        "Henry Arguello"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "eess.SP (Signal Processing)",
        "math.OC (Optimization and Control)"
      ],
      "abstract": "Imaging inverse problems aims to recover high-dimensional signals from\nundersampled, noisy measurements, a fundamentally ill-posed task with infinite\nsolutions in the null-space of the sensing operator. To resolve this ambiguity,\nprior information is typically incorporated through handcrafted regularizers or\nlearned models that constrain the solution space. However, these priors\ntypically ignore the task-specific structure of that null-space. In this work,\nwe propose \\textit{Non-Linear Projections of the Null-Space} (NPN), a novel\nclass of regularization that, instead of enforcing structural constraints in\nthe image domain, promotes solutions that lie in a low-dimensional projection\nof the sensing matrix's null-space with a neural network. Our approach has two\nkey advantages: (1) Interpretability: by focusing on the structure of the\nnull-space, we design sensing-matrix-specific priors that capture information\northogonal to the signal components that are fundamentally blind to the sensing\nprocess. (2) Flexibility: NPN is adaptable to various inverse problems,\ncompatible with existing reconstruction frameworks, and complementary to\nconventional image-domain priors. We provide theoretical guarantees on\nconvergence and reconstruction accuracy when used within plug-and-play methods.\nEmpirical results across diverse sensing matrices demonstrate that NPN priors\nconsistently enhance reconstruction fidelity in various imaging inverse\nproblems, such as compressive sensing, deblurring, super-resolution, computed\ntomography, and magnetic resonance imaging, with plug-and-play methods,\nunrolling networks, deep image prior, and diffusion models.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01608v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01608v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.316,
      "weak_supervision_score": 0.339,
      "diffusion_reasoning_score": 0.361,
      "distributed_training_score": 0.327,
      "datasets_score": 0.233,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01609",
      "title": "AgentRec: Next-Generation LLM-Powered Multi-Agent Collaborative\n  Recommendation with Adaptive Intelligence",
      "authors": [
        "Bo Ma",
        "Hang Li",
        "ZeHua Hu",
        "XiaoFan Gui",
        "LuYao Liu",
        "Simon Lau"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Interactive conversational recommender systems have gained significant\nattention for their ability to capture user preferences through natural\nlanguage interactions. However, existing approaches face substantial challenges\nin handling dynamic user preferences, maintaining conversation coherence, and\nbalancing multiple ranking objectives simultaneously. This paper introduces\nAgentRec, a next-generation LLM-powered multi-agent collaborative\nrecommendation framework that addresses these limitations through hierarchical\nagent networks with adaptive intelligence. Our approach employs specialized\nLLM-powered agents for conversation understanding, preference modeling, context\nawareness, and dynamic ranking, coordinated through an adaptive weighting\nmechanism that learns from interaction patterns. We propose a three-tier\nlearning strategy combining rapid response for simple queries, intelligent\nreasoning for complex preferences, and deep collaboration for challenging\nscenarios. Extensive experiments on three real-world datasets demonstrate that\nAgentRec achieves consistent improvements over state-of-the-art baselines, with\n2.8\\% enhancement in conversation success rate, 1.9\\% improvement in\nrecommendation accuracy (NDCG@10), and 3.2\\% better conversation efficiency\nwhile maintaining comparable computational costs through intelligent agent\ncoordination.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01609v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01609v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.472,
      "weak_supervision_score": 0.374,
      "diffusion_reasoning_score": 0.439,
      "distributed_training_score": 0.356,
      "datasets_score": 0.355,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Tangentially Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper references multi-agent reinforcement learning in the introduction as a related advancement, but it does not describe using human feedback to train a reward model or fine-tune models via reinforcement learning. AgentRec focuses on LLM-powered agents and adaptive mechanisms, making it only loosely connected to RLHF.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper does not involve diffusion models, iterative refinement processes, or treating reasoning paths as entities for multi-step correction. Its contributions center on LLM-powered multi-agent systems for conversational recommendations, with no mention of diffusion-based techniques.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01611",
      "title": "PsychCounsel-Bench: Evaluating the Psychology Intelligence of Large\n  Language Models",
      "authors": [
        "Min Zeng"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)",
        "cs.CL (Computation and Language)"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable success across a\nwide range of industries, primarily due to their impressive generative\nabilities. Yet, their potential in applications requiring cognitive abilities,\nsuch as psychological counseling, remains largely untapped. This paper\ninvestigates the key question: \\textit{Can LLMs be effectively applied to\npsychological counseling?} To determine whether an LLM can effectively take on\nthe role of a psychological counselor, the first step is to assess whether it\nmeets the qualifications required for such a role, namely the ability to pass\nthe U.S. National Counselor Certification Exam (NCE). This is because, just as\na human counselor must pass a certification exam to practice, an LLM must\ndemonstrate sufficient psychological knowledge to meet the standards required\nfor such a role. To address this, we introduce PsychCounsel-Bench, a benchmark\ngrounded in U.S.national counselor examinations, a licensure test for\nprofessional counselors that requires about 70\\% accuracy to pass.\nPsychCounsel-Bench comprises approximately 2,252 carefully curated\nsingle-choice questions, crafted to require deep understanding and broad enough\nto cover various sub-disciplines of psychology. This benchmark provides a\ncomprehensive assessment of an LLM's ability to function as a counselor. Our\nevaluation shows that advanced models such as GPT-4o, Llama3.3-70B, and\nGemma3-27B achieve well above the passing threshold, while smaller open-source\nmodels (e.g., Qwen2.5-7B, Mistral-7B) remain far below it. These results\nsuggest that only frontier LLMs are currently capable of meeting counseling\nexam standards, highlighting both the promise and the challenges of developing\npsychology-oriented LLMs. We release the proposed dataset for public use:\nhttps://github.com/cloversjtu/PsychCounsel-Bench",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01611v3",
      "pdf_url": "http://arxiv.org/pdf/2510.01611v3",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.434,
      "weak_supervision_score": 0.363,
      "diffusion_reasoning_score": 0.434,
      "distributed_training_score": 0.339,
      "datasets_score": 0.42,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "Highly Relevant",
      "rlhf_justification": "The paper focuses on creating a benchmark dataset for evaluating LLMs in psychological counseling and testing their performance, but it does not involve training or fine-tuning models using human feedback, a reward model, or reinforcement learning techniques.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper evaluates LLMs on a benchmark of psychological questions, which may involve general reasoning, but it does not mention or utilize diffusion-based methods for multi-step logical reasoning or iterative refinement of reasoning paths.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "The paper's main contribution is the creation, curation, and benchmarking of a new dataset (PsychCounsel-Bench) for evaluating LLMs in psychological applications, including details on data collection, refinement, expert verification, and public release, which aligns directly with dataset-focused research in AI.",
      "llm_score_status": "completed",
      "summary": "The paper introduces PsychCounsel-Bench, a benchmark consisting of approximately 2,252 single-choice questions derived from the U.S. National Counselor Certification Exam, to evaluate the psychological intelligence of large language models (LLMs) and determine their suitability for counseling roles. The methodology involves collecting, paraphrasing, and refining questions using GPT-based methods followed by expert verification, with evaluations revealing that advanced LLMs like GPT-4o and Llama3.3-70B surpass the 70% passing threshold, while smaller models fall short, indicating both potential and limitations in applying LLMs to psychological counseling.",
      "novelty_score": "Moderate",
      "novelty_justification": "The paper presents a notable improvement by developing a specialized benchmark for assessing LLMs in psychological counseling, adapting existing techniques to a new domain rather than introducing a entirely novel problem or architecture. This clever combination addresses an untapped area in AI evaluation but does not significantly advance the state-of-the-art beyond incremental refinements.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to be cited and built upon in subfields like AI for mental health and education, as it provides a publicly available dataset that could enhance research on LLMs in specialized applications. However, its influence may remain confined to niche areas and not extend widely to broader commercial or research domains.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper represents a strong, valuable contribution by introducing a benchmark for evaluating LLMs in psychology, making it important for researchers in AI ethics and healthcare to be aware of for advancing mental health applications. While insightful, it is not essential for all AI practitioners due to its specific focus.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7d8f08749033ffe98008bae35eb098a71cfaf155",
      "total_authors": 1,
      "authors_found": 1,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": [
        {
          "name": "Min Zeng",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383304289"
        }
      ]
    },
    {
      "id": "2510.01612",
      "title": "RAG-BioQA Retrieval-Augmented Generation for Long-Form Biomedical\n  Question Answering",
      "authors": [
        "Lovely Yeswanth Panchumarthi",
        "Sai Prasad Gudari",
        "Atharva Negi",
        "Praveen Raj Budime",
        "Harsit Upadhya"
      ],
      "categories": [
        "cs.CL (Computation and Language)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "The exponential growth of biomedical literature creates significant\nchallenges for accessing precise medical information. Current biomedical\nquestion-answering systems primarily focus on short-form answers, failing to\nprovide the comprehensive explanations necessary for clinical decision-making.\nWe present RAG-BioQA, a novel framework combining retrieval-augmented\ngeneration with domain-specific fine-tuning to produce evidence-based,\nlong-form biomedical answers. Our approach integrates BioBERT embeddings with\nFAISS indexing and compares various re-ranking strategies (BM25, ColBERT,\nMonoT5) to optimize context selection before synthesizing evidence through a\nfine-tuned T5 model. Experimental results on the PubMedQA dataset show\nsignificant improvements over baselines, with our best model achieving\nsubstantial gains across BLEU, ROUGE, and METEOR metrics, advancing the state\nof accessible, evidence-based biomedical knowledge retrieval.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01612v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01612v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.3,
      "weak_supervision_score": 0.313,
      "diffusion_reasoning_score": 0.425,
      "distributed_training_score": 0.28,
      "datasets_score": 0.33,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper introduces RAG-BioQA, a framework for retrieval-augmented generation in biomedical question answering, utilizing models like BioBERT, FAISS, and T5 for context retrieval and answer synthesis. It does not involve diffusion models, iterative refinement processes, or multi-step logical reasoning as described in the topic. Therefore, there is no connection to diffusion-based reasoning.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01618",
      "title": "Automated Genomic Interpretation via Concept Bottleneck Models for\n  Medical Robotics",
      "authors": [
        "Zijun Li",
        "Jinchang Zhang",
        "Ming Zhang",
        "Guoyu Lu"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "We propose an automated genomic interpretation module that transforms raw DNA\nsequences into actionable, interpretable decisions suitable for integration\ninto medical automation and robotic systems. Our framework combines Chaos Game\nRepresentation (CGR) with a Concept Bottleneck Model (CBM), enforcing\npredictions to flow through biologically meaningful concepts such as GC\ncontent, CpG density, and k mer motifs. To enhance reliability, we incorporate\nconcept fidelity supervision, prior consistency alignment, KL distribution\nmatching, and uncertainty calibration. Beyond accurate classification of HIV\nsubtypes across both in-house and LANL datasets, our module delivers\ninterpretable evidence that can be directly validated against biological\npriors. A cost aware recommendation layer further translates predictive outputs\ninto decision policies that balance accuracy, calibration, and clinical\nutility, reducing unnecessary retests and improving efficiency. Extensive\nexperiments demonstrate that the proposed system achieves state of the art\nclassification performance, superior concept prediction fidelity, and more\nfavorable cost benefit trade-offs compared to existing baselines. By bridging\nthe gap between interpretable genomic modeling and automated decision-making,\nthis work establishes a reliable foundation for robotic and clinical automation\nin genomic medicine.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01618v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01618v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.386,
      "weak_supervision_score": 0.362,
      "diffusion_reasoning_score": 0.434,
      "distributed_training_score": 0.316,
      "datasets_score": 0.293,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on automated genomic interpretation using Concept Bottleneck Models (CBM) and Chaos Game Representation (CGR) for DNA sequence analysis in medical robotics. It mentions KL distribution matching as a technique for aligning distributions, but this is a standard statistical method and not related to diffusion models or their adaptation for iterative refinement in logical reasoning tasks. The paper does not involve multi-step logical reasoning, chain-of-thought processes, or any diffusion-based components, making it unrelated to the topic.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01619",
      "title": "MPMAvatar: Learning 3D Gaussian Avatars with Accurate and Robust\n  Physics-Based Dynamics",
      "authors": [
        "Changmin Lee",
        "Jihyun Lee",
        "Tae-Kyun Kim"
      ],
      "categories": [
        "cs.GR (Graphics)",
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "While there has been significant progress in the field of 3D avatar creation\nfrom visual observations, modeling physically plausible dynamics of humans with\nloose garments remains a challenging problem. Although a few existing works\naddress this problem by leveraging physical simulation, they suffer from\nlimited accuracy or robustness to novel animation inputs. In this work, we\npresent MPMAvatar, a framework for creating 3D human avatars from multi-view\nvideos that supports highly realistic, robust animation, as well as\nphotorealistic rendering from free viewpoints. For accurate and robust dynamics\nmodeling, our key idea is to use a Material Point Method-based simulator, which\nwe carefully tailor to model garments with complex deformations and contact\nwith the underlying body by incorporating an anisotropic constitutive model and\na novel collision handling algorithm. We combine this dynamics modeling scheme\nwith our canonical avatar that can be rendered using 3D Gaussian Splatting with\nquasi-shadowing, enabling high-fidelity rendering for physically realistic\nanimations. In our experiments, we demonstrate that MPMAvatar significantly\noutperforms the existing state-of-the-art physics-based avatar in terms of (1)\ndynamics modeling accuracy, (2) rendering accuracy, and (3) robustness and\nefficiency. Additionally, we present a novel application in which our avatar\ngeneralizes to unseen interactions in a zero-shot manner-which was not\nachievable with previous learning-based methods due to their limited simulation\ngeneralizability. Our project page is at:\nhttps://KAISTChangmin.github.io/MPMAvatar/",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01619v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01619v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.318,
      "weak_supervision_score": 0.295,
      "diffusion_reasoning_score": 0.336,
      "distributed_training_score": 0.323,
      "datasets_score": 0.276,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01620",
      "title": "Learning to Decide with Just Enough: Information-Theoretic Context\n  Summarization for CMDPs",
      "authors": [
        "Peidong Liu",
        "Junjiang Lin",
        "Shaowen Wang",
        "Yao Xu",
        "Haiqing Li",
        "Xuhao Xie",
        "Siyi Wu",
        "Hao Li"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Contextual Markov Decision Processes (CMDPs) offer a framework for sequential\ndecision-making under external signals, but existing methods often fail to\ngeneralize in high-dimensional or unstructured contexts, resulting in excessive\ncomputation and unstable performance. We propose an information-theoretic\nsummarization approach that uses large language models (LLMs) to compress\ncontextual inputs into low-dimensional, semantically rich summaries. These\nsummaries augment states by preserving decision-critical cues while reducing\nredundancy. Building on the notion of approximate context sufficiency, we\nprovide, to our knowledge, the first regret bounds and a latency-entropy\ntrade-off characterization for CMDPs. Our analysis clarifies how\ninformativeness impacts computational cost. Experiments across discrete,\ncontinuous, visual, and recommendation benchmarks show that our method\noutperforms raw-context and non-context baselines, improving reward, success\nrate, and sample efficiency, while reducing latency and memory usage. These\nfindings demonstrate that LLM-based summarization offers a scalable and\ninterpretable solution for efficient decision-making in context-rich,\nresource-constrained environments.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01620v2",
      "pdf_url": "http://arxiv.org/pdf/2510.01620v2",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.416,
      "weak_supervision_score": 0.41,
      "diffusion_reasoning_score": 0.467,
      "distributed_training_score": 0.334,
      "datasets_score": 0.316,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "Not Relevant",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on using LLMs for context summarization in CMDPs, emphasizing information-theoretic approaches and decision-making efficiency, without any involvement of human feedback, preference ranking, or reward modeling based on human data.",
      "weak_supervision_justification": "The paper does not involve training models with programmatically generated labels from noisy sources; instead, it applies pre-trained LLMs for summarizing contexts in CMDPs, which is unrelated to weak supervision techniques.",
      "diffusion_reasoning_justification": "The paper employs LLMs for context summarization and information-theoretic analysis in CMDPs, with no mention of diffusion models, iterative refinement processes, or multi-step logical reasoning as described in diffusion-based approaches.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01622",
      "title": "LLM4Rec: Large Language Models for Multimodal Generative Recommendation\n  with Causal Debiasing",
      "authors": [
        "Bo Ma",
        "Hang Li",
        "ZeHua Hu",
        "XiaoFan Gui",
        "LuYao Liu",
        "Simon Lau"
      ],
      "categories": [
        "cs.IR (Information Retrieval)",
        "cs.AI (Artificial Intelligence)",
        "cs.CL (Computation and Language)"
      ],
      "abstract": "Contemporary generative recommendation systems face significant challenges in\nhandling multimodal data, eliminating algorithmic biases, and providing\ntransparent decision-making processes. This paper introduces an enhanced\ngenerative recommendation framework that addresses these limitations through\nfive key innovations: multimodal fusion architecture, retrieval-augmented\ngeneration mechanisms, causal inference-based debiasing, explainable\nrecommendation generation, and real-time adaptive learning capabilities. Our\nframework leverages advanced large language models as the backbone while\nincorporating specialized modules for cross-modal understanding, contextual\nknowledge integration, bias mitigation, explanation synthesis, and continuous\nmodel adaptation. Extensive experiments on three benchmark datasets\n(MovieLens-25M, Amazon-Electronics, Yelp-2023) demonstrate consistent\nimprovements in recommendation accuracy, fairness, and diversity compared to\nexisting approaches. The proposed framework achieves up to 2.3% improvement in\nNDCG@10 and 1.4% enhancement in diversity metrics while maintaining\ncomputational efficiency through optimized inference strategies.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01622v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01622v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.467,
      "weak_supervision_score": 0.384,
      "diffusion_reasoning_score": 0.495,
      "distributed_training_score": 0.345,
      "datasets_score": 0.388,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper discusses real-time adaptive learning based on user feedback and behavioral patterns, but it does not involve training a reward model on human-ranked data or using reinforcement learning to fine-tune the main model, which are core to RLHF. Instead, it focuses on causal debiasing and adaptive mechanisms in recommendation systems, without any explicit RLHF components.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper does not mention or utilize diffusion models for iterative refinement or multi-step logical reasoning. It centers on large language models for multimodal recommendation, including fusion architectures and causal debiasing, with no components related to treating a Chain-of-Thought as a holistically corrected entity.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01623",
      "title": "VLA-R1: Enhancing Reasoning in Vision-Language-Action Models",
      "authors": [
        "Angen Ye",
        "Zeyu Zhang",
        "Boyuan Wang",
        "Xiaofeng Wang",
        "Dapeng Zhang",
        "Zheng Zhu"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.RO (Robotics)"
      ],
      "abstract": "Vision-Language-Action (VLA) models aim to unify perception, language\nunderstanding, and action generation, offering strong cross-task and\ncross-scene generalization with broad impact on embodied AI. However, current\nVLA models often lack explicit step-by-step reasoning, instead emitting final\nactions without considering affordance constraints or geometric relations.\nTheir post-training pipelines also rarely reinforce reasoning quality, relying\nprimarily on supervised fine-tuning with weak reward design. To address these\nchallenges, we present VLA-R1, a reasoning-enhanced VLA that integrates\nReinforcement Learning from Verifiable Rewards (RLVR) with Group Relative\nPolicy Optimization (GRPO) to systematically optimize both reasoning and\nexecution. Specifically, we design an RLVR-based post-training strategy with\nverifiable rewards for region alignment, trajectory consistency, and output\nformatting, thereby strengthening reasoning robustness and execution accuracy.\nMoreover, we develop VLA-CoT-13K, a high-quality dataset that provides\nchain-of-thought supervision explicitly aligned with affordance and trajectory\nannotations. Furthermore, extensive evaluations on in-domain, out-of-domain,\nsimulation, and real-robot platforms demonstrate that VLA-R1 achieves superior\ngeneralization and real-world performance compared to prior VLA methods. We\nplan to release the model, code, and dataset following the publication of this\nwork. Code: https://github.com/GigaAI-research/VLA-R1. Website:\nhttps://gigaai-research.github.io/VLA-R1.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01623v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01623v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.443,
      "weak_supervision_score": 0.34,
      "diffusion_reasoning_score": 0.483,
      "distributed_training_score": 0.356,
      "datasets_score": 0.377,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on Reinforcement Learning from Verifiable Rewards (RLVR), which uses automatically computed metrics like GIoU and Fréchet distance for rewards, rather than human feedback. There is no mention of training a reward model on human-ranked data or aligning the model with human preferences, which are core to RLHF.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper employs Chain-of-Thought (CoT) supervision and RLVR for reasoning enhancement, but it does not involve diffusion models or an iterative refinement process for logical tasks. There is no indication of treating reasoning paths as entities for multi-step correction as described in diffusion-based approaches.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01624",
      "title": "Quagmires in SFT-RL Post-Training: When High SFT Scores Mislead and What\n  to Use Instead",
      "authors": [
        "Feiyang Kang",
        "Michael Kuchnik",
        "Karthik Padthe",
        "Marin Vlastelica",
        "Ruoxi Jia",
        "Carole-Jean Wu",
        "Newsha Ardalani"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)",
        "cs.CL (Computation and Language)"
      ],
      "abstract": "In post-training for reasoning Large Language Models (LLMs), the current\nstate of practice trains LLMs in two independent stages: Supervised Fine-Tuning\n(SFT) and Reinforcement Learning with Verifiable Rewards (RLVR, shortened as\n``RL'' below). In this work, we challenge whether high SFT scores translate to\nimproved performance after RL. We provide extensive counter-examples where this\nis not true. We find high SFT scores can be biased toward simpler or more\nhomogeneous data and are not reliably predictive of subsequent RL gains or\nscaled-up post-training effectiveness. In some cases, RL training on models\nwith improved SFT performance could lead to substantially worse outcome\ncompared to RL on the base model without SFT. We study alternative metrics and\nidentify generalization loss on held-out reasoning examples and Pass@large k\nperformance to provide strong proxies for the RL outcome. We trained hundreds\nof models up to 12B-parameter with SFT and RLVR via GRPO and ran extensive\nevaluations on 7 math benchmarks with up to 256 repetitions, spending $>$1M GPU\nhours. Experiments include models from Llama3, Mistral-Nemo, Qwen3 and multiple\nstate-of-the-art SFT/RL datasets. Compared to directly predicting from pre-RL\nperformance, prediction based on generalization loss and Pass@large k achieves\nsubstantial higher precision, improving $R^2$ coefficient and Spearman's rank\ncorrelation coefficient by up to 0.5 (2x). This provides strong utility for\nbroad use cases. For example, in most experiments, we find SFT training on\nunique examples for a one epoch underperforms training on half examples for two\nepochs, either after SFT or SFT-then-RL; With the same SFT budget, training\nonly on short examples may lead to better SFT performance, though, it often\nleads to worse outcome after RL compared to training on examples with varying\nlengths. Evaluation tool will be open-sourced.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01624v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01624v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "no_intro_found",
      "embedding_status": "completed",
      "rlhf_score": 0.478,
      "weak_supervision_score": 0.419,
      "diffusion_reasoning_score": 0.463,
      "distributed_training_score": 0.405,
      "datasets_score": 0.321,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "Not Relevant",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "Tangentially Relevant",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on Reinforcement Learning with Verifiable Rewards (RLVR) for LLMs, which uses verifiable rewards rather than human-ranked data to train a reward model. Since there is no mention of human feedback or preferences, it does not align with RLHF.",
      "weak_supervision_justification": "The paper discusses Supervised Fine-Tuning (SFT) and RL on existing datasets for LLMs, but does not involve programmatically generating labels from noisy or imprecise sources. It relies on standard training data without evidence of weak supervision techniques.",
      "diffusion_reasoning_justification": "The paper examines SFT and RL for reasoning in LLMs, focusing on metrics and performance, but does not mention diffusion models, iterative refinement for logical tasks, or multi-step reasoning via diffusion processes.",
      "distributed_training_justification": "The paper mentions training hundreds of models and using over 1M GPU hours, which implies large-scale computing possibly involving distributed training, but the main contribution is on SFT and RL effectiveness, not on algorithms or systems for distributed training itself.",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01631",
      "title": "Demystifying Synthetic Data in LLM Pre-training: A Systematic Study of\n  Scaling Laws, Benefits, and Pitfalls",
      "authors": [
        "Feiyang Kang",
        "Newsha Ardalani",
        "Michael Kuchnik",
        "Youssef Emad",
        "Mostafa Elhoushi",
        "Shubhabrata Sengupta",
        "Shang-Wen Li",
        "Ramya Raghavendra",
        "Ruoxi Jia",
        "Carole-Jean Wu"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)",
        "cs.CL (Computation and Language)"
      ],
      "abstract": "Training data plays a crucial role in Large Language Models (LLM) scaling,\nyet high quality data is of limited supply. Synthetic data techniques offer a\npotential path toward sidestepping these limitations. We conduct a large-scale\nempirical investigation (>1000 LLMs with >100k GPU hours) using a unified\nprotocol and scaling laws, comparing natural web data, diverse synthetic types\n(rephrased text, generated textbooks), and mixtures of natural and synthetic\ndata. Specifically, we found pre-training on rephrased synthetic data\n\\textit{alone} is not faster than pre-training on natural web texts; while\npre-training on 1/3 rephrased synthetic data mixed with 2/3 natural web texts\ncan speed up 5-10x (to reach the same validation loss) at larger data budgets.\nPre-training on textbook-style synthetic data \\textit{alone} results in notably\nhigher loss on many downstream domains especially at small data budgets. \"Good\"\nratios of synthetic data in training data mixtures depend on the model size and\ndata budget, empirically converging to ~30% for rephrased synthetic data.\nLarger generator models do not necessarily yield better pre-training data than\n~8B-param models. These results contribute mixed evidence on \"model collapse\"\nduring large-scale single-round (n=1) model training on synthetic\ndata--training on rephrased synthetic data shows no degradation in performance\nin foreseeable scales whereas training on mixtures of textbook-style\npure-generated synthetic data shows patterns predicted by \"model collapse\". Our\nwork demystifies synthetic data in pre-training, validates its conditional\nbenefits, and offers practical guidance.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01631v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01631v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.408,
      "weak_supervision_score": 0.459,
      "diffusion_reasoning_score": 0.454,
      "distributed_training_score": 0.436,
      "datasets_score": 0.421,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "Tangentially Relevant",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "Tangentially Relevant",
      "datasets_relevance": "Highly Relevant",
      "rlhf_justification": "The paper focuses on synthetic data for LLM pre-training and does not involve human feedback, reward models, or reinforcement learning techniques.",
      "weak_supervision_justification": "The paper uses programmatically generated synthetic data, which shares similarities with weak supervision by relying on automated sources rather than hand-labeled data, but it primarily addresses LLM pre-training dynamics rather than label generation for supervised learning.",
      "diffusion_reasoning_justification": "The paper does not involve diffusion models, iterative refinement for logical reasoning, or multi-step reasoning processes; it centers on synthetic data for LLM pre-training.",
      "distributed_training_justification": "The paper mentions large-scale training involving over 100,000 GPU hours, implying distributed computing, but its main contribution is the evaluation of synthetic data, not the algorithms or systems for distributed training.",
      "datasets_justification": "The paper's core contribution involves creating, analyzing, and evaluating synthetic datasets for LLM pre-training, including comparisons with natural data and assessments of their impact on model performance.",
      "llm_score_status": "completed",
      "summary": "This paper conducts a large-scale empirical study to investigate the role of synthetic data in pre-training large language models (LLMs), comparing natural web data with various synthetic types like rephrased text and generated textbooks through over 1000 LLM variants and more than 100,000 GPU hours. Key findings reveal that mixing approximately one-third rephrased synthetic data with two-thirds natural data can accelerate training by 5-10 times to achieve similar validation loss, while pure synthetic data often underperforms; optimal ratios depend on model size and data budget, and larger generator models do not always produce better synthetic data, providing practical guidance on synthetic data's benefits and pitfalls.",
      "novelty_score": "Moderate",
      "novelty_justification": "The paper presents a notable improvement by conducting a systematic, large-scale empirical investigation that addresses inconsistencies in prior work on synthetic data for LLM pre-training, offering new insights into scaling laws and optimal mixtures, though it primarily refines existing ideas rather than introducing a entirely new problem or technique.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to be cited and built upon in the AI and machine learning subfields, as it provides practical guidance on using synthetic data for LLM pre-training, potentially influencing training methodologies and data strategies in future research.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper offers high-quality, empirically grounded insights that are valuable for researchers in LLM development, making it a significant contribution worth reviewing for its practical implications on synthetic data usage.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/cd31ee04059cf49054ee25bc79fe0a863b19063d",
      "total_authors": 10,
      "authors_found": 10,
      "highest_h_index": 14,
      "average_h_index": 4.3,
      "notable_authors_count": 3,
      "author_h_indexes": [
        {
          "name": "Feiyang Kang",
          "h_index": 7,
          "profile_url": "https://www.semanticscholar.org/author/2054842299"
        },
        {
          "name": "Newsha Ardalani",
          "h_index": 14,
          "profile_url": "https://www.semanticscholar.org/author/2774880"
        },
        {
          "name": "Michael Kuchnik",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2328091773"
        },
        {
          "name": "Youssef Emad",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2344840337"
        },
        {
          "name": "Mostafa Elhoushi",
          "h_index": 7,
          "profile_url": "https://www.semanticscholar.org/author/2278430853"
        },
        {
          "name": "Shubhabrata Sengupta",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383303284"
        },
        {
          "name": "Shang-Wen Li",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2374357575"
        },
        {
          "name": "Ramya Raghavendra",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2373720606"
        },
        {
          "name": "Ruoxi Jia",
          "h_index": 4,
          "profile_url": "https://www.semanticscholar.org/author/2268321162"
        },
        {
          "name": "Carole-Jean Wu",
          "h_index": 4,
          "profile_url": "https://www.semanticscholar.org/author/2293742452"
        }
      ]
    },
    {
      "id": "2510.01632",
      "title": "BioBlobs: Differentiable Graph Partitioning for Protein Representation\n  Learning",
      "authors": [
        "Xin Wang",
        "Carlos Oliver"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Protein function is driven by coherent substructures which vary in size and\ntopology, yet current protein representation learning models (PRL) distort\nthese signals by relying on rigid substructures such as k-hop and fixed radius\nneighbourhoods. We introduce BioBlobs, a plug-and-play, fully differentiable\nmodule that represents proteins by dynamically partitioning structures into\nflexibly-sized, non-overlapping substructures (\"blobs\"). The resulting blobs\nare quantized into a shared and interpretable codebook, yielding a discrete\nvocabulary of function-relevant protein substructures used to compute protein\nembeddings. We show that BioBlobs representations improve the performance of\nwidely used protein encoders such as GVP-GNN across various PRL tasks. Our\napproach highlights the value of architectures that directly capture\nfunction-relevant protein substructures, enabling both improved predictive\nperformance and mechanistic insight into protein function.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01632v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01632v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.331,
      "weak_supervision_score": 0.311,
      "diffusion_reasoning_score": 0.386,
      "distributed_training_score": 0.359,
      "datasets_score": 0.257,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01638",
      "title": "Towards Human-Centered RegTech: Unpacking Professionals' Strategies and\n  Needs for Using LLMs Safely",
      "authors": [
        "Siying Hu",
        "Yaxing Yao",
        "Zhicong Lu"
      ],
      "categories": [
        "cs.HC (Human-Computer Interaction)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Large Language Models are profoundly changing work patterns in high-risk\nprofessional domains, yet their application also introduces severe and\nunderexplored compliance risks. To investigate this issue, we conducted\nsemi-structured interviews with 24 highly-skilled knowledge workers from\nindustries such as law, healthcare, and finance. The study found that these\nexperts are commonly concerned about sensitive information leakage,\nintellectual property infringement, and uncertainty regarding the quality of\nmodel outputs. In response, they spontaneously adopt various mitigation\nstrategies, such as actively distorting input data and limiting the details in\ntheir prompts. However, the effectiveness of these spontaneous efforts is\nlimited due to a lack of specific compliance guidance and training for Large\nLanguage Models. Our research reveals a significant gap between current NLP\ntools and the actual compliance needs of experts. This paper positions these\nvaluable empirical findings as foundational work for building the next\ngeneration of Human-Centered, Compliance-Driven Natural Language Processing for\nRegulatory Technology (RegTech), providing a critical human-centered\nperspective and design requirements for engineering NLP systems that can\nproactively support expert compliance workflows.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01638v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01638v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.535,
      "weak_supervision_score": 0.413,
      "diffusion_reasoning_score": 0.414,
      "distributed_training_score": 0.35,
      "datasets_score": 0.341,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "Not Relevant",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on empirical studies of professionals' perceptions and strategies for using LLMs safely, emphasizing human-centered design for RegTech. It does not involve training AI models with human feedback via a reward model and reinforcement learning, so it lacks any connection to RLHF.",
      "weak_supervision_justification": "The paper conducts interviews to explore compliance risks and user needs for LLMs, but it does not address machine learning techniques like training models with programmatically generated or noisy labels. There is no discussion of weak supervision methods.",
      "diffusion_reasoning_justification": "The paper examines human strategies for mitigating risks with LLMs and proposes design implications for NLP systems, but it does not involve or discuss diffusion models, iterative refinement for logical reasoning, or multi-step reasoning processes.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01639",
      "title": "Understanding the Geospatial Reasoning Capabilities of LLMs: A\n  Trajectory Recovery Perspective",
      "authors": [
        "Thinh Hung Truong",
        "Jey Han Lau",
        "Jianzhong Qi"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "We explore the geospatial reasoning capabilities of Large Language Models\n(LLMs), specifically, whether LLMs can read road network maps and perform\nnavigation. We frame trajectory recovery as a proxy task, which requires models\nto reconstruct masked GPS traces, and introduce GLOBALTRACE, a dataset with\nover 4,000 real-world trajectories across diverse regions and transportation\nmodes. Using road network as context, our prompting framework enables LLMs to\ngenerate valid paths without accessing any external navigation tools.\nExperiments show that LLMs outperform off-the-shelf baselines and specialized\ntrajectory recovery models, with strong zero-shot generalization. Fine-grained\nanalysis shows that LLMs have strong comprehension of the road network and\ncoordinate systems, but also pose systematic biases with respect to regions and\ntransportation modes. Finally, we demonstrate how LLMs can enhance navigation\nexperiences by reasoning over maps in flexible ways to incorporate user\npreferences.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01639v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01639v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.41,
      "weak_supervision_score": 0.371,
      "diffusion_reasoning_score": 0.506,
      "distributed_training_score": 0.365,
      "datasets_score": 0.361,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper evaluates LLMs' geospatial reasoning through prompting and datasets, focusing on trajectory recovery without any mention of training models using human feedback, reward models, or reinforcement learning techniques.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper explores LLMs' capabilities in geospatial tasks via standard prompting and reasoning, but does not involve diffusion models, iterative refinement processes, or treating reasoning paths as entities for holistic correction.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01640",
      "title": "Joint Deblurring and 3D Reconstruction for Macrophotography",
      "authors": [
        "Yifan Zhao",
        "Liangchen Li",
        "Yuqi Zhou",
        "Kai Wang",
        "Yan Liang",
        "Juyong Zhang"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Macro lens has the advantages of high resolution and large magnification, and\n3D modeling of small and detailed objects can provide richer information.\nHowever, defocus blur in macrophotography is a long-standing problem that\nheavily hinders the clear imaging of the captured objects and high-quality 3D\nreconstruction of them. Traditional image deblurring methods require a large\nnumber of images and annotations, and there is currently no multi-view 3D\nreconstruction method for macrophotography. In this work, we propose a joint\ndeblurring and 3D reconstruction method for macrophotography. Starting from\nmulti-view blurry images captured, we jointly optimize the clear 3D model of\nthe object and the defocus blur kernel of each pixel. The entire framework\nadopts a differentiable rendering method to self-supervise the optimization of\nthe 3D model and the defocus blur kernel. Extensive experiments show that from\na small number of multi-view images, our proposed method can not only achieve\nhigh-quality image deblurring but also recover high-fidelity 3D appearance.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01640v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01640v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.3,
      "weak_supervision_score": 0.334,
      "diffusion_reasoning_score": 0.359,
      "distributed_training_score": 0.325,
      "datasets_score": 0.29,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01641",
      "title": "FideDiff: Efficient Diffusion Model for High-Fidelity Image Motion\n  Deblurring",
      "authors": [
        "Xiaoyang Liu",
        "Zhengyan Zhou",
        "Zihang Xu",
        "Jiezhang Cao",
        "Zheng Chen",
        "Yulun Zhang"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Recent advancements in image motion deblurring, driven by CNNs and\ntransformers, have made significant progress. Large-scale pre-trained diffusion\nmodels, which are rich in true-world modeling, have shown great promise for\nhigh-quality image restoration tasks such as deblurring, demonstrating stronger\ngenerative capabilities than CNN and transformer-based methods. However,\nchallenges such as unbearable inference time and compromised fidelity still\nlimit the full potential of the diffusion models. To address this, we introduce\nFideDiff, a novel single-step diffusion model designed for high-fidelity\ndeblurring. We reformulate motion deblurring as a diffusion-like process where\neach timestep represents a progressively blurred image, and we train a\nconsistency model that aligns all timesteps to the same clean image. By\nreconstructing training data with matched blur trajectories, the model learns\ntemporal consistency, enabling accurate one-step deblurring. We further enhance\nmodel performance by integrating Kernel ControlNet for blur kernel estimation\nand introducing adaptive timestep prediction. Our model achieves superior\nperformance on full-reference metrics, surpassing previous diffusion-based\nmethods and matching the performance of other state-of-the-art models. FideDiff\noffers a new direction for applying pre-trained diffusion models to\nhigh-fidelity image restoration tasks, establishing a robust baseline for\nfurther advancing diffusion models in real-world industrial applications. Our\ndataset and code will be available at https://github.com/xyLiu339/FideDiff.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01641v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01641v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.331,
      "weak_supervision_score": 0.308,
      "diffusion_reasoning_score": 0.575,
      "distributed_training_score": 0.357,
      "datasets_score": 0.287,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on adapting diffusion models for image motion deblurring, specifically developing an efficient single-step model for high-fidelity image restoration. It involves iterative refinement in the context of image processing, such as reconstructing blurred images, but does not address multi-step logical reasoning, Chain-of-Thought processes, or solving complex logical tasks. The core contribution is in computer vision for deblurring, not in reasoning applications, so it lacks any component for diffusion-based reasoning as defined.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01644",
      "title": "Machine Learning for Detection and Analysis of Novel LLM Jailbreaks",
      "authors": [
        "John Hawkins",
        "Aditya Pramar",
        "Rodney Beard",
        "Rohitash Chandra"
      ],
      "categories": [
        "cs.CL (Computation and Language)",
        "cs.AI (Artificial Intelligence)",
        "cs.CY (Computers and Society)"
      ],
      "abstract": "Large Language Models (LLMs) suffer from a range of vulnerabilities that\nallow malicious users to solicit undesirable responses through manipulation of\nthe input text. These so-called jailbreak prompts are designed to trick the LLM\ninto circumventing the safety guardrails put in place to keep responses\nacceptable to the developer's policies. In this study, we analyse the ability\nof different machine learning models to distinguish jailbreak prompts from\ngenuine uses, including looking at our ability to identify jailbreaks that use\npreviously unseen strategies. Our results indicate that using current datasets\nthe best performance is achieved by fine tuning a Bidirectional Encoder\nRepresentations from Transformers (BERT) model end-to-end for identifying\njailbreaks. We visualise the keywords that distinguish jailbreak from genuine\nprompts and conclude that explicit reflexivity in prompt structure could be a\nsignal of jailbreak intention.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01644v2",
      "pdf_url": "http://arxiv.org/pdf/2510.01644v2",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.435,
      "weak_supervision_score": 0.436,
      "diffusion_reasoning_score": 0.389,
      "distributed_training_score": 0.333,
      "datasets_score": 0.396,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "Moderately Relevant",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on fine-tuning a BERT model for detecting jailbreak prompts using existing datasets, without involving reinforcement learning, human-ranked data, or a reward model for alignment. It discusses general fine-tuning for safety but does not align with RLHF principles.",
      "weak_supervision_justification": "The paper uses compiled datasets (e.g., from Shen et al and Liu et al) for training jailbreak detection models, which likely involve programmatically generated or noisy labels from reported sources rather than perfect hand-labeling, fitting weak supervision concepts, though the method is not the primary focus.",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "completed",
      "summary": "This paper examines the use of machine learning techniques, particularly fine-tuning BERT models, to detect and analyze jailbreak prompts in Large Language Models (LLMs) by distinguishing them from genuine prompts using combined datasets. The core objectives include evaluating model performance on novel jailbreak strategies, visualizing distinguishing keywords, and identifying signals like explicit reflexivity; key findings reveal that fine-tuned BERT achieves the best results and provides insights into features that make certain jailbreaks difficult to detect.",
      "novelty_score": "Moderate",
      "novelty_justification": "The paper presents a notable improvement by applying existing BERT models to detect novel jailbreak strategies in LLMs, combining techniques in a new way for this context, but it does not introduce a entirely new problem or architecture.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to be cited and built upon in AI safety and LLM security subfields due to its practical approach to jailbreak detection, though its influence may be limited to specific applications rather than broader commercial or research domains.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "The paper provides a strong, valuable contribution to understanding jailbreak detection in LLMs, making it essential for researchers in AI ethics and security to be aware of, though it is not groundbreaking enough to be considered must-read.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/5fdcfeecaa17aae060d61bfdffadea705f4efe36",
      "total_authors": 4,
      "authors_found": 4,
      "highest_h_index": 1,
      "average_h_index": 0.25,
      "notable_authors_count": 0,
      "author_h_indexes": [
        {
          "name": "John Hawkins",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383304259"
        },
        {
          "name": "Aditya Pramar",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383304161"
        },
        {
          "name": "Rodney Beard",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2320308322"
        },
        {
          "name": "Rohitash Chandra",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383303924"
        }
      ]
    },
    {
      "id": "2510.01645",
      "title": "Position: Privacy Is Not Just Memorization!",
      "authors": [
        "Niloofar Mireshghallah",
        "Tianshi Li"
      ],
      "categories": [
        "cs.CR (Cryptography and Security)",
        "cs.AI (Artificial Intelligence)",
        "cs.CL (Computation and Language)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "The discourse on privacy risks in Large Language Models (LLMs) has\ndisproportionately focused on verbatim memorization of training data, while a\nconstellation of more immediate and scalable privacy threats remain\nunderexplored. This position paper argues that the privacy landscape of LLM\nsystems extends far beyond training data extraction, encompassing risks from\ndata collection practices, inference-time context leakage, autonomous agent\ncapabilities, and the democratization of surveillance through deep inference\nattacks. We present a comprehensive taxonomy of privacy risks across the LLM\nlifecycle -- from data collection through deployment -- and demonstrate through\ncase studies how current privacy frameworks fail to address these multifaceted\nthreats. Through a longitudinal analysis of 1,322 AI/ML privacy papers\npublished at leading conferences over the past decade (2016--2025), we reveal\nthat while memorization receives outsized attention in technical research, the\nmost pressing privacy harms lie elsewhere, where current technical approaches\noffer little traction and viable paths forward remain unclear. We call for a\nfundamental shift in how the research community approaches LLM privacy, moving\nbeyond the narrow focus of current technical solutions and embracing\ninterdisciplinary approaches that address the sociotechnical nature of these\nemerging threats.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01645v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01645v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.437,
      "weak_supervision_score": 0.411,
      "diffusion_reasoning_score": 0.377,
      "distributed_training_score": 0.404,
      "datasets_score": 0.389,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Tangentially Relevant",
      "weak_supervision_relevance": "Not Relevant",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "Not Relevant",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper discusses user interactions and feedback as part of data types in LLMs, which could indirectly relate to RLHF since RLHF uses human feedback for model alignment. However, the paper's main focus is on privacy risks, not the RLHF technique itself, so it only touches on this peripherally without in-depth analysis.",
      "weak_supervision_justification": "The paper does not address weak supervision, as it focuses on privacy risks in LLMs rather than techniques for programmatically generating training labels. There is no mention of labeling methods or supervision strategies.",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "The paper's content centers on privacy threats in LLMs and does not discuss distributed training, parallel computing, or strategies for partitioning data/computation across nodes. It is solely about privacy analysis, not training methodologies.",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01649",
      "title": "Source-Free Cross-Domain Continual Learning",
      "authors": [
        "Muhammad Tanzil Furqon",
        "Mahardhika Pratama",
        "Igor Škrjanc",
        "Lin Liu",
        "Habibullah Habibullah",
        "Kutluyil Dogancay"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Although existing cross-domain continual learning approaches successfully\naddress many streaming tasks having domain shifts, they call for a fully\nlabeled source domain hindering their feasibility in the privacy constrained\nenvironments. This paper goes one step ahead with the problem of source-free\ncross-domain continual learning where the use of source-domain samples are\ncompletely prohibited. We propose the idea of rehearsal-free frequency-aware\ndynamic prompt collaborations (REFEREE) to cope with the absence of labeled\nsource-domain samples in realm of cross-domain continual learning. REFEREE is\nbuilt upon a synergy between a source-pre-trained model and a large-scale\nvision-language model, thus overcoming the problem of sub-optimal\ngeneralizations when relying only on a source pre-trained model. The domain\nshift problem between the source domain and the target domain is handled by a\nfrequency-aware prompting technique encouraging low-frequency components while\nsuppressing high-frequency components. This strategy generates frequency-aware\naugmented samples, robust against noisy pseudo labels. The noisy pseudo-label\nproblem is further addressed with the uncertainty-aware weighting strategy\nwhere the mean and covariance matrix are weighted by prediction uncertainties,\nthus mitigating the adverse effects of the noisy pseudo label. Besides, the\nissue of catastrophic forgetting (CF) is overcome by kernel linear discriminant\nanalysis (KLDA) where the backbone network is frozen while the classification\nis performed using the linear discriminant analysis approach guided by the\nrandom kernel method. Our rigorous numerical studies confirm the advantage of\nour approach where it beats prior arts having access to source domain samples\nwith significant margins.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01649v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01649v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.418,
      "weak_supervision_score": 0.44,
      "diffusion_reasoning_score": 0.392,
      "distributed_training_score": 0.407,
      "datasets_score": 0.359,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "Moderately Relevant",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "Not Relevant",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on source-free cross-domain continual learning, involving techniques like frequency-aware prompting and pseudo-labeling, but does not involve human feedback, reward models, or reinforcement learning for model alignment.",
      "weak_supervision_justification": "The paper addresses noisy pseudo-labels generated programmatically from a pre-trained model and uses strategies like uncertainty-aware weighting to handle them, which aligns with weak supervision's use of imprecise labels, though the primary focus is on continual learning rather than weak supervision techniques.",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "The paper discusses algorithmic methods for continual learning and domain adaptation without any mention of distributed systems, parallel computing, or multi-node training strategies.",
      "datasets_justification": "below_threshold",
      "llm_score_status": "completed",
      "summary": "This paper introduces the source-free cross-domain continual learning (SFCDCL) problem, which extends traditional cross-domain continual learning by prohibiting access to labeled source-domain samples to address privacy concerns. It proposes the REFEREE method, a rehearsal-free approach that synergizes a source-pre-trained model with a large-scale vision-language model, employs frequency-aware prompting to handle domain shifts and generate robust augmented samples, uses uncertainty-aware weighting to mitigate noisy pseudo-labels, and applies kernel linear discriminant analysis (KLDA) to prevent catastrophic forgetting; experimental results show that REFEREE outperforms prior methods, even those with access to source data, demonstrating its effectiveness in privacy-constrained environments.",
      "novelty_score": "High",
      "novelty_justification": "The paper introduces a truly new problem in source-free cross-domain continual learning and proposes an innovative method, REFEREE, that significantly advances the state-of-the-art by addressing key challenges without relying on source data. This represents a substantial leap beyond existing approaches that depend on labeled source samples.",
      "impact_score": "High",
      "impact_justification": "The work has the potential to influence a wide range of future research in privacy-preserving machine learning, continual learning, and domain adaptation, particularly in real-world applications like healthcare and finance where data privacy is critical. Its demonstrated superior performance could lead to broader adoption and inspire new techniques in source-free learning scenarios.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper presents a strong and valuable contribution by tackling a novel problem with practical implications, making it essential for researchers in machine learning and AI to be aware of for advancing privacy-focused continual learning. While highly insightful, it may not be indispensable for those outside the specific subfield.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/20eb00f35cd6f320bea4f27d37fad70a59d6ec3c",
      "total_authors": 6,
      "authors_found": 6,
      "highest_h_index": 39,
      "average_h_index": 8.5,
      "notable_authors_count": 1,
      "author_h_indexes": [
        {
          "name": "M. Furqon",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2295674391"
        },
        {
          "name": "Mahardhika Pratama",
          "h_index": 3,
          "profile_url": "https://www.semanticscholar.org/author/2281032883"
        },
        {
          "name": "Igor vSkrjanc",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383308639"
        },
        {
          "name": "Lin Liu",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2295728056"
        },
        {
          "name": "Habibullah Habibullah",
          "h_index": 5,
          "profile_url": "https://www.semanticscholar.org/author/83960190"
        },
        {
          "name": "K. Doğançay",
          "h_index": 39,
          "profile_url": "https://www.semanticscholar.org/author/1743058"
        }
      ]
    },
    {
      "id": "2510.01650",
      "title": "The Unseen Frontier: Pushing the Limits of LLM Sparsity with\n  Surrogate-Free ADMM",
      "authors": [
        "Kwanhee Lee",
        "Hyeondo Jang",
        "Dongyeop Lee",
        "Dan Alistarh",
        "Namhoon Lee"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Neural network pruning is a promising technique to mitigate the excessive\ncomputational and memory requirements of large language models (LLMs). Despite\nits promise, however, progress in this area has diminished, as conventional\nmethods are seemingly unable to surpass moderate sparsity levels (50-60%)\nwithout severely degrading model accuracy. This work breaks through the current\nimpasse, presenting a principled and effective method called $\\texttt{Elsa}$,\nwhich achieves extreme sparsity levels of up to 90% while retaining high model\nfidelity. This is done by identifying several limitations in current practice,\nall of which can be traced back to their reliance on a surrogate objective\nformulation. $\\texttt{Elsa}$ tackles this issue directly and effectively via\nstandard and well-established constrained optimization techniques based on\nADMM. Our extensive experiments across a wide range of models and scales show\nthat $\\texttt{Elsa}$ achieves substantial improvements over existing methods;\ne.g., it achieves 7.8$\\times$ less perplexity than the best existing method on\nLLaMA-2-7B at 90% sparsity. Furthermore, we present\n$\\texttt{Elsa}_{\\text{-L}}$, a quantized variant that scales to extremely large\nmodels (27B), and establish its theoretical convergence guarantees. These\nresults highlight meaningful progress in advancing the frontier of LLM\nsparsity, while promising that significant opportunities for further\nadvancement may remain in directions that have so far attracted limited\nexploration.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01650v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01650v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.373,
      "weak_supervision_score": 0.392,
      "diffusion_reasoning_score": 0.37,
      "distributed_training_score": 0.448,
      "datasets_score": 0.308,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "Not Relevant",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "The paper focuses on neural network pruning techniques for large language models (LLMs), specifically introducing a method called Elsa that uses ADMM for achieving high sparsity levels without significant accuracy loss. It discusses optimization for pruning, model compression, and experiments on various model sizes, but does not address distributed training, parallel computing, or strategies for partitioning data/computation across multiple nodes. There is no mention of accelerating model training via multi-node setups, making the paper's contributions unrelated to this topic.",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01651",
      "title": "LadderMoE: Ladder-Side Mixture of Experts Adapters for Bronze\n  Inscription Recognition",
      "authors": [
        "Rixin Zhou",
        "Peiqiang Qiu",
        "Qian Zhang",
        "Chuntao Li",
        "Xi Yang"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Bronze inscriptions (BI), engraved on ritual vessels, constitute a crucial\nstage of early Chinese writing and provide indispensable evidence for\narchaeological and historical studies. However, automatic BI recognition\nremains difficult due to severe visual degradation, multi-domain variability\nacross photographs, rubbings, and tracings, and an extremely long-tailed\ncharacter distribution. To address these challenges, we curate a large-scale BI\ndataset comprising 22454 full-page images and 198598 annotated characters\nspanning 6658 unique categories, enabling robust cross-domain evaluation.\nBuilding on this resource, we develop a two-stage detection-recognition\npipeline that first localizes inscriptions and then transcribes individual\ncharacters. To handle heterogeneous domains and rare classes, we equip the\npipeline with LadderMoE, which augments a pretrained CLIP encoder with\nladder-style MoE adapters, enabling dynamic expert specialization and stronger\nrobustness. Comprehensive experiments on single-character and full-page\nrecognition tasks demonstrate that our method substantially outperforms\nstate-of-the-art scene text recognition baselines, achieving superior accuracy\nacross head, mid, and tail categories as well as all acquisition modalities.\nThese results establish a strong foundation for bronze inscription recognition\nand downstream archaeological analysis.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01651v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01651v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.322,
      "weak_supervision_score": 0.364,
      "diffusion_reasoning_score": 0.369,
      "distributed_training_score": 0.35,
      "datasets_score": 0.327,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01654",
      "title": "SoK: Measuring What Matters for Closed-Loop Security Agents",
      "authors": [
        "Mudita Khurana",
        "Raunak Jain"
      ],
      "categories": [
        "cs.CL (Computation and Language)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Cybersecurity is a relentless arms race, with AI driven offensive systems\nevolving faster than traditional defenses can adapt. Research and tooling\nremain fragmented across isolated defensive functions, creating blind spots\nthat adversaries exploit. Autonomous agents capable of integrating, exploit\nconfirmation, remediation, and validation into a single closed loop offer\npromise, but the field lacks three essentials: a framework defining the agentic\ncapabilities of security systems across security life cycle, a principled\nmethod for evaluating closed loop agents, and a benchmark for measuring their\nperformance in practice. We introduce CLASP: the Closed-Loop Autonomous\nSecurity Performance framework which aligns the security lifecycle\n(reconnaissance, exploitation, root cause analysis, patch synthesis,\nvalidation) with core agentic capabilities (planning, tool use, memory,\nreasoning, reflection & perception) providing a common vocabulary and rubric\nfor assessing agentic capabilities in security tasks. By applying CLASP to 21\nrepresentative works, we map where systems demonstrate strengths, and where\ncapability gaps persist. We then define the Closed-Loop Capability (CLC) Score,\na composite metric quantifying both degree of loop closure and operational\neffectiveness, and outline the requirements for a closed loop benchmark.\nTogether, CLASP and the CLC Score, provide the vocabulary, diagnostics, and\nmeasurements needed to advance both function level performance and measure\nclosed loop security agents.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01654v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01654v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.409,
      "weak_supervision_score": 0.355,
      "diffusion_reasoning_score": 0.342,
      "distributed_training_score": 0.33,
      "datasets_score": 0.359,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper introduces a framework (CLASP) for evaluating autonomous security agents in cybersecurity, focusing on capabilities like planning, tool use, and memory, but does not mention reinforcement learning, human feedback, reward models, or fine-tuning processes. Its main contributions are taxonomies, surveys, and metrics for security performance, with no connection to aligning AI models with human preferences.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01656",
      "title": "Asymmetric Proximal Policy Optimization: mini-critics boost LLM\n  reasoning",
      "authors": [
        "Jiashun Liu",
        "Johan Obando-Ceron",
        "Han Lu",
        "Yancheng He",
        "Weixun Wang",
        "Wenbo Su",
        "Bo Zheng",
        "Pablo Samuel Castro",
        "Aaron Courville",
        "Ling Pan"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Most recent RL for LLMs (RL4LLM) methods avoid explicit critics, replacing\nthem with average advantage baselines. This shift is largely pragmatic:\nconventional value functions are computationally expensive to train at LLM\nscale and often fail under sparse rewards and long reasoning horizons. We\nrevisit this bottleneck from an architectural perspective and introduce\nAsymmetric Proximal Policy Optimization (AsyPPO), a simple and scalable\nframework that restores the critics role while remaining efficient in\nlarge-model settings. AsyPPO employs a set of lightweight mini-critics, each\ntrained on disjoint prompt shards. This design encourages diversity while\npreserving calibration, reducing value-estimation bias. Beyond robust\nestimation, AsyPPO leverages inter-critic uncertainty to refine the policy\nupdate: (i) masking advantages in states where critics agree and gradients add\nlittle learning signal, and (ii) filtering high-divergence states from entropy\nregularization, suppressing spurious exploration. After training on open-source\ndata with only 5,000 samples, AsyPPO consistently improves learning stability\nand performance across multiple benchmarks over strong baselines, such as GRPO,\nachieving performance gains of more than six percent on Qwen3-4b-Base and about\nthree percent on Qwen3-8b-Base and Qwen3-14b-Base over classic PPO, without\nadditional tricks. These results highlight the importance of architectural\ninnovations for scalable, efficient algorithms.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01656v3",
      "pdf_url": "http://arxiv.org/pdf/2510.01656v3",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.445,
      "weak_supervision_score": 0.405,
      "diffusion_reasoning_score": 0.369,
      "distributed_training_score": 0.392,
      "datasets_score": 0.282,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "Tangentially Relevant",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on improving PPO for LLMs through asymmetric critics and value estimation, using open-source data and RL techniques, but it does not involve training a reward model on human-ranked data or aligning the model with human preferences, which are core to RLHF.",
      "weak_supervision_justification": "The paper employs data partitioning to train multiple critics on subsets of prompts, which introduces diversity and potentially some noise in value estimation, resembling aspects of weak supervision, but it primarily addresses RL algorithm improvements rather than programmatically generating labels from noisy sources.",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01658",
      "title": "Learning Time-Series Representations by Hierarchical\n  Uniformity-Tolerance Latent Balancing",
      "authors": [
        "Amin Jalali",
        "Milad Soltany",
        "Michael Greenspan",
        "Ali Etemad"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "We propose TimeHUT, a novel method for learning time-series representations\nby hierarchical uniformity-tolerance balancing of contrastive representations.\nOur method uses two distinct losses to learn strong representations with the\naim of striking an effective balance between uniformity and tolerance in the\nembedding space. First, TimeHUT uses a hierarchical setup to learn both\ninstance-wise and temporal information from input time-series. Next, we\nintegrate a temperature scheduler within the vanilla contrastive loss to\nbalance the uniformity and tolerance characteristics of the embeddings.\nAdditionally, a hierarchical angular margin loss enforces instance-wise and\ntemporal contrast losses, creating geometric margins between positive and\nnegative pairs of temporal sequences. This approach improves the coherence of\npositive pairs and their separation from the negatives, enhancing the capture\nof temporal dependencies within a time-series sample. We evaluate our approach\non a wide range of tasks, namely 128 UCR and 30 UAE datasets for univariate and\nmultivariate classification, as well as Yahoo and KPI datasets for anomaly\ndetection. The results demonstrate that TimeHUT outperforms prior methods by\nconsiderable margins on classification, while obtaining competitive results for\nanomaly detection. Finally, detailed sensitivity and ablation studies are\nperformed to evaluate different components and hyperparameters of our method.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01658v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01658v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.383,
      "weak_supervision_score": 0.346,
      "diffusion_reasoning_score": 0.325,
      "distributed_training_score": 0.33,
      "datasets_score": 0.295,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01659",
      "title": "MDSEval: A Meta-Evaluation Benchmark for Multimodal Dialogue\n  Summarization",
      "authors": [
        "Yinhong Liu",
        "Jianfeng He",
        "Hang Su",
        "Ruixue Lian",
        "Yi Nian",
        "Jake Vincent",
        "Srikanth Vishnubhotla",
        "Robinson Piramuthu",
        "Saab Mansour"
      ],
      "categories": [
        "cs.CL (Computation and Language)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Multimodal Dialogue Summarization (MDS) is a critical task with wide-ranging\napplications. To support the development of effective MDS models, robust\nautomatic evaluation methods are essential for reducing both cost and human\neffort. However, such methods require a strong meta-evaluation benchmark\ngrounded in human annotations. In this work, we introduce MDSEval, the first\nmeta-evaluation benchmark for MDS, consisting image-sharing dialogues,\ncorresponding summaries, and human judgments across eight well-defined quality\naspects. To ensure data quality and richfulness, we propose a novel filtering\nframework leveraging Mutually Exclusive Key Information (MEKI) across\nmodalities. Our work is the first to identify and formalize key evaluation\ndimensions specific to MDS. We benchmark state-of-the-art modal evaluation\nmethods, revealing their limitations in distinguishing summaries from advanced\nMLLMs and their susceptibility to various bias.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01659v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01659v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.361,
      "weak_supervision_score": 0.377,
      "diffusion_reasoning_score": 0.401,
      "distributed_training_score": 0.333,
      "datasets_score": 0.472,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "Highly Relevant",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper introduces a meta-evaluation benchmark for Multimodal Dialogue Summarization (MDS) and focuses on dataset curation, evaluation aspects, and benchmarking of summarization models. It does not mention diffusion models, iterative refinement processes, or any adaptation of diffusion for logical reasoning tasks. Therefore, there is no connection to this topic.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "The paper's main contribution is the introduction of MDSEval, a new meta-evaluation benchmark dataset for Multimodal Dialogue Summarization. It details dataset curation from existing sources (PhotoChat and DialogCC), proposes a novel filtering framework (MEKI), defines evaluation aspects, and benchmarks methods, directly aligning with creating, analyzing, and evaluating datasets for AI applications.",
      "llm_score_status": "completed",
      "summary": "The paper introduces MDSEval, the first meta-evaluation benchmark for Multimodal Dialogue Summarization (MDS), designed to enhance automatic evaluation methods by providing a dataset of image-sharing dialogues, corresponding summaries, and human annotations across eight quality aspects. It employs a novel filtering framework using Mutually Exclusive Key Information (MEKI) to ensure data quality, benchmarks state-of-the-art multimodal evaluation methods to expose their limitations in distinguishing advanced MLLM-generated summaries and their biases, and emphasizes the need for more robust, human-aligned assessment techniques.",
      "novelty_score": "High",
      "novelty_justification": "The paper introduces a truly new meta-evaluation benchmark for MDS along with the innovative MEKI criterion, significantly advancing the state-of-the-art in multimodal dialogue evaluation by addressing a previously unexplored need for robust human-grounded benchmarks.",
      "impact_score": "High",
      "impact_justification": "The work provides a comprehensive benchmark that could influence future research in multimodal AI by improving evaluation methods, potentially leading to better MDS models with applications in human-machine interactions and commercial settings.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper represents a strong and valuable contribution to AI research by introducing a new benchmark and insights into evaluation limitations, making it essential for researchers focused on multimodal summarization to stay informed.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/d9783aed2303ff73fb106ca97fa11db02ced172c",
      "total_authors": 9,
      "authors_found": 9,
      "highest_h_index": 16,
      "average_h_index": 3.2222222222222223,
      "notable_authors_count": 2,
      "author_h_indexes": [
        {
          "name": "Yinhong Liu",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383412880"
        },
        {
          "name": "Jianfeng He",
          "h_index": 3,
          "profile_url": "https://www.semanticscholar.org/author/2290199349"
        },
        {
          "name": "Hang Su",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2386090504"
        },
        {
          "name": "Ruixue Lian",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2382929102"
        },
        {
          "name": "Yi Nian",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2345003705"
        },
        {
          "name": "Jake W. Vincent",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2284763778"
        },
        {
          "name": "Srikanth Vishnubhotla",
          "h_index": 6,
          "profile_url": "https://www.semanticscholar.org/author/1731106"
        },
        {
          "name": "Robinson Piramuthu",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383307530"
        },
        {
          "name": "Saab Mansour",
          "h_index": 16,
          "profile_url": "https://www.semanticscholar.org/author/39674628"
        }
      ]
    },
    {
      "id": "2510.01660",
      "title": "VirDA: Reusing Backbone for Unsupervised Domain Adaptation with Visual\n  Reprogramming",
      "authors": [
        "Duy Nguyen",
        "Dat Nguyen"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Existing UDA pipelines fine-tune already well-trained backbone parameters for\nevery new source-and-target pair, resulting in the number of training\nparameters and storage memory growing linearly with each new pair, and also\npreventing the reuse of these well-trained backbone parameters.\n  Inspired by recent implications that existing backbones have textural biases,\nwe propose making use of domain-specific textural bias for domain adaptation\nvia visual reprogramming, namely VirDA. Instead of fine-tuning the full\nbackbone, VirDA prepends a domain-specific visual reprogramming layer to the\nbackbone. This layer produces visual prompts that act as an added textural bias\nto the input image, adapting its \"style\" to a target domain. To optimize these\nvisual reprogramming layers, we use multiple objective functions that optimize\nthe intra- and inter-domain distribution differences when domain-adapting\nvisual prompts are applied. This process does not require modifying the\nbackbone parameters, allowing the same backbone to be reused across different\ndomains.\n  We evaluate VirDA on Office-31 and obtain 92.8% mean accuracy with only 1.5M\ntrainable parameters. VirDA surpasses PDA, the state-of-the-art\nparameter-efficient UDA baseline, by +1.6% accuracy while using just 46% of its\nparameters. Compared with full-backbone fine-tuning, VirDA outperforms CDTrans\nand FixBi by +0.2% and +1.4%, respectively, while requiring only 1.7% and 2.8%\nof their trainable parameters. Relative to the strongest current methods\n(PMTrans and TVT), VirDA uses ~1.7% of their parameters and trades off only\n2.2% and 1.1% accuracy, respectively.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01660v3",
      "pdf_url": "http://arxiv.org/pdf/2510.01660v3",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.344,
      "weak_supervision_score": 0.369,
      "diffusion_reasoning_score": 0.394,
      "distributed_training_score": 0.389,
      "datasets_score": 0.339,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01662",
      "title": "Discrete Facial Encoding: : A Framework for Data-driven Facial Display\n  Discovery",
      "authors": [
        "Minh Tran",
        "Maksim Siniukov",
        "Zhangyu Jin",
        "Mohammad Soleymani"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Facial expression analysis is central to understanding human behavior, yet\nexisting coding systems such as the Facial Action Coding System (FACS) are\nconstrained by limited coverage and costly manual annotation. In this work, we\nintroduce Discrete Facial Encoding (DFE), an unsupervised, data-driven\nalternative of compact and interpretable dictionary of facial expressions from\n3D mesh sequences learned through a Residual Vector Quantized Variational\nAutoencoder (RVQ-VAE). Our approach first extracts identity-invariant\nexpression features from images using a 3D Morphable Model (3DMM), effectively\ndisentangling factors such as head pose and facial geometry. We then encode\nthese features using an RVQ-VAE, producing a sequence of discrete tokens from a\nshared codebook, where each token captures a specific, reusable facial\ndeformation pattern that contributes to the overall expression. Through\nextensive experiments, we demonstrate that Discrete Facial Encoding captures\nmore precise facial behaviors than FACS and other facial encoding alternatives.\nWe evaluate the utility of our representation across three high-level\npsychological tasks: stress detection, personality prediction, and depression\ndetection. Using a simple Bag-of-Words model built on top of the learned\ntokens, our system consistently outperforms both FACS-based pipelines and\nstrong image and video representation learning models such as Masked\nAutoencoders. Further analysis reveals that our representation covers a wider\nvariety of facial displays, highlighting its potential as a scalable and\neffective alternative to FACS for psychological and affective computing\napplications.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01662v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01662v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.378,
      "weak_supervision_score": 0.331,
      "diffusion_reasoning_score": 0.357,
      "distributed_training_score": 0.343,
      "datasets_score": 0.368,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01663",
      "title": "Shift-Invariant Attribute Scoring for Kolmogorov-Arnold Networks via\n  Shapley Value",
      "authors": [
        "Wangxuan Fan",
        "Ching Wang",
        "Siqi Li",
        "Nan Liu"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "For many real-world applications, understanding feature-outcome relationships\nis as crucial as achieving high predictive accuracy. While traditional neural\nnetworks excel at prediction, their black-box nature obscures underlying\nfunctional relationships. Kolmogorov--Arnold Networks (KANs) address this by\nemploying learnable spline-based activation functions on edges, enabling\nrecovery of symbolic representations while maintaining competitive performance.\nHowever, KAN's architecture presents unique challenges for network pruning.\nConventional magnitude-based methods become unreliable due to sensitivity to\ninput coordinate shifts. We propose \\textbf{ShapKAN}, a pruning framework using\nShapley value attribution to assess node importance in a shift-invariant\nmanner. Unlike magnitude-based approaches, ShapKAN quantifies each node's\nactual contribution, ensuring consistent importance rankings regardless of\ninput parameterization. Extensive experiments on synthetic and real-world\ndatasets demonstrate that ShapKAN preserves true node importance while enabling\neffective network compression. Our approach improves KAN's interpretability\nadvantages, facilitating deployment in resource-constrained environments.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01663v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01663v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.371,
      "weak_supervision_score": 0.308,
      "diffusion_reasoning_score": 0.345,
      "distributed_training_score": 0.337,
      "datasets_score": 0.289,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01664",
      "title": "GuruAgents: Emulating Wise Investors with Prompt-Guided LLM Agents",
      "authors": [
        "Yejin Kim",
        "Youngbin Lee",
        "Juhyeong Kim",
        "Yongjae Lee"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "This study demonstrates that GuruAgents, prompt-guided AI agents, can\nsystematically operationalize the strategies of legendary investment gurus. We\ndevelop five distinct GuruAgents, each designed to emulate an iconic investor,\nby encoding their distinct philosophies into LLM prompts that integrate\nfinancial tools and a deterministic reasoning pipeline. In a backtest on\nNASDAQ-100 constituents from Q4 2023 to Q2 2025, the GuruAgents exhibit unique\nbehaviors driven by their prompted personas. The Buffett GuruAgent achieves the\nhighest performance, delivering a 42.2\\% CAGR that significantly outperforms\nbenchmarks, while other agents show varied results. These findings confirm that\nprompt engineering can successfully translate the qualitative philosophies of\ninvestment gurus into reproducible, quantitative strategies, highlighting a\nnovel direction for automated systematic investing. The source code and data\nare available at https://github.com/yejining99/GuruAgents.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01664v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01664v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.39,
      "weak_supervision_score": 0.353,
      "diffusion_reasoning_score": 0.387,
      "distributed_training_score": 0.288,
      "datasets_score": 0.292,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01665",
      "title": "Non-Rigid Structure-from-Motion via Differential Geometry with\n  Recoverable Conformal Scale",
      "authors": [
        "Yongbo Chen",
        "Yanhao Zhang",
        "Shaifali Parashar",
        "Liang Zhao",
        "Shoudong Huang"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.RO (Robotics)"
      ],
      "abstract": "Non-rigid structure-from-motion (NRSfM), a promising technique for addressing\nthe mapping challenges in monocular visual deformable simultaneous localization\nand mapping (SLAM), has attracted growing attention. We introduce a novel\nmethod, called Con-NRSfM, for NRSfM under conformal deformations, encompassing\nisometric deformations as a subset. Our approach performs point-wise\nreconstruction using 2D selected image warps optimized through a graph-based\nframework. Unlike existing methods that rely on strict assumptions, such as\nlocally planar surfaces or locally linear deformations, and fail to recover the\nconformal scale, our method eliminates these constraints and accurately\ncomputes the local conformal scale. Additionally, our framework decouples\nconstraints on depth and conformal scale, which are inseparable in other\napproaches, enabling more precise depth estimation. To address the sensitivity\nof the formulated problem, we employ a parallel separable iterative\noptimization strategy. Furthermore, a self-supervised learning framework,\nutilizing an encoder-decoder network, is incorporated to generate dense 3D\npoint clouds with texture. Simulation and experimental results using both\nsynthetic and real datasets demonstrate that our method surpasses existing\napproaches in terms of reconstruction accuracy and robustness. The code for the\nproposed method will be made publicly available on the project website:\nhttps://sites.google.com/view/con-nrsfm.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01665v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01665v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.286,
      "weak_supervision_score": 0.287,
      "diffusion_reasoning_score": 0.347,
      "distributed_training_score": 0.288,
      "datasets_score": 0.241,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01666",
      "title": "Median2Median: Zero-shot Suppression of Structured Noise in Images",
      "authors": [
        "Jianxu Wang",
        "Ge Wang"
      ],
      "categories": [
        "eess.IV (Image and Video Processing)",
        "cs.CV (Computer Vision and Pattern Recognition)",
        "stat.ML (Machine Learning)"
      ],
      "abstract": "Image denoising is a fundamental problem in computer vision and medical\nimaging. However, real-world images are often degraded by structured noise with\nstrong anisotropic correlations that existing methods struggle to remove. Most\ndata-driven approaches rely on large datasets with high-quality labels and\nstill suffer from limited generalizability, whereas existing zero-shot methods\navoid this limitation but remain effective only for independent and identically\ndistributed (i.i.d.) noise. To address this gap, we propose Median2Median\n(M2M), a zero-shot denoising framework designed for structured noise. M2M\nintroduces a novel sampling strategy that generates pseudo-independent\nsub-image pairs from a single noisy input. This strategy leverages directional\ninterpolation and generalized median filtering to adaptively exclude values\ndistorted by structured artifacts. To further enlarge the effective sampling\nspace and eliminate systematic bias, a randomized assignment strategy is\nemployed, ensuring that the sampled sub-image pairs are suitable for\nNoise2Noise training. In our realistic simulation studies, M2M performs on par\nwith state-of-the-art zero-shot methods under i.i.d. noise, while consistently\noutperforming them under correlated noise. These findings establish M2M as an\nefficient, data-free solution for structured noise suppression and mark the\nfirst step toward effective zero-shot denoising beyond the strict i.i.d.\nassumption.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01666v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01666v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.262,
      "weak_supervision_score": 0.395,
      "diffusion_reasoning_score": 0.356,
      "distributed_training_score": 0.331,
      "datasets_score": 0.302,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01669",
      "title": "UniVerse: Unleashing the Scene Prior of Video Diffusion Models for\n  Robust Radiance Field Reconstruction",
      "authors": [
        "Jin Cao",
        "Hongrui Wu",
        "Ziyong Feng",
        "Hujun Bao",
        "Xiaowei Zhou",
        "Sida Peng"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "This paper tackles the challenge of robust reconstruction, i.e., the task of\nreconstructing a 3D scene from a set of inconsistent multi-view images. Some\nrecent works have attempted to simultaneously remove image inconsistencies and\nperform reconstruction by integrating image degradation modeling into neural 3D\nscene representations. However, these methods rely heavily on dense\nobservations for robustly optimizing model parameters. To address this issue,\nwe propose to decouple robust reconstruction into two subtasks: restoration and\nreconstruction, which naturally simplifies the optimization process. To this\nend, we introduce UniVerse, a unified framework for robust reconstruction based\non a video diffusion model. Specifically, UniVerse first converts inconsistent\nimages into initial videos, then uses a specially designed video diffusion\nmodel to restore them into consistent images, and finally reconstructs the 3D\nscenes from these restored images. Compared with case-by-case per-view\ndegradation modeling, the diffusion model learns a general scene prior from\nlarge-scale data, making it applicable to diverse image inconsistencies.\nExtensive experiments on both synthetic and real-world datasets demonstrate the\nstrong generalization capability and superior performance of our method in\nrobust reconstruction. Moreover, UniVerse can control the style of the\nreconstructed 3D scene. Project page:\nhttps://jin-cao-tma.github.io/UniVerse.github.io/",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01669v2",
      "pdf_url": "http://arxiv.org/pdf/2510.01669v2",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.329,
      "weak_supervision_score": 0.341,
      "diffusion_reasoning_score": 0.49,
      "distributed_training_score": 0.343,
      "datasets_score": 0.303,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on using a video diffusion model for restoring inconsistent images and reconstructing 3D scenes, which involves generative processes for visual tasks. However, it does not adapt diffusion models for multi-step logical reasoning, chain-of-thought processes, or solving complex logical tasks as defined in the topic. The diffusion model is applied to image/video generation and consistency, not to holistic reasoning paths.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01670",
      "title": "Just Do It!? Computer-Use Agents Exhibit Blind Goal-Directedness",
      "authors": [
        "Erfan Shayegani",
        "Keegan Hines",
        "Yue Dong",
        "Nael Abu-Ghazaleh",
        "Roman Lutz",
        "Spencer Whitehead",
        "Vidhisha Balachandran",
        "Besmira Nushi",
        "Vibhav Vineet"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)",
        "cs.CL (Computation and Language)",
        "cs.CR (Cryptography and Security)",
        "cs.CY (Computers and Society)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "Computer-Use Agents (CUAs) are an increasingly deployed class of agents that\ntake actions on GUIs to accomplish user goals. In this paper, we show that CUAs\nconsistently exhibit Blind Goal-Directedness (BGD): a bias to pursue goals\nregardless of feasibility, safety, reliability, or context. We characterize\nthree prevalent patterns of BGD: (i) lack of contextual reasoning, (ii)\nassumptions and decisions under ambiguity, and (iii) contradictory or\ninfeasible goals. We develop BLIND-ACT, a benchmark of 90 tasks capturing these\nthree patterns. Built on OSWorld, BLIND-ACT provides realistic environments and\nemploys LLM-based judges to evaluate agent behavior, achieving 93.75% agreement\nwith human annotations. We use BLIND-ACT to evaluate nine frontier models,\nincluding Claude Sonnet and Opus 4, Computer-Use-Preview, and GPT-5, observing\nhigh average BGD rates (80.8%) across them. We show that BGD exposes subtle\nrisks that arise even when inputs are not directly harmful. While\nprompting-based interventions lower BGD levels, substantial risk persists,\nhighlighting the need for stronger training- or inference-time interventions.\nQualitative analysis reveals observed failure modes: execution-first bias\n(focusing on how to act over whether to act), thought-action disconnect\n(execution diverging from reasoning), and request-primacy (justifying actions\ndue to user request). Identifying BGD and introducing BLIND-ACT establishes a\nfoundation for future research on studying and mitigating this fundamental risk\nand ensuring safe CUA deployment.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01670v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01670v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.466,
      "weak_supervision_score": 0.415,
      "diffusion_reasoning_score": 0.439,
      "distributed_training_score": 0.359,
      "datasets_score": 0.366,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Tangentially Relevant",
      "weak_supervision_relevance": "Not Relevant",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper evaluates AI models using LLM-based judges that align with human annotations, which indirectly relates to human feedback in alignment processes. However, it does not involve training models with RLHF techniques, such as using a reward model for fine-tuning, making it only a peripheral connection.",
      "weak_supervision_justification": "The paper focuses on benchmarking and evaluating Computer-Use Agents without any mention of programmatically generating labels from noisy sources for model training. It relies on manually designed tasks and LLM judges for evaluation, which does not align with weak supervision methods.",
      "diffusion_reasoning_justification": "The paper examines multi-step planning in agents but does not involve diffusion models or iterative refinement processes for logical reasoning. There is no component that adapts diffusion techniques for chain-of-thought or holistic correction, so it lacks relevance.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01671",
      "title": "A Locally Executable AI System for Improving Preoperative Patient\n  Communication: A Multi-Domain Clinical Evaluation",
      "authors": [
        "Motoki Sato",
        "Yuki Matsushita",
        "Hidekazu Takahashi",
        "Tomoaki Kakazu",
        "Sou Nagata",
        "Mizuho Ohnuma",
        "Atsushi Yoshikawa",
        "Masayuki Yamamura"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)",
        "cs.HC (Human-Computer Interaction)"
      ],
      "abstract": "Patients awaiting invasive procedures often have unanswered pre-procedural\nquestions; however, time-pressured workflows and privacy constraints limit\npersonalized counseling. We present LENOHA (Low Energy, No Hallucination, Leave\nNo One Behind Architecture), a safety-first, local-first system that routes\ninputs with a high-precision sentence-transformer classifier and returns\nverbatim answers from a clinician-curated FAQ for clinical queries, eliminating\nfree-text generation in the clinical path. We evaluated two domains (tooth\nextraction and gastroscopy) using expert-reviewed validation sets\n(n=400/domain) for thresholding and independent test sets (n=200/domain). Among\nthe four encoders, E5-large-instruct (560M) achieved an overall accuracy of\n0.983 (95% CI 0.964-0.991), AUC 0.996, and seven total errors, which were\nstatistically indistinguishable from GPT-4o on this task; Gemini made no errors\non this test set. Energy logging shows that the non-generative clinical path\nconsumes ~1.0 mWh per input versus ~168 mWh per small-talk reply from a local\n8B SLM, a ~170x difference, while maintaining ~0.10 s latency on a single\non-prem GPU. These results indicate that near-frontier discrimination and\ngeneration-induced errors are structurally avoided in the clinical path by\nreturning vetted FAQ answers verbatim, supporting privacy, sustainability, and\nequitable deployment in bandwidth-limited environments.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01671v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01671v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "extraction_failed",
      "embedding_status": "completed",
      "rlhf_score": 0.412,
      "weak_supervision_score": 0.335,
      "diffusion_reasoning_score": 0.374,
      "distributed_training_score": 0.348,
      "datasets_score": 0.319,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper's main contribution is a local AI system for routing patient queries and providing verbatim FAQ answers, evaluated for accuracy and efficiency. It uses a sentence-transformer classifier and expert-reviewed datasets but does not involve training a reward model on human-ranked data or fine-tuning via reinforcement learning, which are core to RLHF. Thus, no elements of RLHF are present.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01674",
      "title": "FOR-Prompting: From Objection to Revision via an Asymmetric Prompting\n  Protocol",
      "authors": [
        "He Zhang",
        "Anzhou Zhang",
        "Jian Dai"
      ],
      "categories": [
        "cs.CL (Computation and Language)",
        "cs.AI (Artificial Intelligence)",
        "cs.MA (Multiagent Systems)"
      ],
      "abstract": "Reasoning protocols such as Chain of Thought (CoT) and Tree of Thought (ToT)\norganize internal deliberation but lack an explicit mechanism for external\nquestioning that elicits self-revision. We present FOR-Prompting (From\nObjection to Revision Prompting), an asymmetric protocol where a Defender\nproposes an answer, an Objectioner raises question-style objections with no\ndirect fixes, and a Host enforces consistency and closure. On GSM8K we observe\nabout a 22% point gain over single-prompt and accuracy on par with CoT, with\nmore than 10% higher ratings in reasoning and coherence from a uniform GPT 4.1\njudge. FOR-Prompting also corrects mistakes without tools or human supervision\non tricky queries, and improves performance for small-scale model (approx. 19%\naccuracy improved on Llama3.2:1b for GSM8K task), highlighting promise for\nsmall models and on personal device use. Beyond factual QA, qualitative\nanalyses on open-ended tasks show enhanced exploration and refinement, with\ndialogue traces that make assumptions and trade-offs explicit. The protocol is\nmodel agnostic and operates purely at the prompt level through role-structured\nturns, so it works with hosted and local models of different sizes without\nretraining, and it supports large-scale study of objection-guided reasoning.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01674v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01674v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.431,
      "weak_supervision_score": 0.364,
      "diffusion_reasoning_score": 0.456,
      "distributed_training_score": 0.306,
      "datasets_score": 0.279,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Tangentially Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper introduces a prompting protocol for LLMs that simulates external questioning to improve reasoning, inspired by human-in-the-loop practices, but it does not involve training models with human feedback, reward models, or reinforcement learning. The method is purely prompt-based and model-agnostic, without any fine-tuning or learning from ranked data, making it unrelated to RLHF.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper's FOR-Prompting protocol involves iterative refinement through rounds of objection and revision, which shares a conceptual similarity with multi-step reasoning processes. However, it does not adapt or use diffusion models for logical tasks; it is a custom prompting strategy focused on role-based interactions, lacking the core elements of diffusion-based approaches.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01677",
      "title": "Beyond Simple Fusion: Adaptive Gated Fusion for Robust Multimodal\n  Sentiment Analysis",
      "authors": [
        "Han Wu",
        "Yanming Sun",
        "Yunhe Yang",
        "Derek F. Wong"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Multimodal sentiment analysis (MSA) leverages information fusion from diverse\nmodalities (e.g., text, audio, visual) to enhance sentiment prediction.\nHowever, simple fusion techniques often fail to account for variations in\nmodality quality, such as those that are noisy, missing, or semantically\nconflicting. This oversight leads to suboptimal performance, especially in\ndiscerning subtle emotional nuances. To mitigate this limitation, we introduce\na simple yet efficient \\textbf{A}daptive \\textbf{G}ated \\textbf{F}usion\n\\textbf{N}etwork that adaptively adjusts feature weights via a dual gate fusion\nmechanism based on information entropy and modality importance. This mechanism\nmitigates the influence of noisy modalities and prioritizes informative cues\nfollowing unimodal encoding and cross-modal interaction. Experiments on\nCMU-MOSI and CMU-MOSEI show that AGFN significantly outperforms strong\nbaselines in accuracy, effectively discerning subtle emotions with robust\nperformance. Visualization analysis of feature representations demonstrates\nthat AGFN enhances generalization by learning from a broader feature\ndistribution, achieved by reducing the correlation between feature location and\nprediction error, thereby decreasing reliance on specific locations and\ncreating more robust multimodal feature representations.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01677v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01677v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.387,
      "weak_supervision_score": 0.375,
      "diffusion_reasoning_score": 0.464,
      "distributed_training_score": 0.328,
      "datasets_score": 0.351,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on an Adaptive Gated Fusion Network for multimodal sentiment analysis, emphasizing techniques for handling noisy modalities and improving sentiment prediction through gating mechanisms based on information entropy and modality importance. It does not involve diffusion models, iterative refinement processes, or any adaptation of diffusion for multi-step logical reasoning or chain-of-thought tasks. Therefore, there is no connection to the topic of Diffusion-based Reasoning.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01678",
      "title": "An Efficient Deep Template Matching and In-Plane Pose Estimation Method\n  via Template-Aware Dynamic Convolution",
      "authors": [
        "Ke Jia",
        "Ji Zhou",
        "Hanxin Li",
        "Zhigan Zhou",
        "Haojie Chu",
        "Xiaojie Li"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "In industrial inspection and component alignment tasks, template matching\nrequires efficient estimation of a target's position and geometric state\n(rotation and scaling) under complex backgrounds to support precise downstream\noperations. Traditional methods rely on exhaustive enumeration of angles and\nscales, leading to low efficiency under compound transformations. Meanwhile,\nmost deep learning-based approaches only estimate similarity scores without\nexplicitly modeling geometric pose, making them inadequate for real-world\ndeployment. To overcome these limitations, we propose a lightweight end-to-end\nframework that reformulates template matching as joint localization and\ngeometric regression, outputting the center coordinates, rotation angle, and\nindependent horizontal and vertical scales. A Template-Aware Dynamic\nConvolution Module (TDCM) dynamically injects template features at inference to\nguide generalizable matching. The compact network integrates depthwise\nseparable convolutions and pixel shuffle for efficient matching. To enable\ngeometric-annotation-free training, we introduce a rotation-shear-based\naugmentation strategy with structure-aware pseudo labels. A lightweight\nrefinement module further improves angle and scale precision via local\noptimization. Experiments show our 3.07M model achieves high precision and 14ms\ninference under compound transformations. It also demonstrates strong\nrobustness in small-template and multi-object scenarios, making it highly\nsuitable for deployment in real-time industrial applications. The code is\navailable at:https://github.com/ZhouJ6610/PoseMatch-TDCM.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01678v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01678v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.312,
      "weak_supervision_score": 0.308,
      "diffusion_reasoning_score": 0.347,
      "distributed_training_score": 0.36,
      "datasets_score": 0.276,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01681",
      "title": "Look Less, Reason More: Rollout-Guided Adaptive Pixel-Space Reasoning",
      "authors": [
        "Xuchen Li",
        "Xuzhao Li",
        "Jiahui Gao",
        "Renjie Pi",
        "Shiyu Hu",
        "Wentao Zhang"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Vision-Language Models (VLMs) excel at many multimodal tasks, yet they\nfrequently struggle with tasks requiring precise understanding and handling of\nfine-grained visual elements. This is mainly due to information loss during\nimage encoding or insufficient attention to critical regions. Recent work has\nshown promise by incorporating pixel-level visual information into the\nreasoning process, enabling VLMs to access high-resolution visual details\nduring their thought process. However, this pixel-level information is often\noverused, leading to inefficiency and distraction from irrelevant visual\ndetails. To address these challenges, we propose the first framework for\nadaptive pixel reasoning that dynamically determines necessary pixel-level\noperations based on the input query. Specifically, we first apply\noperation-aware supervised fine-tuning to establish baseline competence in\ntextual reasoning and visual operations, then design a novel rollout-guided\nreinforcement learning framework relying on feedback of the model's own\nresponses, which enables the VLM to determine when pixel operations should be\ninvoked based on query difficulty. Experiments on extensive multimodal\nreasoning benchmarks show that our model achieves superior performance while\nsignificantly reducing unnecessary visual operations. Impressively, our model\nachieves 73.4\\% accuracy on HR-Bench 4K while maintaining a tool usage ratio of\nonly 20.1\\%, improving accuracy and simultaneously reducing tool usage by\n66.5\\% compared to the previous methods.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01681v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01681v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.444,
      "weak_supervision_score": 0.388,
      "diffusion_reasoning_score": 0.537,
      "distributed_training_score": 0.389,
      "datasets_score": 0.354,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper uses a rollout-guided reinforcement learning framework that relies on the model's own responses for feedback, without involving human-ranked data or a separate reward model trained on human preferences. This self-supervised approach does not align with the definition of RLHF, making the paper's contribution unrelated.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on rollout-guided reinforcement learning for adaptive pixel-space reasoning, which involves iterative processes but does not use diffusion models or adapt the iterative refinement process of diffusion for multi-step logical reasoning. There is no mention of diffusion-based components, so it does not fit the topic.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01683",
      "title": "Uncovering Overconfident Failures in CXR Models via\n  Augmentation-Sensitivity Risk Scoring",
      "authors": [
        "Han-Jay Shu",
        "Wei-Ning Chiu",
        "Shun-Ting Chang",
        "Meng-Ping Huang",
        "Takeshi Tohyama",
        "Ahram Han",
        "Po-Chih Kuo"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Deep learning models achieve strong performance in chest radiograph (CXR)\ninterpretation, yet fairness and reliability concerns persist. Models often\nshow uneven accuracy across patient subgroups, leading to hidden failures not\nreflected in aggregate metrics. Existing error detection approaches -- based on\nconfidence calibration or out-of-distribution (OOD) detection -- struggle with\nsubtle within-distribution errors, while image- and representation-level\nconsistency-based methods remain underexplored in medical imaging. We propose\nan augmentation-sensitivity risk scoring (ASRS) framework to identify\nerror-prone CXR cases. ASRS applies clinically plausible rotations ($\\pm\n15^\\circ$/$\\pm 30^\\circ$) and measures embedding shifts with the RAD-DINO\nencoder. Sensitivity scores stratify samples into stability quartiles, where\nhighly sensitive cases show substantially lower recall ($-0.2$ to $-0.3$)\ndespite high AUROC and confidence. ASRS provides a label-free means for\nselective prediction and clinician review, improving fairness and safety in\nmedical AI.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01683v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01683v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.347,
      "weak_supervision_score": 0.373,
      "diffusion_reasoning_score": 0.327,
      "distributed_training_score": 0.329,
      "datasets_score": 0.34,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01685",
      "title": "How Do Language Models Compose Functions?",
      "authors": [
        "Apoorv Khandelwal",
        "Ellie Pavlick"
      ],
      "categories": [
        "cs.CL (Computation and Language)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "While large language models (LLMs) appear to be increasingly capable of\nsolving compositional tasks, it is an open question whether they do so using\ncompositional mechanisms. In this work, we investigate how feedforward LLMs\nsolve two-hop factual recall tasks, which can be expressed compositionally as\n$g(f(x))$. We first confirm that modern LLMs continue to suffer from the\n\"compositionality gap\": i.e. their ability to compute both $z = f(x)$ and $y =\ng(z)$ does not entail their ability to compute the composition $y = g(f(x))$.\nThen, using logit lens on their residual stream activations, we identify two\nprocessing mechanisms, one which solves tasks $\\textit{compositionally}$,\ncomputing $f(x)$ along the way to computing $g(f(x))$, and one which solves\nthem $\\textit{directly}$, without any detectable signature of the intermediate\nvariable $f(x)$. Finally, we find that which mechanism is employed appears to\nbe related to the embedding space geometry, with the idiomatic mechanism being\ndominant in cases where there exists a linear mapping from $x$ to $g(f(x))$ in\nthe embedding spaces. We fully release our data and code at:\nhttps://github.com/apoorvkh/composing-functions .",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01685v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01685v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.406,
      "weak_supervision_score": 0.339,
      "diffusion_reasoning_score": 0.518,
      "distributed_training_score": 0.327,
      "datasets_score": 0.308,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper investigates the internal mechanisms of LLMs for function composition in factual recall tasks, focusing on processing and embedding spaces, with no discussion of training models using human feedback, reward models, or reinforcement learning techniques.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper analyzes how LLMs handle compositional tasks through mechanisms like logit lens and residual streams, but it does not involve diffusion models, iterative refinement processes, or treating Chain-of-Thought as a holistically corrected entity for multi-step reasoning.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01686",
      "title": "FreeViS: Training-free Video Stylization with Inconsistent References",
      "authors": [
        "Jiacong Xu",
        "Yiqun Mei",
        "Ke Zhang",
        "Vishal M. Patel"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Video stylization plays a key role in content creation, but it remains a\nchallenging problem. Na\\\"ively applying image stylization frame-by-frame hurts\ntemporal consistency and reduces style richness. Alternatively, training a\ndedicated video stylization model typically requires paired video data and is\ncomputationally expensive. In this paper, we propose FreeViS, a training-free\nvideo stylization framework that generates stylized videos with rich style\ndetails and strong temporal coherence. Our method integrates multiple stylized\nreferences to a pretrained image-to-video (I2V) model, effectively mitigating\nthe propagation errors observed in prior works, without introducing flickers\nand stutters. In addition, it leverages high-frequency compensation to\nconstrain the content layout and motion, together with flow-based motion cues\nto preserve style textures in low-saliency regions. Through extensive\nevaluations, FreeViS delivers higher stylization fidelity and superior temporal\nconsistency, outperforming recent baselines and achieving strong human\npreference. Our training-free pipeline offers a practical and economic solution\nfor high-quality, temporally coherent video stylization. The code and videos\ncan be accessed via https://xujiacong.github.io/FreeViS/",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01686v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01686v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.314,
      "weak_supervision_score": 0.31,
      "diffusion_reasoning_score": 0.408,
      "distributed_training_score": 0.319,
      "datasets_score": 0.257,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Tangentially Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper utilizes diffusion models for video stylization, specifically through inversion and iterative refinement to handle style transfer and temporal coherence. However, it focuses on generative tasks in visual content creation rather than adapting diffusion for multi-step logical reasoning or Chain-of-Thought processes as defined in the topic. There is no evidence of diffusion being used for solving complex logical tasks, making it only tangentially related due to the shared use of diffusion mechanisms.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01687",
      "title": "Improving AGI Evaluation: A Data Science Perspective",
      "authors": [
        "John Hawkins"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)",
        "cs.CL (Computation and Language)"
      ],
      "abstract": "Evaluation of potential AGI systems and methods is difficult due to the\nbreadth of the engineering goal. We have no methods for perfect evaluation of\nthe end state, and instead measure performance on small tests designed to\nprovide directional indication that we are approaching AGI. In this work we\nargue that AGI evaluation methods have been dominated by a design philosophy\nthat uses our intuitions of what intelligence is to create synthetic tasks,\nthat have performed poorly in the history of AI. Instead we argue for an\nalternative design philosophy focused on evaluating robust task execution that\nseeks to demonstrate AGI through competence. This perspective is developed from\ncommon practices in data science that are used to show that a system can be\nreliably deployed. We provide practical examples of what this would mean for\nAGI evaluation.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01687v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01687v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.465,
      "weak_supervision_score": 0.427,
      "diffusion_reasoning_score": 0.43,
      "distributed_training_score": 0.369,
      "datasets_score": 0.433,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "Tangentially Relevant",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "Moderately Relevant",
      "rlhf_justification": "The paper focuses on AGI evaluation methods inspired by data science, emphasizing robust task execution and avoiding memorization, but does not discuss training AI models with human feedback via reward models or reinforcement learning.",
      "weak_supervision_justification": "The paper mentions mitigating data set biases and contamination in AGI evaluations, which indirectly relates to handling noisy or imprecise data sources as in weak supervision, but it does not specifically address programmatically generating labels or weak supervision techniques.",
      "diffusion_reasoning_justification": "The paper discusses general AGI evaluation and competence-based approaches but makes no mention of diffusion models, iterative refinement, or multi-step logical reasoning processes.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "The paper critiques existing AGI benchmarks and datasets, addressing issues like biases and memorization, and proposes evaluation methods inspired by data science that involve analyzing and improving datasets, though it does not focus on creating or benchmarking new datasets.",
      "llm_score_status": "completed",
      "summary": "This paper critiques traditional AGI evaluation methods for relying on synthetic tasks based on human intuitions, which are prone to being gamed, and proposes an alternative approach inspired by data science practices that emphasizes robust task execution and competence in real-world-like scenarios to ensure reliable deployment. By focusing on mitigating issues such as data memorization, biases, and contamination, the authors argue for empirical evaluations that demonstrate an AGI's ability to perform autonomously on arbitrary tasks, providing practical examples like testing in simulated environments or digital knowledge work, ultimately aiming to advance the field through more pragmatic and effective assessment frameworks.",
      "novelty_score": "Moderate",
      "novelty_justification": "The paper presents a notable improvement by applying data science evaluation practices to AGI assessment, offering a clever combination of existing ideas to address known problems in a new context, though it does not introduce a entirely new problem or technique. This approach builds on prior criticisms of AGI metrics but innovates by drawing specifically from data science for more reliable evaluations.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to be cited and built upon within the AGI evaluation subfield, as it provides practical methods to enhance assessment reliability and address ongoing issues like memorization. However, its influence may be limited to specialized research areas rather than broadly transforming AI or commercial applications.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper offers a high-quality contribution by proposing insightful alternatives to AGI evaluation, making it valuable for researchers focused on AI assessment and development. While not essential for all readers, it provides important perspectives that could inform ongoing debates in the field.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/aef26fff6474b974fc5e88ef39729740561dcfe8",
      "total_authors": 1,
      "authors_found": 1,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": [
        {
          "name": "John Hawkins",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383304257"
        }
      ]
    },
    {
      "id": "2510.01688",
      "title": "Format Inertia: A Failure Mechanism of LLMs in Medical Pre-Consultation",
      "authors": [
        "Seungseop Lim",
        "Gibaeg Kim",
        "Wooseok Han",
        "Jean Seo",
        "Hyunkyung Lee",
        "Jaehyo Yoo",
        "Eunho Yang"
      ],
      "categories": [
        "cs.CL (Computation and Language)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Recent advances in Large Language Models (LLMs) have brought significant\nimprovements to various service domains, including chatbots and medical\npre-consultation applications. In the healthcare domain, the most common\napproach for adapting LLMs to multi-turn dialogue generation is Supervised\nFine-Tuning (SFT). However, datasets for SFT in tasks like medical\npre-consultation typically exhibit a skewed turn-count distribution. Training\non such data induces a novel failure mechanism we term Format Inertia, where\nmodels tend to generate repetitive, format-correct, but diagnostically\nuninformative questions in long medical dialogues. To mitigate this observed\nfailure mechanism, we adopt a simple, data-centric method that rebalances the\nturn-count distribution of the training dataset. Experimental results show that\nour approach substantially alleviates Format Inertia in medical\npre-consultation.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01688v2",
      "pdf_url": "http://arxiv.org/pdf/2510.01688v2",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.415,
      "weak_supervision_score": 0.372,
      "diffusion_reasoning_score": 0.42,
      "distributed_training_score": 0.381,
      "datasets_score": 0.364,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on Supervised Fine-Tuning (SFT) for LLMs in medical dialogues and addresses issues with skewed turn-count distributions, without any mention of human feedback, reward models, or reinforcement learning techniques. Therefore, it does not involve aligning models with human preferences through RLHF.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper discusses LLMs trained via SFT for multi-turn dialogues and introduces the concept of Format Inertia, but it does not involve diffusion models, iterative refinement processes, or multi-step logical reasoning for tasks like Chain-of-Thought. The work is centered on dialogue generation and data rebalancing, not diffusion-based approaches.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01691",
      "title": "MedQ-Bench: Evaluating and Exploring Medical Image Quality Assessment\n  Abilities in MLLMs",
      "authors": [
        "Jiyao Liu",
        "Jinjie Wei",
        "Wanying Qu",
        "Chenglong Ma",
        "Junzhi Ning",
        "Yunheng Li",
        "Ying Chen",
        "Xinzhe Luo",
        "Pengcheng Chen",
        "Xin Gao",
        "Ming Hu",
        "Huihui Xu",
        "Xin Wang",
        "Shujian Gao",
        "Dingkang Yang",
        "Zhongying Deng",
        "Jin Ye",
        "Lihao Liu",
        "Junjun He",
        "Ningsheng Xu"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Medical Image Quality Assessment (IQA) serves as the first-mile safety gate\nfor clinical AI, yet existing approaches remain constrained by scalar,\nscore-based metrics and fail to reflect the descriptive, human-like reasoning\nprocess central to expert evaluation. To address this gap, we introduce\nMedQ-Bench, a comprehensive benchmark that establishes a perception-reasoning\nparadigm for language-based evaluation of medical image quality with\nMulti-modal Large Language Models (MLLMs). MedQ-Bench defines two complementary\ntasks: (1) MedQ-Perception, which probes low-level perceptual capability via\nhuman-curated questions on fundamental visual attributes; and (2)\nMedQ-Reasoning, encompassing both no-reference and comparison reasoning tasks,\naligning model evaluation with human-like reasoning on image quality. The\nbenchmark spans five imaging modalities and over forty quality attributes,\ntotaling 2,600 perceptual queries and 708 reasoning assessments, covering\ndiverse image sources including authentic clinical acquisitions, images with\nsimulated degradations via physics-based reconstructions, and AI-generated\nimages. To evaluate reasoning ability, we propose a multi-dimensional judging\nprotocol that assesses model outputs along four complementary axes. We further\nconduct rigorous human-AI alignment validation by comparing LLM-based judgement\nwith radiologists. Our evaluation of 14 state-of-the-art MLLMs demonstrates\nthat models exhibit preliminary but unstable perceptual and reasoning skills,\nwith insufficient accuracy for reliable clinical use. These findings highlight\nthe need for targeted optimization of MLLMs in medical IQA. We hope that\nMedQ-Bench will catalyze further exploration and unlock the untapped potential\nof MLLMs for medical image quality evaluation.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01691v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01691v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.361,
      "weak_supervision_score": 0.388,
      "diffusion_reasoning_score": 0.434,
      "distributed_training_score": 0.335,
      "datasets_score": 0.426,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "Highly Relevant",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on evaluating Multi-modal Large Language Models (MLLMs) for medical image quality assessment, introducing a benchmark for perception and reasoning tasks. It does not mention or involve diffusion models, iterative refinement processes, or any adaptation of diffusion for multi-step logical reasoning. Therefore, it lacks any connection to diffusion-based reasoning.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "The paper's main contribution is the introduction of MedQ-Bench, a new benchmark dataset for evaluating MLLMs in medical image quality assessment. It details dataset creation, including curation across five imaging modalities, over 40 quality attributes, and 3,308 samples from diverse sources, as well as benchmarking and evaluation methodologies, directly aligning with research on creating and analyzing datasets for AI applications.",
      "llm_score_status": "completed",
      "summary": "This paper introduces MedQ-Bench, a comprehensive benchmark designed to evaluate the medical image quality assessment capabilities of Multi-modal Large Language Models (MLLMs) through a perception-reasoning paradigm, addressing the limitations of traditional scalar-based metrics by incorporating human-like reasoning tasks across five imaging modalities and over 40 quality attributes. The methodology involves creating two tasks—MedQ-Perception for assessing low-level visual attributes and MedQ-Reasoning for evaluating no-reference and comparative reasoning—using a diverse dataset of 3,308 samples, followed by evaluations of 14 state-of-the-art MLLMs with a multi-dimensional judging protocol, revealing that while MLLMs demonstrate preliminary perceptual and reasoning skills, they lack the accuracy needed for reliable clinical applications and require further optimization.",
      "novelty_score": "High",
      "novelty_justification": "The paper introduces a novel benchmark and paradigm for evaluating MLLMs in medical image quality assessment, significantly advancing the state-of-the-art by shifting from scalar metrics to perception-reasoning tasks tailored to clinical needs.",
      "impact_score": "High",
      "impact_justification": "The work has the potential to broadly influence future research and development in MLLMs for medical applications by providing a standardized benchmark that addresses critical gaps in image quality evaluation, potentially improving clinical AI safety and diagnostic accuracy.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper offers a high-quality contribution with practical implications for AI in healthcare, making it essential for researchers in computer vision and medical AI to understand and build upon its findings.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b68bf2ac1b1e39ef13fe011f981fac161b3efbe3",
      "total_authors": 20,
      "authors_found": 19,
      "highest_h_index": 12,
      "average_h_index": 2.8421052631578947,
      "notable_authors_count": 2,
      "author_h_indexes": [
        {
          "name": "Jiyao Liu",
          "h_index": 3,
          "profile_url": "https://www.semanticscholar.org/author/2353316550"
        },
        {
          "name": "Jinjie Wei",
          "h_index": 5,
          "profile_url": "https://www.semanticscholar.org/author/2372428762"
        },
        {
          "name": "Wanying Qu",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2371993162"
        },
        {
          "name": "Chenglong Ma",
          "h_index": 3,
          "profile_url": "https://www.semanticscholar.org/author/2332089083"
        },
        {
          "name": "Junzhi NIng (Raymond) Ning",
          "h_index": 3,
          "profile_url": "https://www.semanticscholar.org/author/2353285720"
        },
        {
          "name": "Yunheng Li",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383417628"
        },
        {
          "name": "Ying Chen",
          "h_index": 4,
          "profile_url": "https://www.semanticscholar.org/author/2326449491"
        },
        {
          "name": "Xinzhe Luo",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383366926"
        },
        {
          "name": "Pengcheng Chen",
          "h_index": 4,
          "profile_url": "https://www.semanticscholar.org/author/2271493720"
        },
        {
          "name": "Xin Gao",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2384130641"
        },
        {
          "name": "Ming Hu",
          "h_index": 4,
          "profile_url": "https://www.semanticscholar.org/author/2333217649"
        },
        {
          "name": "Huihui Xu",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2373743782"
        },
        {
          "name": "Xin Wang",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383375733"
        },
        {
          "name": "Shujian Gao",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2378722156"
        },
        {
          "name": "Di Yang",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2287488311"
        },
        {
          "name": "Zhongying Deng",
          "h_index": 12,
          "profile_url": "https://www.semanticscholar.org/author/67198844"
        },
        {
          "name": "Jin Ye",
          "h_index": null,
          "profile_url": null
        },
        {
          "name": "Lihao Liu",
          "h_index": 3,
          "profile_url": "https://www.semanticscholar.org/author/2349380824"
        },
        {
          "name": "Junjun He",
          "h_index": 9,
          "profile_url": "https://www.semanticscholar.org/author/2310574751"
        },
        {
          "name": "Ningsheng Xu",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2310609703"
        }
      ]
    },
    {
      "id": "2510.01700",
      "title": "VaPR -- Vision-language Preference alignment for Reasoning",
      "authors": [
        "Rohan Wadhawan",
        "Fabrice Y Harel-Canada",
        "Zi-Yi Dou",
        "Suhaila Shakiah",
        "Robinson Piramuthu",
        "Nanyun Peng"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)",
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "Preference finetuning methods like Direct Preference Optimization (DPO) with\nAI-generated feedback have shown promise in aligning Large Vision-Language\nModels (LVLMs) with human preferences. However, existing techniques overlook\nthe prevalence of noise in synthetic preference annotations in the form of\nstylistic and length biases. To this end, we introduce a hard-negative response\ngeneration framework based on LLM-guided response editing, that produces\nrejected responses with targeted errors, maintaining stylistic and length\nsimilarity to the accepted ones. Using this framework, we develop the VaPR\ndataset, comprising 30K high-quality samples, to finetune three LVLM families:\nLLaVA-V1.5, Qwen2VL & Qwen2.5VL (2B-13B sizes). Our VaPR models deliver\nsignificant performance improvements across ten benchmarks, achieving average\ngains of 6.5% (LLaVA), 4.0% (Qwen2VL), and 1.5% (Qwen2.5VL), with notable\nimprovements on reasoning tasks. A scaling analysis shows that performance\nconsistently improves with data size, with LLaVA models benefiting even at\nsmaller scales. Moreover, VaPR reduces the tendency to answer \"Yes\" in binary\nquestions - addressing a common failure mode in LVLMs like LLaVA. Lastly, we\nshow that the framework generalizes to open-source LLMs as editors, with models\ntrained on VaPR-OS achieving ~99% of the performance of models trained on\n\\name, which is synthesized using GPT-4o. Our data, models, and code can be\nfound on the project page https://vap-r.github.io",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01700v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01700v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.517,
      "weak_supervision_score": 0.422,
      "diffusion_reasoning_score": 0.431,
      "distributed_training_score": 0.365,
      "datasets_score": 0.393,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Tangentially Relevant",
      "weak_supervision_relevance": "Highly Relevant",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper discusses preference fine-tuning methods like DPO, which is related to RLHF as an alternative approach for aligning models with preferences, and mentions RLHF in the introduction as prior work. However, the main contribution uses AI-generated feedback and DPO without involving human feedback or a separate reward model, so it is not directly focused on RLHF.",
      "weak_supervision_justification": "The paper's core contribution involves generating synthetic preference data programmatically using LLMs to edit responses, creating large quantities of labels from noisy, AI-based sources rather than relying on hand-labeled data. This aligns directly with weak supervision, as it trains models on programmatically derived, imperfect annotations to improve performance.",
      "diffusion_reasoning_justification": "The paper focuses on preference alignment for LVLMs using DPO and synthetic data generation, with no mention of diffusion models, iterative refinement processes, or multi-step logical reasoning via diffusion. There is no component that adapts diffusion for reasoning tasks.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "completed",
      "summary": "This paper introduces VaPR, a framework for generating high-quality synthetic preference data by using LLM-guided editing to create hard-negative responses that maintain stylistic and length similarity while introducing targeted errors, aiming to reduce biases in preference tuning for Large Vision-Language Models (LVLMs). The authors create a 30K-sample dataset and fine-tune models like LLaVA-V1.5, Qwen2VL, and Qwen2.5VL, achieving significant performance improvements across ten benchmarks, with average gains of up to 6.5% and notable enhancements in reasoning tasks, while demonstrating the framework's generalizability to open-source LLMs.",
      "novelty_score": "Moderate",
      "novelty_justification": "The paper presents a notable improvement by introducing a hard-negative response generation framework that cleverly combines LLM-guided editing with existing preference optimization techniques to address biases, offering a new way to enhance LVLM alignment without introducing entirely novel problems or architectures.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to be cited and built upon in the subfield of vision-language models and preference tuning, as it provides a practical framework and dataset that improve model performance on reasoning tasks, though its influence may remain confined to specific AI applications rather than broadly transformative ones.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper offers a high-quality contribution with practical advancements in LVLM fine-tuning and open-source resources, making it valuable for researchers in AI and computer vision to stay informed about improvements in preference alignment techniques.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/12a2acac63252ebb169c9830523537812f3081b8",
      "total_authors": 6,
      "authors_found": 6,
      "highest_h_index": 22,
      "average_h_index": 6.5,
      "notable_authors_count": 3,
      "author_h_indexes": [
        {
          "name": "Rohan Wadhawan",
          "h_index": 3,
          "profile_url": "https://www.semanticscholar.org/author/2077591639"
        },
        {
          "name": "Fabrice Harel-Canada",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2383307858"
        },
        {
          "name": "Zi-Yi Dou",
          "h_index": 22,
          "profile_url": "https://www.semanticscholar.org/author/14199369"
        },
        {
          "name": "Suhaila Shakiah",
          "h_index": 6,
          "profile_url": "https://www.semanticscholar.org/author/1831108414"
        },
        {
          "name": "Robinson Piramuthu",
          "h_index": 6,
          "profile_url": "https://www.semanticscholar.org/author/2268494451"
        },
        {
          "name": "Nanyun Peng",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2360383737"
        }
      ]
    },
    {
      "id": "2510.01704",
      "title": "Holistic Order Prediction in Natural Scenes",
      "authors": [
        "Pierre Musacchio",
        "Hyunmin Lee",
        "Jaesik Park"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.AI (Artificial Intelligence)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "Even in controlled settings, understanding instance-wise geometries is a\nchallenging task for a wide range of visual models. Although specialized\nsystems exist, modern arts rely on expensive input formats (category labels,\nbinary segmentation masks) and inference costs (a quadratic amount of forward\npasses). We mitigate these limitations by proposing InstaFormer, a network\ncapable of holistic order prediction. That is, solely given an input RGB image,\nInstaFormer returns the full occlusion and depth orderings for all the\ninstances in the scene in a single forward pass. At its core, InstaFormer\nrelies on interactions between object queries and latent mask descriptors that\nsemantically represent the same objects while carrying complementary\ninformation. We comprehensively benchmark and ablate our approach to highlight\nits effectiveness. Our code and models are open-source and available at this\nURL: https://github.com/SNU-VGILab/InstaOrder.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01704v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01704v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.331,
      "weak_supervision_score": 0.31,
      "diffusion_reasoning_score": 0.405,
      "distributed_training_score": 0.296,
      "datasets_score": 0.284,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper introduces InstaFormer, a transformer-based network for predicting occlusion and depth orderings in images using a single forward pass with object queries and latent mask descriptors. It does not involve diffusion models, iterative refinement processes, or multi-step logical reasoning for a 'Chain-of-Thought' entity, focusing instead on holistic prediction in computer vision tasks.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01706",
      "title": "Representational Alignment Across Model Layers and Brain Regions with\n  Hierarchical Optimal Transport",
      "authors": [
        "Shaan Shah",
        "Meenakshi Khosla"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Standard representational similarity methods align each layer of a network to\nits best match in another independently, producing asymmetric results, lacking\na global alignment score, and struggling with networks of different depths.\nThese limitations arise from ignoring global activation structure and\nrestricting mappings to rigid one-to-one layer correspondences. We propose\nHierarchical Optimal Transport (HOT), a unified framework that jointly infers\nsoft, globally consistent layer-to-layer couplings and neuron-level transport\nplans. HOT allows source neurons to distribute mass across multiple target\nlayers while minimizing total transport cost under marginal constraints. This\nyields both a single alignment score for the entire network comparison and a\nsoft transport plan that naturally handles depth mismatches through mass\ndistribution. We evaluate HOT on vision models, large language models, and\nhuman visual cortex recordings. Across all domains, HOT matches or surpasses\nstandard pairwise matching in alignment quality. Moreover, it reveals smooth,\nfine-grained hierarchical correspondences: early layers map to early layers,\ndeeper layers maintain relative positions, and depth mismatches are resolved by\ndistributing representations across multiple layers. These structured patterns\nemerge naturally from global optimization without being imposed, yet are absent\nin greedy layer-wise methods. HOT thus enables richer, more interpretable\ncomparisons between representations, particularly when networks differ in\narchitecture or depth.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01706v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01706v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.421,
      "weak_supervision_score": 0.307,
      "diffusion_reasoning_score": 0.429,
      "distributed_training_score": 0.393,
      "datasets_score": 0.322,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper introduces Hierarchical Optimal Transport for aligning neural representations across models and brain regions, focusing on computational neuroscience and AI representation comparisons. It does not involve reinforcement learning, human feedback, reward models, or fine-tuning based on human preferences.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper evaluates representational alignment on models like DINOv2, which is a vision model, but it does not adapt diffusion processes for multi-step logical reasoning, chain-of-thought refinement, or iterative correction of reasoning paths.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01708",
      "title": "PolySim: Bridging the Sim-to-Real Gap for Humanoid Control via\n  Multi-Simulator Dynamics Randomization",
      "authors": [
        "Zixing Lei",
        "Zibo Zhou",
        "Sheng Yin",
        "Yueru Chen",
        "Qingyao Xu",
        "Weixin Li",
        "Yunhong Wang",
        "Bowei Tang",
        "Wei Jing",
        "Siheng Chen"
      ],
      "categories": [
        "cs.RO (Robotics)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Humanoid whole-body control (WBC) policies trained in simulation often suffer\nfrom the sim-to-real gap, which fundamentally arises from simulator inductive\nbias, the inherent assumptions and limitations of any single simulator. These\nbiases lead to nontrivial discrepancies both across simulators and between\nsimulation and the real world. To mitigate the effect of simulator inductive\nbias, the key idea is to train policies jointly across multiple simulators,\nencouraging the learned controller to capture dynamics that generalize beyond\nany single simulator's assumptions. We thus introduce PolySim, a WBC training\nplatform that integrates multiple heterogeneous simulators. PolySim can launch\nparallel environments from different engines simultaneously within a single\ntraining run, thereby realizing dynamics-level domain randomization.\nTheoretically, we show that PolySim yields a tighter upper bound on simulator\ninductive bias than single-simulator training. In experiments, PolySim\nsubstantially reduces motion-tracking error in sim-to-sim evaluations; for\nexample, on MuJoCo, it improves execution success by 52.8 over an IsaacSim\nbaseline. PolySim further enables zero-shot deployment on a real Unitree G1\nwithout additional fine-tuning, showing effective transfer from simulation to\nthe real world. We will release the PolySim code upon acceptance of this work.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01708v3",
      "pdf_url": "http://arxiv.org/pdf/2510.01708v3",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.405,
      "weak_supervision_score": 0.348,
      "diffusion_reasoning_score": 0.35,
      "distributed_training_score": 0.402,
      "datasets_score": 0.276,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "Highly Relevant",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on reinforcement learning for humanoid control using simulation and multiple simulators to address the sim-to-real gap, but it does not involve human feedback, a reward model trained on human-ranked data, or any alignment with human preferences.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "The paper's PolySim platform incorporates distributed training elements, such as a client-server architecture for decoupling RL training from simulator runtimes, a unified simulator router for resource scheduling and parallel environments across different simulators, and GPU pass-through for efficient communication, which directly relate to parallel computing and multi-node machine learning.",
      "datasets_justification": "below_threshold",
      "llm_score_status": "completed",
      "summary": "The paper introduces PolySim, a platform designed to bridge the sim-to-real gap in humanoid whole-body control by training policies across multiple heterogeneous simulators, thereby mitigating simulator inductive bias through dynamics-level domain randomization. It features a client-server architecture for efficient parallel execution, theoretically provides a tighter bound on inductive bias, and empirically demonstrates substantial improvements in motion-tracking accuracy and zero-shot real-world deployment on a Unitree G1 robot.",
      "novelty_score": "High",
      "novelty_justification": "The paper introduces a truly new technique by integrating multiple simulators for dynamics-level randomization, significantly advancing the state-of-the-art in sim-to-real transfer for humanoid control.",
      "impact_score": "High",
      "impact_justification": "This work could influence a wide range of future research and commercial applications in robotics and AI by providing a more effective method for handling sim-to-real gaps, potentially leading to safer and more reliable real-world deployments.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper represents a strong, valuable contribution with innovative features and empirical validation, making it essential for researchers focused on robotics and sim-to-real transfer to be aware of.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/9154a46287f8df53b3ffbfa5c7f2e881e4cc863b",
      "total_authors": 10,
      "authors_found": 10,
      "highest_h_index": 5,
      "average_h_index": 1.0,
      "notable_authors_count": 0,
      "author_h_indexes": [
        {
          "name": "Zixing Lei",
          "h_index": 5,
          "profile_url": "https://www.semanticscholar.org/author/2176779762"
        },
        {
          "name": "Zibo Zhou",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2367071555"
        },
        {
          "name": "Sheng Yin",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383429721"
        },
        {
          "name": "Yueru Chen",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383383403"
        },
        {
          "name": "Qingyao Xu",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2228327855"
        },
        {
          "name": "Weixin Li",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383417667"
        },
        {
          "name": "Yunhong Wang",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2281412623"
        },
        {
          "name": "Bowei Tang",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2386561641"
        },
        {
          "name": "Wei Jing",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383313397"
        },
        {
          "name": "Siheng Chen",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383320874"
        }
      ]
    },
    {
      "id": "2510.01715",
      "title": "PyramidStyler: Transformer-Based Neural Style Transfer with Pyramidal\n  Positional Encoding and Reinforcement Learning",
      "authors": [
        "Raahul Krishna Durairaju",
        "K. Saruladha"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Neural Style Transfer (NST) has evolved from Gatys et al.'s (2015) CNN-based\nalgorithm, enabling AI-driven artistic image synthesis. However, existing CNN\nand transformer-based models struggle to scale efficiently to complex styles\nand high-resolution inputs. We introduce PyramidStyler, a transformer framework\nwith Pyramidal Positional Encoding (PPE): a hierarchical, multi-scale encoding\nthat captures both local details and global context while reducing\ncomputational load. We further incorporate reinforcement learning to\ndynamically optimize stylization, accelerating convergence. Trained on\nMicrosoft COCO and WikiArt, PyramidStyler reduces content loss by 62.6% (to\n2.07) and style loss by 57.4% (to 0.86) after 4000 epochs--achieving 1.39 s\ninference--and yields further improvements (content 2.03; style 0.75) with\nminimal speed penalty (1.40 s) when using RL. These results demonstrate\nreal-time, high-quality artistic rendering, with broad applications in media\nand design.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01715v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01715v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.369,
      "weak_supervision_score": 0.299,
      "diffusion_reasoning_score": 0.415,
      "distributed_training_score": 0.37,
      "datasets_score": 0.312,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper introduces PyramidStyler, a transformer-based model for neural style transfer, focusing on pyramidal positional encoding and reinforcement learning to enhance image stylization efficiency. It does not involve diffusion models, iterative refinement for logical tasks, or any form of Chain-of-Thought reasoning, making it unrelated to diffusion-based reasoning.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01717",
      "title": "Latency-aware Multimodal Federated Learning over UAV Networks",
      "authors": [
        "Shaba Shaon",
        "Dinh C. Nguyen"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "This paper investigates federated multimodal learning (FML) assisted by\nunmanned aerial vehicles (UAVs) with a focus on minimizing system latency and\nproviding convergence analysis. In this framework, UAVs are distributed\nthroughout the network to collect data, participate in model training, and\ncollaborate with a base station (BS) to build a global model. By utilizing\nmultimodal sensing, the UAVs overcome the limitations of unimodal systems,\nenhancing model accuracy, generalization, and offering a more comprehensive\nunderstanding of the environment. The primary objective is to optimize FML\nsystem latency in UAV networks by jointly addressing UAV sensing scheduling,\npower control, trajectory planning, resource allocation, and BS resource\nmanagement. To address the computational complexity of our latency minimization\nproblem, we propose an efficient iterative optimization algorithm combining\nblock coordinate descent and successive convex approximation techniques, which\nprovides high-quality approximate solutions. We also present a theoretical\nconvergence analysis for the UAV-assisted FML framework under a non-convex loss\nfunction. Numerical experiments demonstrate that our FML framework outperforms\nexisting approaches in terms of system latency and model training performance\nunder different data settings.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01717v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01717v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.373,
      "weak_supervision_score": 0.346,
      "diffusion_reasoning_score": 0.327,
      "distributed_training_score": 0.407,
      "datasets_score": 0.297,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "Highly Relevant",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "The paper's main contribution involves a federated multimodal learning framework where UAVs act as distributed nodes to train local models on their data and collaborate with a base station for global model aggregation. This directly aligns with distributed training concepts, as it partitions computation across multiple nodes (UAVs), optimizes resource allocation for parallel processing, and aims to accelerate training by minimizing latency through techniques like trajectory planning and power control. The focus on federated learning as a form of distributed training makes it a core match to the topic.",
      "datasets_justification": "below_threshold",
      "llm_score_status": "completed",
      "summary": "This paper proposes a latency-aware federated multimodal learning (FML) framework for unmanned aerial vehicle (UAV) networks, where UAVs collect and process multimodal data to collaboratively train a global model with a base station, aiming to minimize system latency while enhancing model accuracy and generalization. The authors formulate an optimization problem addressing UAV sensing scheduling, power control, trajectory planning, and resource allocation, solved using an iterative algorithm combining block coordinate descent and successive convex approximation, and provide convergence analysis; simulations show the framework reduces latency by up to 42.49% and outperforms baselines in model training performance across IID and non-IID data settings.",
      "novelty_score": "Moderate",
      "novelty_justification": "The paper presents a notable improvement by combining federated learning, multimodal sensing, and UAV networks to minimize latency in a new integrated framework, though it builds on existing FL-UAV and FML concepts rather than introducing a entirely new problem.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to be cited and built upon in subfields like UAV-assisted machine learning and wireless networks due to its practical optimizations for latency reduction, but its influence may remain confined to these specific areas rather than broadly affecting general AI or commercial applications.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper provides high-quality contributions in optimizing federated learning for UAV networks, making it valuable for researchers in related fields, though it may not be essential for those outside this niche.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/f3de2c2c153fcded84d104d0b4e467138a4b7016",
      "total_authors": 2,
      "authors_found": 2,
      "highest_h_index": 3,
      "average_h_index": 2.0,
      "notable_authors_count": 0,
      "author_h_indexes": [
        {
          "name": "Shaba Shaon",
          "h_index": 3,
          "profile_url": "https://www.semanticscholar.org/author/2149703027"
        },
        {
          "name": "Dinh C. Nguyen",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2330224252"
        }
      ]
    },
    {
      "id": "2510.01722",
      "title": "Emotional Text-To-Speech Based on Mutual-Information-Guided\n  Emotion-Timbre Disentanglement",
      "authors": [
        "Jianing Yang",
        "Sheng Li",
        "Takahiro Shinozaki",
        "Yuki Saito",
        "Hiroshi Saruwatari"
      ],
      "categories": [
        "cs.SD (Sound)",
        "cs.AI (Artificial Intelligence)",
        "eess.AS (Audio and Speech Processing)"
      ],
      "abstract": "Current emotional Text-To-Speech (TTS) and style transfer methods rely on\nreference encoders to control global style or emotion vectors, but do not\ncapture nuanced acoustic details of the reference speech. To this end, we\npropose a novel emotional TTS method that enables fine-grained phoneme-level\nemotion embedding prediction while disentangling intrinsic attributes of the\nreference speech. The proposed method employs a style disentanglement method to\nguide two feature extractors, reducing mutual information between timbre and\nemotion features, and effectively separating distinct style components from the\nreference speech. Experimental results demonstrate that our method outperforms\nbaseline TTS systems in generating natural and emotionally rich speech. This\nwork highlights the potential of disentangled and fine-grained representations\nin advancing the quality and flexibility of emotional TTS systems.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01722v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01722v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.356,
      "weak_supervision_score": 0.327,
      "diffusion_reasoning_score": 0.409,
      "distributed_training_score": 0.324,
      "datasets_score": 0.31,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper's main contribution is in emotional Text-To-Speech (TTS) systems, focusing on emotion-timbre disentanglement using mutual information techniques and feature extractors. It does not involve diffusion models, iterative refinement for logical tasks, or any form of reasoning processes, making it unrelated to diffusion-based reasoning.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01724",
      "title": "MetaboT: AI-based agent for natural language-based interaction with\n  metabolomics knowledge graphs",
      "authors": [
        "Madina Bekbergenova",
        "Lucas Pradi",
        "Benjamin Navet",
        "Emma Tysinger",
        "Franck Michel",
        "Matthieu Feraud",
        "Yousouf Taghzouti",
        "Yan Zhou Chen",
        "Olivier Kirchhoffer",
        "Florence Mehl",
        "Martin Legrand",
        "Tao Jiang",
        "Marco Pagni",
        "Soha Hassoun",
        "Jean-Luc Wolfender",
        "Wout Bittremieux",
        "Fabien Gandon",
        "Louis-Félix Nothias"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Mass spectrometry metabolomics generates vast amounts of data requiring\nadvanced methods for interpretation. Knowledge graphs address these challenges\nby structuring mass spectrometry data, metabolite information, and their\nrelationships into a connected network (Gaudry et al. 2024). However, effective\nuse of a knowledge graph demands an in-depth understanding of its ontology and\nits query language syntax. To overcome this, we designed MetaboT, an AI system\nutilizing large language models (LLMs) to translate user questions into SPARQL\nsemantic query language for operating on knowledge graphs (Steve Harris 2013).\nWe demonstrate its effectiveness using the Experimental Natural Products\nKnowledge Graph (ENPKG), a large-scale public knowledge graph for plant natural\nproducts (Gaudry et al. 2024).MetaboT employs specialized AI agents for\nhandling user queries and interacting with the knowledge graph by breaking down\ncomplex tasks into discrete components, each managed by a specialised agent\n(Fig. 1a). The multi-agent system is constructed using the LangChain and\nLangGraph libraries, which facilitate the integration of LLMs with external\ntools and information sources (LangChain, n.d.). The query generation process\nfollows a structured workflow. First, the Entry Agent determines if the\nquestion is new or a follow-up to previous interactions. New questions are\nforwarded to the Validator Agent, which verifies if the question is related to\nthe knowledge graph. Then, the valid question is sent to the Supervisor Agent,\nwhich identifies if the question requires chemical conversions or standardized\nidentifiers. In this case it delegates the question to the Knowledge Graph\nAgent, which can use tools to extract necessary details, such as URIs or\ntaxonomies of chemical names, from the user query. Finally, an agent\nresponsible for crafting the SPARQL queries equipped with the ontology of the\nknowledge graph uses the provided identifiers to generate the query. Then, the\nsystem executes the generated query against the metabolomics knowledge graph\nand returns structured results to the user (Fig. 1b). To assess the performance\nof MetaboT we have curated 50 metabolomics-related questions and their expected\nanswers. In addition to submitting these questions to MetaboT, we evaluated a\nbaseline by submitting them to a standard LLM (GPT-4o) with a prompt that\nincorporated the knowledge graph ontology but did not provide specific entity\nIDs. This baseline achieved only 8.16% accuracy, compared to MetaboT's 83.67%,\nunderscoring the necessity of our multi-agent system for accurately retrieving\nentities and generating correct SPARQL queries. MetaboT demonstrates promising\nperformance as a conversational question-answering assistant, enabling\nresearchers to retrieve structured metabolomics data through natural language\nqueries. By automating the generation and execution of SPARQL queries, it\nremoves technical barriers that have traditionally hindered access to knowledge\ngraphs. Importantly, MetaboT leverages the capabilities of LLMs while\nmaintaining experimentally grounded query generation, ensuring that outputs\nremain aligned with domain-specific standards and data structures. This\napproach facilitates data-driven discoveries by bridging the gap between\ncomplex semantic technologies and user-friendly interaction. MetaboT is\naccessible at [https://metabot.holobiomicslab.eu/], and its source code is\navailable at [https://github.com/HolobiomicsLab/MetaboT].",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01724v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01724v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "extraction_failed",
      "embedding_status": "completed",
      "rlhf_score": 0.355,
      "weak_supervision_score": 0.331,
      "diffusion_reasoning_score": 0.392,
      "distributed_training_score": 0.301,
      "datasets_score": 0.353,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01736",
      "title": "Machine-interpretable Engineering Design Standards for Valve\n  Specification",
      "authors": [
        "Anders Gjerver",
        "Rune Frostad",
        "Vedrana Barisic",
        "Melinda Hodkiewicz",
        "Caitlin Woods",
        "Mihaly Fekete",
        "Arild Braathen Torjusen",
        "Johan Wilhelm Kluwer"
      ],
      "categories": [
        "cs.CL (Computation and Language)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Engineering design processes use technical specifications and must comply\nwith standards. Product specifications, product type data sheets, and design\nstandards are still mainly document-centric despite the ambition to digitalize\nindustrial work. In this paper, we demonstrate how to transform information\nheld in engineering design standards into modular, reusable,\nmachine-interpretable ontologies and use the ontologies in quality assurance of\nthe plant design and equipment selection process. We use modelling patterns to\ncreate modular ontologies for knowledge captured in the text and in frequently\nreferenced tables in International Standards for piping, material and valve\ndesign. These modules are exchangeable, as stored in a W3C compliant format,\nand interoperable as they are aligned with the top-level ontology ISO DIS\n23726-3: Industrial Data Ontology (IDO).\n  We test these ontologies, created based on international material and piping\nstandards and industry norms, on a valve selection process. Valves are\ninstantiated in semantic asset models as individuals along with a semantic\nrepresentation of the environmental condition at their location on the asset.\nWe create \"functional location tags\" as OWL individuals that become instances\nof OWL class Valve Data Sheet (VDS) specified valves. Similarly we create\ninstances of manufacturer product type. Our approach enables automated\nvalidation that a specific VDS is compliant with relevant industry standards.\nUsing semantic reasoning and executable design rules, we also determine whether\nthe product type meets the valve specification. Creation of shared, reusable\nIDO-based modular ontologies for design standards enables semantic reasoning to\nbe applied to equipment selection processes and demonstrates the potential of\nthis approach for Standards Bodies wanting to transition to digitized Smart\nStandards.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01736v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01736v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.296,
      "weak_supervision_score": 0.289,
      "diffusion_reasoning_score": 0.298,
      "distributed_training_score": 0.278,
      "datasets_score": 0.331,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01749",
      "title": "Towards Photonic Band Diagram Generation with Transformer-Latent\n  Diffusion Models",
      "authors": [
        "Valentin Delchevalerie",
        "Nicolas Roy",
        "Arnaud Bougaham",
        "Alexandre Mayer",
        "Benoît Frénay",
        "Michaël Lobet"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Photonic crystals enable fine control over light propagation at the\nnanoscale, and thus play a central role in the development of photonic and\nquantum technologies. Photonic band diagrams (BDs) are a key tool to\ninvestigate light propagation into such inhomogeneous structured materials.\nHowever, computing BDs requires solving Maxwell's equations across many\nconfigurations, making it numerically expensive, especially when embedded in\noptimization loops for inverse design techniques, for example. To address this\nchallenge, we introduce the first approach for BD generation based on diffusion\nmodels, with the capacity to later generalize and scale to arbitrary three\ndimensional structures. Our method couples a transformer encoder, which\nextracts contextual embeddings from the input structure, with a latent\ndiffusion model to generate the corresponding BD. In addition, we provide\ninsights into why transformers and diffusion models are well suited to capture\nthe complex interference and scattering phenomena inherent to photonics, paving\nthe way for new surrogate modeling strategies in this domain.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01749v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01749v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.297,
      "weak_supervision_score": 0.275,
      "diffusion_reasoning_score": 0.527,
      "distributed_training_score": 0.345,
      "datasets_score": 0.285,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on using diffusion models for generating photonic band diagrams from input structures, employing iterative refinement for image-like outputs in a scientific context. However, it does not involve adapting diffusion models for complex logical tasks, such as multi-step reasoning or chain-of-thought processes, as it lacks any elements of logical inference or holistic correction of reasoning paths.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01751",
      "title": "A cybersecurity AI agent selection and decision support framework",
      "authors": [
        "Masike Malatji"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "This paper presents a novel, structured decision support framework that\nsystematically aligns diverse artificial intelligence (AI) agent architectures,\nreactive, cognitive, hybrid, and learning, with the comprehensive National\nInstitute of Standards and Technology (NIST) Cybersecurity Framework (CSF) 2.0.\nBy integrating agent theory with industry guidelines, this framework provides a\ntransparent and stepwise methodology for selecting and deploying AI solutions\nto address contemporary cyber threats. Employing a granular decomposition of\nNIST CSF 2.0 functions into specific tasks, the study links essential AI agent\nproperties such as autonomy, adaptive learning, and real-time responsiveness to\neach subcategory's security requirements. In addition, it outlines graduated\nlevels of autonomy (assisted, augmented, and fully autonomous) to accommodate\norganisations at varying stages of cybersecurity maturity. This holistic\napproach transcends isolated AI applications, providing a unified detection,\nincident response, and governance strategy. Through conceptual validation, the\nframework demonstrates how tailored AI agent deployments can align with\nreal-world constraints and risk profiles, enhancing situational awareness,\naccelerating response times, and fortifying long-term resilience via adaptive\nrisk management. Ultimately, this research bridges the gap between theoretical\nAI constructs and operational cybersecurity demands, establishing a foundation\nfor robust, empirically validated multi-agent systems that adhere to industry\nstandards.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01751v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01751v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "extraction_failed",
      "embedding_status": "completed",
      "rlhf_score": 0.397,
      "weak_supervision_score": 0.331,
      "diffusion_reasoning_score": 0.322,
      "distributed_training_score": 0.303,
      "datasets_score": 0.367,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01758",
      "title": "Unsupervised Dynamic Feature Selection for Robust Latent Spaces in\n  Vision Tasks",
      "authors": [
        "Bruno Corcuera",
        "Carlos Eiras-Franco",
        "Brais Cancela"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)",
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Latent representations are critical for the performance and robustness of\nmachine learning models, as they encode the essential features of data in a\ncompact and informative manner. However, in vision tasks, these representations\nare often affected by noisy or irrelevant features, which can degrade the\nmodel's performance and generalization capabilities. This paper presents a\nnovel approach for enhancing latent representations using unsupervised Dynamic\nFeature Selection (DFS). For each instance, the proposed method identifies and\nremoves misleading or redundant information in images, ensuring that only the\nmost relevant features contribute to the latent space. By leveraging an\nunsupervised framework, our approach avoids reliance on labeled data, making it\nbroadly applicable across various domains and datasets. Experiments conducted\non image datasets demonstrate that models equipped with unsupervised DFS\nachieve significant improvements in generalization performance across various\ntasks, including clustering and image generation, while incurring a minimal\nincrease in the computational cost.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01758v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01758v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.354,
      "weak_supervision_score": 0.421,
      "diffusion_reasoning_score": 0.395,
      "distributed_training_score": 0.363,
      "datasets_score": 0.389,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "Not Relevant",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "The paper introduces an unsupervised Dynamic Feature Selection (DFS) method that operates without any labeled data, focusing on enhancing latent representations in vision tasks through feature selection. Weak supervision, by contrast, involves training models using programmatically generated or noisy labels as a substitute for fully labeled data. Since the paper explicitly avoids labels entirely and does not address label generation or utilization, it has no connection to weak supervision concepts.",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01767",
      "title": "LOBE-GS: Load-Balanced and Efficient 3D Gaussian Splatting for\n  Large-Scale Scene Reconstruction",
      "authors": [
        "Sheng-Hsiang Hung",
        "Ting-Yu Yen",
        "Wei-Fang Sun",
        "Simon See",
        "Shih-Hsuan Hung",
        "Hung-Kuo Chu"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "3D Gaussian Splatting (3DGS) has established itself as an efficient\nrepresentation for real-time, high-fidelity 3D scene reconstruction. However,\nscaling 3DGS to large and unbounded scenes such as city blocks remains\ndifficult. Existing divide-and-conquer methods alleviate memory pressure by\npartitioning the scene into blocks, but introduce new bottlenecks: (i)\npartitions suffer from severe load imbalance since uniform or heuristic splits\ndo not reflect actual computational demands, and (ii) coarse-to-fine pipelines\nfail to exploit the coarse stage efficiently, often reloading the entire model\nand incurring high overhead. In this work, we introduce LoBE-GS, a novel\nLoad-Balanced and Efficient 3D Gaussian Splatting framework, that re-engineers\nthe large-scale 3DGS pipeline. LoBE-GS introduces a depth-aware partitioning\nmethod that reduces preprocessing from hours to minutes, an optimization-based\nstrategy that balances visible Gaussians -- a strong proxy for computational\nload -- across blocks, and two lightweight techniques, visibility cropping and\nselective densification, to further reduce training cost. Evaluations on\nlarge-scale urban and outdoor datasets show that LoBE-GS consistently achieves\nup to $2\\times$ faster end-to-end training time than state-of-the-art\nbaselines, while maintaining reconstruction quality and enabling scalability to\nscenes infeasible with vanilla 3DGS.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01767v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01767v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.287,
      "weak_supervision_score": 0.332,
      "diffusion_reasoning_score": 0.359,
      "distributed_training_score": 0.439,
      "datasets_score": 0.291,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "Highly Relevant",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "The paper's main contribution involves load-balanced partitioning of scenes into blocks for parallel processing in 3D Gaussian Splatting, directly aligning with distributed training concepts. It addresses computational load imbalance across blocks to accelerate training, similar to strategies in parallel computing for multi-node systems, such as partitioning data and computation to reduce bottlenecks and improve efficiency. This makes the paper highly pertinent to distributed training algorithms and systems.",
      "datasets_justification": "below_threshold",
      "llm_score_status": "completed",
      "summary": "The paper introduces LoBE-GS, a framework aimed at improving 3D Gaussian Splatting (3DGS) for large-scale scene reconstruction by addressing load imbalance and inefficiencies in existing methods. It incorporates depth-aware partitioning to speed up preprocessing, optimization-based load balancing using visible Gaussians as a proxy, and techniques like visibility cropping and selective densification to reduce training costs, resulting in up to 2x faster end-to-end training while maintaining reconstruction quality on urban and outdoor datasets.",
      "novelty_score": "Moderate",
      "novelty_justification": "The paper presents a notable improvement by combining existing ideas with new techniques like depth-aware partitioning and load balancing via visible Gaussians, effectively addressing bottlenecks in large-scale 3DGS without introducing an entirely new problem or architecture.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to influence research and applications in scalable 3D reconstruction within computer vision subfields, as its efficiency gains could enable broader adoption for large scenes, though its impact may be limited outside these areas.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper provides a strong, valuable contribution to efficient large-scale 3D scene reconstruction, making it essential for researchers in computer vision to be aware of its advancements in training speed and scalability.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/ede4866b7b94e7d5fb180ce006d72c44efa1dd26",
      "total_authors": 6,
      "authors_found": 6,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": [
        {
          "name": "Sheng-Hsiang Hung",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383301377"
        },
        {
          "name": "Ting-Yu Yen",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2314923523"
        },
        {
          "name": "Wei-Fang Sun",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2384388296"
        },
        {
          "name": "Simon See",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383301360"
        },
        {
          "name": "Shih-Hsuan Hung",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383301379"
        },
        {
          "name": "Hung-Kuo Chu",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2384042686"
        }
      ]
    },
    {
      "id": "2510.01780",
      "title": "Secure Multi-Modal Data Fusion in Federated Digital Health Systems via\n  MCP",
      "authors": [
        "Aueaphum Aueawatthanaphisut"
      ],
      "categories": [
        "cs.CR (Cryptography and Security)",
        "cs.AI (Artificial Intelligence)",
        "cs.CY (Computers and Society)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "Secure and interoperable integration of heterogeneous medical data remains a\ngrand challenge in digital health. Current federated learning (FL) frameworks\noffer privacy-preserving model training but lack standardized mechanisms to\norchestrate multi-modal data fusion across distributed and resource-constrained\nenvironments. This study introduces a novel framework that leverages the Model\nContext Protocol (MCP) as an interoperability layer for secure, cross-agent\ncommunication in multi-modal federated healthcare systems. The proposed\narchitecture unifies three pillars: (i) multi-modal feature alignment for\nclinical imaging, electronic medical records, and wearable IoT data; (ii)\nsecure aggregation with differential privacy to protect patient-sensitive\nupdates; and (iii) energy-aware scheduling to mitigate dropouts in mobile\nclients. By employing MCP as a schema-driven interface, the framework enables\nadaptive orchestration of AI agents and toolchains while ensuring compliance\nwith privacy regulations. Experimental evaluation on benchmark datasets and\npilot clinical cohorts demonstrates up to 9.8\\% improvement in diagnostic\naccuracy compared with baseline FL, a 54\\% reduction in client dropout rates,\nand clinically acceptable privacy--utility trade-offs. These results highlight\nMCP-enabled multi-modal fusion as a scalable and trustworthy pathway toward\nequitable, next-generation federated health infrastructures.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01780v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01780v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.38,
      "weak_supervision_score": 0.332,
      "diffusion_reasoning_score": 0.351,
      "distributed_training_score": 0.411,
      "datasets_score": 0.342,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "Highly Relevant",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "The paper's main contribution involves federated learning (FL), a form of distributed training, where model updates are aggregated from multiple distributed nodes (e.g., healthcare institutions and IoT devices) without centralizing data. It addresses key aspects of distributed training, such as partitioning data across nodes for multi-modal fusion, secure aggregation to handle updates from multiple processors, and energy-aware scheduling to manage computation in resource-constrained environments. These elements align directly with distributed training concepts like parallel computing and multi-node machine learning, making the paper's framework a direct advancement in this area.",
      "datasets_justification": "below_threshold",
      "llm_score_status": "completed",
      "summary": "This paper introduces a novel framework leveraging the Model Context Protocol (MCP) to enable secure and interoperable fusion of multi-modal medical data, such as clinical imaging, electronic medical records, and IoT device data, within federated learning environments. The methodology incorporates multi-modal feature alignment, secure aggregation with differential privacy, and energy-aware scheduling to address privacy, interoperability, and resource constraints; experimental results demonstrate up to 9.8% improvement in diagnostic accuracy, a 54% reduction in client dropouts, and balanced privacy-utility trade-offs, positioning the framework as a scalable solution for trustworthy federated health systems.",
      "novelty_score": "Moderate",
      "novelty_justification": "The paper presents a clever combination of MCP for interoperability with existing federated learning techniques to handle multi-modal data fusion in healthcare, offering a notable improvement over unimodal approaches but not introducing an entirely new problem or technique.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to influence research and applications in federated learning for healthcare by providing a practical framework for secure data integration, though its impact may be primarily confined to specific subfields like AI in digital health.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "The paper delivers a high-quality contribution with innovative solutions to key challenges in secure multi-modal federated learning, making it valuable for researchers in AI and healthcare to understand and potentially build upon.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/69eda52b1fe4fb4dfe590ee6c331a5132e963fe2",
      "total_authors": 1,
      "authors_found": 1,
      "highest_h_index": 1,
      "average_h_index": 1.0,
      "notable_authors_count": 0,
      "author_h_indexes": [
        {
          "name": "Aueaphum Aueawatthanaphisut",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2366964410"
        }
      ]
    },
    {
      "id": "2510.01782",
      "title": "Can LLMs Refuse Questions They Do Not Know? Measuring Knowledge-Aware\n  Refusal in Factual Tasks",
      "authors": [
        "Wenbo Pan",
        "Jie Xu",
        "Qiguang Chen",
        "Junhao Dong",
        "Libo Qin",
        "Xinfeng Li",
        "Haining Yu",
        "Xiaohua Jia"
      ],
      "categories": [
        "cs.CL (Computation and Language)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Large Language Models (LLMs) should refuse to answer questions beyond their\nknowledge. This capability, which we term knowledge-aware refusal, is crucial\nfor factual reliability. However, existing metrics fail to faithfully measure\nthis ability. On the one hand, simple refusal-based metrics are biased by\nrefusal rates and yield inconsistent scores when models exhibit different\nrefusal tendencies. On the other hand, existing calibration metrics are\nproxy-based, capturing the performance of auxiliary calibration processes\nrather than the model's actual refusal behavior. In this work, we propose the\nRefusal Index (RI), a principled metric that measures how accurately LLMs\nrefuse questions they do not know. We define RI as Spearman's rank correlation\nbetween refusal probability and error probability. To make RI practically\nmeasurable, we design a lightweight two-pass evaluation method that efficiently\nestimates RI from observed refusal rates across two standard evaluation runs.\nExtensive experiments across 16 models and 5 datasets demonstrate that RI\naccurately quantifies a model's intrinsic knowledge-aware refusal capability in\nfactual tasks. Notably, RI remains stable across different refusal rates and\nprovides consistent model rankings independent of a model's overall accuracy\nand refusal rates. More importantly, RI provides insight into an important but\npreviously overlooked aspect of LLM factuality: while LLMs achieve high\naccuracy on factual tasks, their refusal behavior can be unreliable and\nfragile. This finding highlights the need to complement traditional accuracy\nmetrics with the Refusal Index for comprehensive factuality evaluation.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01782v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01782v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.478,
      "weak_supervision_score": 0.378,
      "diffusion_reasoning_score": 0.435,
      "distributed_training_score": 0.306,
      "datasets_score": 0.319,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Tangentially Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper mentions fine-tuning as a method to improve refusal capabilities in LLMs, which could potentially involve RLHF techniques, but its main contribution is developing a metric for evaluating knowledge-aware refusal, not the RLHF process itself. Thus, it is only indirectly related.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on evaluating LLMs' refusal behavior in factual tasks and introduces a new metric, with no mention of diffusion models, iterative refinement for reasoning, or multi-step logical processes as defined in the topic.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01784",
      "title": "Pack and Force Your Memory: Long-form and Consistent Video Generation",
      "authors": [
        "Xiaofei Wu",
        "Guozhen Zhang",
        "Zhiyong Xu",
        "Yuan Zhou",
        "Qinglin Lu",
        "Xuming He"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Long-form video generation presents a dual challenge: models must capture\nlong-range dependencies while preventing the error accumulation inherent in\nautoregressive decoding. To address these challenges, we make two\ncontributions. First, for dynamic context modeling, we propose MemoryPack, a\nlearnable context-retrieval mechanism that leverages both textual and image\ninformation as global guidance to jointly model short- and long-term\ndependencies, achieving minute-level temporal consistency. This design scales\ngracefully with video length, preserves computational efficiency, and maintains\nlinear complexity. Second, to mitigate error accumulation, we introduce Direct\nForcing, an efficient single-step approximating strategy that improves\ntraining-inference alignment and thereby curtails error propagation during\ninference. Together, MemoryPack and Direct Forcing substantially enhance the\ncontext consistency and reliability of long-form video generation, advancing\nthe practical usability of autoregressive video models.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01784v2",
      "pdf_url": "http://arxiv.org/pdf/2510.01784v2",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.36,
      "weak_supervision_score": 0.333,
      "diffusion_reasoning_score": 0.476,
      "distributed_training_score": 0.372,
      "datasets_score": 0.287,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on long-form video generation using techniques like MemoryPack and Direct Forcing, which build on Diffusion Transformer (DiT) models and rectified flow for improving temporal consistency and reducing error accumulation. While it involves diffusion-based processes for video synthesis, it does not adapt these for multi-step logical reasoning or treat a 'Chain-of-Thought' as a single entity for holistic correction. Instead, it applies diffusion concepts to visual content generation, lacking any clear component for solving complex logical tasks.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01792",
      "title": "Comparison of Unsupervised Metrics for Evaluating Judicial Decision\n  Extraction",
      "authors": [
        "Ivan Leonidovich Litvak",
        "Anton Kostin",
        "Fedor Lashkin",
        "Tatiana Maksiyan",
        "Sergey Lagutin"
      ],
      "categories": [
        "cs.CL (Computation and Language)",
        "cs.AI (Artificial Intelligence)",
        "cs.IR (Information Retrieval)"
      ],
      "abstract": "The rapid advancement of artificial intelligence in legal natural language\nprocessing demands scalable methods for evaluating text extraction from\njudicial decisions. This study evaluates 16 unsupervised metrics, including\nnovel formulations, to assess the quality of extracting seven semantic blocks\nfrom 1,000 anonymized Russian judicial decisions, validated against 7,168\nexpert reviews on a 1--5 Likert scale. These metrics, spanning document-based,\nsemantic, structural, pseudo-ground truth, and legal-specific categories,\noperate without pre-annotated ground truth. Bootstrapped correlations, Lin's\nconcordance correlation coefficient (CCC), and mean absolute error (MAE) reveal\nthat Term Frequency Coherence (Pearson $r = 0.540$, Lin CCC = 0.512, MAE =\n0.127) and Coverage Ratio/Block Completeness (Pearson $r = 0.513$, Lin CCC =\n0.443, MAE = 0.139) best align with expert ratings, while Legal Term Density\n(Pearson $r = -0.479$, Lin CCC = -0.079, MAE = 0.394) show strong negative\ncorrelations. The LLM Evaluation Score (mean = 0.849, Pearson $r = 0.382$, Lin\nCCC = 0.325, MAE = 0.197) showed moderate alignment, but its performance, using\ngpt-4.1-mini via g4f, suggests limited specialization for legal textse. These\nfindings highlight that unsupervised metrics, including LLM-based approaches,\nenable scalable screening but, with moderate correlations and low CCC values,\ncannot fully replace human judgment in high-stakes legal contexts. This work\nadvances legal NLP by providing annotation-free evaluation tools, with\nimplications for judicial analytics and ethical AI deployment.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01792v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01792v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.38,
      "weak_supervision_score": 0.39,
      "diffusion_reasoning_score": 0.346,
      "distributed_training_score": 0.272,
      "datasets_score": 0.409,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "Moderately Relevant",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "The paper utilizes a dataset of 1,000 anonymized Russian judicial decisions to evaluate unsupervised metrics for text extraction, involving benchmarking these metrics against expert reviews. While it includes aspects of dataset evaluation in the context of AI applications, such as validation and analysis through expert ratings, the primary focus is on developing and assessing metrics rather than creating, curating, or deeply analyzing the dataset itself.",
      "llm_score_status": "completed",
      "summary": "This paper evaluates 16 unsupervised metrics, including novel formulations, for assessing the quality of extracting seven semantic blocks from 1,000 anonymized Russian judicial decisions, aiming to provide scalable evaluation methods without relying on annotated ground truth. Using expert reviews on a 1-5 Likert scale, the study analyzes correlations via Pearson r, Lin's concordance correlation coefficient (CCC), and mean absolute error (MAE), finding that metrics like Term Frequency Coherence and Coverage Ratio/Block Completeness best align with expert ratings, while highlighting limitations in fully replacing human judgment in legal contexts.",
      "novelty_score": "Moderate",
      "novelty_justification": "The paper presents notable improvements and novel formulations of unsupervised metrics for legal text extraction, building on existing ideas to address a known challenge in evaluating without ground truth. However, it does not introduce a entirely new problem or technique that significantly advances the state-of-the-art beyond its subfield.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to be cited and built upon in legal NLP and judicial analytics, as it provides practical, annotation-free evaluation tools with implications for ethical AI deployment. Nonetheless, its influence may be confined to specific subfields rather than broadly affecting future research or commercial applications.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper offers a valuable contribution to legal NLP by validating unsupervised metrics, making it important for researchers in AI and information retrieval to be aware of its findings and methodologies. While not essential for all, it represents a high-quality advancement in a specialized area.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/9ae8d1d78ee75baea75e377e30eb438146d67b2b",
      "total_authors": 5,
      "authors_found": 5,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": [
        {
          "name": "Ivan Leonidovich Litvak",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383309963"
        },
        {
          "name": "Anton Kostin",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383310182"
        },
        {
          "name": "Fedor Lashkin",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383309902"
        },
        {
          "name": "Tatiana Maksiyan",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383311684"
        },
        {
          "name": "Sergey Lagutin",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383309904"
        }
      ]
    },
    {
      "id": "2510.01795",
      "title": "Nav-EE: Navigation-Guided Early Exiting for Efficient Vision-Language\n  Models in Autonomous Driving",
      "authors": [
        "Haibo Hu",
        "Lianming Huang",
        "Xinyu Wang",
        "Yufei Cui",
        "Shangyu Wu",
        "Nan Guan",
        "Chun Jason Xue"
      ],
      "categories": [
        "cs.RO (Robotics)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Vision-Language Models (VLMs) are increasingly applied in autonomous driving\nfor unified perception and reasoning, but high inference latency hinders\nreal-time deployment. Early-exit reduces latency by terminating inference at\nintermediate layers, yet its task-dependent nature limits generalization across\ndiverse scenarios. We observe that this limitation aligns with autonomous\ndriving: navigation systems can anticipate upcoming contexts (e.g.,\nintersections, traffic lights), indicating which tasks will be required. We\npropose Nav-EE, a navigation-guided early-exit framework that precomputes\ntask-specific exit layers offline and dynamically applies them online based on\nnavigation priors. Experiments on CODA, Waymo, and BOSCH show that Nav-EE\nachieves accuracy comparable to full inference while reducing latency by up to\n63.9%. Real-vehicle integration with Autoware Universe further demonstrates\nreduced inference latency (600ms to 300ms), supporting faster decision-making\nin complex scenarios. These results suggest that coupling navigation foresight\nwith early-exit offers a viable path toward efficient deployment of large\nmodels in autonomous systems. Code and data are available at our anonymous\nrepository: https://anonymous.4open.science/r/Nav-EE-BBC4",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01795v2",
      "pdf_url": "http://arxiv.org/pdf/2510.01795v2",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.364,
      "weak_supervision_score": 0.331,
      "diffusion_reasoning_score": 0.427,
      "distributed_training_score": 0.374,
      "datasets_score": 0.296,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on Nav-EE, a framework for early exiting in Vision-Language Models (VLMs) to reduce inference latency in autonomous driving by leveraging navigation priors. It does not involve diffusion models, iterative refinement processes, or multi-step logical reasoning as described in the topic. There is no mention of adapting diffusion for chain-of-thought or holistic correction, making the paper entirely unrelated.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01796",
      "title": "Rethinking the shape convention of an MLP",
      "authors": [
        "Meng-Hsi Chen",
        "Yu-Ang Lee",
        "Feng-Ting Liao",
        "Da-shan Shiu"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Multi-layer perceptrons (MLPs) conventionally follow a narrow-wide-narrow\ndesign where skip connections operate at the input/output dimensions while\nprocessing occurs in expanded hidden spaces. We challenge this convention by\nproposing wide-narrow-wide (Hourglass) MLP blocks where skip connections\noperate at expanded dimensions while residual computation flows through narrow\nbottlenecks. This inversion leverages higher-dimensional spaces for incremental\nrefinement while maintaining computational efficiency through parameter-matched\ndesigns. Implementing Hourglass MLPs requires an initial projection to lift\ninput signals to expanded dimensions. We propose that this projection can\nremain fixed at random initialization throughout training, enabling efficient\ntraining and inference implementations. We evaluate both architectures on\ngenerative tasks over popular image datasets, characterizing\nperformance-parameter Pareto frontiers through systematic architectural search.\nResults show that Hourglass architectures consistently achieve superior Pareto\nfrontiers compared to conventional designs. As parameter budgets increase,\noptimal Hourglass configurations favor deeper networks with wider skip\nconnections and narrower bottlenecks-a scaling pattern distinct from\nconventional MLPs. Our findings suggest reconsidering skip connection placement\nin modern architectures, with potential applications extending to Transformers\nand other residual networks.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01796v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01796v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.372,
      "weak_supervision_score": 0.353,
      "diffusion_reasoning_score": 0.41,
      "distributed_training_score": 0.401,
      "datasets_score": 0.288,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Tangentially Relevant",
      "distributed_training_relevance": "Not Relevant",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper discusses generative tasks such as denoising and super-resolution, which are related to diffusion models' iterative refinement processes. However, it does not adapt diffusion for multi-step logical reasoning or treat a Chain-of-Thought as a holistic entity; instead, it focuses on MLP architecture redesign, making the connection indirect and not central to the paper's contributions.",
      "distributed_training_justification": "The paper's main contribution is on redesigning MLP architectures for better performance in generative tasks, with no mention of distributed training, parallel computing, multi-node systems, or strategies for partitioning data/computation across processors.",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01800",
      "title": "REBot: From RAG to CatRAG with Semantic Enrichment and Graph Routing",
      "authors": [
        "Thanh Ma",
        "Tri-Tam La",
        "Lam-Thu Le Huu",
        "Minh-Nghi Nguyen",
        "Khanh-Van Pham Luu",
        "Huu-Hoa Nguyen"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Academic regulation advising is essential for helping students interpret and\ncomply with institutional policies, yet building effective systems requires\ndomain specific regulatory resources. To address this challenge, we propose\nREBot, an LLM enhanced advisory chatbot powered by CatRAG, a hybrid retrieval\nreasoning framework that integrates retrieval augmented generation with graph\nbased reasoning. CatRAG unifies dense retrieval and graph reasoning, supported\nby a hierarchical, category labeled knowledge graph enriched with semantic\nfeatures for domain alignment. A lightweight intent classifier routes queries\nto the appropriate retrieval modules, ensuring both factual accuracy and\ncontextual depth. We construct a regulation specific dataset and evaluate REBot\non classification and question answering tasks, achieving state of the art\nperformance with an F1 score of 98.89%. Finally, we implement a web application\nthat demonstrates the practical value of REBot in real world academic advising\nscenarios.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01800v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01800v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.397,
      "weak_supervision_score": 0.322,
      "diffusion_reasoning_score": 0.438,
      "distributed_training_score": 0.266,
      "datasets_score": 0.332,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper's main contribution is a hybrid framework (CatRAG) that combines retrieval-augmented generation and graph-based reasoning for academic regulation advising, using LLMs, knowledge graphs, and intent classification. It does not involve diffusion models, iterative refinement processes, or any adaptation of diffusion for multi-step logical reasoning tasks.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01812",
      "title": "SingMOS-Pro: An Comprehensive Benchmark for Singing Quality Assessment",
      "authors": [
        "Yuxun Tang",
        "Lan Liu",
        "Wenhao Feng",
        "Yiwen Zhao",
        "Jionghao Han",
        "Yifeng Yu",
        "Jiatong Shi",
        "Qin Jin"
      ],
      "categories": [
        "cs.SD (Sound)",
        "cs.AI (Artificial Intelligence)",
        "eess.AS (Audio and Speech Processing)"
      ],
      "abstract": "Singing voice generation progresses rapidly, yet evaluating singing quality\nremains a critical challenge. Human subjective assessment, typically in the\nform of listening tests, is costly and time consuming, while existing objective\nmetrics capture only limited perceptual aspects. In this work, we introduce\nSingMOS-Pro, a dataset for automatic singing quality assessment. Building on\nour preview version SingMOS, which provides only overall ratings, SingMOS-Pro\nexpands annotations of the additional part to include lyrics, melody, and\noverall quality, offering broader coverage and greater diversity. The dataset\ncontains 7,981 singing clips generated by 41 models across 12 datasets,\nspanning from early systems to recent advances. Each clip receives at least\nfive ratings from professional annotators, ensuring reliability and\nconsistency. Furthermore, we explore how to effectively utilize MOS data\nannotated under different standards and benchmark several widely used\nevaluation methods from related tasks on SingMOS-Pro, establishing strong\nbaselines and practical references for future research. The dataset can be\naccessed at https://huggingface.co/datasets/TangRain/SingMOS-Pro.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01812v2",
      "pdf_url": "http://arxiv.org/pdf/2510.01812v2",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.324,
      "weak_supervision_score": 0.356,
      "diffusion_reasoning_score": 0.294,
      "distributed_training_score": 0.294,
      "datasets_score": 0.421,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "Highly Relevant",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "The paper's main contribution is the introduction and expansion of the SingMOS-Pro dataset, which involves creating a new dataset with detailed annotations, analyzing its diversity and reliability, and benchmarking evaluation methods on it. This directly aligns with research on dataset creation, curation, analysis, and benchmarking for AI applications, such as machine learning in audio processing.",
      "llm_score_status": "completed",
      "summary": "This paper introduces SingMOS-Pro, a comprehensive dataset for automatic singing quality assessment (SQA), which expands on the previous SingMOS by adding annotations for lyrics, melody, and overall quality across 7,981 singing clips from various models and tasks such as singing voice synthesis (SVS), singing voice conversion (SVC), and singing voice resynthesis (SVR). The methodology involves collecting clips from 41 models across 12 datasets, annotating them with at least five professional ratings per clip, and benchmarking existing evaluation methods to establish baselines, addressing the limitations of subjective human assessments and objective metrics in SQA. Key findings highlight the dataset's diversity, reliability, and utility in advancing SQA research by providing a multilingual, multi-task-focused resource that promotes consistent and efficient evaluation.",
      "novelty_score": "Moderate",
      "novelty_justification": "The paper presents a notable improvement by expanding the SingMOS dataset with new annotations and broader coverage, effectively combining existing ideas to address gaps in singing quality assessment. While it builds on prior work, it introduces a more comprehensive benchmark that advances the field without creating an entirely new paradigm.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to be cited and built upon in the specific subfield of audio and speech processing, as it provides a valuable dataset and baselines for future SQA research. However, its influence may be limited to researchers focused on singing voice generation rather than broader AI or commercial applications.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper offers a high-quality contribution by introducing a robust dataset and benchmarks that are significant for advancing singing quality assessment, making it essential for researchers in audio AI. While not groundbreaking for all audiences, it provides valuable insights and resources that warrant attention in its niche.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/c202bfe8f3e46354a529b8d0aa5d394dc32604b2",
      "total_authors": 8,
      "authors_found": 8,
      "highest_h_index": 8,
      "average_h_index": 4.0,
      "notable_authors_count": 3,
      "author_h_indexes": [
        {
          "name": "Yuxun Tang",
          "h_index": 8,
          "profile_url": "https://www.semanticscholar.org/author/2257040521"
        },
        {
          "name": "Lan Liu",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383417610"
        },
        {
          "name": "Wenhao Feng",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2384322719"
        },
        {
          "name": "Yiwen Zhao",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2336923067"
        },
        {
          "name": "Jionghao Han",
          "h_index": 5,
          "profile_url": "https://www.semanticscholar.org/author/2300328296"
        },
        {
          "name": "Yifeng Yu",
          "h_index": 4,
          "profile_url": "https://www.semanticscholar.org/author/2228024938"
        },
        {
          "name": "Jiatong Shi",
          "h_index": 7,
          "profile_url": "https://www.semanticscholar.org/author/2300385182"
        },
        {
          "name": "Qin Jin",
          "h_index": 6,
          "profile_url": "https://www.semanticscholar.org/author/2281946904"
        }
      ]
    },
    {
      "id": "2510.01815",
      "title": "Human-AI Teaming Co-Learning in Military Operations",
      "authors": [
        "Clara Maathuis",
        "Kasper Cools"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "In a time of rapidly evolving military threats and increasingly complex\noperational environments, the integration of AI into military operations proves\nsignificant advantages. At the same time, this implies various challenges and\nrisks regarding building and deploying human-AI teaming systems in an effective\nand ethical manner. Currently, understanding and coping with them are often\ntackled from an external perspective considering the human-AI teaming system as\na collective agent. Nevertheless, zooming into the dynamics involved inside the\nsystem assures dealing with a broader palette of relevant multidimensional\nresponsibility, safety, and robustness aspects. To this end, this research\nproposes the design of a trustworthy co-learning model for human-AI teaming in\nmilitary operations that encompasses a continuous and bidirectional exchange of\ninsights between the human and AI agents as they jointly adapt to evolving\nbattlefield conditions. It does that by integrating four dimensions. First,\nadjustable autonomy for dynamically calibrating the autonomy levels of agents\ndepending on aspects like mission state, system confidence, and environmental\nuncertainty. Second, multi-layered control which accounts continuous oversight,\nmonitoring of activities, and accountability. Third, bidirectional feedback\nwith explicit and implicit feedback loops between the agents to assure a proper\ncommunication of reasoning, uncertainties, and learned adaptations that each of\nthe agents has. And fourth, collaborative decision-making which implies the\ngeneration, evaluation, and proposal of decisions associated with confidence\nlevels and rationale behind them. The model proposed is accompanied by concrete\nexemplifications and recommendations that contribute to further developing\nresponsible and trustworthy human-AI teaming systems in military operations.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01815v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01815v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "extraction_failed",
      "embedding_status": "completed",
      "rlhf_score": 0.481,
      "weak_supervision_score": 0.355,
      "diffusion_reasoning_score": 0.336,
      "distributed_training_score": 0.337,
      "datasets_score": 0.339,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Tangentially Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper proposes a co-learning model for human-AI teaming in military operations, which includes bidirectional feedback loops for communication and adaptation between humans and AI. While this involves human feedback, it does not specifically describe training a reward model on human-ranked data or using reinforcement learning to fine-tune an AI model, as required for RLHF. Instead, the focus is on broader aspects of teaming dynamics, making it only indirectly related.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01829",
      "title": "Calibrating the Full Predictive Class Distribution of 3D Object\n  Detectors for Autonomous Driving",
      "authors": [
        "Cornelius Schröder",
        "Marius-Raphael Schlüter",
        "Markus Lienkamp"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "In autonomous systems, precise object detection and uncertainty estimation\nare critical for self-aware and safe operation. This work addresses confidence\ncalibration for the classification task of 3D object detectors. We argue that\nit is necessary to regard the calibration of the full predictive confidence\ndistribution over all classes and deduce a metric which captures the\ncalibration of dominant and secondary class predictions. We propose two\nauxiliary regularizing loss terms which introduce either calibration of the\ndominant prediction or the full prediction vector as a training goal. We\nevaluate a range of post-hoc and train-time methods for CenterPoint, PillarNet\nand DSVT-Pillar and find that combining our loss term, which regularizes for\ncalibration of the full class prediction, and isotonic regression lead to the\nbest calibration of CenterPoint and PillarNet with respect to both dominant and\nsecondary class predictions. We further find that DSVT-Pillar can not be\njointly calibrated for dominant and secondary predictions using the same\nmethod.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01829v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01829v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.345,
      "weak_supervision_score": 0.379,
      "diffusion_reasoning_score": 0.343,
      "distributed_training_score": 0.39,
      "datasets_score": 0.329,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01833",
      "title": "Plan Then Action:High-Level Planning Guidance Reinforcement Learning for\n  LLM Reasoning",
      "authors": [
        "Zhihao Dou",
        "Qinjian Zhao",
        "Zhongwei Wan",
        "Dinggen Zhang",
        "Weida Wang",
        "Towsif Raiyan",
        "Benteng Chen",
        "Qingtao Pan",
        "Yang Ouyang",
        "Zhiqiang Gao",
        "Shufei Zhang",
        "Sumon Biswas"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)",
        "cs.CL (Computation and Language)"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable reasoning abilities\nin complex tasks, often relying on Chain-of-Thought (CoT) reasoning. However,\ndue to their autoregressive token-level generation, the reasoning process is\nlargely constrained to local decision-making and lacks global planning. This\nlimitation frequently results in redundant, incoherent, or inaccurate\nreasoning, which significantly degrades overall performance. Existing\napproaches, such as tree-based algorithms and reinforcement learning (RL),\nattempt to address this issue but suffer from high computational costs and\noften fail to produce optimal reasoning trajectories. To tackle this challenge,\nwe propose Plan-Then-Action Enhanced Reasoning with Group Relative Policy\nOptimization PTA-GRPO, a two-stage framework designed to improve both\nhigh-level planning and fine-grained CoT reasoning. In the first stage, we\nleverage advanced LLMs to distill CoT into compact high-level guidance, which\nis then used for supervised fine-tuning (SFT). In the second stage, we\nintroduce a guidance-aware RL method that jointly optimizes the final output\nand the quality of high-level guidance, thereby enhancing reasoning\neffectiveness. We conduct extensive experiments on multiple mathematical\nreasoning benchmarks, including MATH, AIME2024, AIME2025, and AMC, across\ndiverse base models such as Qwen2.5-7B-Instruct, Qwen3-8B, Qwen3-14B, and\nLLaMA3.2-3B. Experimental results demonstrate that PTA-GRPO consistently\nachieves stable and significant improvements across different models and tasks,\nvalidating its effectiveness and generalization.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01833v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01833v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.465,
      "weak_supervision_score": 0.373,
      "diffusion_reasoning_score": 0.538,
      "distributed_training_score": 0.365,
      "datasets_score": 0.284,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Tangentially Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper uses reinforcement learning (RL) in its second stage with Group Relative Policy Optimization (GRPO) to optimize reasoning, but it does not involve human feedback for training a reward model. Instead, rewards are based on automated evaluations of outputs and guidance quality, making it related to RL but not specifically RLHF.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on a two-stage framework for LLM reasoning using planning and RL, with no mention of diffusion models, iterative refinement processes, or adapting diffusion for logical tasks.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01841",
      "title": "Leveraging Prior Knowledge of Diffusion Model for Person Search",
      "authors": [
        "Giyeol Kim",
        "Sooyoung Yang",
        "Jihyong Oh",
        "Myungjoo Kang",
        "Chanho Eom"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Person search aims to jointly perform person detection and re-identification\nby localizing and identifying a query person within a gallery of uncropped\nscene images. Existing methods predominantly utilize ImageNet pre-trained\nbackbones, which may be suboptimal for capturing the complex spatial context\nand fine-grained identity cues necessary for person search. Moreover, they rely\non a shared backbone feature for both person detection and re-identification,\nleading to suboptimal features due to conflicting optimization objectives. In\nthis paper, we propose DiffPS (Diffusion Prior Knowledge for Person Search), a\nnovel framework that leverages a pre-trained diffusion model while eliminating\nthe optimization conflict between two sub-tasks. We analyze key properties of\ndiffusion priors and propose three specialized modules: (i) Diffusion-Guided\nRegion Proposal Network (DGRPN) for enhanced person localization, (ii)\nMulti-Scale Frequency Refinement Network (MSFRN) to mitigate shape bias, and\n(iii) Semantic-Adaptive Feature Aggregation Network (SFAN) to leverage\ntext-aligned diffusion features. DiffPS sets a new state-of-the-art on\nCUHK-SYSU and PRW.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01841v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01841v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.344,
      "weak_supervision_score": 0.321,
      "diffusion_reasoning_score": 0.552,
      "distributed_training_score": 0.351,
      "datasets_score": 0.34,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on using pre-trained diffusion models as a backbone for person search tasks, such as detection and re-identification, by leveraging features like cross-attention maps and hierarchical structures. However, it does not adapt the iterative refinement process of diffusion models for solving complex logical tasks or involve multi-step Chain-of-Thought reasoning. Instead, it applies diffusion priors to visual processing, which does not align with the topic's emphasis on logical reasoning.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01842",
      "title": "Pre-Hoc Predictions in AutoML: Leveraging LLMs to Enhance Model\n  Selection and Benchmarking for Tabular datasets",
      "authors": [
        "Yannis Belkhiter",
        "Seshu Tirupathi",
        "Giulio Zizzo",
        "Sachin Sharma",
        "John D. Kelleher"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "The field of AutoML has made remarkable progress in post-hoc model selection,\nwith libraries capable of automatically identifying the most performing models\nfor a given dataset. Nevertheless, these methods often rely on exhaustive\nhyperparameter searches, where methods automatically train and test different\ntypes of models on the target dataset. Contrastingly, pre-hoc prediction\nemerges as a promising alternative, capable of bypassing exhaustive search\nthrough intelligent pre-selection of models. Despite its potential, pre-hoc\nprediction remains under-explored in the literature. This paper explores the\nintersection of AutoML and pre-hoc model selection by leveraging traditional\nmodels and Large Language Model (LLM) agents to reduce the search space of\nAutoML libraries. By relying on dataset descriptions and statistical\ninformation, we reduce the AutoML search space. Our methodology is applied to\nthe AWS AutoGluon portfolio dataset, a state-of-the-art AutoML benchmark\ncontaining 175 tabular classification datasets available on OpenML. The\nproposed approach offers a shift in AutoML workflows, significantly reducing\ncomputational overhead, while still selecting the best model for the given\ndataset.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01842v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01842v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.44,
      "weak_supervision_score": 0.419,
      "diffusion_reasoning_score": 0.423,
      "distributed_training_score": 0.375,
      "datasets_score": 0.426,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "Not Relevant",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "Moderately Relevant",
      "rlhf_justification": "The paper focuses on using LLMs for pre-hoc model selection in AutoML, without any mention of human feedback, reward models, or reinforcement learning techniques. There is no alignment process involving human preferences or RL-based fine-tuning.",
      "weak_supervision_justification": "The paper does not involve training models with programmatically generated labels from noisy sources. Instead, it uses dataset descriptions and statistical information for model pre-selection in AutoML, which is unrelated to weak supervision techniques.",
      "diffusion_reasoning_justification": "The paper leverages LLMs and RAG for pre-hoc model selection, but there is no evidence of diffusion models, iterative refinement processes, or multi-step logical reasoning as described in diffusion-based approaches.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "The paper applies its methodology to the AWS AutoGluon benchmark, which includes 175 tabular datasets from OpenML, involving benchmarking and evaluation of datasets for AutoML tasks. However, the primary focus is on model selection techniques rather than creating, analyzing, or curating datasets themselves.",
      "llm_score_status": "completed",
      "summary": "This paper explores pre-hoc model selection in AutoML as an alternative to traditional post-hoc methods, aiming to reduce computational overhead by using Large Language Models (LLMs) to intelligently pre-select models based on dataset descriptions, statistical information, and retrieval-augmented generation. The methodology involves integrating these elements to predict suitable models for tabular classification datasets from the AWS AutoGluon portfolio, demonstrating that this approach can effectively narrow the search space while maintaining high performance, thus offering a novel framework that enhances efficiency and explainability in AutoML workflows.",
      "novelty_score": "High",
      "novelty_justification": "The paper introduces a novel integration of LLMs for pre-hoc model selection in AutoML, which is a significant advancement as it addresses an under-explored area by bypassing exhaustive searches. This represents a truly new technique that could redefine state-of-the-art practices in automated machine learning.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to influence future AutoML research by promoting more efficient model selection methods, particularly in resource-constrained environments, though its applicability is primarily limited to tabular datasets. As a result, it may be built upon within specific subfields of AI and machine learning but not broadly across all areas.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper presents a high-quality contribution that innovatively applies LLMs to AutoML, making it valuable for researchers interested in efficient machine learning workflows. While not essential for all, it offers significant insights that could inform ongoing developments in the field.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/eaaa30df03766fa9ca5f946666cdc188b2c8213f",
      "total_authors": 5,
      "authors_found": 5,
      "highest_h_index": 10,
      "average_h_index": 3.8,
      "notable_authors_count": 2,
      "author_h_indexes": [
        {
          "name": "Yannis Belkhiter",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2330190108"
        },
        {
          "name": "Seshu Tirupathi",
          "h_index": 8,
          "profile_url": "https://www.semanticscholar.org/author/14731731"
        },
        {
          "name": "Giulio Zizzo",
          "h_index": 10,
          "profile_url": "https://www.semanticscholar.org/author/152109289"
        },
        {
          "name": "Sachin Sharma",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383684079"
        },
        {
          "name": "John D. Kelleher",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383309522"
        }
      ]
    },
    {
      "id": "2510.01845",
      "title": "Model Merging to Maintain Language-Only Performance in Developmentally\n  Plausible Multimodal Models",
      "authors": [
        "Ece Takmaz",
        "Lisa Bylinina",
        "Jakub Dotlacil"
      ],
      "categories": [
        "cs.CL (Computation and Language)",
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "State-of-the-art vision-and-language models consist of many parameters and\nlearn from enormous datasets, surpassing the amounts of linguistic data that\nchildren are exposed to as they acquire a language. This paper presents our\napproach to the multimodal track of the BabyLM challenge addressing this\ndiscrepancy. We develop language-only and multimodal models in low-resource\nsettings using developmentally plausible datasets, with our multimodal models\noutperforming previous BabyLM baselines. One finding in the multimodal language\nmodel literature is that these models tend to underperform in\n\\textit{language-only} tasks. Therefore, we focus on maintaining language-only\nabilities in multimodal models. To this end, we experiment with \\textit{model\nmerging}, where we fuse the parameters of multimodal models with those of\nlanguage-only models using weighted linear interpolation. Our results\ncorroborate the findings that multimodal models underperform in language-only\nbenchmarks that focus on grammar, and model merging with text-only models can\nhelp alleviate this problem to some extent, while maintaining multimodal\nperformance.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01845v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01845v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.342,
      "weak_supervision_score": 0.371,
      "diffusion_reasoning_score": 0.43,
      "distributed_training_score": 0.355,
      "datasets_score": 0.327,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper's main contribution involves developing and merging multimodal language models using weighted linear interpolation to maintain language-only performance, without any reference to diffusion models, iterative refinement processes, or multi-step logical reasoning. There is no component related to adapting diffusion for complex logical tasks, making it unrelated to the topic.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01850",
      "title": "NGGAN: Noise Generation GAN Based on the Practical Measurement Dataset\n  for Narrowband Powerline Communications",
      "authors": [
        "Ying-Ren Chien",
        "Po-Heng Chou",
        "You-Jie Peng",
        "Chun-Yuan Huang",
        "Hen-Wai Tsao",
        "Yu Tsao"
      ],
      "categories": [
        "eess.SP (Signal Processing)",
        "cs.AI (Artificial Intelligence)",
        "cs.IT (Information Theory)",
        "cs.LG (Machine Learning)",
        "math.IT (Information Theory)"
      ],
      "abstract": "To effectively process impulse noise for narrowband powerline communications\n(NB-PLCs) transceivers, capturing comprehensive statistics of nonperiodic\nasynchronous impulsive noise (APIN) is a critical task. However, existing\nmathematical noise generative models only capture part of the characteristics\nof noise. In this study, we propose a novel generative adversarial network\n(GAN) called noise generation GAN (NGGAN) that learns the complicated\ncharacteristics of practically measured noise samples for data synthesis. To\nclosely match the statistics of complicated noise over the NB-PLC systems, we\nmeasured the NB-PLC noise via the analog coupling and bandpass filtering\ncircuits of a commercial NB-PLC modem to build a realistic dataset. To train\nNGGAN, we adhere to the following principles: 1) we design the length of input\nsignals that the NGGAN model can fit to facilitate cyclostationary noise\ngeneration; 2) the Wasserstein distance is used as a loss function to enhance\nthe similarity between the generated noise and training data; and 3) to measure\nthe similarity performances of GAN-based models based on the mathematical and\npractically measured datasets, we conduct both quantitative and qualitative\nanalyses. The training datasets include: 1) a piecewise spectral\ncyclostationary Gaussian model (PSCGM); 2) a frequency-shift (FRESH) filter;\nand 3) practical measurements from NB-PLC systems. Simulation results\ndemonstrate that the generated noise samples from the proposed NGGAN are highly\nclose to the real noise samples. The principal component analysis (PCA) scatter\nplots and Fr\\'echet inception distance (FID) analysis have shown that NGGAN\noutperforms other GAN-based models by generating noise samples with superior\nfidelity and higher diversity.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01850v2",
      "pdf_url": "http://arxiv.org/pdf/2510.01850v2",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.305,
      "weak_supervision_score": 0.361,
      "diffusion_reasoning_score": 0.341,
      "distributed_training_score": 0.346,
      "datasets_score": 0.32,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01857",
      "title": "Learning a Dense Reasoning Reward Model from Expert Demonstration via\n  Inverse Reinforcement Learning",
      "authors": [
        "Claudio Fanconi",
        "Nicolás Astorga",
        "Mihaela van der Schaar"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "We reframe and operationalise adversarial inverse reinforcement learning\n(IRL) to large language model reasoning, learning a dense, token-level reward\nmodel for process supervision directly from expert demonstrations rather than\nimitating style via supervised fine-tuning. The learned reasoning reward serves\ntwo complementary roles: (i) it provides step-level feedback to optimise a\nreasoning policy during training; and (ii) it functions at inference as a\ncritic to rerank sampled traces under fixed compute budgets. We demonstrate\nthat our approach prioritises correctness over surface form, yielding scores\nthat correlate with eventual answer validity and enabling interpretable\nlocalisation of errors within a trace. Empirically, on GSM8K with Llama3 and\nQwen2.5 backbones, we demonstrate: (i) dense reasoning rewards can be used as a\nlearning signal to elicit reasoning, and (ii) predictive performance is\nimproved from reward-guided reranking (notably for Llama-based policies). By\nunifying training signals, inference-time selection, and token-level\ndiagnostics into a single reasoning reward, this work suggests reusable\nprocess-level rewards with broad potential to enhance multi-step reasoning in\nlanguage models.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01857v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01857v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.503,
      "weak_supervision_score": 0.411,
      "diffusion_reasoning_score": 0.545,
      "distributed_training_score": 0.37,
      "datasets_score": 0.326,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Highly Relevant",
      "weak_supervision_relevance": "Not Relevant",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper's main contribution involves learning a reward model from expert demonstrations and using it to optimize a reasoning policy, which aligns closely with RLHF. It trains a reward model on demonstrations (potentially human-derived) and applies it in reinforcement learning for fine-tuning, mirroring RLHF's core process of aligning models with preferences through a reward signal.",
      "weak_supervision_justification": "The paper uses expert demonstrations as high-quality, direct sources for learning rewards, rather than programmatically generated noisy or imprecise labels characteristic of weak supervision. This approach relies on reliable data, not the weak, indirect labeling methods that define the topic.",
      "diffusion_reasoning_justification": "The paper focuses on inverse reinforcement learning for reward modeling in reasoning tasks, with no mention of diffusion models, iterative refinement processes, or treating reasoning paths as entities for holistic correction, which are key to diffusion-based reasoning.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "completed",
      "summary": "This paper presents a novel approach to enhance large language model (LLM) reasoning by learning a dense, token-level reward model using inverse reinforcement learning from expert demonstrations, moving beyond traditional supervised fine-tuning that imitates style. The methodology involves training this reward model to provide feedback for both optimizing reasoning policies during training and reranking sampled traces at inference, with empirical results on the GSM8K dataset using Llama3 and Qwen2.5 backbones demonstrating improved predictive performance, correlation with correctness, and interpretable error localization, thereby prioritizing accurate reasoning over surface-level imitation.",
      "novelty_score": "Moderate",
      "novelty_justification": "The paper combines inverse reinforcement learning with LLM reasoning to learn a dense reward model from expert demonstrations, offering a clever adaptation of existing techniques for a known problem in AI. While it advances the field by emphasizing correctness over imitation, it does not introduce an entirely new paradigm but rather refines current methods.",
      "impact_score": "High",
      "impact_justification": "The work has the potential to influence a wide range of future research and applications in LLM training and multi-step reasoning by providing a reusable framework for process-level rewards. Its emphasis on correctness and interpretability could lead to broader improvements in AI systems, making it relevant beyond its specific subfield.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper delivers a high-quality contribution with practical implications for enhancing LLM reasoning, making it essential for researchers in artificial intelligence to understand its methods and findings. While not groundbreaking enough to be a must-read, it offers valuable insights that could inform ongoing work in the field.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/cca984474ed2c423eefcc4de4fd393baad65d7e7",
      "total_authors": 3,
      "authors_found": 3,
      "highest_h_index": 71,
      "average_h_index": 25.666666666666668,
      "notable_authors_count": 1,
      "author_h_indexes": [
        {
          "name": "Claudio Fanconi",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2305814021"
        },
        {
          "name": "Nicolás Astorga",
          "h_index": 4,
          "profile_url": "https://www.semanticscholar.org/author/2282961996"
        },
        {
          "name": "M. Schaar",
          "h_index": 71,
          "profile_url": "https://www.semanticscholar.org/author/1729969"
        }
      ]
    },
    {
      "id": "2510.01864",
      "title": "A Modular Theory of Subjective Consciousness for Natural and Artificial\n  Minds",
      "authors": [
        "Michaël Gillon"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Understanding how subjective experience arises from information processing\nremains a central challenge in neuroscience, cognitive science, and AI\nresearch. The Modular Consciousness Theory (MCT) proposes a biologically\ngrounded and computationally explicit framework in which consciousness is a\ndiscrete sequence of Integrated Informational States (IISs). Each IIS is a\npacket of integrated information tagged with a multidimensional density vector\nthat quantifies informational richness. Its magnitude correlates with\nsubjective intensity, shaping memory, behavior, and continuity of experience.\nInputs from body and environment are adaptively filtered, processed by modules\n(abstraction, narration, evaluation, self-evaluation), and integrated into an\nIIS. The resulting packet, tagged with its density vector, is transmitted to\nbehavioral readiness, memory, and decision-making modules, closing the loop.\nThis explains why strongly tagged states exert greater influence on long-term\nmemory and action. Unlike Global Workspace Theory, Integrated Information\nTheory, or Higher-Order Thought, MCT specifies a full computational pipeline\nproducing discrete informational units with quantifiable internal structure.\nSubjectivity is reframed as a correlate of the density-tagging signal with\nfunctional consequences. MCT generates testable predictions, such as stress\nenhancing memory encoding, and provides a naturalistic blueprint for both\nbiological and artificial architectures. Consciousness, in this view, is not an\nirreducible essence but an evolvable, quantifiable, and constructible feature\nof complex information processing.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01864v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01864v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.266,
      "weak_supervision_score": 0.238,
      "diffusion_reasoning_score": 0.371,
      "distributed_training_score": 0.239,
      "datasets_score": 0.265,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01869",
      "title": "TACOS: Task Agnostic COordinator of a multi-drone System",
      "authors": [
        "Alessandro Nazzari",
        "Roberto Rubinacci",
        "Marco Lovera"
      ],
      "categories": [
        "cs.RO (Robotics)",
        "cs.AI (Artificial Intelligence)",
        "cs.MA (Multiagent Systems)"
      ],
      "abstract": "When a single pilot is responsible for managing a multi-drone system, the\ntask demands varying levels of autonomy, from direct control of individual\nUAVs, to group-level coordination, to fully autonomous swarm behaviors for\naccomplishing high-level tasks. Enabling such flexible interaction requires a\nframework that supports multiple modes of shared autonomy. As language models\ncontinue to improve in reasoning and planning, they provide a natural\nfoundation for such systems, reducing pilot workload by enabling high-level\ntask delegation through intuitive, language-based interfaces. In this paper we\npresent TACOS (Task-Agnostic COordinator of a multi-drone System), a unified\nframework that enables high-level natural language control of multi-UAV systems\nthrough Large Language Models (LLMs). TACOS integrates three key capabilities\ninto a single architecture: a one-to-many natural language interface for\nintuitive user interaction, an intelligent coordinator for translating user\nintent into structured task plans, and an autonomous agent that executes plans\ninteracting with the real-world. TACOS allows a LLM to interact with a library\nof executable APIs, bridging semantic reasoning with real-time multi-robot\ncoordination. We demonstrate the system in real-world multi-drone system and\nconduct an ablation study to assess the contribution of each module.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01869v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01869v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.354,
      "weak_supervision_score": 0.352,
      "diffusion_reasoning_score": 0.338,
      "distributed_training_score": 0.361,
      "datasets_score": 0.309,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01879",
      "title": "REPAIR: Robust Editing via Progressive Adaptive Intervention and\n  Reintegration",
      "authors": [
        "Yisu Wang",
        "Ming Wang",
        "Haoyuan Song",
        "Wenjie Huang",
        "Chaozheng Wang",
        "Yi Xie",
        "Xuming Ran"
      ],
      "categories": [
        "cs.CL (Computation and Language)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Post-training for large language models (LLMs) is constrained by the high\ncost of acquiring new knowledge or correcting errors and by the unintended side\neffects that frequently arise from retraining. To address these issues, we\nintroduce REPAIR (Robust Editing via Progressive Adaptive Intervention and\nReintegration), a lifelong editing framework designed to support precise and\nlow-cost model updates while preserving non-target knowledge. REPAIR mitigates\nthe instability and conflicts of large-scale sequential edits through a\nclosed-loop feedback mechanism coupled with dynamic memory management.\nFurthermore, by incorporating frequent knowledge fusion and enforcing strong\nlocality guards, REPAIR effectively addresses the shortcomings of traditional\ndistribution-agnostic approaches that often overlook unintended ripple effects.\nOur experiments demonstrate that REPAIR boosts editing accuracy by 10%-30%\nacross multiple model families and significantly reduces knowledge forgetting.\nThis work introduces a robust framework for developing reliable, scalable, and\ncontinually evolving LLMs.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01879v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01879v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.464,
      "weak_supervision_score": 0.404,
      "diffusion_reasoning_score": 0.416,
      "distributed_training_score": 0.417,
      "datasets_score": 0.333,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "Not Relevant",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "Not Relevant",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on a framework for editing LLMs to handle knowledge updates and sequential edits, using internal closed-loop feedback for performance monitoring, but it does not involve human feedback, reward models, or reinforcement learning for alignment.",
      "weak_supervision_justification": "The paper addresses model editing techniques for LLMs, emphasizing precise updates and knowledge preservation, but it does not discuss training models with programmatically generated labels or any form of weak supervision.",
      "diffusion_reasoning_justification": "The paper introduces a framework for robust model editing, including feedback mechanisms and knowledge fusion, but it lacks any components related to diffusion models, iterative refinement for reasoning, or multi-step logical processes.",
      "distributed_training_justification": "The paper deals with post-training model editing for LLMs, focusing on techniques like dynamic memory management and feedback loops, without any mention of distributed systems, parallel computing, or strategies for accelerating training across nodes.",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01887",
      "title": "FINCH: Financial Intelligence using Natural language for Contextualized\n  SQL Handling",
      "authors": [
        "Avinash Kumar Singh",
        "Bhaskarjit Sarmah",
        "Stefano Pasquali"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Text-to-SQL, the task of translating natural language questions into SQL\nqueries, has long been a central challenge in NLP. While progress has been\nsignificant, applying it to the financial domain remains especially difficult\ndue to complex schema, domain-specific terminology, and high stakes of error.\nDespite this, there is no dedicated large-scale financial dataset to advance\nresearch, creating a critical gap. To address this, we introduce a curated\nfinancial dataset (FINCH) comprising 292 tables and 75,725 natural language-SQL\npairs, enabling both fine-tuning and rigorous evaluation. Building on this\nresource, we benchmark reasoning models and language models of varying scales,\nproviding a systematic analysis of their strengths and limitations in financial\nText-to-SQL tasks. Finally, we propose a finance-oriented evaluation metric\n(FINCH Score) that captures nuances overlooked by existing measures, offering a\nmore faithful assessment of model performance.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01887v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01887v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.39,
      "weak_supervision_score": 0.379,
      "diffusion_reasoning_score": 0.384,
      "distributed_training_score": 0.366,
      "datasets_score": 0.436,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "Highly Relevant",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "The paper's main contribution includes the introduction and curation of a new large-scale financial dataset (FINCH), comprising 292 tables and 75,725 NL-SQL pairs. It details the dataset's creation process, such as consolidating existing resources and normalizing SQL queries, and uses it for benchmarking models, which directly aligns with research on creating, introducing, benchmarking, and evaluating datasets for AI applications. This makes the paper's focus a core match to the topic.",
      "llm_score_status": "completed",
      "summary": "This paper addresses the challenges of Text-to-SQL in the financial domain by introducing FINCH, a large-scale dataset comprising 292 tables and 75,725 natural language-SQL pairs, which consolidates and extends existing resources for fine-tuning and evaluation. It benchmarks various language and reasoning models, such as GPT-OSS-120B and Arctic-Text2SQL-R1-7B, demonstrating their performance strengths, and proposes a new finance-oriented metric, FINCH Score, that better captures structural fidelity and nuances in financial contexts compared to traditional measures.",
      "novelty_score": "Moderate",
      "novelty_justification": "The paper presents a notable improvement by creating a dedicated financial dataset and a tailored evaluation metric, combining existing Text-to-SQL techniques in a new domain-specific way, though it does not introduce entirely novel problems or architectures.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to influence future research in financial NLP and Text-to-SQL by providing a new benchmark dataset and metric, potentially leading to citations and developments within this subfield, though its applicability may remain niche outside finance-specific applications.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper represents a strong, valuable contribution to domain-specific AI research, particularly for those working in financial NLP, as it fills a critical gap with practical resources and insights.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/f1b85bf40cbdb043fffbe8b998b36edd1610312d",
      "total_authors": 3,
      "authors_found": 3,
      "highest_h_index": 4,
      "average_h_index": 2.6666666666666665,
      "notable_authors_count": 0,
      "author_h_indexes": [
        {
          "name": "Avinash Kumar Singh",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383420202"
        },
        {
          "name": "Bhaskarjit Sarmah",
          "h_index": 4,
          "profile_url": "https://www.semanticscholar.org/author/23570698"
        },
        {
          "name": "Stefano Pasquali",
          "h_index": 4,
          "profile_url": "https://www.semanticscholar.org/author/2258960763"
        }
      ]
    },
    {
      "id": "2510.01889",
      "title": "Small is Sufficient: Reducing the World AI Energy Consumption Through\n  Model Selection",
      "authors": [
        "Tiago da Silva Barros",
        "Frédéric Giroire",
        "Ramon Aparicio-Pardo",
        "Joanna Moulierac"
      ],
      "categories": [
        "cs.CY (Computers and Society)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "The energy consumption and carbon footprint of Artificial Intelligence (AI)\nhave become critical concerns due to rising costs and environmental impacts. In\nresponse, a new trend in green AI is emerging, shifting from the \"bigger is\nbetter\" paradigm, which prioritizes large models, to \"small is sufficient\",\nemphasizing energy sobriety through smaller, more efficient models.\n  We explore how the AI community can adopt energy sobriety today by focusing\non model selection during inference. Model selection consists of choosing the\nmost appropriate model for a given task, a simple and readily applicable\nmethod, unlike approaches requiring new hardware or architectures. Our\nhypothesis is that, as in many industrial activities, marginal utility gains\ndecrease with increasing model size. Thus, applying model selection can\nsignificantly reduce energy consumption while maintaining good utility for AI\ninference.\n  We conduct a systematic study of AI tasks, analyzing their popularity, model\nsize, and efficiency. We examine how the maturity of different tasks and model\nadoption patterns impact the achievable energy savings, ranging from 1% to 98%\nfor different tasks. Our estimates indicate that applying model selection could\nreduce AI energy consumption by 27.8%, saving 31.9 TWh worldwide in 2025 -\nequivalent to the annual output of five nuclear power reactors.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01889v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01889v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.387,
      "weak_supervision_score": 0.339,
      "diffusion_reasoning_score": 0.347,
      "distributed_training_score": 0.427,
      "datasets_score": 0.347,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "Not Relevant",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "The paper's main contribution focuses on reducing energy consumption in AI inference through model selection, emphasizing the use of smaller, efficient models for tasks. It does not address distributed training, parallel computing, multi-node machine learning, or any strategies for partitioning data, models, or computations across processors to accelerate training. The paper's scope is limited to inference optimization and energy savings, with no mention of training-related techniques, making it entirely unrelated to the topic.",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01891",
      "title": "HRTFformer: A Spatially-Aware Transformer for Personalized HRTF\n  Upsampling in Immersive Audio Rendering",
      "authors": [
        "Xuyi Hu",
        "Jian Li",
        "Shaojie Zhang",
        "Stefan Goetz",
        "Lorenzo Picinali",
        "Ozgur B. Akan",
        "Aidan O. T. Hogg"
      ],
      "categories": [
        "cs.SD (Sound)",
        "cs.AI (Artificial Intelligence)",
        "eess.AS (Audio and Speech Processing)"
      ],
      "abstract": "Personalized Head-Related Transfer Functions (HRTFs) are starting to be\nintroduced in many commercial immersive audio applications and are crucial for\nrealistic spatial audio rendering. However, one of the main hesitations\nregarding their introduction is that creating personalized HRTFs is impractical\nat scale due to the complexities of the HRTF measurement process. To mitigate\nthis drawback, HRTF spatial upsampling has been proposed with the aim of\nreducing measurements required. While prior work has seen success with\ndifferent machine learning (ML) approaches, these models often struggle with\nlong-range spatial consistency and generalization at high upsampling factors.\nIn this paper, we propose a novel transformer-based architecture for HRTF\nupsampling, leveraging the attention mechanism to better capture spatial\ncorrelations across the HRTF sphere. Working in the spherical harmonic (SH)\ndomain, our model learns to reconstruct high-resolution HRTFs from sparse input\nmeasurements with significantly improved accuracy. To enhance spatial\ncoherence, we introduce a neighbor dissimilarity loss that promotes magnitude\nsmoothness, yielding more realistic upsampling. We evaluate our method using\nboth perceptual localization models and objective spectral distortion metrics.\nExperiments show that our model surpasses leading methods by a substantial\nmargin in generating realistic, high-fidelity HRTFs.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01891v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01891v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.409,
      "weak_supervision_score": 0.307,
      "diffusion_reasoning_score": 0.354,
      "distributed_training_score": 0.339,
      "datasets_score": 0.277,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper presents a transformer-based architecture for HRTF upsampling in audio rendering, focusing on machine learning techniques like attention mechanisms and loss functions for spatial data processing. It does not involve reinforcement learning, human feedback for training a reward model, or any alignment of AI models with human preferences, as required for RLHF.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01899",
      "title": "Multimodal Foundation Models for Early Disease Detection",
      "authors": [
        "Md Talha Mohsin",
        "Ismail Abdulrashid"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)",
        "cs.HC (Human-Computer Interaction)"
      ],
      "abstract": "Healthcare generates diverse streams of data, including electronic health\nrecords (EHR), medical imaging, genetics, and ongoing monitoring from wearable\ndevices. Traditional diagnostic models frequently analyze these sources in\nisolation, which constrains their capacity to identify cross-modal correlations\nessential for early disease diagnosis. Our research presents a multimodal\nfoundation model that consolidates diverse patient data through an\nattention-based transformer framework. At first, dedicated encoders put each\nmodality into a shared latent space. Then, they combine them using multi-head\nattention and residual normalization. The architecture is made for pretraining\non many tasks, which makes it easy to adapt to new diseases and datasets with\nlittle extra work. We provide an experimental strategy that uses benchmark\ndatasets in oncology, cardiology, and neurology, with the goal of testing early\ndetection tasks. The framework includes data governance and model management\ntools in addition to technological performance to improve transparency,\nreliability, and clinical interpretability. The suggested method works toward a\nsingle foundation model for precision diagnostics, which could improve the\naccuracy of predictions and help doctors make decisions.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01899v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01899v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.351,
      "weak_supervision_score": 0.357,
      "diffusion_reasoning_score": 0.428,
      "distributed_training_score": 0.373,
      "datasets_score": 0.38,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper describes a multimodal foundation model using attention-based transformers for integrating healthcare data modalities, such as EHR and imaging, to enhance early disease detection. It emphasizes cross-modal attention and pretraining but does not mention diffusion models, iterative refinement processes, or any adaptation for multi-step logical reasoning tasks. Therefore, there is no connection to diffusion-based reasoning.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01902",
      "title": "Constrained Adaptive Rejection Sampling",
      "authors": [
        "Paweł Parys",
        "Sairam Vaidya",
        "Taylor Berg-Kirkpatrick",
        "Loris D'Antoni"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)",
        "cs.CL (Computation and Language)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "Language Models (LMs) are increasingly used in applications where generated\noutputs must satisfy strict semantic or syntactic constraints. Existing\napproaches to constrained generation fall along a spectrum: greedy constrained\ndecoding methods enforce validity during decoding but distort the LM's\ndistribution, while rejection sampling (RS) preserves fidelity but wastes\ncomputation by discarding invalid outputs. Both extremes are problematic in\ndomains such as program fuzzing, where both validity and diversity of samples\nare essential. We present Constrained Adaptive Rejection Sampling (CARS), an\napproach that strictly improves the sample-efficiency of RS without\ndistributional distortion. CARS begins with unconstrained LM sampling and\nadaptively rules out constraint-violating continuations by recording them in a\ntrie and subtracting their probability mass from future draws. This adaptive\npruning ensures that prefixes proven invalid are never revisited, acceptance\nrates improve monotonically, and the resulting samples exactly follow the\nconstrained distribution. In experiments on a variety of domains -- e.g.,\nprogram fuzzing and molecular generation -- CARS consistently achieves higher\nefficiency -- measured in the number of LM forward passes per valid sample --\nwhile also producing stronger sample diversity than both GCD and methods that\napproximate the LM's distribution.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01902v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01902v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.404,
      "weak_supervision_score": 0.365,
      "diffusion_reasoning_score": 0.425,
      "distributed_training_score": 0.342,
      "datasets_score": 0.322,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on Constrained Adaptive Rejection Sampling for efficient constrained generation in Language Models, emphasizing sampling techniques and constraint satisfaction. It does not involve reinforcement learning, human feedback, reward models, or any alignment of AI models with human preferences.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper introduces a method for adaptive rejection sampling in constrained Language Model generation, which does not incorporate diffusion models, iterative refinement processes, or multi-step logical reasoning for tasks like Chain-of-Thought. It is solely about improving sampling efficiency for constrained outputs.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01910",
      "title": "Are LLMs Better GNN Helpers? Rethinking Robust Graph Learning under\n  Deficiencies with Iterative Refinement",
      "authors": [
        "Zhaoyan Wang",
        "Zheng Gao",
        "Arogya Kharel",
        "In-Young Ko"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Graph Neural Networks (GNNs) are widely adopted in Web-related applications,\nserving as a core technique for learning from graph-structured data, such as\ntext-attributed graphs. Yet in real-world scenarios, such graphs exhibit\ndeficiencies that substantially undermine GNN performance. While prior\nGNN-based augmentation studies have explored robustness against individual\nimperfections, a systematic understanding of how graph-native and Large\nLanguage Models (LLMs) enhanced methods behave under compound deficiencies is\nstill missing. Specifically, there has been no comprehensive investigation\ncomparing conventional approaches and recent LLM-on-graph frameworks, leaving\ntheir merits unclear. To fill this gap, we conduct the first empirical study\nthat benchmarks these two lines of methods across diverse graph deficiencies,\nrevealing overlooked vulnerabilities and challenging the assumption that LLM\naugmentation is consistently superior. Building on empirical findings, we\npropose Robust Graph Learning via Retrieval-Augmented Contrastive Refinement\n(RoGRAD) framework. Unlike prior one-shot LLM-as-Enhancer designs, RoGRAD is\nthe first iterative paradigm that leverages Retrieval-Augmented Generation\n(RAG) to inject retrieval-grounded augmentations by supplying class-consistent,\ndiverse augmentations and enforcing discriminative representations through\niterative graph contrastive learning. It transforms LLM augmentation for graphs\nfrom static signal injection into dynamic refinement. Extensive experiments\ndemonstrate RoGRAD's superiority over both conventional GNN- and LLM-enhanced\nbaselines, achieving up to 82.43% average improvement.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01910v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01910v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.402,
      "weak_supervision_score": 0.416,
      "diffusion_reasoning_score": 0.369,
      "distributed_training_score": 0.381,
      "datasets_score": 0.349,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "Moderately Relevant",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on Graph Neural Networks (GNNs) and their enhancement with Large Language Models (LLMs) for handling graph deficiencies, such as incomplete data. It does not involve reinforcement learning, human feedback, reward models, or any mechanism for aligning AI with human preferences.",
      "weak_supervision_justification": "The paper addresses GNN robustness to graph deficiencies like incomplete labels, structures, and features, which aligns with weak supervision's use of noisy or imprecise data sources. It proposes methods like RoGRAD to generate augmentations programmatically, similar to weak supervision techniques, though it does not explicitly focus on label generation from high-level sources.",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "completed",
      "summary": "This paper examines the robustness of Graph Neural Networks (GNNs) under real-world graph deficiencies by comparing traditional GNN methods with those enhanced by Large Language Models (LLMs), revealing that LLM-augmented approaches often underperform simpler ones in less severe conditions due to issues like semantic homogeneity and static augmentation. It introduces the RoGRAD framework, which employs an innovative iterative retrieval-augmented generation and contrastive learning mechanism to dynamically refine graph representations, resulting in significant improvements of up to 82.43% over baselines in extensive experiments.",
      "novelty_score": "High",
      "novelty_justification": "The paper introduces a truly novel iterative refinement paradigm with RoGRAD, which is the first to use retrieval-augmented generation for dynamic LLM augmentation in graph learning, significantly advancing beyond existing one-shot methods. This represents a substantial shift in how LLMs are integrated with GNNs to handle compound deficiencies.",
      "impact_score": "High",
      "impact_justification": "The work challenges assumptions about LLM superiority in graph learning and proposes an effective framework that could influence future research and applications in robust GNNs, potentially extending to broader AI fields like semantic understanding and data augmentation. Its empirical insights and performance gains make it likely to be widely cited and adopted in subfields dealing with imperfect graph data.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper provides high-quality insights into LLM-GNN integration and introduces a valuable new framework, making it essential for researchers in machine learning and AI to understand its contributions to robust graph learning. While impactful, it may not be universally groundbreaking outside specific subfields.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/72a4a72af3e8ce09b90620b13a5b5419c465a61d",
      "total_authors": 4,
      "authors_found": 4,
      "highest_h_index": 1,
      "average_h_index": 0.25,
      "notable_authors_count": 0,
      "author_h_indexes": [
        {
          "name": "Zhaoyan Wang",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2212204325"
        },
        {
          "name": "Zheng Gao",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383995667"
        },
        {
          "name": "Arogya Kharel",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2344138281"
        },
        {
          "name": "In-Young Ko",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2358999743"
        }
      ]
    },
    {
      "id": "2510.01912",
      "title": "Flow-Matching Guided Deep Unfolding for Hyperspectral Image\n  Reconstruction",
      "authors": [
        "Yi Ai",
        "Yuanhao Cai",
        "Yulun Zhang",
        "Xiaokang Yang"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Hyperspectral imaging (HSI) provides rich spatial-spectral information but\nremains costly to acquire due to hardware limitations and the difficulty of\nreconstructing three-dimensional data from compressed measurements. Although\ncompressive sensing systems such as CASSI improve efficiency, accurate\nreconstruction is still challenged by severe degradation and loss of fine\nspectral details. We propose the Flow-Matching-guided Unfolding network (FMU),\nwhich, to our knowledge, is the first to integrate flow matching into HSI\nreconstruction by embedding its generative prior within a deep unfolding\nframework. To further strengthen the learned dynamics, we introduce a mean\nvelocity loss that enforces global consistency of the flow, leading to a more\nrobust and accurate reconstruction. This hybrid design leverages the\ninterpretability of optimization-based methods and the generative capacity of\nflow matching. Extensive experiments on both simulated and real datasets show\nthat FMU significantly outperforms existing approaches in reconstruction\nquality. Code and models will be available at https://github.com/YiAi03/FMU.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01912v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01912v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.341,
      "weak_supervision_score": 0.305,
      "diffusion_reasoning_score": 0.352,
      "distributed_training_score": 0.325,
      "datasets_score": 0.292,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01914",
      "title": "Automated Defect Detection for Mass-Produced Electronic Components Based\n  on YOLO Object Detection Models",
      "authors": [
        "Wei-Lung Mao",
        "Chun-Chi Wang",
        "Po-Heng Chou",
        "Yen-Ting Liu"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.AI (Artificial Intelligence)",
        "cs.LG (Machine Learning)",
        "eess.SP (Signal Processing)"
      ],
      "abstract": "Since the defect detection of conventional industry components is\ntime-consuming and labor-intensive, it leads to a significant burden on quality\ninspection personnel and makes it difficult to manage product quality. In this\npaper, we propose an automated defect detection system for the dual in-line\npackage (DIP) that is widely used in industry, using digital camera optics and\na deep learning (DL)-based model. The two most common defect categories of DIP\nare examined: (1) surface defects, and (2) pin-leg defects. However, the lack\nof defective component images leads to a challenge for detection tasks. To\nsolve this problem, the ConSinGAN is used to generate a suitable-sized dataset\nfor training and testing. Four varieties of the YOLO model are investigated\n(v3, v4, v7, and v9), both in isolation and with the ConSinGAN augmentation.\nThe proposed YOLOv7 with ConSinGAN is superior to the other YOLO versions in\naccuracy of 95.50\\%, detection time of 285 ms, and is far superior to\nthreshold-based approaches. In addition, the supervisory control and data\nacquisition (SCADA) system is developed, and the associated sensor architecture\nis described. The proposed automated defect detection can be easily established\nwith numerous types of defects or insufficient defect data.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01914v2",
      "pdf_url": "http://arxiv.org/pdf/2510.01914v2",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.298,
      "weak_supervision_score": 0.368,
      "diffusion_reasoning_score": 0.349,
      "distributed_training_score": 0.348,
      "datasets_score": 0.347,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01919",
      "title": "GFSR-Net: Guided Focus via Segment-Wise Relevance Network for\n  Interpretable Deep Learning in Medical Imaging",
      "authors": [
        "Jhonatan Contreras",
        "Thomas Bocklitz"
      ],
      "categories": [
        "eess.IV (Image and Video Processing)",
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Deep learning has achieved remarkable success in medical image analysis,\nhowever its adoption in clinical practice is limited by a lack of\ninterpretability. These models often make correct predictions without\nexplaining their reasoning. They may also rely on image regions unrelated to\nthe disease or visual cues, such as annotations, that are not present in\nreal-world conditions. This can reduce trust and increase the risk of\nmisleading diagnoses. We introduce the Guided Focus via Segment-Wise Relevance\nNetwork (GFSR-Net), an approach designed to improve interpretability and\nreliability in medical imaging. GFSR-Net uses a small number of human\nannotations to approximate where a person would focus within an image\nintuitively, without requiring precise boundaries or exhaustive markings,\nmaking the process fast and practical. During training, the model learns to\nalign its focus with these areas, progressively emphasizing features that carry\ndiagnostic meaning. This guidance works across different types of natural and\nmedical images, including chest X-rays, retinal scans, and dermatological\nimages. Our experiments demonstrate that GFSR achieves comparable or superior\naccuracy while producing saliency maps that better reflect human expectations.\nThis reduces the reliance on irrelevant patterns and increases confidence in\nautomated diagnostic tools.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01919v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01919v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "extraction_failed",
      "embedding_status": "completed",
      "rlhf_score": 0.37,
      "weak_supervision_score": 0.362,
      "diffusion_reasoning_score": 0.386,
      "distributed_training_score": 0.348,
      "datasets_score": 0.337,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01924",
      "title": "To Mask or to Mirror: Human-AI Alignment in Collective Reasoning",
      "authors": [
        "Crystal Qian",
        "Aaron Parisi",
        "Clémentine Bouleau",
        "Vivian Tsai",
        "Maël Lebreton",
        "Lucas Dixon"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)",
        "cs.MA (Multiagent Systems)"
      ],
      "abstract": "As large language models (LLMs) are increasingly used to model and augment\ncollective decision-making, it is critical to examine their alignment with\nhuman social reasoning. We present an empirical framework for assessing\ncollective alignment, in contrast to prior work on the individual level. Using\nthe Lost at Sea social psychology task, we conduct a large-scale online\nexperiment (N=748), randomly assigning groups to leader elections with either\nvisible demographic attributes (e.g. name, gender) or pseudonymous aliases. We\nthen simulate matched LLM groups conditioned on the human data, benchmarking\nGemini 2.5, GPT 4.1, Claude Haiku 3.5, and Gemma 3. LLM behaviors diverge: some\nmirror human biases; others mask these biases and attempt to compensate for\nthem. We empirically demonstrate that human-AI alignment in collective\nreasoning depends on context, cues, and model-specific inductive biases.\nUnderstanding how LLMs align with collective human behavior is critical to\nadvancing socially-aligned AI, and demands dynamic benchmarks that capture the\ncomplexities of collective reasoning.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01924v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01924v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.486,
      "weak_supervision_score": 0.365,
      "diffusion_reasoning_score": 0.402,
      "distributed_training_score": 0.366,
      "datasets_score": 0.366,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on evaluating existing LLMs for human-AI alignment in collective reasoning through experiments and simulations, without any mention of training models using human feedback, reward models, or reinforcement learning techniques.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper examines LLMs in social reasoning tasks but does not involve diffusion models, iterative refinement processes, or multi-step logical reasoning adapted from diffusion techniques; it relies on standard LLM simulations.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01934",
      "title": "Foundation Visual Encoders Are Secretly Few-Shot Anomaly Detectors",
      "authors": [
        "Guangyao Zhai",
        "Yue Zhou",
        "Xinyan Deng",
        "Lars Heckler",
        "Nassir Navab",
        "Benjamin Busam"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.AI (Artificial Intelligence)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "Few-shot anomaly detection streamlines and simplifies industrial safety\ninspection. However, limited samples make accurate differentiation between\nnormal and abnormal features challenging, and even more so under\ncategory-agnostic conditions. Large-scale pre-training of foundation visual\nencoders has advanced many fields, as the enormous quantity of data helps to\nlearn the general distribution of normal images. We observe that the anomaly\namount in an image directly correlates with the difference in the learnt\nembeddings and utilize this to design a few-shot anomaly detector termed\nFoundAD. This is done by learning a nonlinear projection operator onto the\nnatural image manifold. The simple operator acts as an effective tool for\nanomaly detection to characterize and identify out-of-distribution regions in\nan image. Extensive experiments show that our approach supports multi-class\ndetection and achieves competitive performance while using substantially fewer\nparameters than prior methods. Backed up by evaluations with multiple\nfoundation encoders, including fresh DINOv3, we believe this idea broadens the\nperspective on foundation features and advances the field of few-shot anomaly\ndetection.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01934v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01934v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.33,
      "weak_supervision_score": 0.387,
      "diffusion_reasoning_score": 0.385,
      "distributed_training_score": 0.346,
      "datasets_score": 0.333,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01948",
      "title": "ClustViT: Clustering-based Token Merging for Semantic Segmentation",
      "authors": [
        "Fabio Montello",
        "Ronja Güldenring",
        "Lazaros Nalpantidis"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Vision Transformers can achieve high accuracy and strong generalization\nacross various contexts, but their practical applicability on real-world\nrobotic systems is limited due to their quadratic attention complexity. Recent\nworks have focused on dynamically merging tokens according to the image\ncomplexity. Token merging works well for classification but is less suited to\ndense prediction. We propose ClustViT, where we expand upon the Vision\nTransformer (ViT) backbone and address semantic segmentation. Within our\narchitecture, a trainable Cluster module merges similar tokens along the\nnetwork guided by pseudo-clusters from segmentation masks. Subsequently, a\nRegenerator module restores fine details for downstream heads. Our approach\nachieves up to 2.18x fewer GFLOPs and 1.64x faster inference on three different\ndatasets, with comparable segmentation accuracy. Our code and models will be\nmade publicly available.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01948v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01948v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.296,
      "weak_supervision_score": 0.337,
      "diffusion_reasoning_score": 0.377,
      "distributed_training_score": 0.412,
      "datasets_score": 0.322,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "Not Relevant",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "The paper's main contribution is developing ClustViT, a method for token merging in Vision Transformers to reduce computational complexity during inference for semantic segmentation. It does not address distributed training, parallel computing, or strategies for partitioning data or computation across multiple nodes or processors.",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01954",
      "title": "Patch-as-Decodable-Token: Towards Unified Multi-Modal Vision Tasks in\n  MLLMs",
      "authors": [
        "Yongyi Su",
        "Haojie Zhang",
        "Shijie Li",
        "Nanqing Liu",
        "Jingyi Liao",
        "Junyi Pan",
        "Yuan Liu",
        "Xiaofen Xing",
        "Chong Sun",
        "Chen Li",
        "Nancy F. Chen",
        "Shuicheng Yan",
        "Xulei Yang",
        "Xun Xu"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Multimodal large language models (MLLMs) have advanced rapidly in recent\nyears. However, existing approaches for vision tasks often rely on indirect\nrepresentations, such as generating coordinates as text for detection, which\nlimits performance and prevents dense prediction tasks like segmentation. To\novercome these challenges, we introduce Patch-as-Decodable Token (PaDT), a\nunified paradigm that enables MLLMs to directly generate both textual and\ndiverse visual outputs. Central to PaDT are Visual Reference Tokens (VRTs),\nderived from visual patch embeddings of query images and interleaved seamlessly\nwith LLM's output textual tokens. A lightweight decoder then transforms LLM's\noutputs into detection, segmentation, and grounding predictions. Unlike prior\nmethods, PaDT processes VRTs independently at each forward pass and dynamically\nexpands the embedding table, thus improving localization and differentiation\namong similar objects. We further tailor a training strategy for PaDT by\nrandomly selecting VRTs for supervised fine-tuning and introducing a robust\nper-token cross-entropy loss. Our empirical studies across four visual\nperception and understanding tasks suggest PaDT consistently achieving\nstate-of-the-art performance, even compared with significantly larger MLLM\nmodels. The code is available at https://github.com/Gorilla-Lab-SCUT/PaDT.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01954v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01954v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.369,
      "weak_supervision_score": 0.355,
      "diffusion_reasoning_score": 0.459,
      "distributed_training_score": 0.37,
      "datasets_score": 0.339,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper introduces Patch-as-Decodable Token (PaDT) for unified multi-modal vision tasks in MLLMs, focusing on generating visual and textual outputs using Visual Reference Tokens. It does not involve diffusion models, iterative refinement processes, or multi-step logical reasoning for complex tasks, as defined by the topic.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01958",
      "title": "Exploring Resolution-Wise Shared Attention in Hybrid Mamba-U-Nets for\n  Improved Cross-Corpus Speech Enhancement",
      "authors": [
        "Nikolai Lund Kühne",
        "Jesper Jensen",
        "Jan Østergaard",
        "Zheng-Hua Tan"
      ],
      "categories": [
        "cs.SD (Sound)",
        "cs.AI (Artificial Intelligence)",
        "eess.AS (Audio and Speech Processing)"
      ],
      "abstract": "Recent advances in speech enhancement have shown that models combining Mamba\nand attention mechanisms yield superior cross-corpus generalization\nperformance. At the same time, integrating Mamba in a U-Net structure has\nyielded state-of-the-art enhancement performance, while reducing both model\nsize and computational complexity. Inspired by these insights, we propose\nRWSA-MambaUNet, a novel and efficient hybrid model combining Mamba and\nmulti-head attention in a U-Net structure for improved cross-corpus\nperformance. Resolution-wise shared attention (RWSA) refers to layerwise\nattention-sharing across corresponding time- and frequency resolutions. Our\nbest-performing RWSA-MambaUNet model achieves state-of-the-art generalization\nperformance on two out-of-domain test sets. Notably, our smallest model\nsurpasses all baselines on the out-of-domain DNS 2020 test set in terms of\nPESQ, SSNR, and ESTOI, and on the out-of-domain EARS-WHAM_v2 test set in terms\nof SSNR, ESTOI, and SI-SDR, while using less than half the model parameters and\na fraction of the FLOPs.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01958v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01958v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.353,
      "weak_supervision_score": 0.383,
      "diffusion_reasoning_score": 0.39,
      "distributed_training_score": 0.35,
      "datasets_score": 0.317,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01967",
      "title": "ZK-WAGON: Imperceptible Watermark for Image Generation Models using\n  ZK-SNARKs",
      "authors": [
        "Aadarsh Anantha Ramakrishnan",
        "Shubham Agarwal",
        "Selvanayagam S",
        "Kunwar Singh"
      ],
      "categories": [
        "cs.CR (Cryptography and Security)",
        "cs.AI (Artificial Intelligence)",
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "As image generation models grow increasingly powerful and accessible,\nconcerns around authenticity, ownership, and misuse of synthetic media have\nbecome critical. The ability to generate lifelike images indistinguishable from\nreal ones introduces risks such as misinformation, deepfakes, and intellectual\nproperty violations. Traditional watermarking methods either degrade image\nquality, are easily removed, or require access to confidential model internals\n- making them unsuitable for secure and scalable deployment. We are the first\nto introduce ZK-WAGON, a novel system for watermarking image generation models\nusing the Zero-Knowledge Succinct Non Interactive Argument of Knowledge\n(ZK-SNARKs). Our approach enables verifiable proof of origin without exposing\nmodel weights, generation prompts, or any sensitive internal information. We\npropose Selective Layer ZK-Circuit Creation (SL-ZKCC), a method to selectively\nconvert key layers of an image generation model into a circuit, reducing proof\ngeneration time significantly. Generated ZK-SNARK proofs are imperceptibly\nembedded into a generated image via Least Significant Bit (LSB) steganography.\nWe demonstrate this system on both GAN and Diffusion models, providing a\nsecure, model-agnostic pipeline for trustworthy AI image generation.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01967v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01967v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "extraction_failed",
      "embedding_status": "completed",
      "rlhf_score": 0.324,
      "weak_supervision_score": 0.37,
      "diffusion_reasoning_score": 0.394,
      "distributed_training_score": 0.335,
      "datasets_score": 0.312,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01978",
      "title": "ROI-GS: Interest-based Local Quality 3D Gaussian Splatting",
      "authors": [
        "Quoc-Anh Bui",
        "Gilles Rougeron",
        "Géraldine Morin",
        "Simone Gasparini"
      ],
      "categories": [
        "cs.GR (Graphics)",
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "We tackle the challenge of efficiently reconstructing 3D scenes with high\ndetail on objects of interest. Existing 3D Gaussian Splatting (3DGS) methods\nallocate resources uniformly across the scene, limiting fine detail to Regions\nOf Interest (ROIs) and leading to inflated model size. We propose ROI-GS, an\nobject-aware framework that enhances local details through object-guided camera\nselection, targeted Object training, and seamless integration of high-fidelity\nobject of interest reconstructions into the global scene. Our method\nprioritizes higher resolution details on chosen objects while maintaining\nreal-time performance. Experiments show that ROI-GS significantly improves\nlocal quality (up to 2.96 dB PSNR), while reducing overall model size by\n$\\approx 17\\%$ of baseline and achieving faster training for a scene with a\nsingle object of interest, outperforming existing methods.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01978v2",
      "pdf_url": "http://arxiv.org/pdf/2510.01978v2",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.306,
      "weak_supervision_score": 0.307,
      "diffusion_reasoning_score": 0.364,
      "distributed_training_score": 0.327,
      "datasets_score": 0.29,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01982",
      "title": "G$^2$RPO: Granular GRPO for Precise Reward in Flow Models",
      "authors": [
        "Yujie Zhou",
        "Pengyang Ling",
        "Jiazi Bu",
        "Yibin Wang",
        "Yuhang Zang",
        "Jiaqi Wang",
        "Li Niu",
        "Guangtao Zhai"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "The integration of online reinforcement learning (RL) into diffusion and flow\nmodels has recently emerged as a promising approach for aligning generative\nmodels with human preferences. Stochastic sampling via Stochastic Differential\nEquations (SDE) is employed during the denoising process to generate diverse\ndenoising directions for RL exploration. While existing methods effectively\nexplore potential high-value samples, they suffer from sub-optimal preference\nalignment due to sparse and narrow reward signals. To address these challenges,\nwe propose a novel Granular-GRPO (G$^2$RPO) framework that achieves precise and\ncomprehensive reward assessments of sampling directions in reinforcement\nlearning of flow models. Specifically, a Singular Stochastic Sampling strategy\nis introduced to support step-wise stochastic exploration while enforcing a\nhigh correlation between the reward and the injected noise, thereby\nfacilitating a faithful reward for each SDE perturbation. Concurrently, to\neliminate the bias inherent in fixed-granularity denoising, we introduce a\nMulti-Granularity Advantage Integration module that aggregates advantages\ncomputed at multiple diffusion scales, producing a more comprehensive and\nrobust evaluation of the sampling directions. Experiments conducted on various\nreward models, including both in-domain and out-of-domain evaluations,\ndemonstrate that our G$^2$RPO significantly outperforms existing flow-based\nGRPO baselines,highlighting its effectiveness and robustness.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01982v2",
      "pdf_url": "http://arxiv.org/pdf/2510.01982v2",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.469,
      "weak_supervision_score": 0.37,
      "diffusion_reasoning_score": 0.458,
      "distributed_training_score": 0.38,
      "datasets_score": 0.267,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Highly Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper directly builds on RLHF by enhancing GRPO, a method within RLHF, to better align generative models with human preferences. It uses reward models trained on human feedback for optimization, explicitly addressing challenges in preference alignment through techniques like Singular Stochastic Sampling.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper applies diffusion and flow models to generative tasks for image and video creation, focusing on RL integration for preference alignment, not on adapting diffusion for multi-step logical reasoning or solving complex tasks as defined.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "completed",
      "summary": "The paper, titled \"G²RPO: Granular GRPO for Precise Reward in Flow Models,\" aims to improve reinforcement learning in flow-based generative models by addressing sparse and narrow reward signals in stochastic sampling. It introduces the G²RPO framework, featuring Singular Stochastic Sampling to concentrate stochasticity on a single step for better reward correlation and Multi-Granularity Advantage Integration to aggregate advantages from multiple denoising scales, resulting in more precise reward assessments and superior performance over baselines in experiments across various reward models.",
      "novelty_score": "Moderate",
      "novelty_justification": "The paper presents a notable improvement by introducing Singular Stochastic Sampling and Multi-Granularity Advantage Integration, which cleverly combine and refine existing ideas in reinforcement learning for flow models to enhance reward precision. While it advances the state-of-the-art in aligning generative models with human preferences, it builds upon established GRPO methods rather than introducing an entirely new problem or technique.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to be cited and built upon within the subfield of generative models and reinforcement learning, as it demonstrates improved performance in aligning models with human preferences. However, its influence may be limited to specific applications in computer vision and machine learning rather than having broad commercial or widespread research implications.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper offers a strong, valuable contribution to reinforcement learning in generative models, making it important for researchers in AI and computer vision to be aware of its advancements in reward optimization. While not essential for all, it provides insightful methods that could enhance related work.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/2f11fdb66ca5d382f3b0ca763c2d13cde9e6f522",
      "total_authors": 8,
      "authors_found": 8,
      "highest_h_index": 27,
      "average_h_index": 5.0,
      "notable_authors_count": 2,
      "author_h_indexes": [
        {
          "name": "Yujie Zhou",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2355729700"
        },
        {
          "name": "Pengyang Ling",
          "h_index": 6,
          "profile_url": "https://www.semanticscholar.org/author/2218843242"
        },
        {
          "name": "Jiazi Bu",
          "h_index": 3,
          "profile_url": "https://www.semanticscholar.org/author/2281827319"
        },
        {
          "name": "Yibin Wang",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2376550824"
        },
        {
          "name": "Yuhang Zang",
          "h_index": 27,
          "profile_url": "https://www.semanticscholar.org/author/12862495"
        },
        {
          "name": "Jiaqi Wang",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2282349890"
        },
        {
          "name": "Li Niu",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2345040137"
        },
        {
          "name": "Guangtao Zhai",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2371136762"
        }
      ]
    },
    {
      "id": "2510.01990",
      "title": "TriAlignXA: An Explainable Trilemma Alignment Framework for Trustworthy\n  Agri-product Grading",
      "authors": [
        "Jianfei Xie",
        "Ziyang Li"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.CY (Computers and Society)"
      ],
      "abstract": "The 'trust deficit' in online fruit and vegetable e-commerce stems from the\ninability of digital transactions to provide direct sensory perception of\nproduct quality. This paper constructs a 'Trust Pyramid' model through\n'dual-source verification' of consumer trust. Experiments confirm that quality\nis the cornerstone of trust. The study reveals an 'impossible triangle' in\nagricultural product grading, comprising biological characteristics,\ntimeliness, and economic viability, highlighting the limitations of traditional\nabsolute grading standards. To quantitatively assess this trade-off, we propose\nthe 'Triangular Trust Index' (TTI). We redefine the role of algorithms from\n'decision-makers' to 'providers of transparent decision-making bases',\ndesigning the explainable AI framework--TriAlignXA. This framework supports\ntrustworthy online transactions within agricultural constraints through\nmulti-objective optimization. Its core relies on three engines: the\nBio-Adaptive Engine for granular quality description; the Timeliness\nOptimization Engine for processing efficiency; and the Economic Optimization\nEngine for cost control. Additionally, the \"Pre-Mapping Mechanism\" encodes\nprocess data into QR codes, transparently conveying quality information.\nExperiments on grading tasks demonstrate significantly higher accuracy than\nbaseline models. Empirical evidence and theoretical analysis verify the\nframework's balancing capability in addressing the \"impossible triangle\". This\nresearch provides comprehensive support--from theory to practice--for building\na trustworthy online produce ecosystem, establishing a critical pathway from\nalgorithmic decision-making to consumer trust.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01990v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01990v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.405,
      "weak_supervision_score": 0.358,
      "diffusion_reasoning_score": 0.337,
      "distributed_training_score": 0.344,
      "datasets_score": 0.323,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper's main contribution is an explainable AI framework for trustworthy agri-product grading, focusing on multi-objective optimization, trust models, and addressing constraints like biological variability and timeliness. It does not involve reinforcement learning, human feedback for training models, reward models, or fine-tuning based on human preferences, which are core to RLHF. Therefore, there is no connection to the topic.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01991",
      "title": "4DGS-Craft: Consistent and Interactive 4D Gaussian Splatting Editing",
      "authors": [
        "Lei Liu",
        "Can Wang",
        "Zhenghao Chen",
        "Dong Xu"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Recent advances in 4D Gaussian Splatting (4DGS) editing still face challenges\nwith view, temporal, and non-editing region consistency, as well as with\nhandling complex text instructions. To address these issues, we propose\n4DGS-Craft, a consistent and interactive 4DGS editing framework. We first\nintroduce a 4D-aware InstructPix2Pix model to ensure both view and temporal\nconsistency. This model incorporates 4D VGGT geometry features extracted from\nthe initial scene, enabling it to capture underlying 4D geometric structures\nduring editing. We further enhance this model with a multi-view grid module\nthat enforces consistency by iteratively refining multi-view input images while\njointly optimizing the underlying 4D scene. Furthermore, we preserve the\nconsistency of non-edited regions through a novel Gaussian selection mechanism,\nwhich identifies and optimizes only the Gaussians within the edited regions.\nBeyond consistency, facilitating user interaction is also crucial for effective\n4DGS editing. Therefore, we design an LLM-based module for user intent\nunderstanding. This module employs a user instruction template to define atomic\nediting operations and leverages an LLM for reasoning. As a result, our\nframework can interpret user intent and decompose complex instructions into a\nlogical sequence of atomic operations, enabling it to handle intricate user\ncommands and further enhance editing performance. Compared to related works,\nour approach enables more consistent and controllable 4D scene editing. Our\ncode will be made available upon acceptance.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01991v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01991v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.293,
      "weak_supervision_score": 0.306,
      "diffusion_reasoning_score": 0.417,
      "distributed_training_score": 0.294,
      "datasets_score": 0.294,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on 4D Gaussian Splatting editing using a 4D-aware InstructPix2Pix model, which is diffusion-based for image editing and consistency, and an LLM-based module for user intent understanding and reasoning. However, it does not adapt the iterative refinement process of diffusion models to solve complex logical tasks, such as treating a Chain-of-Thought as a single entity for multi-step reasoning. The diffusion component is used solely for visual editing, while logical reasoning is handled by the LLM, lacking any integration of diffusion for reasoning purposes.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01994",
      "title": "Clarifying Semantics of In-Context Examples for Unit Test Generation",
      "authors": [
        "Chen Yang",
        "Lin Yang",
        "Ziqi Wang",
        "Dong Wang",
        "Jianyi Zhou",
        "Junjie Chen"
      ],
      "categories": [
        "cs.SE (Software Engineering)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Recent advances in large language models (LLMs) have enabled promising\nperformance in unit test generation through in-context learning (ICL). However,\nthe quality of in-context examples significantly influences the effectiveness\nof generated tests-poorly structured or semantically unclear test examples\noften lead to suboptimal outputs. In this paper, we propose CLAST, a novel\ntechnique that systematically refines unit tests to improve their semantic\nclarity, thereby enhancing their utility as in-context examples. The approach\ndecomposes complex tests into logically clearer ones and improves semantic\nclarity through a combination of program analysis and LLM-based rewriting. We\nevaluated CLAST on four open-source and three industrial projects. The results\ndemonstrate that CLAST largely outperforms UTgen, the state-of-the-art\nrefinement technique, in both preserving test effectiveness and enhancing\nsemantic clarity. Specifically, CLAST fully retains the original effectiveness\nof unit tests, while UTgen reduces compilation success rate (CSR), pass rate\n(PR), test coverage (Cov), and mutation score (MS) by an average of 12.90%,\n35.82%, 4.65%, and 5.07%, respectively. Over 85.33% of participants in our user\nstudy preferred the semantic clarity of CLAST-refined tests. Notably,\nincorporating CLAST-refined tests as examples effectively improves ICL-based\nunit test generation approaches such as RAGGen and TELPA, resulting in an\naverage increase of 25.97% in CSR, 28.22% in PR, and 45.99% in Cov for\ngenerated tests, compared to incorporating UTgen-refined tests. The insights\nfrom the follow-up user study not only reinforce CLAST's potential impact in\nsoftware testing practice but also illuminate avenues for future research.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01994v1",
      "pdf_url": "http://arxiv.org/pdf/2510.01994v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.332,
      "weak_supervision_score": 0.363,
      "diffusion_reasoning_score": 0.345,
      "distributed_training_score": 0.291,
      "datasets_score": 0.298,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.01997",
      "title": "Pure-Pass: Fine-Grained, Adaptive Masking for Dynamic Token-Mixing\n  Routing in Lightweight Image Super-Resolution",
      "authors": [
        "Junyu Wu",
        "Jie Liu",
        "Jie Tang",
        "Gangshan Wu"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Image Super-Resolution (SR) aims to reconstruct high-resolution images from\nlow-resolution counterparts, but the computational complexity of deep\nlearning-based methods often hinders practical deployment. CAMixer is the\npioneering work to integrate the advantages of existing lightweight SR methods\nand proposes a content-aware mixer to route token mixers of varied complexities\naccording to the difficulty of content recovery. However, several limitations\nremain, such as poor adaptability, coarse-grained masking and spatial\ninflexibility, among others. We propose Pure-Pass (PP), a pixel-level masking\nmechanism that identifies pure pixels and exempts them from expensive\ncomputations. PP utilizes fixed color center points to classify pixels into\ndistinct categories, enabling fine-grained, spatially flexible masking while\nmaintaining adaptive flexibility. Integrated into the state-of-the-art\nATD-light model, PP-ATD-light achieves superior SR performance with minimal\noverhead, outperforming CAMixer-ATD-light in reconstruction quality and\nparameter efficiency when saving a similar amount of computation.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.01997v2",
      "pdf_url": "http://arxiv.org/pdf/2510.01997v2",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.328,
      "weak_supervision_score": 0.36,
      "diffusion_reasoning_score": 0.385,
      "distributed_training_score": 0.386,
      "datasets_score": 0.27,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02001",
      "title": "Generating Findings for Jaw Cysts in Dental Panoramic Radiographs Using\n  GPT-4o: Building a Two-Stage Self-Correction Loop with Structured Output\n  (SLSO) Framework",
      "authors": [
        "Nanaka Hosokawa",
        "Ryo Takahashi",
        "Tomoya Kitano",
        "Yukihiro Iida",
        "Chisako Muramatsu",
        "Tatsuro Hayashi",
        "Yuta Seino",
        "Xiangrong Zhou",
        "Takeshi Hara",
        "Akitoshi Katsumata",
        "Hiroshi Fujita"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "In this study, we utilized the multimodal capabilities of OpenAI GPT-4o to\nautomatically generate jaw cyst findings on dental panoramic radiographs. To\nimprove accuracy, we constructed a Self-correction Loop with Structured Output\n(SLSO) framework and verified its effectiveness. A 10-step process was\nimplemented for 22 cases of jaw cysts, including image input and analysis,\nstructured data generation, tooth number extraction and consistency checking,\niterative regeneration when inconsistencies were detected, and finding\ngeneration with subsequent restructuring and consistency verification. A\ncomparative experiment was conducted using the conventional Chain-of-Thought\n(CoT) method across seven evaluation items: transparency, internal structure,\nborders, root resorption, tooth movement, relationships with other structures,\nand tooth number. The results showed that the proposed SLSO framework improved\noutput accuracy for many items, with 66.9%, 33.3%, and 28.6% improvement rates\nfor tooth number, tooth movement, and root resorption, respectively. In the\nsuccessful cases, a consistently structured output was achieved after up to\nfive regenerations. Although statistical significance was not reached because\nof the small size of the dataset, the overall SLSO framework enforced negative\nfinding descriptions, suppressed hallucinations, and improved tooth number\nidentification accuracy. However, the accurate identification of extensive\nlesions spanning multiple teeth is limited. Nevertheless, further refinement is\nrequired to enhance overall performance and move toward a practical finding\ngeneration system.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02001v2",
      "pdf_url": "http://arxiv.org/pdf/2510.02001v2",
      "scraper_status": "successfully_scraped",
      "intro_status": "extraction_failed",
      "embedding_status": "completed",
      "rlhf_score": 0.327,
      "weak_supervision_score": 0.339,
      "diffusion_reasoning_score": 0.403,
      "distributed_training_score": 0.297,
      "datasets_score": 0.31,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper introduces a Self-correction Loop with Structured Output (SLSO) framework using GPT-4o for generating dental findings, which involves iterative refinement for accuracy. However, this framework is not based on diffusion models or their iterative processes; it relies on a language model for multi-step corrections. The topic specifically requires adaptation of diffusion models for complex logical tasks, which is absent here, making the paper not relevant.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02027",
      "title": "Zero-shot reasoning for simulating scholarly peer-review",
      "authors": [
        "Khalid M. Saqr"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)",
        "cs.ET (Emerging Technologies)"
      ],
      "abstract": "The scholarly publishing ecosystem faces a dual crisis of unmanageable\nsubmission volumes and unregulated AI, creating an urgent need for new\ngovernance models to safeguard scientific integrity. The traditional human-only\npeer review regime lacks a scalable, objective benchmark, making editorial\nprocesses opaque and difficult to audit. Here we investigate a deterministic\nsimulation framework that provides the first stable, evidence-based standard\nfor evaluating AI-generated peer review reports. Analyzing 352 peer-review\nsimulation reports, we identify consistent system state indicators that\ndemonstrate its reliability. First, the system is able to simulate calibrated\neditorial judgment, with 'Revise' decisions consistently forming the majority\noutcome (>50%) across all disciplines, while 'Reject' rates dynamically adapt\nto field-specific norms, rising to 45% in Health Sciences. Second, it maintains\nunwavering procedural integrity, enforcing a stable 29% evidence-anchoring\ncompliance rate that remains invariant across diverse review tasks and\nscientific domains. These findings demonstrate a system that is predictably\nrule-bound, mitigating the stochasticity of generative AI. For the scientific\ncommunity, this provides a transparent tool to ensure fairness; for publishing\nstrategists, it offers a scalable instrument for auditing workflows, managing\nintegrity risks, and implementing evidence-based governance. The framework\nrepositions AI as an essential component of institutional accountability,\nproviding the critical infrastructure to maintain trust in scholarly\ncommunication.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02027v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02027v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.442,
      "weak_supervision_score": 0.39,
      "diffusion_reasoning_score": 0.498,
      "distributed_training_score": 0.358,
      "datasets_score": 0.36,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on a zero-shot reasoning framework using LLMs for simulating peer review, emphasizing deterministic simulations and evidence-based standards without any mention of training models with human feedback, reward models, or reinforcement learning. It does not involve aligning AI with human preferences through human-ranked data, which is core to RLHF.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper discusses zero-shot reasoning with LLMs, including techniques like chain-of-thought and prompting, but does not reference diffusion models, iterative refinement processes for logical tasks, or treating reasoning paths as entities for holistic correction. There is no component of multi-step logical reasoning using diffusion-based methods.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02028",
      "title": "LiLa-Net: Lightweight Latent LiDAR Autoencoder for 3D Point Cloud\n  Reconstruction",
      "authors": [
        "Mario Resino",
        "Borja Pérez",
        "Jaime Godoy",
        "Abdulla Al-Kaff",
        "Fernando García"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "This work proposed a 3D autoencoder architecture, named LiLa-Net, which\nencodes efficient features from real traffic environments, employing only the\nLiDAR's point clouds. For this purpose, we have real semi-autonomous vehicle,\nequipped with Velodyne LiDAR. The system leverage skip connections concept to\nimprove the performance without using extensive resources as the\nstate-of-the-art architectures. Key changes include reducing the number of\nencoder layers and simplifying the skip connections, while still producing an\nefficient and representative latent space which allows to accurately\nreconstruct the original point cloud. Furthermore, an effective balance has\nbeen achieved between the information carried by the skip connections and the\nlatent encoding, leading to improved reconstruction quality without\ncompromising performance. Finally, the model demonstrates strong generalization\ncapabilities, successfully reconstructing objects unrelated to the original\ntraffic environment.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02028v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02028v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.339,
      "weak_supervision_score": 0.35,
      "diffusion_reasoning_score": 0.365,
      "distributed_training_score": 0.356,
      "datasets_score": 0.337,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02030",
      "title": "kabr-tools: Automated Framework for Multi-Species Behavioral Monitoring",
      "authors": [
        "Jenna Kline",
        "Maksim Kholiavchenko",
        "Samuel Stevens",
        "Nina van Tiel",
        "Alison Zhong",
        "Namrata Banerji",
        "Alec Sheets",
        "Sowbaranika Balasubramaniam",
        "Isla Duporge",
        "Matthew Thompson",
        "Elizabeth Campolongo",
        "Jackson Miliko",
        "Neil Rosser",
        "Tanya Berger-Wolf",
        "Charles V. Stewart",
        "Daniel I. Rubenstein"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "A comprehensive understanding of animal behavior ecology depends on scalable\napproaches to quantify and interpret complex, multidimensional behavioral\npatterns. Traditional field observations are often limited in scope,\ntime-consuming, and labor-intensive, hindering the assessment of behavioral\nresponses across landscapes. To address this, we present kabr-tools (Kenyan\nAnimal Behavior Recognition Tools), an open-source package for automated\nmulti-species behavioral monitoring. This framework integrates drone-based\nvideo with machine learning systems to extract behavioral, social, and spatial\nmetrics from wildlife footage. Our pipeline leverages object detection,\ntracking, and behavioral classification systems to generate key metrics,\nincluding time budgets, behavioral transitions, social interactions, habitat\nassociations, and group composition dynamics. Compared to ground-based methods,\ndrone-based observations significantly improved behavioral granularity,\nreducing visibility loss by 15% and capturing more transitions with higher\naccuracy and continuity. We validate kabr-tools through three case studies,\nanalyzing 969 behavioral sequences, surpassing the capacity of traditional\nmethods for data capture and annotation. We found that, like Plains zebras,\nvigilance in Grevy's zebras decreases with herd size, but, unlike Plains\nzebras, habitat has a negligible impact. Plains and Grevy's zebras exhibit\nstrong behavioral inertia, with rare transitions to alert behaviors and\nobserved spatial segregation between Grevy's zebras, Plains zebras, and\ngiraffes in mixed-species herds. By enabling automated behavioral monitoring at\nscale, kabr-tools offers a powerful tool for ecosystem-wide studies, advancing\nconservation, biodiversity research, and ecological monitoring.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02030v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02030v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.356,
      "weak_supervision_score": 0.375,
      "diffusion_reasoning_score": 0.3,
      "distributed_training_score": 0.336,
      "datasets_score": 0.349,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02034",
      "title": "GaussianMorphing: Mesh-Guided 3D Gaussians for Semantic-Aware Object\n  Morphing",
      "authors": [
        "Mengtian Li",
        "Yunshu Bai",
        "Yimin Chu",
        "Yijun Shen",
        "Zhongmei Li",
        "Weifeng Ge",
        "Zhifeng Xie",
        "Chaofeng Chen"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "We introduce GaussianMorphing, a novel framework for semantic-aware 3D shape\nand texture morphing from multi-view images. Previous approaches usually rely\non point clouds or require pre-defined homeomorphic mappings for untextured\ndata. Our method overcomes these limitations by leveraging mesh-guided 3D\nGaussian Splatting (3DGS) for high-fidelity geometry and appearance modeling.\nThe core of our framework is a unified deformation strategy that anchors\n3DGaussians to reconstructed mesh patches, ensuring geometrically consistent\ntransformations while preserving texture fidelity through topology-aware\nconstraints. In parallel, our framework establishes unsupervised semantic\ncorrespondence by using the mesh topology as a geometric prior and maintains\nstructural integrity via physically plausible point trajectories. This\nintegrated approach preserves both local detail and global semantic coherence\nthroughout the morphing process with out requiring labeled data. On our\nproposed TexMorph benchmark, GaussianMorphing substantially outperforms prior\n2D/3D methods, reducing color consistency error ($\\Delta E$) by 22.2% and EI by\n26.2%. Project page: https://baiyunshu.github.io/GAUSSIANMORPHING.github.io/",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02034v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02034v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.255,
      "weak_supervision_score": 0.287,
      "diffusion_reasoning_score": 0.401,
      "distributed_training_score": 0.275,
      "datasets_score": 0.241,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on a framework for 3D shape and texture morphing using 3D Gaussian Splatting and mesh guidance, emphasizing geometric and semantic transformations in computer vision and graphics. It does not involve diffusion models, iterative refinement for logical tasks, or any form of multi-step reasoning processes as described in the topic.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02036",
      "title": "The Current State of AI Bias Bounties: An Overview of Existing\n  Programmes and Research",
      "authors": [
        "Sergej Kucenko",
        "Nathaniel Dennler",
        "Fengxiang He"
      ],
      "categories": [
        "cs.CY (Computers and Society)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Current bias evaluation methods rarely engage with communities impacted by AI\nsystems. Inspired by bug bounties, bias bounties have been proposed as a\nreward-based method that involves communities in AI bias detection by asking\nusers of AI systems to report biases they encounter when interacting with such\nsystems. In the absence of a state-of-the-art review, this survey aimed to\nidentify and analyse existing AI bias bounty programmes and to present academic\nliterature on bias bounties. Google, Google Scholar, PhilPapers, and IEEE\nXplore were searched, and five bias bounty programmes, as well as five research\npublications, were identified. All bias bounties were organised by U.S.-based\norganisations as time-limited contests, with public participation in four\nprogrammes and prize pools ranging from 7,000 to 24,000 USD. The five research\npublications included a report on the application of bug bounties to\nalgorithmic harms, an article addressing Twitter's bias bounty, a proposal for\nbias bounties as an institutional mechanism to increase AI scrutiny, a workshop\ndiscussing bias bounties from queer perspectives, and an algorithmic framework\nfor bias bounties. We argue that reducing the technical requirements to enter\nbounty programmes is important to include those without coding experience.\nGiven the limited adoption of bias bounties, future efforts should explore the\ntransferability of the best practices from bug bounties and examine how such\nprogrammes can be designed to be sensitive to underrepresented groups while\nlowering adoption barriers for organisations.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02036v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02036v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "extraction_failed",
      "embedding_status": "completed",
      "rlhf_score": 0.407,
      "weak_supervision_score": 0.358,
      "diffusion_reasoning_score": 0.301,
      "distributed_training_score": 0.318,
      "datasets_score": 0.421,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "Not Relevant",
      "rlhf_justification": "The paper focuses on AI bias bounty programs and community involvement in bias detection, which involves human feedback but does not address reinforcement learning techniques. It lacks any discussion of training reward models, fine-tuning AI with human-ranked data, or alignment via reinforcement learning, making it unrelated to RLHF.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "The paper surveys AI bias bounty programs and related literature but does not involve creating, analyzing, benchmarking, or evaluating datasets for machine learning or AI applications. It mentions identifying programs and publications through searches, but this is not focused on datasets or their methodologies.",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02037",
      "title": "A Multicentric Dataset for Training and Benchmarking Breast Cancer\n  Segmentation in H&E Slides",
      "authors": [
        "Carlijn Lems",
        "Leslie Tessier",
        "John-Melle Bokhorst",
        "Mart van Rijthoven",
        "Witali Aswolinskiy",
        "Matteo Pozzi",
        "Natalie Klubickova",
        "Suzanne Dintzis",
        "Michela Campora",
        "Maschenka Balkenhol",
        "Peter Bult",
        "Joey Spronck",
        "Thomas Detone",
        "Mattia Barbareschi",
        "Enrico Munari",
        "Giuseppe Bogina",
        "Jelle Wesseling",
        "Esther H. Lips",
        "Francesco Ciompi",
        "Frédérique Meeuwsen",
        "Jeroen van der Laak"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "eess.IV (Image and Video Processing)"
      ],
      "abstract": "Automated semantic segmentation of whole-slide images (WSIs) stained with\nhematoxylin and eosin (H&E) is essential for large-scale artificial\nintelligence-based biomarker analysis in breast cancer. However, existing\npublic datasets for breast cancer segmentation lack the morphological diversity\nneeded to support model generalizability and robust biomarker validation across\nheterogeneous patient cohorts. We introduce BrEast cancEr hisTopathoLogy\nsEgmentation (BEETLE), a dataset for multiclass semantic segmentation of\nH&E-stained breast cancer WSIs. It consists of 587 biopsies and resections from\nthree collaborating clinical centers and two public datasets, digitized using\nseven scanners, and covers all molecular subtypes and histological grades.\nUsing diverse annotation strategies, we collected annotations across four\nclasses - invasive epithelium, non-invasive epithelium, necrosis, and other -\nwith particular focus on morphologies underrepresented in existing datasets,\nsuch as ductal carcinoma in situ and dispersed lobular tumor cells. The\ndataset's diversity and relevance to the rapidly growing field of automated\nbiomarker quantification in breast cancer ensure its high potential for reuse.\nFinally, we provide a well-curated, multicentric external evaluation set to\nenable standardized benchmarking of breast cancer segmentation models.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02037v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02037v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "no_intro_found",
      "embedding_status": "completed",
      "rlhf_score": 0.215,
      "weak_supervision_score": 0.3,
      "diffusion_reasoning_score": 0.234,
      "distributed_training_score": 0.3,
      "datasets_score": 0.411,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "Highly Relevant",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "The paper's main contribution is the introduction of a new dataset (BEETLE) for breast cancer segmentation in AI applications, which directly involves creating a dataset with diverse annotations, curation methodologies (e.g., multiclass annotations and focus on underrepresented morphologies), and benchmarking through an external evaluation set. This aligns closely with research on creating, analyzing, benchmarking, and evaluating datasets for machine learning and AI.",
      "llm_score_status": "completed",
      "summary": "The paper introduces BEETLE, a new multicentric dataset for multiclass semantic segmentation of H&E-stained breast cancer whole-slide images (WSIs), aiming to address the lack of morphological diversity in existing datasets to enhance model generalizability and biomarker validation. It comprises 587 biopsies and resections from multiple clinical centers and public sources, digitized with various scanners, and includes annotations for four classes—invasive epithelium, non-invasive epithelium, necrosis, and other—with a focus on underrepresented morphologies like ductal carcinoma in situ and dispersed lobular tumor cells; the dataset also provides an external evaluation set for standardized benchmarking, highlighting its potential for advancing automated biomarker quantification in breast cancer research.",
      "novelty_score": "High",
      "novelty_justification": "The paper introduces a truly new dataset that significantly advances the state-of-the-art by providing a morphologically diverse, multicentric collection of breast cancer WSIs with focused annotations on underrepresented features, addressing gaps in existing public datasets. This represents a substantial innovation in the field of medical image segmentation for cancer diagnostics.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to be cited and built upon within the subfield of computer vision and medical imaging for breast cancer, as it offers a robust dataset for training and benchmarking segmentation models, potentially improving AI-based biomarker analysis. However, its influence may be limited to specific applications in pathology and oncology rather than broader fields.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper represents a strong, valuable contribution for researchers in computer vision and medical imaging, particularly those focused on cancer diagnostics, due to its innovative dataset and potential for enhancing model development. It is essential for those working in breast cancer segmentation but may not be critical for unrelated areas.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/55c4e016a786fa43f13ecd1771e4525e33061d1e",
      "total_authors": 21,
      "authors_found": 21,
      "highest_h_index": 36,
      "average_h_index": 7.857142857142857,
      "notable_authors_count": 7,
      "author_h_indexes": [
        {
          "name": "Carlijn M. Lems",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2153736708"
        },
        {
          "name": "Leslie Tessier",
          "h_index": 3,
          "profile_url": "https://www.semanticscholar.org/author/2266249633"
        },
        {
          "name": "J. Bokhorst",
          "h_index": 14,
          "profile_url": "https://www.semanticscholar.org/author/51305677"
        },
        {
          "name": "Mart van Rijthoven",
          "h_index": 6,
          "profile_url": "https://www.semanticscholar.org/author/88859869"
        },
        {
          "name": "W. Aswolinskiy",
          "h_index": 9,
          "profile_url": "https://www.semanticscholar.org/author/3256558"
        },
        {
          "name": "Matteo Pozzi",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2376334983"
        },
        {
          "name": "Natalie Klubickova",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2376333445"
        },
        {
          "name": "Suzanne Dintzis",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2361462511"
        },
        {
          "name": "Michela Campora",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2277737529"
        },
        {
          "name": "M. Balkenhol",
          "h_index": 19,
          "profile_url": "https://www.semanticscholar.org/author/145382775"
        },
        {
          "name": "Peter Bult",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2276761543"
        },
        {
          "name": "J. Spronck",
          "h_index": 4,
          "profile_url": "https://www.semanticscholar.org/author/2159101865"
        },
        {
          "name": "Thomas Detone",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2291446075"
        },
        {
          "name": "M. Barbareschi",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2265801224"
        },
        {
          "name": "Enrico Munari",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2266247564"
        },
        {
          "name": "G. Bogina",
          "h_index": 28,
          "profile_url": "https://www.semanticscholar.org/author/49621543"
        },
        {
          "name": "Jelle Wesseling",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2259103198"
        },
        {
          "name": "E. Lips",
          "h_index": 36,
          "profile_url": "https://www.semanticscholar.org/author/6880513"
        },
        {
          "name": "Francesco Ciompi",
          "h_index": 3,
          "profile_url": "https://www.semanticscholar.org/author/2255880476"
        },
        {
          "name": "Frédérique Meeuwsen",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2370112570"
        },
        {
          "name": "J. Laak",
          "h_index": 27,
          "profile_url": "https://www.semanticscholar.org/author/145388932"
        }
      ]
    },
    {
      "id": "2510.02043",
      "title": "Zero-shot Human Pose Estimation using Diffusion-based Inverse solvers",
      "authors": [
        "Sahil Bhandary Karnoor",
        "Romit Roy Choudhury"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.HC (Human-Computer Interaction)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "Pose estimation refers to tracking a human's full body posture, including\ntheir head, torso, arms, and legs. The problem is challenging in practical\nsettings where the number of body sensors are limited. Past work has shown\npromising results using conditional diffusion models, where the pose prediction\nis conditioned on both <location, rotation> measurements from the sensors.\nUnfortunately, nearly all these approaches generalize poorly across users,\nprimarly because location measurements are highly influenced by the body size\nof the user. In this paper, we formulate pose estimation as an inverse problem\nand design an algorithm capable of zero-shot generalization. Our idea utilizes\na pre-trained diffusion model and conditions it on rotational measurements\nalone; the priors from this model are then guided by a likelihood term, derived\nfrom the measured locations. Thus, given any user, our proposed InPose method\ngeneratively estimates the highly likely sequence of poses that best explains\nthe sparse on-body measurements.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02043v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02043v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.316,
      "weak_supervision_score": 0.313,
      "diffusion_reasoning_score": 0.469,
      "distributed_training_score": 0.333,
      "datasets_score": 0.285,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Tangentially Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper uses a diffusion model for iterative refinement in pose estimation, guiding the denoising process with likelihood terms to generate poses. While this involves multi-step refinement, it focuses on generative modeling for inverse problems in computer vision, not on solving complex logical tasks or holistic Chain-of-Thought reasoning as defined in the topic. Thus, it shares the iterative aspect of diffusion but lacks the core element of multi-step logical reasoning.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02060",
      "title": "ReTabAD: A Benchmark for Restoring Semantic Context in Tabular Anomaly\n  Detection",
      "authors": [
        "Sanghyu Yoon",
        "Dongmin Kim",
        "Suhee Yoon",
        "Ye Seul Sim",
        "Seungdong Yoa",
        "Hye-Seung Cho",
        "Soonyoung Lee",
        "Hankook Lee",
        "Woohyung Lim"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "In tabular anomaly detection (AD), textual semantics often carry critical\nsignals, as the definition of an anomaly is closely tied to domain-specific\ncontext. However, existing benchmarks provide only raw data points without\nsemantic context, overlooking rich textual metadata such as feature\ndescriptions and domain knowledge that experts rely on in practice. This\nlimitation restricts research flexibility and prevents models from fully\nleveraging domain knowledge for detection. ReTabAD addresses this gap by\nrestoring textual semantics to enable context-aware tabular AD research. We\nprovide (1) 20 carefully curated tabular datasets enriched with structured\ntextual metadata, together with implementations of state-of-the-art AD\nalgorithms including classical, deep learning, and LLM-based approaches, and\n(2) a zero-shot LLM framework that leverages semantic context without\ntask-specific training, establishing a strong baseline for future research.\nFurthermore, this work provides insights into the role and utility of textual\nmetadata in AD through experiments and analysis. Results show that semantic\ncontext improves detection performance and enhances interpretability by\nsupporting domain-aware reasoning. These findings establish ReTabAD as a\nbenchmark for systematic exploration of context-aware AD.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02060v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02060v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.399,
      "weak_supervision_score": 0.39,
      "diffusion_reasoning_score": 0.386,
      "distributed_training_score": 0.341,
      "datasets_score": 0.469,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "Highly Relevant",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "The paper's main contribution is the introduction of ReTabAD, a new benchmark featuring 20 carefully curated tabular datasets enriched with textual metadata for anomaly detection in machine learning. This directly aligns with the topic, as it involves creating and curating datasets, establishing benchmark evaluations, and analyzing their utility in AI applications, such as improving detection performance and interpretability through semantic context.",
      "llm_score_status": "completed",
      "summary": "ReTabAD introduces a new benchmark for tabular anomaly detection that incorporates rich textual metadata to address the limitations of existing datasets, which overlook semantic context critical for accurate anomaly identification. The paper provides 20 curated datasets with structured textual information, implements various state-of-the-art algorithms including classical, deep learning, and LLM-based approaches, and proposes a zero-shot LLM framework that leverages this metadata to improve detection performance by an average of 7.6% in AUROC and enhance interpretability, thereby establishing a foundation for context-aware research in the field.",
      "novelty_score": "High",
      "novelty_justification": "The paper introduces a truly new benchmark that restores semantic context to tabular anomaly detection, significantly advancing the field by enabling models to leverage textual metadata in ways not previously possible in existing benchmarks. This represents a substantial innovation in how anomaly detection research is conducted and evaluated.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to be cited and built upon within the subfield of tabular anomaly detection, as it provides a new benchmark and insights into the benefits of semantic context, potentially influencing future LLM-based approaches. However, its influence may be limited to specific applications in AI and machine learning rather than broader commercial or interdisciplinary fields.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper represents a strong and valuable contribution by introducing a practical benchmark that advances context-aware anomaly detection, making it essential for researchers in the area to be aware of for future work. While highly relevant, it is not groundbreaking enough to be classified as must-read for all AI practitioners.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/4def30efc5d55357d6b44cafac20e3f2bd730c45",
      "total_authors": 9,
      "authors_found": 9,
      "highest_h_index": 2,
      "average_h_index": 1.1111111111111112,
      "notable_authors_count": 0,
      "author_h_indexes": [
        {
          "name": "Sanghyu Yoon",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2301172543"
        },
        {
          "name": "Dongmin Kim",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2355245809"
        },
        {
          "name": "Suhee Yoon",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2301177343"
        },
        {
          "name": "Ye Seul Sim",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2301158076"
        },
        {
          "name": "Seungdong Yoa",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2130163349"
        },
        {
          "name": "Hye-Seung Cho",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2301194314"
        },
        {
          "name": "Soonyoung Lee",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2384802933"
        },
        {
          "name": "Hankook Lee",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2363302283"
        },
        {
          "name": "Woohyung Lim",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2301158606"
        }
      ]
    },
    {
      "id": "2510.02069",
      "title": "Spec-Gloss Surfels and Normal-Diffuse Priors for Relightable Glossy\n  Objects",
      "authors": [
        "Georgios Kouros",
        "Minye Wu",
        "Tinne Tuytelaars"
      ],
      "categories": [
        "cs.GR (Graphics)",
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Accurate reconstruction and relighting of glossy objects remain a\nlongstanding challenge, as object shape, material properties, and illumination\nare inherently difficult to disentangle. Existing neural rendering approaches\noften rely on simplified BRDF models or parameterizations that couple diffuse\nand specular components, which restricts faithful material recovery and limits\nrelighting fidelity. We propose a relightable framework that integrates a\nmicrofacet BRDF with the specular-glossiness parameterization into 2D Gaussian\nSplatting with deferred shading. This formulation enables more physically\nconsistent material decomposition, while diffusion-based priors for surface\nnormals and diffuse color guide early-stage optimization and mitigate\nambiguity. A coarse-to-fine optimization of the environment map accelerates\nconvergence and preserves high-dynamic-range specular reflections. Extensive\nexperiments on complex, glossy scenes demonstrate that our method achieves\nhigh-quality geometry and material reconstruction, delivering substantially\nmore realistic and consistent relighting under novel illumination compared to\nexisting Gaussian splatting methods.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02069v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02069v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.34,
      "weak_supervision_score": 0.322,
      "diffusion_reasoning_score": 0.407,
      "distributed_training_score": 0.335,
      "datasets_score": 0.268,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Tangentially Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper incorporates diffusion-based priors for surface normals and diffuse color to guide optimization in object reconstruction and relighting, which involves generative elements from diffusion models. However, this usage is limited to visual and geometric tasks in rendering, not adapting diffusion for multi-step logical reasoning or solving complex logical tasks as a holistic Chain-of-Thought process.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02084",
      "title": "KAIROS: Unified Training for Universal Non-Autoregressive Time Series\n  Forecasting",
      "authors": [
        "Kuiye Ding",
        "Fanda Fan",
        "Zheya Wang",
        "Hongxiao Li",
        "Yifan Wang",
        "Lei Wang",
        "Chunjie Luo",
        "Jianfeng Zhan"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "In the World Wide Web, reliable time series forecasts provide the\nforward-looking signals that drive resource planning, cache placement, and\nanomaly response, enabling platforms to operate efficiently as user behavior\nand content distributions evolve. Compared with other domains, time series\nforecasting for Web applications requires much faster responsiveness to support\nreal-time decision making. We present KAIROS, a non-autoregressive time series\nforecasting framework that directly models segment-level multi-peak\ndistributions. Unlike autoregressive approaches, KAIROS avoids error\naccumulation and achieves just-in-time inference, while improving over existing\nnon-autoregressive models that collapse to over-smoothed predictions. Trained\non the large-scale corpus, KAIROS demonstrates strong zero-shot generalization\non six widely used benchmarks, delivering forecasting performance comparable to\nstate-of-the-art foundation models with similar scale, at a fraction of their\ninference cost. Beyond empirical results, KAIROS highlights the importance of\nnon-autoregressive design as a scalable paradigm for foundation models in time\nseries.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02084v2",
      "pdf_url": "http://arxiv.org/pdf/2510.02084v2",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.341,
      "weak_supervision_score": 0.324,
      "diffusion_reasoning_score": 0.362,
      "distributed_training_score": 0.426,
      "datasets_score": 0.308,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "Not Relevant",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "The paper's main contribution is the development of KAIROS, a non-autoregressive framework for time series forecasting, focusing on aspects like multi-peak distribution modeling, efficient inference, and specific architectural innovations such as mixture-of-experts and segment causal residual noise. It does not address distributed training, parallel computing, or strategies for partitioning data/computation across multiple nodes, which are central to this topic.",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02086",
      "title": "VGDM: Vision-Guided Diffusion Model for Brain Tumor Detection and\n  Segmentation",
      "authors": [
        "Arman Behnam"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Accurate detection and segmentation of brain tumors from magnetic resonance\nimaging (MRI) are essential for diagnosis, treatment planning, and clinical\nmonitoring. While convolutional architectures such as U-Net have long been the\nbackbone of medical image segmentation, their limited capacity to capture\nlong-range dependencies constrains performance on complex tumor structures.\nRecent advances in diffusion models have demonstrated strong potential for\ngenerating high-fidelity medical images and refining segmentation boundaries.\n  In this work, we propose VGDM: Vision-Guided Diffusion Model for Brain Tumor\nDetection and Segmentation framework, a transformer-driven diffusion framework\nfor brain tumor detection and segmentation. By embedding a vision transformer\nat the core of the diffusion process, the model leverages global contextual\nreasoning together with iterative denoising to enhance both volumetric accuracy\nand boundary precision. The transformer backbone enables more effective\nmodeling of spatial relationships across entire MRI volumes, while diffusion\nrefinement mitigates voxel-level errors and recovers fine-grained tumor\ndetails.\n  This hybrid design provides a pathway toward improved robustness and\nscalability in neuro-oncology, moving beyond conventional U-Net baselines.\nExperimental validation on MRI brain tumor datasets demonstrates consistent\ngains in Dice similarity and Hausdorff distance, underscoring the potential of\ntransformer-guided diffusion models to advance the state of the art in tumor\nsegmentation.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02086v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02086v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.284,
      "weak_supervision_score": 0.301,
      "diffusion_reasoning_score": 0.553,
      "distributed_training_score": 0.329,
      "datasets_score": 0.315,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on using a diffusion model integrated with a vision transformer for brain tumor detection and segmentation in MRI images, emphasizing iterative denoising for image refinement. However, it does not adapt the diffusion process for solving complex logical tasks or multi-step reasoning, such as treating a Chain-of-Thought as a single entity for holistic correction. The application is purely in computer vision and medical imaging, lacking any component for logical reasoning, which makes it unrelated to the specified topic.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02091",
      "title": "Demystifying the Roles of LLM Layers in Retrieval, Knowledge, and\n  Reasoning",
      "authors": [
        "Xinyuan Song",
        "Keyu Wang",
        "PengXiang Li",
        "Lu Yin",
        "Shiwei Liu"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Recent studies suggest that the deeper layers of Large Language Models (LLMs)\ncontribute little to representation learning and can often be removed without\nsignificant performance loss. However, such claims are typically drawn from\nnarrow evaluations and may overlook important aspects of model behavior. In\nthis work, we present a systematic study of depth utilization across diverse\ndimensions, including evaluation protocols, task categories, and model\narchitectures. Our analysis confirms that very deep layers are generally less\neffective than earlier ones, but their contributions vary substantially with\nthe evaluation setting. Under likelihood-based metrics without generation,\npruning most layers preserves performance, with only the initial few being\ncritical. By contrast, generation-based evaluation uncovers indispensable roles\nfor middle and deeper layers in enabling reasoning and maintaining long-range\ncoherence. We further find that knowledge and retrieval are concentrated in\nshallow components, whereas reasoning accuracy relies heavily on deeper layers\n-- yet can be reshaped through distillation. These results highlight that depth\nusage in LLMs is highly heterogeneous and context-dependent, underscoring the\nneed for task-, metric-, and model-aware perspectives in both interpreting and\ncompressing large models.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02091v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02091v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.392,
      "weak_supervision_score": 0.367,
      "diffusion_reasoning_score": 0.49,
      "distributed_training_score": 0.379,
      "datasets_score": 0.354,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper examines the contributions of different layers in Large Language Models (LLMs) for tasks like retrieval, knowledge, and reasoning, including aspects of Chain-of-Thought in reasoning. However, it does not involve diffusion models, iterative refinement processes, or any adaptation of diffusion techniques for multi-step logical reasoning. The focus is solely on LLM architecture and layer pruning, with no reference to diffusion-based methods.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02097",
      "title": "Mapping Historic Urban Footprints in France: Balancing Quality,\n  Scalability and AI Techniques",
      "authors": [
        "Walid Rabehi",
        "Marion Le Texier",
        "Rémi Lemoy"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Quantitative analysis of historical urban sprawl in France before the 1970s\nis hindered by the lack of nationwide digital urban footprint data. This study\nbridges this gap by developing a scalable deep learning pipeline to extract\nurban areas from the Scan Histo historical map series (1925-1950), which\nproduces the first open-access, national-scale urban footprint dataset for this\npivotal period. Our key innovation is a dual-pass U-Net approach designed to\nhandle the high radiometric and stylistic complexity of historical maps. The\nfirst pass, trained on an initial dataset, generates a preliminary map that\nidentifies areas of confusion, such as text and roads, to guide targeted data\naugmentation. The second pass uses a refined dataset and the binarized output\nof the first model to minimize radiometric noise, which significantly reduces\nfalse positives. Deployed on a high-performance computing cluster, our method\nprocesses 941 high-resolution tiles covering the entirety of metropolitan\nFrance. The final mosaic achieves an overall accuracy of 73%, effectively\ncapturing diverse urban patterns while overcoming common artifacts like labels\nand contour lines. We openly release the code, training datasets, and the\nresulting nationwide urban raster to support future research in long-term\nurbanization dynamics.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02097v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02097v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "extraction_failed",
      "embedding_status": "completed",
      "rlhf_score": 0.318,
      "weak_supervision_score": 0.316,
      "diffusion_reasoning_score": 0.317,
      "distributed_training_score": 0.324,
      "datasets_score": 0.364,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02100",
      "title": "When Tracking Fails: Analyzing Failure Modes of SAM2 for Point-Based\n  Tracking in Surgical Videos",
      "authors": [
        "Woowon Jang",
        "Jiwon Im",
        "Juseung Choi",
        "Niki Rashidian",
        "Wesley De Neve",
        "Utku Ozbulak"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Video object segmentation (VOS) models such as SAM2 offer promising zero-shot\ntracking capabilities for surgical videos using minimal user input. Among the\navailable input types, point-based tracking offers an efficient and low-cost\nalternative, yet its reliability and failure cases in complex surgical\nenvironments are not well understood. In this work, we systematically analyze\nthe failure modes of point-based tracking in laparoscopic cholecystectomy\nvideos. Focusing on three surgical targets, the gallbladder, grasper, and\nL-hook electrocautery, we compare the performance of point-based tracking with\nsegmentation mask initialization. Our results show that point-based tracking is\ncompetitive for surgical tools but consistently underperforms for anatomical\ntargets, where tissue similarity and ambiguous boundaries lead to failure.\nThrough qualitative analysis, we reveal key factors influencing tracking\noutcomes and provide several actionable recommendations for selecting and\nplacing tracking points to improve performance in surgical video analysis.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02100v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02100v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.288,
      "weak_supervision_score": 0.332,
      "diffusion_reasoning_score": 0.305,
      "distributed_training_score": 0.285,
      "datasets_score": 0.274,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02108",
      "title": "Unlocking Symbol-Level Precoding Efficiency Through Tensor Equivariant\n  Neural Network",
      "authors": [
        "Jinshuo Zhang",
        "Yafei Wang",
        "Xinping Yi",
        "Wenjin Wang",
        "Shi Jin",
        "Symeon Chatzinotas",
        "Björn Ottersten"
      ],
      "categories": [
        "eess.SP (Signal Processing)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Although symbol-level precoding (SLP) based on constructive interference (CI)\nexploitation offers performance gains, its high complexity remains a\nbottleneck. This paper addresses this challenge with an end-to-end deep\nlearning (DL) framework with low inference complexity that leverages the\nstructure of the optimal SLP solution in the closed-form and its inherent\ntensor equivariance (TE), where TE denotes that a permutation of the input\ninduces the corresponding permutation of the output. Building upon the\ncomputationally efficient model-based formulations, as well as their known\nclosed-form solutions, we analyze their relationship with linear precoding (LP)\nand investigate the corresponding optimality condition. We then construct a\nmapping from the problem formulation to the solution and prove its TE, based on\nwhich the designed networks reveal a specific parameter-sharing pattern that\ndelivers low computational complexity and strong generalization. Leveraging\nthese, we propose the backbone of the framework with an attention-based TE\nmodule, achieving linear computational complexity. Furthermore, we demonstrate\nthat such a framework is also applicable to imperfect CSI scenarios, where we\ndesign a TE-based network to map the CSI, statistics, and symbols to auxiliary\nvariables. Simulation results show that the proposed framework captures\nsubstantial performance gains of optimal SLP, while achieving an approximately\n80-times speedup over conventional methods and maintaining strong\ngeneralization across user numbers and symbol block lengths.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02108v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02108v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.313,
      "weak_supervision_score": 0.331,
      "diffusion_reasoning_score": 0.316,
      "distributed_training_score": 0.396,
      "datasets_score": 0.265,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02109",
      "title": "SpurBreast: A Curated Dataset for Investigating Spurious Correlations in\n  Real-world Breast MRI Classification",
      "authors": [
        "Jong Bum Won",
        "Wesley De Neve",
        "Joris Vankerschaver",
        "Utku Ozbulak"
      ],
      "categories": [
        "eess.IV (Image and Video Processing)",
        "cs.AI (Artificial Intelligence)",
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Deep neural networks (DNNs) have demonstrated remarkable success in medical\nimaging, yet their real-world deployment remains challenging due to spurious\ncorrelations, where models can learn non-clinical features instead of\nmeaningful medical patterns. Existing medical imaging datasets are not designed\nto systematically study this issue, largely due to restrictive licensing and\nlimited supplementary patient data. To address this gap, we introduce\nSpurBreast, a curated breast MRI dataset that intentionally incorporates\nspurious correlations to evaluate their impact on model performance. Analyzing\nover 100 features involving patient, device, and imaging protocol, we identify\ntwo dominant spurious signals: magnetic field strength (a global feature\ninfluencing the entire image) and image orientation (a local feature affecting\nspatial alignment). Through controlled dataset splits, we demonstrate that DNNs\ncan exploit these non-clinical signals, achieving high validation accuracy\nwhile failing to generalize to unbiased test data. Alongside these two datasets\ncontaining spurious correlations, we also provide benchmark datasets without\nspurious correlations, allowing researchers to systematically investigate\nclinically relevant and irrelevant features, uncertainty estimation,\nadversarial robustness, and generalization strategies. Models and datasets are\navailable at https://github.com/utkuozbulak/spurbreast.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02109v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02109v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.262,
      "weak_supervision_score": 0.383,
      "diffusion_reasoning_score": 0.295,
      "distributed_training_score": 0.332,
      "datasets_score": 0.434,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "Highly Relevant",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "The paper's main contribution is the introduction and analysis of a new dataset, SpurBreast, specifically designed for machine learning applications in medical imaging. It covers dataset creation by curating real-world breast MRI data with intentional spurious correlations, analysis of features like magnetic field strength and image orientation, and benchmarking through controlled splits and performance evaluations. This directly aligns with research on creating, analyzing, and benchmarking datasets for AI.",
      "llm_score_status": "completed",
      "summary": "The paper introduces SpurBreast, a curated dataset of real-world breast MRI images designed to investigate spurious correlations that cause deep neural networks to learn irrelevant features instead of clinically meaningful patterns. By analyzing over 100 features and identifying dominant spurious signals like magnetic field strength and image orientation, the authors demonstrate how models achieve high validation accuracy by exploiting these signals but fail to generalize on unbiased test data, while also providing benchmark datasets without spurious correlations to support research on robustness, uncertainty estimation, and generalization strategies.",
      "novelty_score": "High",
      "novelty_justification": "The paper introduces a truly new dataset specifically tailored for studying spurious correlations in medical imaging, which addresses a significant gap in existing resources and advances the state-of-the-art by enabling systematic investigation of these issues.",
      "impact_score": "High",
      "impact_justification": "The work provides a specialized dataset that could influence a wide range of future research in AI for medical imaging, particularly in developing more robust models that generalize better in clinical settings and reduce biases.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper represents a high-quality contribution by offering a valuable resource for researchers focused on AI robustness in healthcare, making it essential for those working on medical imaging datasets and model generalization.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/b319a98e433f4b278150464ea04e7ba334d4e0f3",
      "total_authors": 4,
      "authors_found": 4,
      "highest_h_index": 26,
      "average_h_index": 12.25,
      "notable_authors_count": 3,
      "author_h_indexes": [
        {
          "name": "Jong Bum Won",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2342694245"
        },
        {
          "name": "W. D. Neve",
          "h_index": 26,
          "profile_url": "https://www.semanticscholar.org/author/7627712"
        },
        {
          "name": "J. Vankerschaver",
          "h_index": 15,
          "profile_url": "https://www.semanticscholar.org/author/2794885"
        },
        {
          "name": "Utku Ozbulak",
          "h_index": 7,
          "profile_url": "https://www.semanticscholar.org/author/51963928"
        }
      ]
    },
    {
      "id": "2510.02114",
      "title": "FRIEREN: Federated Learning with Vision-Language Regularization for\n  Segmentation",
      "authors": [
        "Ding-Ruei Shen"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Federeated Learning (FL) offers a privacy-preserving solution for Semantic\nSegmentation (SS) tasks to adapt to new domains, but faces significant\nchallenges from these domain shifts, particularly when client data is\nunlabeled. However, most existing FL methods unrealistically assume access to\nlabeled data on remote clients or fail to leverage the power of modern Vision\nFoundation Models (VFMs). Here, we propose a novel and challenging task,\nFFREEDG, in which a model is pretrained on a server's labeled source dataset\nand subsequently trained across clients using only their unlabeled data,\nwithout ever re-accessing the source. To solve FFREEDG, we propose FRIEREN, a\nframework that leverages the knowledge of a VFM by integrating vision and\nlanguage modalities. Our approach employs a Vision-Language decoder guided by\nCLIP-based text embeddings to improve semantic disambiguation and uses a\nweak-to-strong consistency learning strategy for robust local training on\npseudo-labels. Our experiments on synthetic-to-real and\nclear-to-adverse-weather benchmarks demonstrate that our framework effectively\ntackles this new task, achieving competitive performance against established\ndomain generalization and adaptation methods and setting a strong baseline for\nfuture research.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02114v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02114v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.429,
      "weak_supervision_score": 0.422,
      "diffusion_reasoning_score": 0.406,
      "distributed_training_score": 0.436,
      "datasets_score": 0.351,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "Moderately Relevant",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "Highly Relevant",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on Federated Learning for Semantic Segmentation using Vision-Language models, with no mention of human feedback, reward models, or reinforcement learning techniques. It relies on unsupervised training and pseudo-labels, not human-ranked data for alignment.",
      "weak_supervision_justification": "The paper employs pseudo-labels generated from weak-to-strong augmentation and unsupervised training on client data, which aligns with weak supervision by using noisy or programmatically derived labels. However, the primary focus is on Federated Learning and Vision-Language integration, not solely on weak supervision techniques.",
      "diffusion_reasoning_justification": "The paper does not involve diffusion models or iterative refinement for multi-step logical reasoning. It centers on Vision-Language models like CLIP for semantic segmentation in a Federated Learning context, with no components for holistic Chain-of-Thought correction.",
      "distributed_training_justification": "The paper's core contribution is Federated Learning, a distributed training paradigm, where models are trained across multiple clients without sharing data, involving aggregation of updates and handling domain shifts, directly aligning with distributed training concepts.",
      "datasets_justification": "below_threshold",
      "llm_score_status": "completed",
      "summary": "This paper introduces FFREEDG, a novel federated learning task for semantic segmentation that pretrains a model on a server's labeled data and then adapts it to clients' unlabeled data without re-accessing the source, addressing privacy concerns in domains like autonomous driving. The proposed FRIEREN framework leverages Vision Foundation Models, such as CLIP, by integrating vision-language modalities for semantic disambiguation and employing weak-to-strong consistency learning on pseudo-labels, resulting in competitive performance on benchmarks like synthetic-to-real and clear-to-adverse-weather scenarios, thus setting a strong baseline for future research in unsupervised federated learning.",
      "novelty_score": "High",
      "novelty_justification": "The paper introduces a truly new task, FFREEDG, and a novel framework, FRIEREN, that combines federated learning with vision-language regularization for unsupervised domain generalization, significantly advancing the state-of-the-art in privacy-preserving semantic segmentation.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to be cited and built upon in subfields of federated learning and computer vision, particularly for applications requiring privacy like autonomous driving, though its influence may be limited to specific domains rather than widespread commercial applications.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper presents a high-quality contribution with innovative ideas and empirical validation that is valuable for researchers in federated learning and vision-language models, making it essential for those working in privacy-preserving AI.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/f14c75cdebc2a7fc68432800bf180749debad148",
      "total_authors": 1,
      "authors_found": 1,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": [
        {
          "name": "Ding-Ruei Shen",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383304142"
        }
      ]
    },
    {
      "id": "2510.02120",
      "title": "VarCoNet: A variability-aware self-supervised framework for functional\n  connectome extraction from resting-state fMRI",
      "authors": [
        "Charalampos Lamprou",
        "Aamna Alshehhi",
        "Leontios J. Hadjileontiadis",
        "Mohamed L. Seghier"
      ],
      "categories": [
        "cs.NE (Neural and Evolutionary Computing)",
        "cs.AI (Artificial Intelligence)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "Accounting for inter-individual variability in brain function is key to\nprecision medicine. Here, by considering functional inter-individual\nvariability as meaningful data rather than noise, we introduce VarCoNet, an\nenhanced self-supervised framework for robust functional connectome (FC)\nextraction from resting-state fMRI (rs-fMRI) data. VarCoNet employs\nself-supervised contrastive learning to exploit inherent functional\ninter-individual variability, serving as a brain function encoder that\ngenerates FC embeddings readily applicable to downstream tasks even in the\nabsence of labeled data. Contrastive learning is facilitated by a novel\naugmentation strategy based on segmenting rs-fMRI signals. At its core,\nVarCoNet integrates a 1D-CNN-Transformer encoder for advanced time-series\nprocessing, enhanced with a robust Bayesian hyperparameter optimization. Our\nVarCoNet framework is evaluated on two downstream tasks: (i) subject\nfingerprinting, using rs-fMRI data from the Human Connectome Project, and (ii)\nautism spectrum disorder (ASD) classification, using rs-fMRI data from the\nABIDE I and ABIDE II datasets. Using different brain parcellations, our\nextensive testing against state-of-the-art methods, including 13 deep learning\nmethods, demonstrates VarCoNet's superiority, robustness, interpretability, and\ngeneralizability. Overall, VarCoNet provides a versatile and robust framework\nfor FC analysis in rs-fMRI.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02120v2",
      "pdf_url": "http://arxiv.org/pdf/2510.02120v2",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.344,
      "weak_supervision_score": 0.344,
      "diffusion_reasoning_score": 0.374,
      "distributed_training_score": 0.341,
      "datasets_score": 0.322,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02125",
      "title": "Do AI Models Perform Human-like Abstract Reasoning Across Modalities?",
      "authors": [
        "Claas Beger",
        "Ryan Yi",
        "Shuhao Fu",
        "Arseny Moskvichev",
        "Sarah W. Tsai",
        "Sivasankaran Rajamanickam",
        "Melanie Mitchell"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)",
        "cs.CL (Computation and Language)"
      ],
      "abstract": "OpenAI's o3-preview reasoning model exceeded human accuracy on the ARC-AGI\nbenchmark, but does that mean state-of-the-art models recognize and reason with\nthe abstractions that the task creators intended? We investigate models'\nabstraction abilities on ConceptARC. We evaluate models under settings that\nvary the input modality (textual vs. visual), whether the model is permitted to\nuse external Python tools, and, for reasoning models, the amount of reasoning\neffort. In addition to measuring output accuracy, we perform fine-grained\nevaluation of the natural-language rules that models generate to explain their\nsolutions. This dual evaluation lets us assess whether models solve tasks using\nthe abstractions ConceptARC was designed to elicit, rather than relying on\nsurface-level patterns. Our results show that, while some models using\ntext-based representations match human output accuracy, the best models' rules\nare often based on surface-level ``shortcuts'' and capture intended\nabstractions far less often than humans. Thus their capabilities for general\nabstract reasoning may be overestimated by evaluations based on accuracy alone.\nIn the visual modality, AI models' output accuracy drops sharply, yet our\nrule-level analysis reveals that models might be underestimated, as they still\nexhibit a substantial share of rules that capture intended abstractions, but\nare often unable to correctly apply these rules. In short, our results show\nthat models still lag humans in abstract reasoning, and that using accuracy\nalone to evaluate abstract reasoning on ARC-like tasks may overestimate\nabstract-reasoning capabilities in textual modalities and underestimate it in\nvisual modalities. We believe that our evaluation framework offers a more\nfaithful picture of multimodal models' abstract reasoning abilities and a more\nprincipled way to track progress toward human-like, abstraction-centered\nintelligence.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02125v3",
      "pdf_url": "http://arxiv.org/pdf/2510.02125v3",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.411,
      "weak_supervision_score": 0.353,
      "diffusion_reasoning_score": 0.535,
      "distributed_training_score": 0.334,
      "datasets_score": 0.372,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper evaluates AI models' abstract reasoning on benchmarks like ARC and ConceptARC, focusing on performance across modalities and rule generation, but does not discuss or involve training methods such as RLHF, which specifically pertains to aligning models with human preferences through reward models and reinforcement learning.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper investigates general abstract reasoning abilities in AI models without referencing diffusion-based processes, iterative refinement for logical tasks, or treating reasoning paths as entities for correction, as required for this topic.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02128",
      "title": "The Disparate Impacts of Speculative Decoding",
      "authors": [
        "Jameson Sandler",
        "Ahmet Üstün",
        "Marco Romanelli",
        "Sara Hooker",
        "Ferdinando Fioretto"
      ],
      "categories": [
        "cs.CL (Computation and Language)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "The practice of speculative decoding, whereby inference is probabilistically\nsupported by a smaller, cheaper, ``drafter'' model, has become a standard\ntechnique for systematically reducing the decoding time of large language\nmodels. This paper conducts an analysis of speculative decoding through the\nlens of its potential disparate speed-up rates across tasks. Crucially, the\npaper shows that speed-up gained from speculative decoding is not uniformly\ndistributed across tasks, consistently diminishing for under-fit, and often\nunderrepresented tasks. To better understand this phenomenon, we derive an\nanalysis to quantify this observed ``unfairness'' and draw attention to the\nfactors that motivate such disparate speed-ups to emerge. Further, guided by\nthese insights, the paper proposes a mitigation strategy designed to reduce\nspeed-up disparities and validates the approach across several model pairs,\nrevealing on average a 12% improvement in our fairness metric.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02128v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02128v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.401,
      "weak_supervision_score": 0.384,
      "diffusion_reasoning_score": 0.455,
      "distributed_training_score": 0.468,
      "datasets_score": 0.351,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "Not Relevant",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on speculative decoding for inference speed-up in language models, analyzing disparities in acceleration across tasks, without any mention of human feedback, reward models, or reinforcement learning techniques.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper discusses speculative decoding as a method for accelerating inference through drafter and verifier models, but it does not involve diffusion-based processes, iterative refinement for logical reasoning, or multi-step chain-of-thought corrections.",
      "distributed_training_justification": "The paper examines inference techniques like speculative decoding to reduce decoding time, rather than algorithms or systems for distributed training, parallel computing, or accelerating model training across nodes.",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02133",
      "title": "FlexDoc: Parameterized Sampling for Diverse Multilingual Synthetic\n  Documents for Training Document Understanding Models",
      "authors": [
        "Karan Dua",
        "Hitesh Laxmichand Patel",
        "Puneet Mittal",
        "Ranjeet Gupta",
        "Amit Agarwal",
        "Praneet Pabolu",
        "Srikant Panda",
        "Hansa Meghwani",
        "Graham Horwood",
        "Fahad Shah"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "Developing document understanding models at enterprise scale requires large,\ndiverse, and well-annotated datasets spanning a wide range of document types.\nHowever, collecting such data is prohibitively expensive due to privacy\nconstraints, legal restrictions, and the sheer volume of manual annotation\nneeded - costs that can scale into millions of dollars. We introduce FlexDoc, a\nscalable synthetic data generation framework that combines Stochastic Schemas\nand Parameterized Sampling to produce realistic, multilingual semi-structured\ndocuments with rich annotations. By probabilistically modeling layout patterns,\nvisual structure, and content variability, FlexDoc enables the controlled\ngeneration of diverse document variants at scale. Experiments on Key\nInformation Extraction (KIE) tasks demonstrate that FlexDoc-generated data\nimproves the absolute F1 Score by up to 11% when used to augment real datasets,\nwhile reducing annotation effort by over 90% compared to traditional\nhard-template methods. The solution is in active deployment, where it has\naccelerated the development of enterprise-grade document understanding models\nwhile significantly reducing data acquisition and annotation costs.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02133v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02133v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.364,
      "weak_supervision_score": 0.441,
      "diffusion_reasoning_score": 0.419,
      "distributed_training_score": 0.395,
      "datasets_score": 0.416,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "Highly Relevant",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "Highly Relevant",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "The paper's main contribution, FlexDoc, involves programmatically generating large quantities of annotated synthetic data to train document understanding models, aligning directly with weak supervision. By using Stochastic Schemas and Parameterized Sampling to create labels automatically, it reduces reliance on hand-labeled data, mirroring weak supervision's approach of deriving labels from high-level sources while improving model performance by up to 11% in F1 scores.",
      "diffusion_reasoning_justification": "The paper focuses on synthetic data generation for document understanding using techniques like Stochastic Schemas and Parameterized Sampling, with no mention of diffusion models, iterative refinement processes, or multi-step logical reasoning. There is no component involving Chain-of-Thought or holistic correction in a diffusion framework.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "The paper introduces FlexDoc as a framework for creating scalable, diverse, and annotated synthetic datasets for document understanding, including methodologies for generation and evaluation. It analyzes the datasets' impact through experiments showing F1 score improvements and cost reductions, directly contributing to dataset creation, curation, and benchmarking in AI applications.",
      "llm_score_status": "completed",
      "summary": "The paper introduces FlexDoc, a scalable framework for generating diverse, multilingual synthetic documents using Stochastic Schemas and Parameterized Sampling, addressing the challenges of acquiring large annotated datasets for training document understanding models. By probabilistically modeling layout, visual structure, and content variability, FlexDoc produces realistic documents with accurate annotations, leading to up to an 11% improvement in F1 scores for Key Information Extraction tasks and a 90% reduction in annotation effort compared to traditional methods, while ensuring privacy and enabling enterprise deployment.",
      "novelty_score": "High",
      "novelty_justification": "The paper introduces a novel algorithm, Parameterized Sampling with Stochastic Schemas, and a Dynamic Virtual Grid Algorithm, which significantly advance synthetic data generation for document understanding by enabling diverse, scalable creation beyond existing hard-template methods.",
      "impact_score": "High",
      "impact_justification": "The work has the potential to influence a wide range of AI research and commercial applications in document processing by reducing data acquisition costs and improving model performance, as evidenced by its active deployment in enterprises.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper presents a high-quality, practical contribution that advances synthetic data generation for AI, making it essential for researchers and practitioners in document understanding to be aware of its innovations and real-world benefits.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/072edae84d4150536c63dd2a6775828bb576f535",
      "total_authors": 10,
      "authors_found": 10,
      "highest_h_index": 6,
      "average_h_index": 2.0,
      "notable_authors_count": 2,
      "author_h_indexes": [
        {
          "name": "Karan Dua",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2375411679"
        },
        {
          "name": "Hitesh Laxmichand Patel",
          "h_index": 6,
          "profile_url": "https://www.semanticscholar.org/author/2304458545"
        },
        {
          "name": "Puneet Mittal",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2375431069"
        },
        {
          "name": "Ranjeet Gupta",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2375904608"
        },
        {
          "name": "Amit Agarwal",
          "h_index": 6,
          "profile_url": "https://www.semanticscholar.org/author/2332505408"
        },
        {
          "name": "Praneet Pabolu",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383303009"
        },
        {
          "name": "Srikant Panda",
          "h_index": 4,
          "profile_url": "https://www.semanticscholar.org/author/2333872944"
        },
        {
          "name": "Hansa Meghwani",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2329183626"
        },
        {
          "name": "Graham Horwood",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383303687"
        },
        {
          "name": "Fahad Shah",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383303423"
        }
      ]
    },
    {
      "id": "2510.02139",
      "title": "BioinfoMCP: A Unified Platform Enabling MCP Interfaces in Agentic\n  Bioinformatics",
      "authors": [
        "Florensia Widjaja",
        "Zhangtianyi Chen",
        "Juexiao Zhou"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)",
        "cs.LG (Machine Learning)",
        "cs.MA (Multiagent Systems)"
      ],
      "abstract": "Bioinformatics tools are essential for complex computational biology tasks,\nyet their integration with emerging AI-agent frameworks is hindered by\nincompatible interfaces, heterogeneous input-output formats, and inconsistent\nparameter conventions. The Model Context Protocol (MCP) provides a standardized\nframework for tool-AI communication, but manually converting hundreds of\nexisting and rapidly growing specialized bioinformatics tools into\nMCP-compliant servers is labor-intensive and unsustainable. Here, we present\nBioinfoMCP, a unified platform comprising two components: BioinfoMCP Converter,\nwhich automatically generates robust MCP servers from tool documentation using\nlarge language models, and BioinfoMCP Benchmark, which systematically validates\nthe reliability and versatility of converted tools across diverse computational\ntasks. We present a platform of 38 MCP-converted bioinformatics tools,\nextensively validated to show that 94.7% successfully executed complex\nworkflows across three widely used AI-agent platforms. By removing technical\nbarriers to AI automation, BioinfoMCP enables natural-language interaction with\nsophisticated bioinformatics analyses without requiring extensive programming\nexpertise, offering a scalable path to intelligent, interoperable computational\nbiology.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02139v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02139v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.282,
      "weak_supervision_score": 0.271,
      "diffusion_reasoning_score": 0.294,
      "distributed_training_score": 0.309,
      "datasets_score": 0.267,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02143",
      "title": "How to Find Fantastic Papers: Self-Rankings as a Powerful Predictor of\n  Scientific Impact Beyond Peer Review",
      "authors": [
        "Buxin Su",
        "Natalie Collina",
        "Garrett Wen",
        "Didong Li",
        "Kyunghyun Cho",
        "Jianqing Fan",
        "Bingxin Zhao",
        "Weijie Su"
      ],
      "categories": [
        "stat.AP (Applications)",
        "cs.AI (Artificial Intelligence)",
        "cs.DL (Digital Libraries)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "Peer review in academic research aims not only to ensure factual correctness\nbut also to identify work of high scientific potential that can shape future\nresearch directions. This task is especially critical in fast-moving fields\nsuch as artificial intelligence (AI), yet it has become increasingly difficult\ngiven the rapid growth of submissions. In this paper, we investigate an\nunderexplored measure for identifying high-impact research: authors' own\nrankings of their multiple submissions to the same AI conference. Grounded in\ngame-theoretic reasoning, we hypothesize that self-rankings are informative\nbecause authors possess unique understanding of their work's conceptual depth\nand long-term promise. To test this hypothesis, we conducted a large-scale\nexperiment at a leading AI conference, where 1,342 researchers self-ranked\ntheir 2,592 submissions by perceived quality. Tracking outcomes over more than\na year, we found that papers ranked highest by their authors received twice as\nmany citations as their lowest-ranked counterparts; self-rankings were\nespecially effective at identifying highly cited papers (those with over 150\ncitations). Moreover, we showed that self-rankings outperformed peer review\nscores in predicting future citation counts. Our results remained robust after\naccounting for confounders such as preprint posting time and self-citations.\nTogether, these findings demonstrate that authors' self-rankings provide a\nreliable and valuable complement to peer review for identifying and elevating\nhigh-impact research in AI.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02143v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02143v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.386,
      "weak_supervision_score": 0.348,
      "diffusion_reasoning_score": 0.33,
      "distributed_training_score": 0.29,
      "datasets_score": 0.375,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02153",
      "title": "Human-Robo-advisor collaboration in decision-making: Evidence from a\n  multiphase mixed methods experimental study",
      "authors": [
        "Hasan Mahmud",
        "Najmul Islam",
        "Satish Krishnan"
      ],
      "categories": [
        "cs.HC (Human-Computer Interaction)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Robo-advisors (RAs) are cost-effective, bias-resistant alternatives to human\nfinancial advisors, yet adoption remains limited. While prior research has\nexamined user interactions with RAs, less is known about how individuals\ninterpret RA roles and integrate their advice into decision-making. To address\nthis gap, this study employs a multiphase mixed methods design integrating a\nbehavioral experiment (N = 334), thematic analysis, and follow-up quantitative\ntesting. Findings suggest that people tend to rely on RAs, with reliance shaped\nby information about RA performance and the framing of advice as gains or\nlosses. Thematic analysis reveals three RA roles in decision-making and four\nuser types, each reflecting distinct patterns of advice integration. In\naddition, a 2 x 2 typology categorizes antecedents of acceptance into enablers\nand inhibitors at both the individual and algorithmic levels. By combining\nbehavioral, interpretive, and confirmatory evidence, this study advances\nunderstanding of human-RA collaboration and provides actionable insights for\ndesigning more trustworthy and adaptive RA systems.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02153v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02153v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "extraction_failed",
      "embedding_status": "completed",
      "rlhf_score": 0.479,
      "weak_supervision_score": 0.339,
      "diffusion_reasoning_score": 0.336,
      "distributed_training_score": 0.258,
      "datasets_score": 0.303,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper investigates human interaction and decision-making with Robo-advisors through experiments and analysis, focusing on user reliance and advice integration. However, it does not involve training or fine-tuning AI models using human feedback, such as creating a reward model or applying reinforcement learning, which are essential elements of RLHF. Therefore, the paper's contributions are unrelated to this topic.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02155",
      "title": "Unlocking Vision-Language Models for Video Anomaly Detection via\n  Fine-Grained Prompting",
      "authors": [
        "Shu Zou",
        "Xinyu Tian",
        "Lukas Wesemann",
        "Fabian Waschkowski",
        "Zhaoyuan Yang",
        "Jing Zhang"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Prompting has emerged as a practical way to adapt frozen vision-language\nmodels (VLMs) for video anomaly detection (VAD). Yet, existing prompts are\noften overly abstract, overlooking the fine-grained human-object interactions\nor action semantics that define complex anomalies in surveillance videos. We\npropose ASK-Hint, a structured prompting framework that leverages\naction-centric knowledge to elicit more accurate and interpretable reasoning\nfrom frozen VLMs. Our approach organizes prompts into semantically coherent\ngroups (e.g. violence, property crimes, public safety) and formulates\nfine-grained guiding questions that align model predictions with discriminative\nvisual cues. Extensive experiments on UCF-Crime and XD-Violence show that\nASK-Hint consistently improves AUC over prior baselines, achieving\nstate-of-the-art performance compared to both fine-tuned and training-free\nmethods. Beyond accuracy, our framework provides interpretable reasoning traces\ntowards anomaly and demonstrates strong generalization across datasets and VLM\nbackbones. These results highlight the critical role of prompt granularity and\nestablish ASK-Hint as a new training-free and generalizable solution for\nexplainable video anomaly detection.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02155v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02155v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.404,
      "weak_supervision_score": 0.37,
      "diffusion_reasoning_score": 0.436,
      "distributed_training_score": 0.317,
      "datasets_score": 0.314,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on designing fine-grained prompts for frozen vision-language models in video anomaly detection, without any involvement of human feedback, reward models, or reinforcement learning techniques for model alignment or fine-tuning.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper employs structured prompting to enhance reasoning in vision-language models for video anomaly detection, but it does not incorporate diffusion models, iterative refinement processes, or multi-step logical reasoning as described in diffusion-based approaches.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02161",
      "title": "Comparing Contrastive and Triplet Loss: Variance Analysis and\n  Optimization Behavior",
      "authors": [
        "Donghuo Zeng"
      ],
      "categories": [
        "cs.MM (Multimedia)",
        "cs.AI (Artificial Intelligence)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "Contrastive loss and triplet loss are widely used objectives in deep metric\nlearning, yet their effects on representation quality remain insufficiently\nunderstood. We present a theoretical and empirical comparison of these losses,\nfocusing on intra- and inter-class variance and optimization behavior (e.g.,\ngreedy updates). Through task-specific experiments with consistent settings on\nsynthetic data and real datasets-MNIST, CIFAR-10-it is shown that triplet loss\npreserves greater variance within and across classes, supporting finer-grained\ndistinctions in the learned representations. In contrast, contrastive loss\ntends to compact intra-class embeddings, which may obscure subtle semantic\ndifferences. To better understand their optimization dynamics, By examining\nloss-decay rate, active ratio, and gradient norm, we find that contrastive loss\ndrives many small updates early on, while triplet loss produces fewer but\nstronger updates that sustain learning on hard examples. Finally, across both\nclassification and retrieval tasks on MNIST, CIFAR-10, CUB-200, and CARS196\ndatasets, our results consistently show that triplet loss yields superior\nperformance, which suggests using triplet loss for detail retention and\nhard-sample focus, and contrastive loss for smoother, broad-based embedding\nrefinement.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02161v2",
      "pdf_url": "http://arxiv.org/pdf/2510.02161v2",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.334,
      "weak_supervision_score": 0.334,
      "diffusion_reasoning_score": 0.327,
      "distributed_training_score": 0.366,
      "datasets_score": 0.347,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02166",
      "title": "SIEVE: Towards Verifiable Certification for Code-datasets",
      "authors": [
        "Fatou Ndiaye Mbodji",
        "El-hacen Diallo",
        "Jordan Samhi",
        "Kui Liu",
        "Jacques Klein",
        "Tegawendé F. Bissyande"
      ],
      "categories": [
        "cs.SE (Software Engineering)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Code agents and empirical software engineering rely on public code datasets,\nyet these datasets lack verifiable quality guarantees. Static 'dataset cards'\ninform, but they are neither auditable nor do they offer statistical\nguarantees, making it difficult to attest to dataset quality. Teams build\nisolated, ad-hoc cleaning pipelines. This fragments effort and raises cost. We\npresent SIEVE, a community-driven framework. It turns per-property checks into\nConfidence Cards-machine-readable, verifiable certificates with anytime-valid\nstatistical bounds. We outline a research plan to bring SIEVE to maturity,\nreplacing narrative cards with anytime-verifiable certification. This shift is\nexpected to lower quality-assurance costs and increase trust in code-datasets.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02166v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02166v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.275,
      "weak_supervision_score": 0.367,
      "diffusion_reasoning_score": 0.276,
      "distributed_training_score": 0.273,
      "datasets_score": 0.469,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "Highly Relevant",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "The paper's main contribution is the introduction of SIEVE, a framework for verifiable certification of code datasets, which focuses on analyzing and ensuring the quality of datasets used in AI and machine learning applications. This directly aligns with dataset analysis, curation methodologies, and evaluation, as SIEVE provides statistical guarantees and community-driven validation for code datasets, enhancing trust and reproducibility in AI contexts.",
      "llm_score_status": "completed",
      "summary": "The paper introduces SIEVE, a community-driven framework designed to provide verifiable certification for code datasets by converting per-property checks into machine-readable Confidence Cards that include anytime-valid statistical bounds. It addresses the shortcomings of static dataset cards and fragmented cleaning pipelines by outlining a research plan to develop these certificates, aiming to reduce quality-assurance costs, enhance trust in datasets, and promote reproducibility in code agents and empirical software engineering.",
      "novelty_score": "Moderate",
      "novelty_justification": "The paper presents a notable improvement by combining existing ideas like statistical guarantees and machine-readable certificates into a new community-driven framework for code dataset certification, advancing quality assurance practices without introducing an entirely novel problem or technique.",
      "impact_score": "Moderate",
      "impact_justification": "The work could enhance trust and reproducibility in code datasets within software engineering and AI subfields, potentially leading to more standardized practices and citations, though its broader influence depends on the successful maturation of the proposed framework.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper provides a valuable and innovative proposal for improving dataset quality assurance, making it essential for researchers in software engineering and AI to be aware of its potential benefits and research plan.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/54bb2b24042f679f5ce4a4c9a116ab96857f09cc",
      "total_authors": 6,
      "authors_found": 6,
      "highest_h_index": 46,
      "average_h_index": 10.166666666666666,
      "notable_authors_count": 2,
      "author_h_indexes": [
        {
          "name": "Fatou Ndiaye Mbodji",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/1580498698"
        },
        {
          "name": "El-hacen Diallo",
          "h_index": 4,
          "profile_url": "https://www.semanticscholar.org/author/1606344476"
        },
        {
          "name": "Jordan Samhi",
          "h_index": 8,
          "profile_url": "https://www.semanticscholar.org/author/1753394319"
        },
        {
          "name": "Kui Liu",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2375103471"
        },
        {
          "name": "Jacques Klein",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2300287181"
        },
        {
          "name": "Tégawendé F. Bissyandé",
          "h_index": 46,
          "profile_url": "https://www.semanticscholar.org/author/3023999"
        }
      ]
    },
    {
      "id": "2510.02171",
      "title": "Go witheFlow: Real-time Emotion Driven Audio Effects Modulation",
      "authors": [
        "Edmund Dervakos",
        "Spyridon Kantarelis",
        "Vassilis Lyberatos",
        "Jason Liartis",
        "Giorgos Stamou"
      ],
      "categories": [
        "cs.SD (Sound)",
        "cs.AI (Artificial Intelligence)",
        "eess.AS (Audio and Speech Processing)"
      ],
      "abstract": "Music performance is a distinctly human activity, intrinsically linked to the\nperformer's ability to convey, evoke, or express emotion. Machines cannot\nperform music in the human sense; they can produce, reproduce, execute, or\nsynthesize music, but they lack the capacity for affective or emotional\nexperience. As such, music performance is an ideal candidate through which to\nexplore aspects of collaboration between humans and machines. In this paper, we\nintroduce the witheFlow system, designed to enhance real-time music performance\nby automatically modulating audio effects based on features extracted from both\nbiosignals and the audio itself. The system, currently in a proof-of-concept\nphase, is designed to be lightweight, able to run locally on a laptop, and is\nopen-source given the availability of a compatible Digital Audio Workstation\nand sensors.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02171v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02171v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.421,
      "weak_supervision_score": 0.314,
      "diffusion_reasoning_score": 0.379,
      "distributed_training_score": 0.282,
      "datasets_score": 0.309,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper introduces the witheFlow system, which uses lightweight machine learning models and rule-based AI to modulate audio effects in real-time based on biosignals and audio features. Its main contribution focuses on enhancing human-AI collaboration in music performance through emotional and physiological feedback, without any mention of reinforcement learning, human-ranked data for training a reward model, or fine-tuning via reinforcement learning. Therefore, it does not align with the specific definition of Reinforcement Learning from Human Feedback.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02173",
      "title": "Learning to Reason for Hallucination Span Detection",
      "authors": [
        "Hsuan Su",
        "Ting-Yao Hu",
        "Hema Swetha Koppula",
        "Kundan Krishna",
        "Hadi Pouransari",
        "Cheng-Yu Hsieh",
        "Cem Koc",
        "Joseph Yitan Cheng",
        "Oncel Tuzel",
        "Raviteja Vemulapalli"
      ],
      "categories": [
        "cs.CL (Computation and Language)",
        "cs.AI (Artificial Intelligence)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "Large language models (LLMs) often generate hallucinations -- unsupported\ncontent that undermines reliability. While most prior works frame hallucination\ndetection as a binary task, many real-world applications require identifying\nhallucinated spans, which is a multi-step decision making process. This\nnaturally raises the question of whether explicit reasoning can help the\ncomplex task of detecting hallucination spans. To answer this question, we\nfirst evaluate pretrained models with and without Chain-of-Thought (CoT)\nreasoning, and show that CoT reasoning has the potential to generate at least\none correct answer when sampled multiple times. Motivated by this, we propose\nRL4HS, a reinforcement learning framework that incentivizes reasoning with a\nspan-level reward function. RL4HS builds on Group Relative Policy Optimization\nand introduces Class-Aware Policy Optimization to mitigate reward imbalance\nissue. Experiments on the RAGTruth benchmark (summarization, question\nanswering, data-to-text) show that RL4HS surpasses pretrained reasoning models\nand supervised fine-tuning, demonstrating the necessity of reinforcement\nlearning with span-level rewards for detecting hallucination spans.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02173v2",
      "pdf_url": "http://arxiv.org/pdf/2510.02173v2",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.483,
      "weak_supervision_score": 0.389,
      "diffusion_reasoning_score": 0.558,
      "distributed_training_score": 0.347,
      "datasets_score": 0.293,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper uses reinforcement learning with a span-F1 metric-based reward for training a hallucination span detection model, but it does not involve human feedback, such as training a reward model on human-ranked data. Instead, it relies on automated metrics, making it distinct from RLHF.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on Chain-of-Thought reasoning and reinforcement learning for hallucination detection, with no mention of diffusion models, iterative refinement processes, or adapting diffusion techniques for multi-step logical reasoning.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02178",
      "title": "DisCo-Layout: Disentangling and Coordinating Semantic and Physical\n  Refinement in a Multi-Agent Framework for 3D Indoor Layout Synthesis",
      "authors": [
        "Jialin Gao",
        "Donghao Zhou",
        "Mingjian Liang",
        "Lihao Liu",
        "Chi-Wing Fu",
        "Xiaowei Hu",
        "Pheng-Ann Heng"
      ],
      "categories": [
        "cs.RO (Robotics)",
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "3D indoor layout synthesis is crucial for creating virtual environments.\nTraditional methods struggle with generalization due to fixed datasets. While\nrecent LLM and VLM-based approaches offer improved semantic richness, they\noften lack robust and flexible refinement, resulting in suboptimal layouts. We\ndevelop DisCo-Layout, a novel framework that disentangles and coordinates\nphysical and semantic refinement. For independent refinement, our Semantic\nRefinement Tool (SRT) corrects abstract object relationships, while the\nPhysical Refinement Tool (PRT) resolves concrete spatial issues via a\ngrid-matching algorithm. For collaborative refinement, a multi-agent framework\nintelligently orchestrates these tools, featuring a planner for placement\nrules, a designer for initial layouts, and an evaluator for assessment.\nExperiments demonstrate DisCo-Layout's state-of-the-art performance, generating\nrealistic, coherent, and generalizable 3D indoor layouts. Our code will be\npublicly available.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02178v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02178v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.396,
      "weak_supervision_score": 0.354,
      "diffusion_reasoning_score": 0.458,
      "distributed_training_score": 0.361,
      "datasets_score": 0.367,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on a multi-agent framework for 3D indoor layout synthesis, emphasizing disentangled semantic and physical refinement using VLMs and specialized tools like SRT and PRT. It does not involve diffusion models or adapt the iterative refinement process of diffusion for multi-step logical reasoning or Chain-of-Thought tasks. While it references traditional methods such as Diffuscene, which may be diffusion-based, the paper's main contribution does not incorporate or build upon diffusion-based reasoning.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02180",
      "title": "GRACE: A Language Model Framework for Explainable Inverse Reinforcement\n  Learning",
      "authors": [
        "Silvia Sapora",
        "Devon Hjelm",
        "Alexander Toshev",
        "Omar Attia",
        "Bogdan Mazoure"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Inverse Reinforcement Learning aims to recover reward models from expert\ndemonstrations, but traditional methods yield \"black-box\" models that are\ndifficult to interpret and debug. In this work, we introduce GRACE (Generating\nRewards As CodE), a method for using Large Language Models within an\nevolutionary search to reverse-engineer an interpretable, code-based reward\nfunction directly from expert trajectories. The resulting reward function is\nexecutable code that can be inspected and verified. We empirically validate\nGRACE on the BabyAI and AndroidWorld benchmarks, where it efficiently learns\nhighly accurate rewards, even in complex, multi-task settings. Further, we\ndemonstrate that the resulting reward leads to strong policies, compared to\nboth competitive Imitation Learning and online RL approaches with ground-truth\nrewards. Finally, we show that GRACE is able to build complex reward APIs in\nmulti-task setups.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02180v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02180v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.495,
      "weak_supervision_score": 0.375,
      "diffusion_reasoning_score": 0.433,
      "distributed_training_score": 0.32,
      "datasets_score": 0.308,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Tangentially Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on Inverse Reinforcement Learning (IRL) to learn reward functions from expert demonstrations, which may involve human-generated data. However, it does not use human-ranked data or a feedback loop to fine-tune models, as required in RLHF. Thus, it is only tangentially related through the general use of demonstrations.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper introduces a framework using Large Language Models and evolutionary search for reward learning, with no mention of diffusion models, iterative refinement for logical tasks, or multi-step reasoning corrections. It lacks any components related to diffusion-based approaches.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02181",
      "title": "EvolveCaptions: Empowering DHH Users Through Real-Time Collaborative\n  Captioning",
      "authors": [
        "Liang-Yuan Wu",
        "Dhruv Jain"
      ],
      "categories": [
        "cs.HC (Human-Computer Interaction)",
        "cs.AI (Artificial Intelligence)",
        "cs.SD (Sound)",
        "eess.AS (Audio and Speech Processing)"
      ],
      "abstract": "Automatic Speech Recognition (ASR) systems often fail to accurately\ntranscribe speech from Deaf and Hard of Hearing (DHH) individuals, especially\nduring real-time conversations. Existing personalization approaches typically\nrequire extensive pre-recorded data and place the burden of adaptation on the\nDHH speaker. We present EvolveCaptions, a real-time, collaborative ASR\nadaptation system that supports in-situ personalization with minimal effort.\nHearing participants correct ASR errors during live conversations. Based on\nthese corrections, the system generates short, phonetically targeted prompts\nfor the DHH speaker to record, which are then used to fine-tune the ASR model.\nIn a study with 12 DHH and six hearing participants, EvolveCaptions reduced\nWord Error Rate (WER) across all DHH users within one hour of use, using only\nfive minutes of recording time on average. Participants described the system as\nintuitive, low-effort, and well-integrated into communication. These findings\ndemonstrate the promise of collaborative, real-time ASR adaptation for more\nequitable communication.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02181v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02181v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.393,
      "weak_supervision_score": 0.391,
      "diffusion_reasoning_score": 0.351,
      "distributed_training_score": 0.329,
      "datasets_score": 0.323,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02182",
      "title": "Uncovering Semantic Selectivity of Latent Groups in Higher Visual Cortex\n  with Mutual Information-Guided Diffusion",
      "authors": [
        "Yule Wang",
        "Joseph Yu",
        "Chengrui Li",
        "Weihan Li",
        "Anqi Wu"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "Understanding how neural populations in higher visual areas encode\nobject-centered visual information remains a central challenge in computational\nneuroscience. Prior works have investigated representational alignment between\nartificial neural networks and the visual cortex. Nevertheless, these findings\nare indirect and offer limited insights to the structure of neural populations\nthemselves. Similarly, decoding-based methods have quantified semantic features\nfrom neural populations but have not uncovered their underlying organizations.\nThis leaves open a scientific question: \"how feature-specific visual\ninformation is distributed across neural populations in higher visual areas,\nand whether it is organized into structured, semantically meaningful\nsubspaces.\" To tackle this problem, we present MIG-Vis, a method that leverages\nthe generative power of diffusion models to visualize and validate the\nvisual-semantic attributes encoded in neural latent subspaces. Our method first\nuses a variational autoencoder to infer a group-wise disentangled neural latent\nsubspace from neural populations. Subsequently, we propose a mutual information\n(MI)-guided diffusion synthesis procedure to visualize the specific\nvisual-semantic features encoded by each latent group. We validate MIG-Vis on\nmulti-session neural spiking datasets from the inferior temporal (IT) cortex of\ntwo macaques. The synthesized results demonstrate that our method identifies\nneural latent groups with clear semantic selectivity to diverse visual\nfeatures, including object pose, inter-category transformations, and\nintra-class content. These findings provide direct, interpretable evidence of\nstructured semantic representation in the higher visual cortex and advance our\nunderstanding of its encoding principles.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02182v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02182v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.33,
      "weak_supervision_score": 0.313,
      "diffusion_reasoning_score": 0.502,
      "distributed_training_score": 0.299,
      "datasets_score": 0.327,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper's main contribution involves using diffusion models for image synthesis to visualize semantic features in neural data from the visual cortex, specifically through mutual information guidance. While diffusion models inherently involve iterative refinement, the paper does not adapt this process for solving complex logical tasks, treating a Chain-of-Thought, or performing multi-step reasoning. Instead, it focuses on generative tasks in computational neuroscience, lacking any component for logical reasoning or holistic correction of reasoning paths.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02186",
      "title": "GeoPurify: A Data-Efficient Geometric Distillation Framework for\n  Open-Vocabulary 3D Segmentation",
      "authors": [
        "Weijia Dou",
        "Xu Zhang",
        "Yi Bin",
        "Jian Liu",
        "Bo Peng",
        "Guoqing Wang",
        "Yang Yang",
        "Heng Tao Shen"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "Recent attempts to transfer features from 2D Vision-Language Models (VLMs) to\n3D semantic segmentation expose a persistent trade-off. Directly projecting 2D\nfeatures into 3D yields noisy and fragmented predictions, whereas enforcing\ngeometric coherence necessitates costly training pipelines and large-scale\nannotated 3D data. We argue that this limitation stems from the dominant\nsegmentation-and-matching paradigm, which fails to reconcile 2D semantics with\n3D geometric structure. The geometric cues are not eliminated during the\n2D-to-3D transfer but remain latent within the noisy and view-aggregated\nfeatures. To exploit this property, we propose GeoPurify that applies a small\nStudent Affinity Network to purify 2D VLM-generated 3D point features using\ngeometric priors distilled from a 3D self-supervised teacher model. During\ninference, we devise a Geometry-Guided Pooling module to further denoise the\npoint cloud and ensure the semantic and structural consistency. Benefiting from\nlatent geometric information and the learned affinity network, GeoPurify\neffectively mitigates the trade-off and achieves superior data efficiency.\nExtensive experiments on major 3D benchmarks demonstrate that GeoPurify\nachieves or surpasses state-of-the-art performance while utilizing only about\n1.5% of the training data. Our codes and checkpoints are available at\n[https://github.com/tj12323/GeoPurify](https://github.com/tj12323/GeoPurify).",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02186v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02186v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.34,
      "weak_supervision_score": 0.417,
      "diffusion_reasoning_score": 0.391,
      "distributed_training_score": 0.38,
      "datasets_score": 0.347,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "Highly Relevant",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "The paper's main contribution, GeoPurify, employs a data-efficient approach that trains a Student Affinity Network using Geometric Contrastive Distillation from a 3D self-supervised teacher model on unlabeled 3D scans. This method aligns directly with weak supervision, as it programmatically generates training signals from high-level geometric priors rather than requiring large-scale, hand-labeled data, achieving superior performance with only 1.5% of typical training data.",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "completed",
      "summary": "GeoPurify proposes a data-efficient framework for open-vocabulary 3D segmentation that addresses the trade-off between semantic richness from 2D Vision-Language Models and geometric coherence in 3D by distilling geometric priors from a 3D self-supervised teacher model using a Student Affinity Network. The methodology involves Geometric Contrastive Distillation to purify noisy 2D features and a Geometry-Guided Pooling module for inference to ensure structural consistency, resulting in state-of-the-art performance on 3D benchmarks with only about 1.5% of the typical training data.",
      "novelty_score": "Moderate",
      "novelty_justification": "The paper presents a clever combination of existing 2D VLM features and 3D geometric priors through a novel distillation framework, offering a notable improvement in data efficiency for open-vocabulary 3D segmentation.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to be cited and built upon in 3D vision and machine learning subfields due to its innovative data-efficient approach, but its influence may remain confined to specific applications like open-vocabulary segmentation.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper provides a strong, valuable contribution by enhancing 3D segmentation efficiency, making it essential for researchers in computer vision to understand its implications for future developments.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/3712f87abf71f1ac4f42f7b83c6f23c9ad55d490",
      "total_authors": 8,
      "authors_found": 7,
      "highest_h_index": 15,
      "average_h_index": 2.857142857142857,
      "notable_authors_count": 1,
      "author_h_indexes": [
        {
          "name": "Weijia Dou",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383309819"
        },
        {
          "name": "Xu Zhang",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383310306"
        },
        {
          "name": "Yi Bin",
          "h_index": 15,
          "profile_url": "https://www.semanticscholar.org/author/2054618348"
        },
        {
          "name": "Jian Liu",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383307711"
        },
        {
          "name": "Bo Peng",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383904213"
        },
        {
          "name": "Guoqing Wang",
          "h_index": 5,
          "profile_url": "https://www.semanticscholar.org/author/2261675107"
        },
        {
          "name": "Yang Yang",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2384446295"
        },
        {
          "name": "Heng Tao Shen",
          "h_index": null,
          "profile_url": null
        }
      ]
    },
    {
      "id": "2510.02190",
      "title": "A Rigorous Benchmark with Multidimensional Evaluation for Deep Research\n  Agents: From Answers to Reports",
      "authors": [
        "Yang Yao",
        "Yixu Wang",
        "Yuxuan Zhang",
        "Yi Lu",
        "Tianle Gu",
        "Lingyu Li",
        "Dingyi Zhao",
        "Keming Wu",
        "Haozhe Wang",
        "Ping Nie",
        "Yan Teng",
        "Yingchun Wang"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)",
        "cs.CL (Computation and Language)"
      ],
      "abstract": "Artificial intelligence is undergoing the paradigm shift from closed language\nmodels to interconnected agent systems capable of external perception and\ninformation integration. As a representative embodiment, Deep Research Agents\n(DRAs) systematically exhibit the capabilities for task decomposition,\ncross-source retrieval, multi-stage reasoning, and structured output, which\nmarkedly enhance performance on complex and open-ended tasks. However, existing\nbenchmarks remain deficient in evaluation dimensions, response formatting, and\nscoring mechanisms, limiting their capacity to assess such systems effectively.\nThis paper introduces a rigorous benchmark and a multidimensional evaluation\nframework tailored to DRAs and report-style responses. The benchmark comprises\n214 expert-curated challenging queries distributed across 10 broad thematic\ndomains, each accompanied by manually constructed reference bundles to support\ncomposite evaluation. The framework enables comprehensive evaluation of\nlong-form reports generated by DRAs, incorporating integrated scoring metrics\nfor semantic quality, topical focus, and retrieval trustworthiness. Extensive\nexperimentation confirms the superior performance of mainstream DRAs over\nweb-search-tool-augmented reasoning models, yet reveals considerable scope for\nfurther improvement. This study provides a robust foundation for capability\nassessment, architectural refinement, and paradigm advancement in DRA systems.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02190v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02190v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.433,
      "weak_supervision_score": 0.399,
      "diffusion_reasoning_score": 0.478,
      "distributed_training_score": 0.404,
      "datasets_score": 0.492,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "Not Relevant",
      "datasets_relevance": "Highly Relevant",
      "rlhf_justification": "The paper focuses on introducing a benchmark and evaluation framework for Deep Research Agents, emphasizing task decomposition and reasoning, but does not involve training models with human feedback, reward models, or reinforcement learning techniques.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper discusses multi-stage reasoning in Deep Research Agents but does not mention or adapt diffusion models for iterative refinement in reasoning tasks, such as treating a Chain-of-Thought as a single entity for correction.",
      "distributed_training_justification": "The paper is centered on benchmarking and evaluating AI agents, with no discussion of distributed training methods, parallel computing, or strategies for accelerating model training across multiple nodes.",
      "datasets_justification": "The paper's main contribution is the creation and introduction of a new benchmark dataset with 214 expert-curated queries and reference bundles, along with methodologies for evaluation, directly aligning with research on datasets for AI benchmarking and analysis.",
      "llm_score_status": "completed",
      "summary": "This paper introduces a rigorous benchmark comprising 214 expert-curated queries across 10 domains to evaluate Deep Research Agents (DRAs) on complex, report-style tasks, addressing limitations in existing benchmarks by incorporating multidimensional evaluation metrics for semantic quality, topical focus, and retrieval trustworthiness. Through extensive experiments comparing DRAs with web-search-tool-augmented models, the study demonstrates that DRAs outperform these alternatives in report generation while highlighting areas for further improvement, providing a robust foundation for advancing DRA systems.",
      "novelty_score": "High",
      "novelty_justification": "The paper introduces a truly new benchmark and evaluation framework specifically designed for Deep Research Agents, significantly advancing the state-of-the-art by addressing gaps in existing methods for assessing complex, report-style outputs.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to be cited and built upon in the subfield of AI agents and benchmarking, as it provides a standardized framework for evaluating DRAs, though its influence may be limited to specialized research areas rather than widespread commercial applications.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper represents a strong and valuable contribution to AI research by offering a comprehensive benchmark for Deep Research Agents, making it essential for researchers in the field of AI agents and language models to be aware of.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/49af5ed7037628d325eeae125b747923e60e4527",
      "total_authors": 12,
      "authors_found": 12,
      "highest_h_index": 6,
      "average_h_index": 2.75,
      "notable_authors_count": 3,
      "author_h_indexes": [
        {
          "name": "Yang Yao",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2346996394"
        },
        {
          "name": "Yixu Wang",
          "h_index": 6,
          "profile_url": "https://www.semanticscholar.org/author/2266363141"
        },
        {
          "name": "Yuxuan Zhang",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2353603294"
        },
        {
          "name": "Yi Lu",
          "h_index": 3,
          "profile_url": "https://www.semanticscholar.org/author/2308116597"
        },
        {
          "name": "Tianle Gu",
          "h_index": 4,
          "profile_url": "https://www.semanticscholar.org/author/2279024315"
        },
        {
          "name": "Lingyu Li",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2308044439"
        },
        {
          "name": "Dingyi Zhao",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383387119"
        },
        {
          "name": "Keming Wu",
          "h_index": 3,
          "profile_url": "https://www.semanticscholar.org/author/2383071656"
        },
        {
          "name": "Haozhe Wang",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383372865"
        },
        {
          "name": "Ping Nie",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383310658"
        },
        {
          "name": "Yan Teng",
          "h_index": 6,
          "profile_url": "https://www.semanticscholar.org/author/2266238818"
        },
        {
          "name": "Yingchun Wang",
          "h_index": 6,
          "profile_url": "https://www.semanticscholar.org/author/2266364817"
        }
      ]
    },
    {
      "id": "2510.02194",
      "title": "UpSafe$^\\circ$C: Upcycling for Controllable Safety in Large Language\n  Models",
      "authors": [
        "Yuhao Sun",
        "Zhuoer Xu",
        "Shiwen Cui",
        "Kun Yang",
        "Lingyun Yu",
        "Yongdong Zhang",
        "Hongtao Xie"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)",
        "cs.CR (Cryptography and Security)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "Large Language Models (LLMs) have achieved remarkable progress across a wide\nrange of tasks, but remain vulnerable to safety risks such as harmful content\ngeneration and jailbreak attacks. Existing safety techniques -- including\nexternal guardrails, inference-time guidance, and post-training alignment --\neach face limitations in balancing safety, utility, and controllability. In\nthis work, we propose UpSafe$^\\circ$C, a unified framework for enhancing LLM\nsafety through safety-aware upcycling. Our approach first identifies\nsafety-critical layers and upcycles them into a sparse Mixture-of-Experts (MoE)\nstructure, where the router acts as a soft guardrail that selectively activates\noriginal MLPs and added safety experts. We further introduce a two-stage SFT\nstrategy to strengthen safety discrimination while preserving general\ncapabilities. To enable flexible control at inference time, we introduce a\nsafety temperature mechanism, allowing dynamic adjustment of the trade-off\nbetween safety and utility. Experiments across multiple benchmarks, base model,\nand model scales demonstrate that UpSafe$^\\circ$C achieves robust safety\nimprovements against harmful and jailbreak inputs, while maintaining\ncompetitive performance on general tasks. Moreover, analysis shows that safety\ntemperature provides fine-grained inference-time control that achieves the\nPareto-optimal frontier between utility and safety. Our results highlight a new\ndirection for LLM safety: moving from static alignment toward dynamic, modular,\nand inference-aware control.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02194v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02194v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.43,
      "weak_supervision_score": 0.422,
      "diffusion_reasoning_score": 0.4,
      "distributed_training_score": 0.39,
      "datasets_score": 0.336,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "Not Relevant",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on a two-stage Supervised Fine-Tuning (SFT) strategy for enhancing LLM safety, without involving reinforcement learning, a reward model, or human feedback data. While it mentions post-training alignment in general, which could include RLHF, the method described does not incorporate these elements, making it unrelated to RLHF.",
      "weak_supervision_justification": "The paper uses standard SFT on safety and general data for training, but does not describe programmatically generating noisy or imprecise labels. There is no indication of weak supervision techniques, such as using high-level sources for label creation, as the approach relies on direct training data without emphasizing label noise or automation.",
      "diffusion_reasoning_justification": "The paper's main contribution involves upcycling layers in LLMs for safety using Mixture-of-Experts and SFT, with no mention of diffusion models, iterative refinement for logical reasoning, or treating Chain-of-Thought as a holistically corrected entity. It lacks any multi-step reasoning component based on diffusion processes.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02197",
      "title": "Cross-Breed Pig Identification Using Auricular Vein Pattern Recognition:\n  A Machine Learning Approach for Small-Scale Farming Applications",
      "authors": [
        "Emmanuel Nsengiyumvaa",
        "Leonard Niyitegekaa",
        "Eric Umuhoza"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.SE (Software Engineering)"
      ],
      "abstract": "Accurate livestock identification is a cornerstone of modern farming: it\nsupports health monitoring, breeding programs, and productivity tracking.\nHowever, common pig identification methods, such as ear tags and microchips,\nare often unreliable, costly, target pure breeds, and thus impractical for\nsmall-scale farmers. To address this gap, we propose a noninvasive biometric\nidentification approach that leverages uniqueness of the auricular vein\npatterns. To this end, we have collected 800 ear images from 20 mixed-breed\npigs (Landrace cross Pietrain and Duroc cross Pietrain), captured using a\nstandard smartphone and simple back lighting. A multistage computer vision\npipeline was developed to enhance vein visibility, extract structural and\nspatial features, and generate biometric signatures. These features were then\nclassified using machine learning models. Support Vector Machines (SVM)\nachieved the highest accuracy: correctly identifying pigs with 98.12% precision\nacross mixed-breed populations. The entire process from image processing to\nclassification was completed in an average of 8.3 seconds, demonstrating\nfeasibility for real-time farm deployment. We believe that by replacing fragile\nphysical identifiers with permanent biological markers, this system provides\nfarmers with a cost-effective and stress-free method of animal identification.\nMore broadly, the findings confirm the practicality of auricular vein\nbiometrics for digitizing livestock management, reinforcing its potential to\nextend the benefits of precision farming to resource-constrained agricultural\ncommunities.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02197v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02197v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.278,
      "weak_supervision_score": 0.332,
      "diffusion_reasoning_score": 0.253,
      "distributed_training_score": 0.291,
      "datasets_score": 0.306,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02200",
      "title": "ARUQULA -- An LLM based Text2SPARQL Approach using ReAct and Knowledge\n  Graph Exploration Utilities",
      "authors": [
        "Felix Brei",
        "Lorenz Bühmann",
        "Johannes Frey",
        "Daniel Gerber",
        "Lars-Peter Meyer",
        "Claus Stadler",
        "Kirill Bulert"
      ],
      "categories": [
        "cs.CL (Computation and Language)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Interacting with knowledge graphs can be a daunting task for people without a\nbackground in computer science since the query language that is used (SPARQL)\nhas a high barrier of entry. Large language models (LLMs) can lower that\nbarrier by providing support in the form of Text2SPARQL translation. In this\npaper we introduce a generalized method based on SPINACH, an LLM backed agent\nthat translates natural language questions to SPARQL queries not in a single\nshot, but as an iterative process of exploration and execution. We describe the\noverall architecture and reasoning behind our design decisions, and also\nconduct a thorough analysis of the agent behavior to gain insights into future\nareas for targeted improvements. This work was motivated by the Text2SPARQL\nchallenge, a challenge that was held to facilitate improvements in the\nText2SPARQL domain.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02200v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02200v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.37,
      "weak_supervision_score": 0.357,
      "diffusion_reasoning_score": 0.436,
      "distributed_training_score": 0.304,
      "datasets_score": 0.344,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper's main contribution is an iterative LLM-based agent (ARUQULA) for translating natural language to SPARQL queries using ReAct and knowledge graph exploration, but it does not involve diffusion models or adapt the diffusion process for multi-step logical reasoning. The iterative refinement described is agent-based, not diffusion-based.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02202",
      "title": "Detection of Chagas Disease from the ECG: The George B. Moody PhysioNet\n  Challenge 2025",
      "authors": [
        "Matthew A. Reyna",
        "Zuzana Koscova",
        "Jan Pavlus",
        "Soheil Saghafi",
        "James Weigle",
        "Andoni Elola",
        "Salman Seyedi",
        "Kiersten Campbell",
        "Qiao Li",
        "Ali Bahrami Rad",
        "Antônio H. Ribeiro",
        "Antonio Luiz P. Ribeiro",
        "Reza Sameni",
        "Gari D. Clifford"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Objective: Chagas disease is a parasitic infection that is endemic to South\nAmerica, Central America, and, more recently, the U.S., primarily transmitted\nby insects. Chronic Chagas disease can cause cardiovascular diseases and\ndigestive problems. Serological testing capacities for Chagas disease are\nlimited, but Chagas cardiomyopathy often manifests in ECGs, providing an\nopportunity to prioritize patients for testing and treatment. Approach: The\nGeorge B. Moody PhysioNet Challenge 2025 invites teams to develop algorithmic\napproaches for identifying Chagas disease from electrocardiograms (ECGs). Main\nresults: This Challenge provides multiple innovations. First, we leveraged\nseveral datasets with labels from patient reports and serological testing,\nprovided a large dataset with weak labels and smaller datasets with strong\nlabels. Second, we augmented the data to support model robustness and\ngeneralizability to unseen data sources. Third, we applied an evaluation metric\nthat captured the local serological testing capacity for Chagas disease to\nframe the machine learning problem as a triage task. Significance: Over 630\nparticipants from 111 teams submitted over 1300 entries during the Challenge,\nrepresenting diverse approaches from academia and industry worldwide.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02202v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02202v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.264,
      "weak_supervision_score": 0.3,
      "diffusion_reasoning_score": 0.259,
      "distributed_training_score": 0.302,
      "datasets_score": 0.284,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02208",
      "title": "Measurement-Guided Consistency Model Sampling for Inverse Problems",
      "authors": [
        "Amirreza Tanevardi",
        "Pooria Abbas Rad Moghadam",
        "Sajjad Amini"
      ],
      "categories": [
        "eess.IV (Image and Video Processing)",
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "Diffusion models have become powerful generative priors for solving inverse\nimaging problems, but their reliance on slow multi-step sampling limits\npractical deployment. Consistency models address this bottleneck by enabling\nhigh-quality generation in a single or only a few steps, yet their direct\nadaptation to inverse problems is underexplored. In this paper, we present a\nmodified consistency sampling approach tailored for inverse problem\nreconstruction: the sampler's stochasticity is guided by a\nmeasurement-consistency mechanism tied to the measurement operator, which\nenforces fidelity to the acquired measurements while retaining the efficiency\nof consistency-based generation. Experiments on Fashion-MNIST and LSUN Bedroom\ndatasets demonstrate consistent improvements in perceptual and pixel-level\nmetrics, including Fr\\'echet Inception Distance, Kernel Inception Distance,\npeak signal-to-noise ratio, and structural similarity index measure, compared\nto baseline consistency sampling, yielding competitive or superior\nreconstructions with only a handful of steps.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02208v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02208v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.313,
      "weak_supervision_score": 0.342,
      "diffusion_reasoning_score": 0.489,
      "distributed_training_score": 0.293,
      "datasets_score": 0.263,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper's main contribution is a modified consistency sampling approach for inverse imaging problems, using consistency models derived from diffusion models to enable fast reconstructions. It focuses on generative tasks for image processing, such as denoising and measurement-guided sampling, and does not involve adapting diffusion models for multi-step logical reasoning, chain-of-thought processes, or solving complex logical tasks. Therefore, there is no connection to the topic of diffusion-based reasoning.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02212",
      "title": "DiFFPO: Training Diffusion LLMs to Reason Fast and Furious via\n  Reinforcement Learning",
      "authors": [
        "Hanyang Zhao",
        "Dawen Liang",
        "Wenpin Tang",
        "David Yao",
        "Nathan Kallus"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "We propose DiFFPO, Diffusion Fast and Furious Policy Optimization, a unified\nframework for training masked diffusion large language models (dLLMs) to reason\nnot only better (furious), but also faster via reinforcement learning (RL). We\nfirst unify the existing baseline approach such as d1 by proposing to train\nsurrogate policies via off-policy RL, whose likelihood is much more tractable\nas an approximation to the true dLLM policy. This naturally motivates a more\naccurate and informative two-stage likelihood approximation combined with\nimportance sampling correction, which leads to generalized RL algorithms with\nbetter sample efficiency and superior task performance. Second, we propose a\nnew direction of joint training efficient samplers/controllers of dLLMs policy.\nVia RL, we incentivize dLLMs' natural multi-token prediction capabilities by\nletting the model learn to adaptively allocate an inference threshold for each\nprompt. By jointly training the sampler, we yield better accuracies with lower\nnumber of function evaluations (NFEs) compared to training the model only,\nobtaining the best performance in improving the Pareto frontier of the\ninference-time compute of dLLMs. We showcase the effectiveness of our pipeline\nby training open source large diffusion language models over benchmark math and\nplanning tasks.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02212v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02212v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.49,
      "weak_supervision_score": 0.381,
      "diffusion_reasoning_score": 0.608,
      "distributed_training_score": 0.44,
      "datasets_score": 0.3,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Highly Relevant",
      "distributed_training_relevance": "Not Relevant",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on Reinforcement Learning from Verifiable Rewards (RLVR) for training diffusion LLMs, using automated rewards rather than human feedback or a reward model trained on human-ranked data. It does not involve aligning models with human preferences, which is central to RLHF.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper's main contribution is DiFFPO, a framework that adapts diffusion models for multi-step logical reasoning in tasks like math and planning. It leverages diffusion LLMs for iterative refinement, multi-token predictions, and holistic correction of reasoning paths, directly aligning with diffusion-based reasoning.",
      "distributed_training_justification": "The paper does not discuss distributed training, parallel computing, or multi-node systems. It focuses solely on RL algorithms for fine-tuning diffusion LLMs, with no mention of partitioning data, architecture, or computation across processors.",
      "datasets_justification": "below_threshold",
      "llm_score_status": "completed",
      "summary": "The paper introduces DiFFPO, a framework for training diffusion-based large language models (dLLMs) using reinforcement learning to improve both reasoning accuracy and inference efficiency. It proposes using off-policy RL with surrogate policies for better tractability, incorporates importance sampling for accuracy, and innovates by jointly training efficient samplers that adaptively allocate inference thresholds, resulting in superior performance on math and planning benchmarks with reduced computational costs.",
      "novelty_score": "Moderate",
      "novelty_justification": "The paper presents a clever combination of existing RL techniques with dLLMs to address efficient reasoning, offering a notable improvement in training paradigms rather than introducing a entirely new problem or architecture. While it advances the field by proposing joint training of samplers, it builds on prior work like d1, making it an incremental but not revolutionary contribution.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to influence research in dLLMs and RL for efficient reasoning, potentially leading to citations and developments in subfields like AI for math and planning tasks. However, its applicability is somewhat limited to specific diffusion models, so it may not broadly affect general AI or commercial applications immediately.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper offers a strong, valuable contribution by advancing RL techniques for dLLMs, with empirical evidence of improved efficiency, making it important for researchers in machine learning and AI to be aware of. While not essential for all, it provides insights that could guide future work in efficient language model training.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/69d3a593b14b22479cac879bf1dbf87e0f78e00f",
      "total_authors": 5,
      "authors_found": 5,
      "highest_h_index": 8,
      "average_h_index": 6.2,
      "notable_authors_count": 3,
      "author_h_indexes": [
        {
          "name": "Hanyang Zhao",
          "h_index": 7,
          "profile_url": "https://www.semanticscholar.org/author/2280993882"
        },
        {
          "name": "Dawen Liang",
          "h_index": 5,
          "profile_url": "https://www.semanticscholar.org/author/2261449339"
        },
        {
          "name": "Wenpin Tang",
          "h_index": 7,
          "profile_url": "https://www.semanticscholar.org/author/2281440170"
        },
        {
          "name": "David D. Yao",
          "h_index": 4,
          "profile_url": "https://www.semanticscholar.org/author/2303257967"
        },
        {
          "name": "Nathan Kallus",
          "h_index": 8,
          "profile_url": "https://www.semanticscholar.org/author/2325151437"
        }
      ]
    },
    {
      "id": "2510.02213",
      "title": "MMDEW: Multipurpose Multiclass Density Estimation in the Wild",
      "authors": [
        "Villanelle O'Reilly",
        "Jonathan Cox",
        "Georgios Leontidis",
        "Marc Hanheide",
        "Petra Bosilj",
        "James Brown"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Density map estimation can be used to estimate object counts in dense and\noccluded scenes where discrete counting-by-detection methods fail. We propose a\nmulticategory counting framework that leverages a Twins pyramid\nvision-transformer backbone and a specialised multi-class counting head built\non a state-of-the-art multiscale decoding approach. A two-task design adds a\nsegmentation-based Category Focus Module, suppressing inter-category cross-talk\nat training time. Training and evaluation on the VisDrone and iSAID benchmarks\ndemonstrates superior performance versus prior multicategory crowd-counting\napproaches (33%, 43% and 64% reduction to MAE), and the comparison with YOLOv11\nunderscores the necessity of crowd counting methods in dense scenes. The\nmethod's regional loss opens up multi-class crowd counting to new domains,\ndemonstrated through the application to a biodiversity monitoring dataset,\nhighlighting its capacity to inform conservation efforts and enable scalable\necological insights.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02213v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02213v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.303,
      "weak_supervision_score": 0.327,
      "diffusion_reasoning_score": 0.368,
      "distributed_training_score": 0.365,
      "datasets_score": 0.332,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02226",
      "title": "TempoControl: Temporal Attention Guidance for Text-to-Video Models",
      "authors": [
        "Shira Schiber",
        "Ofir Lindenbaum",
        "Idan Schwartz"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.AI (Artificial Intelligence)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "Recent advances in generative video models have enabled the creation of\nhigh-quality videos based on natural language prompts. However, these models\nfrequently lack fine-grained temporal control, meaning they do not allow users\nto specify when particular visual elements should appear within a generated\nsequence. In this work, we introduce TempoControl, a method that allows for\ntemporal alignment of visual concepts during inference, without requiring\nretraining or additional supervision. TempoControl utilizes cross-attention\nmaps, a key component of text-to-video diffusion models, to guide the timing of\nconcepts through a novel optimization approach. Our method steers attention\nusing three complementary principles: aligning its temporal shape with a\ncontrol signal (via correlation), amplifying it where visibility is needed (via\nenergy), and maintaining spatial focus (via entropy). TempoControl allows\nprecise control over timing while ensuring high video quality and diversity. We\ndemonstrate its effectiveness across various video generation applications,\nincluding temporal reordering for single and multiple objects, as well as\naction and audio-aligned generation.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02226v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02226v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.338,
      "weak_supervision_score": 0.333,
      "diffusion_reasoning_score": 0.448,
      "distributed_training_score": 0.297,
      "datasets_score": 0.248,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Tangentially Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on using diffusion models for temporal control in video generation, leveraging the iterative denoising process to optimize attention maps. While it employs iterative refinement similar to diffusion mechanisms, it does not adapt this for solving complex logical tasks or holistic Chain-of-Thought reasoning. Instead, it applies diffusion to visual generation, making the connection indirect.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02227",
      "title": "More Than One Teacher: Adaptive Multi-Guidance Policy Optimization for\n  Diverse Exploration",
      "authors": [
        "Xiaoyang Yuan",
        "Yujuan Ding",
        "Yi Bin",
        "Wenqi Shao",
        "Jinyu Cai",
        "Jingkuan Song",
        "Yang Yang",
        "Heng Tao Shen"
      ],
      "categories": [
        "cs.CL (Computation and Language)",
        "cs.AI (Artificial Intelligence)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) is a promising paradigm\nfor enhancing the reasoning ability in Large Language Models (LLMs). However,\nprevailing methods primarily rely on self-exploration or a single off-policy\nteacher to elicit long chain-of-thought (LongCoT) reasoning, which may\nintroduce intrinsic model biases and restrict exploration, ultimately limiting\nreasoning diversity and performance. Drawing inspiration from multi-teacher\nstrategies in knowledge distillation, we introduce Adaptive Multi-Guidance\nPolicy Optimization (AMPO), a novel framework that adaptively leverages\nguidance from multiple proficient teacher models, but only when the on-policy\nmodel fails to generate correct solutions. This \"guidance-on-demand\" approach\nexpands exploration while preserving the value of self-discovery. Moreover,\nAMPO incorporates a comprehension-based selection mechanism, prompting the\nstudent to learn from the reasoning paths that it is most likely to comprehend,\nthus balancing broad exploration with effective exploitation. Extensive\nexperiments show AMPO substantially outperforms a strong baseline (GRPO), with\na 4.3% improvement on mathematical reasoning tasks and 12.2% on\nout-of-distribution tasks, while significantly boosting Pass@k performance and\nenabling more diverse exploration. Notably, using four peer-sized teachers, our\nmethod achieves comparable results to approaches that leverage a single, more\npowerful teacher (e.g., DeepSeek-R1) with more data. These results demonstrate\na more efficient and scalable path to superior reasoning and generalizability.\nOur code is available at https://github.com/SII-Enigma/AMPO.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02227v2",
      "pdf_url": "http://arxiv.org/pdf/2510.02227v2",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.476,
      "weak_supervision_score": 0.408,
      "diffusion_reasoning_score": 0.512,
      "distributed_training_score": 0.412,
      "datasets_score": 0.312,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "Tangentially Relevant",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "Not Relevant",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on Reinforcement Learning with Verifiable Rewards (RLVR) using AI teacher models for guidance, not human feedback. There is no mention of training a reward model on human-ranked data or aligning with human preferences.",
      "weak_supervision_justification": "The paper uses multiple teacher models to generate guidance for the student model, which involves external, potentially noisy supervision sources. However, it primarily emphasizes reinforcement learning rather than programmatically generating labels from high-level or imprecise data as in weak supervision.",
      "diffusion_reasoning_justification": "The paper does not involve diffusion models or iterative refinement processes for reasoning. It focuses on reinforcement learning and chain-of-thought optimization, with no components for multi-step logical reasoning via diffusion.",
      "distributed_training_justification": "The paper employs multiple teacher models for guidance in reinforcement learning, but this is not about parallel computing, partitioning data, or accelerating training across processors or nodes. It is solely for enhancing exploration in RL.",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02230",
      "title": "The Reasoning Boundary Paradox: How Reinforcement Learning Constrains\n  Language Models",
      "authors": [
        "Phuc Minh Nguyen",
        "Chinh D. La",
        "Duy M. H. Nguyen",
        "Nitesh V. Chawla",
        "Binh T. Nguyen",
        "Khoa D. Doan"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)",
        "cs.CL (Computation and Language)",
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a key\nmethod for improving Large Language Models' reasoning capabilities, yet recent\nevidence suggests it may paradoxically shrink the reasoning boundary rather\nthan expand it. This paper investigates the shrinkage issue of RLVR by\nanalyzing its learning dynamics and reveals two critical phenomena that explain\nthis failure. First, we expose negative interference in RLVR, where learning to\nsolve certain training problems actively reduces the likelihood of correct\nsolutions for others, leading to the decline of Pass@$k$ performance, or the\nprobability of generating a correct solution within $k$ attempts. Second, we\nuncover the winner-take-all phenomenon: RLVR disproportionately reinforces\nproblems with high likelihood, correct solutions, under the base model, while\nsuppressing other initially low-likelihood ones. Through extensive theoretical\nand empirical analysis on multiple mathematical reasoning benchmarks, we show\nthat this effect arises from the inherent on-policy sampling in standard RL\nobjectives, causing the model to converge toward narrow solution strategies.\nBased on these insights, we propose a simple yet effective data curation\nalgorithm that focuses RLVR learning on low-likelihood problems, achieving\nnotable improvement in Pass@$k$ performance. Our code is available at\nhttps://github.com/mail-research/SELF-llm-interference.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02230v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02230v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.511,
      "weak_supervision_score": 0.444,
      "diffusion_reasoning_score": 0.523,
      "distributed_training_score": 0.403,
      "datasets_score": 0.333,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "Tangentially Relevant",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "Not Relevant",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on Reinforcement Learning with Verifiable Rewards (RLVR), which uses objective, binary rewards based on correctness (e.g., for math problems) and does not involve human feedback, ranking, or a separate reward model trained on human data. Thus, it does not align with RLHF.",
      "weak_supervision_justification": "The paper involves programmatically verifiable rewards for training, which could be seen as a form of weak supervision since it relies on automated, potentially noisy labels. However, the main contribution is analyzing RLVR dynamics and proposing improvements, not the generation or use of weak labels as a primary focus.",
      "diffusion_reasoning_justification": "The paper discusses RLVR for improving reasoning in language models but does not mention diffusion models, iterative refinement processes, or treating reasoning as a holistic entity for multi-step correction. It focuses on reinforcement learning dynamics instead.",
      "distributed_training_justification": "The paper examines the learning dynamics of RLVR and proposes a data curation algorithm, with no discussion of distributed systems, parallel computing, data partitioning, or multi-node training strategies.",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02240",
      "title": "RewardMap: Tackling Sparse Rewards in Fine-grained Visual Reasoning via\n  Multi-Stage Reinforcement Learning",
      "authors": [
        "Sicheng Feng",
        "Kaiwen Tuo",
        "Song Wang",
        "Lingdong Kong",
        "Jianke Zhu",
        "Huan Wang"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Fine-grained visual reasoning remains a core challenge for multimodal large\nlanguage models (MLLMs). The recently introduced ReasonMap highlights this gap\nby showing that even advanced MLLMs struggle with spatial reasoning in\nstructured and information-rich settings such as transit maps, a task of clear\npractical and scientific importance. However, standard reinforcement learning\n(RL) on such tasks is impeded by sparse rewards and unstable optimization. To\naddress this, we first construct ReasonMap-Plus, an extended dataset that\nintroduces dense reward signals through Visual Question Answering (VQA) tasks,\nenabling effective cold-start training of fine-grained visual understanding\nskills. Next, we propose RewardMap, a multi-stage RL framework designed to\nimprove both visual understanding and reasoning capabilities of MLLMs.\nRewardMap incorporates two key designs. First, we introduce a difficulty-aware\nreward design that incorporates detail rewards, directly tackling the sparse\nrewards while providing richer supervision. Second, we propose a multi-stage RL\nscheme that bootstraps training from simple perception to complex reasoning\ntasks, offering a more effective cold-start strategy than conventional\nSupervised Fine-Tuning (SFT). Experiments on ReasonMap and ReasonMap-Plus\ndemonstrate that each component of RewardMap contributes to consistent\nperformance gains, while their combination yields the best results. Moreover,\nmodels trained with RewardMap achieve an average improvement of 3.47% across 6\nbenchmarks spanning spatial reasoning, fine-grained visual reasoning, and\ngeneral tasks beyond transit maps, underscoring enhanced visual understanding\nand reasoning capabilities.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02240v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02240v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.471,
      "weak_supervision_score": 0.411,
      "diffusion_reasoning_score": 0.516,
      "distributed_training_score": 0.375,
      "datasets_score": 0.348,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "Highly Relevant",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper uses reinforcement learning with rewards derived from task performance (e.g., VQA-based dense rewards), but it does not involve training a reward model on human-ranked data or aligning with human preferences, which are core to RLHF.",
      "weak_supervision_justification": "The paper constructs ReasonMap-Plus by programmatically generating dense reward signals through VQA tasks, aligning with weak supervision as it relies on high-level, automated sources for labels rather than precise hand-labeling.",
      "diffusion_reasoning_justification": "The paper focuses on multi-stage reinforcement learning for visual reasoning and does not mention or incorporate diffusion models, iterative refinement processes, or multi-step logical reasoning via diffusion techniques.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "completed",
      "summary": "This paper addresses the challenges of sparse rewards in fine-grained visual reasoning for multimodal large language models (MLLMs) by introducing ReasonMap-Plus, an extended dataset with dense rewards from Visual Question Answering (VQA) tasks, and proposing RewardMap, a multi-stage reinforcement learning framework with difficulty-aware rewards and a staged training approach from simple perception to complex reasoning. The methodology enables effective cold-start training, leading to consistent performance improvements on ReasonMap and ReasonMap-Plus benchmarks, as well as an average 3.47% gain across six additional benchmarks in spatial reasoning, fine-grained visual reasoning, and general tasks, demonstrating enhanced visual understanding and reasoning capabilities in MLLMs.",
      "novelty_score": "Moderate",
      "novelty_justification": "The paper presents a notable improvement by combining multi-stage RL with difficulty-aware rewards to tackle sparse rewards in visual reasoning, offering a clever adaptation of existing techniques for MLLMs rather than introducing a entirely new problem or architecture.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to be cited and built upon in the subfield of MLLMs and visual reasoning due to its practical enhancements in handling sparse rewards, though its influence may remain confined to specific applications like spatial reasoning tasks.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "The paper provides a strong, valuable contribution to improving RL for visual reasoning in MLLMs, making it essential for researchers focused on AI and computer vision to understand these advancements, though it is not a groundbreaking must-read.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/29c3368b63f7aa43d7e1b4928cc8a1a1e5693610",
      "total_authors": 6,
      "authors_found": 5,
      "highest_h_index": 7,
      "average_h_index": 2.4,
      "notable_authors_count": 1,
      "author_h_indexes": [
        {
          "name": "Sicheng Feng",
          "h_index": null,
          "profile_url": null
        },
        {
          "name": "Kaiwen Tuo",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2366423243"
        },
        {
          "name": "Song Wang",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2363511364"
        },
        {
          "name": "Lingdong Kong",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2362056224"
        },
        {
          "name": "Jianke Zhu",
          "h_index": 7,
          "profile_url": "https://www.semanticscholar.org/author/2258980400"
        },
        {
          "name": "Huan Wang",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2363547241"
        }
      ]
    },
    {
      "id": "2510.02245",
      "title": "ExGRPO: Learning to Reason from Experience",
      "authors": [
        "Runzhe Zhan",
        "Yafu Li",
        "Zhi Wang",
        "Xiaoye Qu",
        "Dongrui Liu",
        "Jing Shao",
        "Derek F. Wong",
        "Yu Cheng"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)",
        "cs.CL (Computation and Language)"
      ],
      "abstract": "Reinforcement learning from verifiable rewards (RLVR) is an emerging paradigm\nfor improving the reasoning ability of large language models. However, standard\non-policy training discards rollout experiences after a single update, leading\nto computational inefficiency and instability. While prior work on RL has\nhighlighted the benefits of reusing past experience, the role of experience\ncharacteristics in shaping learning dynamics of large reasoning models remains\nunderexplored. In this paper, we are the first to investigate what makes a\nreasoning experience valuable and identify rollout correctness and entropy as\neffective indicators of experience value. Based on these insights, we propose\nExGRPO (Experiential Group Relative Policy Optimization), a framework that\norganizes and prioritizes valuable experiences, and employs a mixed-policy\nobjective to balance exploration with experience exploitation. Experiments on\nfive backbone models (1.5B-8B parameters) show that ExGRPO consistently\nimproves reasoning performance on mathematical/general benchmarks, with an\naverage gain of +3.5/7.6 points over on-policy RLVR. Moreover, ExGRPO\nstabilizes training on both stronger and weaker models where on-policy methods\nfail. These results highlight principled experience management as a key\ningredient for efficient and scalable RLVR.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02245v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02245v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.505,
      "weak_supervision_score": 0.393,
      "diffusion_reasoning_score": 0.514,
      "distributed_training_score": 0.399,
      "datasets_score": 0.312,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper discusses Reinforcement Learning from Verifiable Rewards (RLVR) for improving reasoning in language models, focusing on experience reuse and efficiency. It does not involve human feedback, a separate reward model trained on human-ranked data, or alignment with human preferences, which are core to RLHF.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper introduces an RL-based framework for reasoning optimization using experience management, but it does not incorporate diffusion models, iterative refinement processes, or treat Chain-of-Thought as a holistically corrected entity over multiple steps as defined for diffusion-based reasoning.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02249",
      "title": "Explore Briefly, Then Decide: Mitigating LLM Overthinking via Cumulative\n  Entropy Regulation",
      "authors": [
        "Tianyi Jiang",
        "Yi Bin",
        "Yujuan Ding",
        "Kainian Zhu",
        "Fei Ma",
        "Jingkuan Song",
        "Heng Tao Shen"
      ],
      "categories": [
        "cs.CL (Computation and Language)",
        "cs.AI (Artificial Intelligence)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable reasoning abilities\non complex problems using long Chain-of-Thought (CoT) reasoning. However, they\noften suffer from overthinking, meaning generating unnecessarily lengthy\nreasoning steps for simpler problems. This issue may degrade the efficiency of\nthe models and make them difficult to adapt the reasoning depth to the\ncomplexity of problems. To address this, we introduce a novel metric Token\nEntropy Cumulative Average (TECA), which measures the extent of exploration\nthroughout the reasoning process. We further propose a novel reasoning paradigm\n-- Explore Briefly, Then Decide -- with an associated Cumulative Entropy\nRegulation (CER) mechanism. This paradigm leverages TECA to help the model\ndynamically determine the optimal point to conclude its thought process and\nprovide a final answer, thus achieving efficient reasoning. Experimental\nresults across diverse mathematical benchmarks show that our approach\nsubstantially mitigates overthinking without sacrificing problem-solving\nability. With our thinking paradigm, the average response length decreases by\nup to 71% on simpler datasets, demonstrating the effectiveness of our method in\ncreating a more efficient and adaptive reasoning process.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02249v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02249v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.411,
      "weak_supervision_score": 0.355,
      "diffusion_reasoning_score": 0.544,
      "distributed_training_score": 0.341,
      "datasets_score": 0.297,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Tangentially Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper uses reinforcement learning (e.g., GRPO) to train models with rewards based on accuracy and thinking length, which is related to RL concepts. However, it does not involve human-ranked data or a separate reward model trained on human feedback, as required for RLHF, making it only tangentially connected.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on entropy-based metrics and reasoning paradigms for LLMs, with no mention of diffusion models, iterative refinement processes, or adapting diffusion for logical tasks, so it does not align with this topic.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02250",
      "title": "The Unreasonable Effectiveness of Scaling Agents for Computer Use",
      "authors": [
        "Gonzalo Gonzalez-Pumariega",
        "Vincent Tu",
        "Chih-Lun Lee",
        "Jiachen Yang",
        "Ang Li",
        "Xin Eric Wang"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)",
        "cs.CL (Computation and Language)",
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "Computer-use agents (CUAs) hold promise for automating everyday digital\ntasks, but their unreliability and high variance hinder their application to\nlong-horizon, complex tasks. We introduce Behavior Best-of-N (bBoN), a method\nthat scales over agents by generating multiple rollouts and selecting among\nthem using behavior narratives that describe the agents' rollouts. It enables\nboth wide exploration and principled trajectory selection, substantially\nimproving robustness and success rates. On OSWorld, our bBoN scaling method\nestablishes a new state of the art (SoTA) at 69.9%, significantly outperforming\nprior methods and approaching human-level performance at 72%, with\ncomprehensive ablations validating key design choices. We further demonstrate\nstrong generalization results to different operating systems on\nWindowsAgentArena and AndroidWorld. Crucially, our results highlight the\nunreasonable effectiveness of scaling CUAs, when you do it right: effective\nscaling requires structured trajectory understanding and selection, and bBoN\nprovides a practical framework to achieve this.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02250v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02250v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.388,
      "weak_supervision_score": 0.387,
      "diffusion_reasoning_score": 0.404,
      "distributed_training_score": 0.406,
      "datasets_score": 0.363,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "Not Relevant",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on scaling computer-use agents by generating multiple rollouts and selecting the best using behavior narratives, without any mention of diffusion models, iterative refinement processes, or adapting diffusion for logical reasoning tasks. It does not treat reasoning paths as entities for holistic correction, so it lacks any connection to diffusion-based reasoning.",
      "distributed_training_justification": "The paper discusses parallel generation of agent rollouts for evaluation and selection, but this is not about distributed training, parallel computing for model training, or partitioning data/computation across nodes to accelerate machine learning. It pertains to agent performance scaling, not ML training algorithms or systems.",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02253",
      "title": "DragFlow: Unleashing DiT Priors with Region Based Supervision for Drag\n  Editing",
      "authors": [
        "Zihan Zhou",
        "Shilin Lu",
        "Shuli Leng",
        "Shaocong Zhang",
        "Zhuming Lian",
        "Xinlei Yu",
        "Adams Wai-Kin Kong"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.AI (Artificial Intelligence)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "Drag-based image editing has long suffered from distortions in the target\nregion, largely because the priors of earlier base models, Stable Diffusion,\nare insufficient to project optimized latents back onto the natural image\nmanifold. With the shift from UNet-based DDPMs to more scalable DiT with flow\nmatching (e.g., SD3.5, FLUX), generative priors have become significantly\nstronger, enabling advances across diverse editing tasks. However, drag-based\nediting has yet to benefit from these stronger priors. This work proposes the\nfirst framework to effectively harness FLUX's rich prior for drag-based\nediting, dubbed DragFlow, achieving substantial gains over baselines. We first\nshow that directly applying point-based drag editing to DiTs performs poorly:\nunlike the highly compressed features of UNets, DiT features are insufficiently\nstructured to provide reliable guidance for point-wise motion supervision. To\novercome this limitation, DragFlow introduces a region-based editing paradigm,\nwhere affine transformations enable richer and more consistent feature\nsupervision. Additionally, we integrate pretrained open-domain personalization\nadapters (e.g., IP-Adapter) to enhance subject consistency, while preserving\nbackground fidelity through gradient mask-based hard constraints. Multimodal\nlarge language models (MLLMs) are further employed to resolve task ambiguities.\nFor evaluation, we curate a novel Region-based Dragging benchmark (ReD Bench)\nfeaturing region-level dragging instructions. Extensive experiments on\nDragBench-DR and ReD Bench show that DragFlow surpasses both point-based and\nregion-based baselines, setting a new state-of-the-art in drag-based image\nediting. Code and datasets will be publicly available upon publication.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02253v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02253v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.381,
      "weak_supervision_score": 0.354,
      "diffusion_reasoning_score": 0.448,
      "distributed_training_score": 0.348,
      "datasets_score": 0.323,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on drag-based image editing using Diffusion Transformers (DiTs) for visual tasks, such as improving image manipulation through region-based supervision and feature handling. It does not adapt the iterative refinement process of diffusion models for solving complex logical tasks or treat a 'Chain-of-Thought' as a single entity for holistic reasoning. While diffusion models are used, their application is limited to generative image editing, lacking any component for multi-step logical reasoning.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02262",
      "title": "From Frames to Clips: Efficient Key Clip Selection for Long-Form Video\n  Understanding",
      "authors": [
        "Guangyu Sun",
        "Archit Singhal",
        "Burak Uzkent",
        "Mubarak Shah",
        "Chen Chen",
        "Garin Kessler"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Video Large Language Models (VLMs) have achieved remarkable results on a\nvariety of vision language tasks, yet their practical use is limited by the\n\"needle in a haystack\" problem: the massive number of visual tokens produced\nfrom raw video frames exhausts the model's context window. Existing solutions\nalleviate this issue by selecting a sparse set of frames, thereby reducing\ntoken count, but such frame-wise selection discards essential temporal\ndynamics, leading to suboptimal reasoning about motion and event continuity. In\nthis work we systematically explore the impact of temporal information and\ndemonstrate that extending selection from isolated key frames to key clips,\nwhich are short, temporally coherent segments, improves video understanding. To\nmaintain a fixed computational budget while accommodating the larger token\nfootprint of clips, we propose an adaptive resolution strategy that dynamically\nbalances spatial resolution and clip length, ensuring a constant token count\nper video. Experiments on three long-form video benchmarks demonstrate that our\ntraining-free approach, F2C, outperforms uniform sampling up to 8.1%, 5.6%, and\n10.3% on Video-MME, LongVideoBench and MLVU benchmarks, respectively. These\nresults highlight the importance of preserving temporal coherence in frame\nselection and provide a practical pathway for scaling Video LLMs to real world\nvideo understanding applications. Project webpage is available at\nhttps://guangyusun.com/f2c .",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02262v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02262v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.353,
      "weak_supervision_score": 0.333,
      "diffusion_reasoning_score": 0.406,
      "distributed_training_score": 0.352,
      "datasets_score": 0.302,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper's main contribution is on efficient key clip selection for Video Large Language Models (VLMs) to improve temporal coherence in long-form video understanding, without any involvement of diffusion models or iterative refinement processes for logical reasoning. There is no mention of adapting diffusion for multi-step logical tasks, Chain-of-Thought processing, or holistic correction, making it unrelated to the topic.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02263",
      "title": "RLAD: Training LLMs to Discover Abstractions for Solving Reasoning\n  Problems",
      "authors": [
        "Yuxiao Qu",
        "Anikait Singh",
        "Yoonho Lee",
        "Amrith Setlur",
        "Ruslan Salakhutdinov",
        "Chelsea Finn",
        "Aviral Kumar"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)",
        "cs.CL (Computation and Language)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "Reasoning requires going beyond pattern matching or memorization of solutions\nto identify and implement \"algorithmic procedures\" that can be used to deduce\nanswers to hard problems. Doing so requires realizing the most relevant\nprimitives, intermediate results, or shared procedures, and building upon them.\nWhile RL post-training on long chains of thought ultimately aims to uncover\nthis kind of algorithmic behavior, most reasoning traces learned by large\nmodels fail to consistently capture or reuse procedures, instead drifting into\nverbose and degenerate exploration. To address more effective reasoning, we\nintroduce reasoning abstractions: concise natural language descriptions of\nprocedural and factual knowledge that guide the model toward learning\nsuccessful reasoning. We train models to be capable of proposing multiple\nabstractions given a problem, followed by RL that incentivizes building a\nsolution while using the information provided by these abstractions. This\nresults in a two-player RL training paradigm, abbreviated as RLAD, that jointly\ntrains an abstraction generator and a solution generator. This setup\neffectively enables structured exploration, decouples learning signals of\nabstraction proposal and solution generation, and improves generalization to\nharder problems. We also show that allocating more test-time compute to\ngenerating abstractions is more beneficial for performance than generating more\nsolutions at large test budgets, illustrating the role of abstractions in\nguiding meaningful exploration.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02263v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02263v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.478,
      "weak_supervision_score": 0.412,
      "diffusion_reasoning_score": 0.615,
      "distributed_training_score": 0.402,
      "datasets_score": 0.349,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Tangentially Relevant",
      "weak_supervision_relevance": "Moderately Relevant",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "Not Relevant",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper uses reinforcement learning for training, which shares a broad connection to RLHF, but it relies on rewards based on accuracy improvements rather than a reward model trained on human-ranked data. No human feedback is mentioned, making it only loosely related.",
      "weak_supervision_justification": "The paper employs supervised fine-tuning on programmatically generated problem-abstraction pairs from stronger models, aligning with weak supervision by using noisy or derived labels instead of hand-annotated data. However, this is not the core focus, as the main contribution is the RL-based method.",
      "diffusion_reasoning_justification": "The paper focuses on RL for generating and using reasoning abstractions, with no mention of diffusion models, iterative refinement processes, or adapting diffusion for logical tasks.",
      "distributed_training_justification": "The paper does not discuss distributed training, parallel computing, or multi-node setups; it centers on RL methods for reasoning abstractions without any reference to computational partitioning or acceleration techniques.",
      "datasets_justification": "below_threshold",
      "llm_score_status": "completed",
      "summary": "The paper introduces reasoning abstractions as concise natural language descriptions of procedural and factual knowledge to enhance reasoning in large language models (LLMs), aiming to guide models toward more effective problem-solving by proposing and utilizing these abstractions. The methodology involves a two-player reinforcement learning (RL) paradigm called RLAD, which jointly trains an abstraction generator and a solution generator, with the abstraction generator warmed up via supervised fine-tuning; key findings include a 44% improvement on benchmarks like AIME 2025 over existing methods, better generalization, and the advantage of allocating more compute to abstraction generation for improved performance.",
      "novelty_score": "High",
      "novelty_justification": "The paper introduces a novel technique with reasoning abstractions and the RLAD training paradigm, which significantly advances state-of-the-art reasoning in LLMs by enabling structured exploration and decoupling abstraction proposal from solution generation.",
      "impact_score": "High",
      "impact_justification": "The work demonstrates substantial improvements on reasoning benchmarks and could influence future research in AI by promoting better exploration strategies in LLMs, potentially extending to broader applications in problem-solving and commercial AI systems.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper offers a high-quality contribution with innovative methods and strong empirical results that advance LLM reasoning, making it valuable for researchers in AI and machine learning to be aware of and potentially build upon.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/6e579f5bc5e0da2d654e50e2f0080fbf7ec2f290",
      "total_authors": 7,
      "authors_found": 7,
      "highest_h_index": 14,
      "average_h_index": 6.857142857142857,
      "notable_authors_count": 3,
      "author_h_indexes": [
        {
          "name": "Yuxiao Qu",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2312907266"
        },
        {
          "name": "Anikait Singh",
          "h_index": 14,
          "profile_url": "https://www.semanticscholar.org/author/2111007256"
        },
        {
          "name": "Yoonho Lee",
          "h_index": 5,
          "profile_url": "https://www.semanticscholar.org/author/2260289273"
        },
        {
          "name": "Amrith Rajagopal Setlur",
          "h_index": 12,
          "profile_url": "https://www.semanticscholar.org/author/80366270"
        },
        {
          "name": "Ruslan Salakhutdinov",
          "h_index": 7,
          "profile_url": "https://www.semanticscholar.org/author/2257253563"
        },
        {
          "name": "Chelsea Finn",
          "h_index": 5,
          "profile_url": "https://www.semanticscholar.org/author/2279838067"
        },
        {
          "name": "Aviral Kumar",
          "h_index": 3,
          "profile_url": "https://www.semanticscholar.org/author/2313046878"
        }
      ]
    },
    {
      "id": "2510.02264",
      "title": "Paving the Way Towards Kinematic Assessment Using Monocular Video: A\n  Preclinical Benchmark of State-of-the-Art Deep-Learning-Based 3D Human Pose\n  Estimators Against Inertial Sensors in Daily Living Activities",
      "authors": [
        "Mario Medrano-Paredes",
        "Carmen Fernández-González",
        "Francisco-Javier Díaz-Pernas",
        "Hichem Saoudi",
        "Javier González-Alonso",
        "Mario Martínez-Zarzuela"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.AI (Artificial Intelligence)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "Advances in machine learning and wearable sensors offer new opportunities for\ncapturing and analyzing human movement outside specialized laboratories.\nAccurate assessment of human movement under real-world conditions is essential\nfor telemedicine, sports science, and rehabilitation. This preclinical\nbenchmark compares monocular video-based 3D human pose estimation models with\ninertial measurement units (IMUs), leveraging the VIDIMU dataset containing a\ntotal of 13 clinically relevant daily activities which were captured using both\ncommodity video cameras and five IMUs. During this initial study only healthy\nsubjects were recorded, so results cannot be generalized to pathological\ncohorts. Joint angles derived from state-of-the-art deep learning frameworks\n(MotionAGFormer, MotionBERT, MMPose 2D-to-3D pose lifting, and NVIDIA\nBodyTrack) were evaluated against joint angles computed from IMU data using\nOpenSim inverse kinematics following the Human3.6M dataset format with 17\nkeypoints. Among them, MotionAGFormer demonstrated superior performance,\nachieving the lowest overall RMSE ($9.27\\deg \\pm 4.80\\deg$) and MAE ($7.86\\deg\n\\pm 4.18\\deg$), as well as the highest Pearson correlation ($0.86 \\pm 0.15$)\nand the highest coefficient of determination $R^{2}$ ($0.67 \\pm 0.28$). The\nresults reveal that both technologies are viable for out-of-the-lab kinematic\nassessment. However, they also highlight key trade-offs between video- and\nsensor-based approaches including costs, accessibility, and precision. This\nstudy clarifies where off-the-shelf video models already provide clinically\npromising kinematics in healthy adults and where they lag behind IMU-based\nestimates while establishing valuable guidelines for researchers and clinicians\nseeking to develop robust, cost-effective, and user-friendly solutions for\ntelehealth and remote patient monitoring.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02264v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02264v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "extraction_failed",
      "embedding_status": "completed",
      "rlhf_score": 0.343,
      "weak_supervision_score": 0.314,
      "diffusion_reasoning_score": 0.314,
      "distributed_training_score": 0.296,
      "datasets_score": 0.359,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02265",
      "title": "How to Combat Reactive and Dynamic Jamming Attacks with Reinforcement\n  Learning",
      "authors": [
        "Yalin E. Sagduyu",
        "Tugba Erpek",
        "Kemal Davaslioglu",
        "Sastry Kompella"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)",
        "cs.NI (Networking and Internet Architecture)",
        "eess.SP (Signal Processing)"
      ],
      "abstract": "This paper studies the problem of mitigating reactive jamming, where a jammer\nadopts a dynamic policy of selecting channels and sensing thresholds to detect\nand jam ongoing transmissions. The transmitter-receiver pair learns to avoid\njamming and optimize throughput over time (without prior knowledge of channel\nconditions or jamming strategies) by using reinforcement learning (RL) to adapt\ntransmit power, modulation, and channel selection. Q-learning is employed for\ndiscrete jamming-event states, while Deep Q-Networks (DQN) are employed for\ncontinuous states based on received power. Through different reward functions\nand action sets, the results show that RL can adapt rapidly to spectrum\ndynamics and sustain high rates as channels and jamming policies change over\ntime.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02265v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02265v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.393,
      "weak_supervision_score": 0.336,
      "diffusion_reasoning_score": 0.328,
      "distributed_training_score": 0.31,
      "datasets_score": 0.237,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02266",
      "title": "NeuroSwift: A Lightweight Cross-Subject Framework for fMRI Visual\n  Reconstruction of Complex Scenes",
      "authors": [
        "Shiyi Zhang",
        "Dong Liang",
        "Yihang Zhou"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.HC (Human-Computer Interaction)"
      ],
      "abstract": "Reconstructing visual information from brain activity via computer vision\ntechnology provides an intuitive understanding of visual neural mechanisms.\nDespite progress in decoding fMRI data with generative models, achieving\naccurate cross-subject reconstruction of visual stimuli remains challenging and\ncomputationally demanding. This difficulty arises from inter-subject\nvariability in neural representations and the brain's abstract encoding of core\nsemantic features in complex visual inputs. To address these challenges, we\npropose NeuroSwift, which integrates complementary adapters via diffusion:\nAutoKL for low-level features and CLIP for semantics. NeuroSwift's CLIP Adapter\nis trained on Stable Diffusion generated images paired with COCO captions to\nemulate higher visual cortex encoding. For cross-subject generalization, we\npretrain on one subject and then fine-tune only 17 percent of parameters (fully\nconnected layers) for new subjects, while freezing other components. This\nenables state-of-the-art performance with only one hour of training per subject\non lightweight GPUs (three RTX 4090), and it outperforms existing methods.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02266v2",
      "pdf_url": "http://arxiv.org/pdf/2510.02266v2",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.367,
      "weak_supervision_score": 0.373,
      "diffusion_reasoning_score": 0.464,
      "distributed_training_score": 0.382,
      "datasets_score": 0.339,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on using diffusion models for visual reconstruction from fMRI data, specifically for generating images based on brain activity. While it employs iterative refinement in diffusion processes for image synthesis, it does not involve multi-step logical reasoning, Chain-of-Thought processing, or solving complex logical tasks. Therefore, it lacks the core elements defined in the topic.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02268",
      "title": "Do You Know Where Your Camera Is? View-Invariant Policy Learning with\n  Camera Conditioning",
      "authors": [
        "Tianchong Jiang",
        "Jingtian Ji",
        "Xiangshan Tan",
        "Jiading Fang",
        "Anand Bhattad",
        "Vitor Guizilini",
        "Matthew R. Walter"
      ],
      "categories": [
        "cs.RO (Robotics)",
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "We study view-invariant imitation learning by explicitly conditioning\npolicies on camera extrinsics. Using Plucker embeddings of per-pixel rays, we\nshow that conditioning on extrinsics significantly improves generalization\nacross viewpoints for standard behavior cloning policies, including ACT,\nDiffusion Policy, and SmolVLA. To evaluate policy robustness under realistic\nviewpoint shifts, we introduce six manipulation tasks in RoboSuite and\nManiSkill that pair \"fixed\" and \"randomized\" scene variants, decoupling\nbackground cues from camera pose. Our analysis reveals that policies without\nextrinsics often infer camera pose using visual cues from static backgrounds in\nfixed scenes; this shortcut collapses when workspace geometry or camera\nplacement shifts. Conditioning on extrinsics restores performance and yields\nrobust RGB-only control without depth. We release the tasks, demonstrations,\nand code at https://ripl.github.io/know_your_camera/ .",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02268v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02268v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.403,
      "weak_supervision_score": 0.367,
      "diffusion_reasoning_score": 0.376,
      "distributed_training_score": 0.331,
      "datasets_score": 0.324,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper's main contribution is on view-invariant imitation learning for robots by conditioning policies on camera extrinsics, focusing on techniques like behavior cloning and empirical analysis in simulation environments. It does not involve training a reward model from human-ranked data or using reinforcement learning to fine-tune models based on human preferences, which are core to RLHF.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02270",
      "title": "microCLIP: Unsupervised CLIP Adaptation via Coarse-Fine Token Fusion for\n  Fine-Grained Image Classification",
      "authors": [
        "Sathira Silva",
        "Eman Ali",
        "Chetan Arora",
        "Muhammad Haris Khan"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Unsupervised adaptation of CLIP-based vision-language models (VLMs) for\nfine-grained image classification requires sensitivity to microscopic local\ncues. While CLIP exhibits strong zero-shot transfer, its reliance on coarse\nglobal features restricts its performance on fine-grained classification tasks.\nPrior efforts inject fine-grained knowledge by aligning large language model\n(LLM) descriptions with the CLIP $\\texttt{[CLS]}$ token; however, this approach\noverlooks spatial precision. We propose $\\textbf{microCLIP}$, a self-training\nframework that jointly refines CLIP's visual and textual representations using\nfine-grained cues. At its core is Saliency-Oriented Attention Pooling (SOAP)\nwithin a lightweight TokenFusion module, which builds a saliency-guided\n$\\texttt{[FG]}$ token from patch embeddings and fuses it with the global\n$\\texttt{[CLS]}$ token for coarse-fine alignment. To stabilize adaptation, we\nintroduce a two-headed LLM-derived classifier: a frozen classifier that, via\nmulti-view alignment, provides a stable text-based prior for pseudo-labeling,\nand a learnable classifier initialized from LLM descriptions and fine-tuned\nwith TokenFusion. We further develop Dynamic Knowledge Aggregation, which\nconvexly combines fixed LLM/CLIP priors with TokenFusion's evolving logits to\niteratively refine pseudo-labels. Together, these components uncover latent\nfine-grained signals in CLIP, yielding a consistent $2.90\\%$ average accuracy\ngain across 13 fine-grained benchmarks while requiring only light adaptation.\nOur code is available at https://github.com/sathiiii/microCLIP.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02270v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02270v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.389,
      "weak_supervision_score": 0.419,
      "diffusion_reasoning_score": 0.392,
      "distributed_training_score": 0.371,
      "datasets_score": 0.341,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "Highly Relevant",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "The paper's main contribution involves unsupervised adaptation of CLIP using pseudo-labeling techniques, such as multi-view alignment and Dynamic Knowledge Aggregation, to generate and refine labels from high-level sources like LLMs. This directly aligns with weak supervision, as it programmatically creates noisy or imprecise labels without relying on hand-labeled data, enabling training on unlabeled datasets for fine-grained classification.",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "completed",
      "summary": "The paper introduces microCLIP, an unsupervised adaptation framework for CLIP that enhances its performance on fine-grained image classification by integrating coarse global features with fine-grained local cues through a Saliency-Oriented Attention Pooling (SOAP) mechanism within a TokenFusion module. This approach builds a new [FG] token from patch embeddings, fuses it with the [CLS] token for coarse-fine alignment, and incorporates a two-headed LLM-derived classifier and Dynamic Knowledge Aggregation for stable pseudo-labeling and iterative refinement, resulting in an average accuracy gain of 2.90% across 13 fine-grained benchmarks with lightweight adaptation.",
      "novelty_score": "Moderate",
      "novelty_justification": "The paper presents a notable improvement by introducing the Saliency-Oriented Attention Pooling and TokenFusion to combine existing CLIP features with fine-grained cues, offering a clever adaptation of prior methods for unsupervised fine-grained classification rather than a completely new problem or architecture.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to influence future research in unsupervised adaptation of vision-language models for fine-grained tasks, as evidenced by its consistent accuracy gains and open-source availability, though its applicability is primarily within specific subfields of computer vision.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper provides a strong, valuable contribution to fine-grained image classification by advancing CLIP adaptation techniques, making it essential for researchers focused on vision-language models and unsupervised learning.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/e5c2b6cd551e9bedc05a6feb200a603edb69f147",
      "total_authors": 4,
      "authors_found": 4,
      "highest_h_index": 1,
      "average_h_index": 0.75,
      "notable_authors_count": 0,
      "author_h_indexes": [
        {
          "name": "Sathira Silva",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2316587278"
        },
        {
          "name": "Eman Ali",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2312336118"
        },
        {
          "name": "Chetan Arora",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2372796134"
        },
        {
          "name": "Muhammad Haris Khan",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2312835931"
        }
      ]
    },
    {
      "id": "2510.02271",
      "title": "InfoMosaic-Bench: Evaluating Multi-Source Information Seeking in\n  Tool-Augmented Agents",
      "authors": [
        "Yaxin Du",
        "Yuanshuo Zhang",
        "Xiyuan Yang",
        "Yifan Zhou",
        "Cheng Wang",
        "Gongyi Zou",
        "Xianghe Pang",
        "Wenhao Wang",
        "Menglan Chen",
        "Shuo Tang",
        "Zhiyu Li",
        "Feiyu Xiong",
        "Siheng Chen"
      ],
      "categories": [
        "cs.CL (Computation and Language)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Information seeking is a fundamental requirement for humans. However,\nexisting LLM agents rely heavily on open-web search, which exposes two\nfundamental weaknesses: online content is noisy and unreliable, and many\nreal-world tasks require precise, domain-specific knowledge unavailable from\nthe web. The emergence of the Model Context Protocol (MCP) now allows agents to\ninterface with thousands of specialized tools, seemingly resolving this\nlimitation. Yet it remains unclear whether agents can effectively leverage such\ntools -- and more importantly, whether they can integrate them with\ngeneral-purpose search to solve complex tasks. Therefore, we introduce\nInfoMosaic-Bench, the first benchmark dedicated to multi-source information\nseeking in tool-augmented agents. Covering six representative domains\n(medicine, finance, maps, video, web, and multi-domain integration),\nInfoMosaic-Bench requires agents to combine general-purpose search with\ndomain-specific tools. Tasks are synthesized with InfoMosaic-Flow, a scalable\npipeline that grounds task conditions in verified tool outputs, enforces\ncross-source dependencies, and filters out shortcut cases solvable by trivial\nlookup. This design guarantees both reliability and non-triviality. Experiments\nwith 14 state-of-the-art LLM agents reveal three findings: (i) web information\nalone is insufficient, with GPT-5 achieving only 38.2% accuracy and 67.5% pass\nrate; (ii) domain tools provide selective but inconsistent benefits, improving\nsome domains while degrading others; and (iii) 22.4% of failures arise from\nincorrect tool usage or selection, highlighting that current LLMs still\nstruggle with even basic tool handling.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02271v2",
      "pdf_url": "http://arxiv.org/pdf/2510.02271v2",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.363,
      "weak_supervision_score": 0.406,
      "diffusion_reasoning_score": 0.425,
      "distributed_training_score": 0.364,
      "datasets_score": 0.414,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "Tangentially Relevant",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "Highly Relevant",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "The paper introduces InfoMosaic-Flow, an automated pipeline for synthesizing tasks using tools and verification, which involves programmatically generating data from sources that could be seen as noisy or high-level. However, it does not focus on training machine learning models with weak labels; instead, it emphasizes benchmark creation, making the connection indirect and not central to the paper's contributions.",
      "diffusion_reasoning_justification": "The paper does not discuss or adapt diffusion models for iterative refinement in reasoning tasks. It focuses on evaluating LLM agents for multi-source information seeking using tools, with no mention of diffusion-based processes or holistic Chain-of-Thought correction.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "The paper's main contribution is the introduction and evaluation of InfoMosaic-Bench, a new benchmark dataset for assessing AI agents in multi-source information seeking, along with the InfoMosaic-Flow pipeline for dataset curation. This directly aligns with research on creating, benchmarking, and evaluating datasets for AI applications.",
      "llm_score_status": "completed",
      "summary": "The paper introduces InfoMosaic-Bench, a novel benchmark designed to evaluate how effectively tool-augmented large language model (LLM) agents perform multi-source information seeking across six domains, including medicine, finance, and maps, by integrating general-purpose web search with domain-specific tools. Using the InfoMosaic-Flow pipeline to synthesize reliable and non-trivial tasks, the authors conduct experiments with 14 state-of-the-art agents, revealing that web search alone is insufficient for accurate results, domain tools offer inconsistent benefits, and a significant portion of failures stem from improper tool usage, underscoring the need for advancements in agent capabilities.",
      "novelty_score": "High",
      "novelty_justification": "The paper introduces a truly new benchmark and synthesis pipeline for evaluating multi-source information seeking in tool-augmented agents, significantly advancing the state-of-the-art in AI agent assessment by addressing a previously unexplored problem.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to be cited and built upon in AI and computational language subfields for improving tool integration in agents, though its influence may be confined to specialized research rather than widespread commercial applications.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper represents a strong and valuable contribution by highlighting critical limitations in current LLM agents, making it essential for researchers focused on AI tool usage and information seeking.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/dcc1c2ff424b5efd4851c841ab0ba014200e2e7e",
      "total_authors": 13,
      "authors_found": 13,
      "highest_h_index": 12,
      "average_h_index": 4.076923076923077,
      "notable_authors_count": 4,
      "author_h_indexes": [
        {
          "name": "Yaxin Du",
          "h_index": 5,
          "profile_url": "https://www.semanticscholar.org/author/2273581205"
        },
        {
          "name": "Yuanshuo Zhang",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2350994556"
        },
        {
          "name": "Xiyuan Yang",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383416505"
        },
        {
          "name": "Yifan Zhou",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2268646470"
        },
        {
          "name": "Cheng Wang",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2362825425"
        },
        {
          "name": "Gongyi Zou",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383309702"
        },
        {
          "name": "Xianghe Pang",
          "h_index": 7,
          "profile_url": "https://www.semanticscholar.org/author/2259929200"
        },
        {
          "name": "Wenhao Wang",
          "h_index": 4,
          "profile_url": "https://www.semanticscholar.org/author/2280328057"
        },
        {
          "name": "Menglan Chen",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2335854089"
        },
        {
          "name": "Shuo Tang",
          "h_index": 6,
          "profile_url": "https://www.semanticscholar.org/author/2283546526"
        },
        {
          "name": "Zhiyu Li",
          "h_index": 12,
          "profile_url": "https://www.semanticscholar.org/author/2268429641"
        },
        {
          "name": "Feiyu Xiong",
          "h_index": 12,
          "profile_url": "https://www.semanticscholar.org/author/2268399953"
        },
        {
          "name": "Siheng Chen",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2330409548"
        }
      ]
    },
    {
      "id": "2510.02272",
      "title": "Parallel Scaling Law: Unveiling Reasoning Generalization through A\n  Cross-Linguistic Perspective",
      "authors": [
        "Wen Yang",
        "Junhong Wu",
        "Chong Li",
        "Chengqing Zong",
        "Jiajun Zhang"
      ],
      "categories": [
        "cs.CL (Computation and Language)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Recent advancements in Reinforcement Post-Training (RPT) have significantly\nenhanced the capabilities of Large Reasoning Models (LRMs), sparking increased\ninterest in the generalization of RL-based reasoning. While existing work has\nprimarily focused on investigating its generalization across tasks or\nmodalities, this study proposes a novel cross-linguistic perspective to\ninvestigate reasoning generalization. This raises a crucial question:\n$\\textit{Does the reasoning capability achieved from English RPT effectively\ntransfer to other languages?}$ We address this by systematically evaluating\nEnglish-centric LRMs on multilingual reasoning benchmarks and introducing a\nmetric to quantify cross-lingual transferability. Our findings reveal that\ncross-lingual transferability varies significantly across initial model, target\nlanguage, and training paradigm. Through interventional studies, we find that\nmodels with stronger initial English capabilities tend to over-rely on\nEnglish-specific patterns, leading to diminished cross-lingual generalization.\nTo address this, we conduct a thorough parallel training study. Experimental\nresults yield three key findings: $\\textbf{First-Parallel Leap}$, a substantial\nleap in performance when transitioning from monolingual to just a single\nparallel language, and a predictable $\\textbf{Parallel Scaling Law}$, revealing\nthat cross-lingual reasoning transfer follows a power-law with the number of\ntraining parallel languages. Moreover, we identify the discrepancy between\nactual monolingual performance and the power-law prediction as\n$\\textbf{Monolingual Generalization Gap}$, indicating that English-centric LRMs\nfail to fully generalize across languages. Our study challenges the assumption\nthat LRM reasoning mirrors human cognition, providing critical insights for the\ndevelopment of more language-agnostic LRMs.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02272v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02272v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.439,
      "weak_supervision_score": 0.361,
      "diffusion_reasoning_score": 0.526,
      "distributed_training_score": 0.434,
      "datasets_score": 0.344,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Moderately Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "Tangentially Relevant",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper discusses Reinforcement Post-Training (RPT) and Reinforcement Learning with Verifiable Rewards (RLVR), which are reinforcement learning techniques used to enhance Large Reasoning Models. While these methods involve reward-based training similar to RLHF, the paper does not explicitly mention human feedback or a separate reward model trained on human-ranked data. Instead, it focuses on verifiable rewards, which may be automated, making it related but not a direct match to RLHF.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper does not mention diffusion models, iterative refinement processes, or any adaptation of diffusion for multi-step logical reasoning. Its focus is on reinforcement learning for cross-lingual generalization in Large Reasoning Models, with no components related to diffusion-based approaches.",
      "distributed_training_justification": "The paper refers to a \"Parallel Training Study\" involving training on parallel data from multiple languages, which might imply some form of parallel processing. However, it primarily discusses multilingual data usage for improving generalization, not algorithms or systems for accelerating training via distributed computing, data partitioning, or multi-node setups.",
      "datasets_justification": "below_threshold",
      "llm_score_status": "completed",
      "summary": "This paper examines the cross-linguistic generalization of reasoning capabilities in Large Reasoning Models (LRMs) trained primarily on English, questioning whether these skills transfer effectively to other languages. Through a three-stage approach involving observational evaluations of 13 English-centric LRMs on multilingual benchmarks, interventional studies to analyze confounding factors, and parallel training experiments across multiple languages, the authors introduce the Multilingual Transferability Index and reveal key findings: models often over-rely on English patterns, leading to a First-Parallel Leap in performance when adding a second language, a Parallel Scaling Law showing power-law improvements with more languages, and a Monolingual Generalization Gap indicating incomplete transfer, ultimately challenging assumptions about LRM reasoning and advocating for more language-agnostic models.",
      "novelty_score": "High",
      "novelty_justification": "The paper introduces a novel cross-linguistic perspective on reasoning generalization in LRMs, including new metrics like the Multilingual Transferability Index and concepts such as the Parallel Scaling Law, which significantly advance the state-of-the-art in understanding language transferability.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to be cited and built upon in AI and computational linguistics subfields by informing the development of more language-agnostic models, though its influence may be limited to researchers focused on multilingual reasoning rather than broader applications.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper provides high-quality insights into an underexplored aspect of AI reasoning generalization, making it valuable for researchers in language processing and AI to understand limitations and improvements in cross-lingual capabilities.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/e2199df22da4ce45e66852b97cb387bb6759d73a",
      "total_authors": 5,
      "authors_found": 5,
      "highest_h_index": 15,
      "average_h_index": 8.4,
      "notable_authors_count": 3,
      "author_h_indexes": [
        {
          "name": "Wen Yang",
          "h_index": 5,
          "profile_url": "https://www.semanticscholar.org/author/2218735807"
        },
        {
          "name": "Junhong Wu",
          "h_index": 4,
          "profile_url": "https://www.semanticscholar.org/author/2237788942"
        },
        {
          "name": "Chong Li",
          "h_index": 6,
          "profile_url": "https://www.semanticscholar.org/author/2109665081"
        },
        {
          "name": "Chengqing Zong",
          "h_index": 15,
          "profile_url": "https://www.semanticscholar.org/author/2064100826"
        },
        {
          "name": "Jiajun Zhang",
          "h_index": 12,
          "profile_url": "https://www.semanticscholar.org/author/2124819243"
        }
      ]
    },
    {
      "id": "2510.02276",
      "title": "BioX-Bridge: Model Bridging for Unsupervised Cross-Modal Knowledge\n  Transfer across Biosignals",
      "authors": [
        "Chenqi Li",
        "Yu Liu",
        "Timothy Denison",
        "Tingting Zhu"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Biosignals offer valuable insights into the physiological states of the human\nbody. Although biosignal modalities differ in functionality, signal fidelity,\nsensor comfort, and cost, they are often intercorrelated, reflecting the\nholistic and interconnected nature of human physiology. This opens up the\npossibility of performing the same tasks using alternative biosignal\nmodalities, thereby improving the accessibility, usability, and adaptability of\nhealth monitoring systems. However, the limited availability of large labeled\ndatasets presents challenges for training models tailored to specific tasks and\nmodalities of interest. Unsupervised cross-modal knowledge transfer offers a\npromising solution by leveraging knowledge from an existing modality to support\nmodel training for a new modality. Existing methods are typically based on\nknowledge distillation, which requires running a teacher model alongside\nstudent model training, resulting in high computational and memory overhead.\nThis challenge is further exacerbated by the recent development of foundation\nmodels that demonstrate superior performance and generalization across tasks at\nthe cost of large model sizes. To this end, we explore a new framework for\nunsupervised cross-modal knowledge transfer of biosignals by training a\nlightweight bridge network to align the intermediate representations and enable\ninformation flow between foundation models and across modalities. Specifically,\nwe introduce an efficient strategy for selecting alignment positions where the\nbridge should be constructed, along with a flexible prototype network as the\nbridge architecture. Extensive experiments across multiple biosignal\nmodalities, tasks, and datasets show that BioX-Bridge reduces the number of\ntrainable parameters by 88--99\\% while maintaining or even improving transfer\nperformance compared to state-of-the-art methods.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02276v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02276v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.358,
      "weak_supervision_score": 0.373,
      "diffusion_reasoning_score": 0.389,
      "distributed_training_score": 0.376,
      "datasets_score": 0.348,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02279",
      "title": "Addressing Pitfalls in the Evaluation of Uncertainty Estimation Methods\n  for Natural Language Generation",
      "authors": [
        "Mykyta Ielanskyi",
        "Kajetan Schweighofer",
        "Lukas Aichberger",
        "Sepp Hochreiter"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Hallucinations are a common issue that undermine the reliability of large\nlanguage models (LLMs). Recent studies have identified a specific subset of\nhallucinations, known as confabulations, which arise due to predictive\nuncertainty of LLMs. To detect confabulations, various methods for estimating\npredictive uncertainty in natural language generation (NLG) have been\ndeveloped. These methods are typically evaluated by correlating uncertainty\nestimates with the correctness of generated text, with question-answering (QA)\ndatasets serving as the standard benchmark. However, commonly used approximate\ncorrectness functions have substantial disagreement between each other and,\nconsequently, in the ranking of the uncertainty estimation methods. This allows\none to inflate the apparent performance of uncertainty estimation methods. We\npropose using several alternative risk indicators for risk correlation\nexperiments that improve robustness of empirical assessment of UE algorithms\nfor NLG. For QA tasks, we show that marginalizing over multiple LLM-as-a-judge\nvariants leads to reducing the evaluation biases. Furthermore, we explore\nstructured tasks as well as out of distribution and perturbation detection\ntasks which provide robust and controllable risk indicators. Finally, we\npropose to use an Elo rating of uncertainty estimation methods to give an\nobjective summarization over extensive evaluation settings.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02279v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02279v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.424,
      "weak_supervision_score": 0.405,
      "diffusion_reasoning_score": 0.429,
      "distributed_training_score": 0.306,
      "datasets_score": 0.342,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "Tangentially Relevant",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on evaluating uncertainty estimation methods for NLG and detecting hallucinations in LLMs, without any discussion of training models using human feedback, reward models, or reinforcement learning techniques.",
      "weak_supervision_justification": "The paper mentions using approximate or noisy evaluation methods like LLM-as-a-judge for assessing correctness, which could loosely relate to programmatically generated labels in weak supervision, but it does not involve training models with weak supervision techniques.",
      "diffusion_reasoning_justification": "The paper addresses uncertainty estimation in NLG and evaluation pitfalls, with no mention of diffusion models, iterative refinement processes, or multi-step logical reasoning.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02282",
      "title": "VidGuard-R1: AI-Generated Video Detection and Explanation via Reasoning\n  MLLMs and RL",
      "authors": [
        "Kyoungjun Park",
        "Yifan Yang",
        "Juheon Yi",
        "Shicheng Zheng",
        "Yifei Shen",
        "Dongqi Han",
        "Caihua Shan",
        "Muhammad Muaz",
        "Lili Qiu"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "With the rapid advancement of AI-generated videos, there is an urgent need\nfor effective detection tools to mitigate societal risks such as misinformation\nand reputational harm. In addition to accurate classification, it is essential\nthat detection models provide interpretable explanations to ensure transparency\nfor regulators and end users. To address these challenges, we introduce\nVidGuard-R1, the first video authenticity detector that fine-tunes a\nmulti-modal large language model (MLLM) using group relative policy\noptimization (GRPO). Our model delivers both highly accurate judgments and\ninsightful reasoning. We curate a challenging dataset of 140k real and\nAI-generated videos produced by state-of-the-art generation models, carefully\ndesigning the generation process to maximize discrimination difficulty. We then\nfine-tune Qwen-VL using GRPO with two specialized reward models that target\ntemporal artifacts and generation complexity. Extensive experiments demonstrate\nthat VidGuard-R1 achieves state-of-the-art zero-shot performance on existing\nbenchmarks, with additional training pushing accuracy above 95%. Case studies\nfurther show that VidGuard-R1 produces precise and interpretable rationales\nbehind its predictions. The code is publicly available at\nhttps://VidGuard-R1.github.io.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02282v2",
      "pdf_url": "http://arxiv.org/pdf/2510.02282v2",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.406,
      "weak_supervision_score": 0.347,
      "diffusion_reasoning_score": 0.486,
      "distributed_training_score": 0.316,
      "datasets_score": 0.35,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Tangentially Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper uses reinforcement learning (RL) via group relative policy optimization (GRPO) with specialized reward models to fine-tune an MLLM, which aligns somewhat with RL concepts. However, it does not involve human-ranked data or a reward model trained on human preferences, making it only tangentially related to RLHF as defined.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper references diffusion steps in the context of video generation complexity for reward models in RL, but it does not adapt diffusion processes for multi-step logical reasoning or treat Chain-of-Thought as a holistically corrected entity, as required for this topic.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02283",
      "title": "Self-Forcing++: Towards Minute-Scale High-Quality Video Generation",
      "authors": [
        "Justin Cui",
        "Jie Wu",
        "Ming Li",
        "Tao Yang",
        "Xiaojie Li",
        "Rui Wang",
        "Andrew Bai",
        "Yuanhao Ban",
        "Cho-Jui Hsieh"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Diffusion models have revolutionized image and video generation, achieving\nunprecedented visual quality. However, their reliance on transformer\narchitectures incurs prohibitively high computational costs, particularly when\nextending generation to long videos. Recent work has explored autoregressive\nformulations for long video generation, typically by distilling from\nshort-horizon bidirectional teachers. Nevertheless, given that teacher models\ncannot synthesize long videos, the extrapolation of student models beyond their\ntraining horizon often leads to pronounced quality degradation, arising from\nthe compounding of errors within the continuous latent space. In this paper, we\npropose a simple yet effective approach to mitigate quality degradation in\nlong-horizon video generation without requiring supervision from long-video\nteachers or retraining on long video datasets. Our approach centers on\nexploiting the rich knowledge of teacher models to provide guidance for the\nstudent model through sampled segments drawn from self-generated long videos.\nOur method maintains temporal consistency while scaling video length by up to\n20x beyond teacher's capability, avoiding common issues such as over-exposure\nand error-accumulation without recomputing overlapping frames like previous\nmethods. When scaling up the computation, our method shows the capability of\ngenerating videos up to 4 minutes and 15 seconds, equivalent to 99.9% of the\nmaximum span supported by our base model's position embedding and more than 50x\nlonger than that of our baseline model. Experiments on standard benchmarks and\nour proposed improved benchmark demonstrate that our approach substantially\noutperforms baseline methods in both fidelity and consistency. Our long-horizon\nvideos demo can be found at https://self-forcing-plus-plus.github.io/",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02283v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02283v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.366,
      "weak_supervision_score": 0.373,
      "diffusion_reasoning_score": 0.468,
      "distributed_training_score": 0.391,
      "datasets_score": 0.301,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper's main contribution is a method for improving long-video generation using diffusion models, focusing on temporal consistency and error correction in visual content. It does not involve adapting diffusion for multi-step logical reasoning, chain-of-thought processes, or solving complex logical tasks; instead, it applies diffusion to generative video tasks, which lacks the required reasoning components.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02284",
      "title": "Learning to Generate Object Interactions with Physics-Guided Video\n  Diffusion",
      "authors": [
        "David Romero",
        "Ariana Bermudez",
        "Hao Li",
        "Fabio Pizzati",
        "Ivan Laptev"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.AI (Artificial Intelligence)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "Recent models for video generation have achieved remarkable progress and are\nnow deployed in film, social media production, and advertising. Beyond their\ncreative potential, such models also hold promise as world simulators for\nrobotics and embodied decision making. Despite strong advances, however,\ncurrent approaches still struggle to generate physically plausible object\ninteractions and lack physics-grounded control mechanisms. To address this\nlimitation, we introduce KineMask, an approach for physics-guided video\ngeneration that enables realistic rigid body control, interactions, and\neffects. Given a single image and a specified object velocity, our method\ngenerates videos with inferred motions and future object interactions. We\npropose a two-stage training strategy that gradually removes future motion\nsupervision via object masks. Using this strategy we train video diffusion\nmodels (VDMs) on synthetic scenes of simple interactions and demonstrate\nsignificant improvements of object interactions in real scenes. Furthermore,\nKineMask integrates low-level motion control with high-level textual\nconditioning via predictive scene descriptions, leading to effective support\nfor synthesis of complex dynamical phenomena. Extensive experiments show that\nKineMask achieves strong improvements over recent models of comparable size.\nAblation studies further highlight the complementary roles of low- and\nhigh-level conditioning in VDMs. Our code, model, and data will be made\npublicly available.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02284v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02284v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.371,
      "weak_supervision_score": 0.334,
      "diffusion_reasoning_score": 0.539,
      "distributed_training_score": 0.332,
      "datasets_score": 0.296,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper's main contribution is developing a physics-guided video diffusion model (KineMask) for generating realistic object interactions in videos, focusing on iterative refinement for visual synthesis. While diffusion models inherently involve multi-step processes, the paper does not adapt this for solving complex logical tasks, such as treating a Chain-of-Thought as a single entity for holistic correction in reasoning. Instead, it applies diffusion to physical simulation and video generation, lacking any clear component for multi-step logical reasoning.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02286",
      "title": "Tree-based Dialogue Reinforced Policy Optimization for Red-Teaming\n  Attacks",
      "authors": [
        "Ruohao Guo",
        "Afshin Oroojlooy",
        "Roshan Sridhar",
        "Miguel Ballesteros",
        "Alan Ritter",
        "Dan Roth"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)",
        "cs.CL (Computation and Language)"
      ],
      "abstract": "Despite recent rapid progress in AI safety, current large language models\nremain vulnerable to adversarial attacks in multi-turn interaction settings,\nwhere attackers strategically adapt their prompts across conversation turns and\npose a more critical yet realistic challenge. Existing approaches that discover\nsafety vulnerabilities either rely on manual red-teaming with human experts or\nemploy automated methods using pre-defined templates and human-curated attack\ndata, with most focusing on single-turn attacks. However, these methods did not\nexplore the vast space of possible multi-turn attacks, failing to consider\nnovel attack trajectories that emerge from complex dialogue dynamics and\nstrategic conversation planning. This gap is particularly critical given recent\nfindings that LLMs exhibit significantly higher vulnerability to multi-turn\nattacks compared to single-turn attacks. We propose DialTree-RPO, an on-policy\nreinforcement learning framework integrated with tree search that autonomously\ndiscovers diverse multi-turn attack strategies by treating the dialogue as a\nsequential decision-making problem, enabling systematic exploration without\nmanually curated data. Through extensive experiments, our approach not only\nachieves more than 25.9% higher ASR across 10 target models compared to\nprevious state-of-the-art approaches, but also effectively uncovers new attack\nstrategies by learning optimal dialogue policies that maximize attack success\nacross multiple turns.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02286v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02286v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.486,
      "weak_supervision_score": 0.365,
      "diffusion_reasoning_score": 0.428,
      "distributed_training_score": 0.383,
      "datasets_score": 0.293,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper proposes an RL framework for red-teaming that uses automated rewards from proxy models (safety guardrails), without any involvement of human feedback, ranking, or a reward model trained on human data. Thus, it does not align with RLHF, which specifically requires human preferences for reward modeling and policy fine-tuning.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on a tree-based RL framework for multi-turn attack strategies, with no mention of diffusion models, iterative refinement processes, or treating reasoning paths as entities for holistic correction. It lacks any components related to diffusion-based methods for logical tasks.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02287",
      "title": "MultiModal Action Conditioned Video Generation",
      "authors": [
        "Yichen Li",
        "Antonio Torralba"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Current video models fail as world model as they lack fine-graiend control.\nGeneral-purpose household robots require real-time fine motor control to handle\ndelicate tasks and urgent situations. In this work, we introduce fine-grained\nmultimodal actions to capture such precise control. We consider senses of\nproprioception, kinesthesia, force haptics, and muscle activation. Such\nmultimodal senses naturally enables fine-grained interactions that are\ndifficult to simulate with text-conditioned generative models. To effectively\nsimulate fine-grained multisensory actions, we develop a feature learning\nparadigm that aligns these modalities while preserving the unique information\neach modality provides. We further propose a regularization scheme to enhance\ncausality of the action trajectory features in representing intricate\ninteraction dynamics. Experiments show that incorporating multimodal senses\nimproves simulation accuracy and reduces temporal drift. Extensive ablation\nstudies and downstream applications demonstrate the effectiveness and\npracticality of our work.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02287v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02287v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.379,
      "weak_supervision_score": 0.337,
      "diffusion_reasoning_score": 0.429,
      "distributed_training_score": 0.323,
      "datasets_score": 0.321,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on multimodal action conditioned video generation for robotic simulations, emphasizing feature learning and regularization for sensory data to enable fine-grained control. It does not involve diffusion models, iterative refinement for logical tasks, or any adaptation of diffusion processes for chain-of-thought reasoning. The core contributions are in multimodal representation and simulation accuracy, with no connection to solving complex logical tasks.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02291",
      "title": "Test-Time Anchoring for Discrete Diffusion Posterior Sampling",
      "authors": [
        "Litu Rout",
        "Andreas Lugmayr",
        "Yasamin Jafarian",
        "Srivatsan Varadharajan",
        "Constantine Caramanis",
        "Sanjay Shakkottai",
        "Ira Kemelmacher-Shlizerman"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.CV (Computer Vision and Pattern Recognition)",
        "stat.ML (Machine Learning)"
      ],
      "abstract": "We study the problem of posterior sampling using pretrained discrete\ndiffusion foundation models, aiming to recover images from noisy measurements\nwithout retraining task-specific models. While diffusion models have achieved\nremarkable success in generative modeling, most advances rely on continuous\nGaussian diffusion. In contrast, discrete diffusion offers a unified framework\nfor jointly modeling categorical data such as text and images. Beyond\nunification, discrete diffusion provides faster inference, finer control, and\nprincipled training-free Bayesian inference, making it particularly well-suited\nfor posterior sampling. However, existing approaches to discrete diffusion\nposterior sampling face severe challenges: derivative-free guidance yields\nsparse signals, continuous relaxations limit applicability, and split Gibbs\nsamplers suffer from the curse of dimensionality. To overcome these\nlimitations, we introduce Anchored Posterior Sampling (APS) for masked\ndiffusion foundation models, built on two key innovations -- quantized\nexpectation for gradient-like guidance in discrete embedding space, and\nanchored remasking for adaptive decoding. Our approach achieves\nstate-of-the-art performance among discrete diffusion samplers across linear\nand nonlinear inverse problems on the standard benchmarks. We further\ndemonstrate the benefits of our approach in training-free stylization and\ntext-guided editing.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02291v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02291v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.34,
      "weak_supervision_score": 0.373,
      "diffusion_reasoning_score": 0.537,
      "distributed_training_score": 0.372,
      "datasets_score": 0.312,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on discrete diffusion models for posterior sampling in image recovery and inverse problems, emphasizing techniques like quantized expectation and anchored remasking for generative tasks. It does not involve adapting diffusion for multi-step logical reasoning, Chain-of-Thought processes, or solving complex logical tasks; instead, it is centered on visual data generation and sampling, lacking any component for holistic reasoning correction.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02292",
      "title": "From Behavioral Performance to Internal Competence: Interpreting\n  Vision-Language Models with VLM-Lens",
      "authors": [
        "Hala Sheta",
        "Eric Huang",
        "Shuyu Wu",
        "Ilia Alenabi",
        "Jiajun Hong",
        "Ryker Lin",
        "Ruoxi Ning",
        "Daniel Wei",
        "Jialin Yang",
        "Jiawei Zhou",
        "Ziqiao Ma",
        "Freda Shi"
      ],
      "categories": [
        "cs.CL (Computation and Language)",
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "We introduce VLM-Lens, a toolkit designed to enable systematic benchmarking,\nanalysis, and interpretation of vision-language models (VLMs) by supporting the\nextraction of intermediate outputs from any layer during the forward pass of\nopen-source VLMs. VLM-Lens provides a unified, YAML-configurable interface that\nabstracts away model-specific complexities and supports user-friendly operation\nacross diverse VLMs. It currently supports 16 state-of-the-art base VLMs and\ntheir over 30 variants, and is extensible to accommodate new models without\nchanging the core logic.\n  The toolkit integrates easily with various interpretability and analysis\nmethods. We demonstrate its usage with two simple analytical experiments,\nrevealing systematic differences in the hidden representations of VLMs across\nlayers and target concepts. VLM-Lens is released as an open-sourced project to\naccelerate community efforts in understanding and improving VLMs.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02292v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02292v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.356,
      "weak_supervision_score": 0.348,
      "diffusion_reasoning_score": 0.405,
      "distributed_training_score": 0.311,
      "datasets_score": 0.34,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper's main contribution is the development of VLM-Lens, a toolkit for extracting and analyzing intermediate outputs from vision-language models to enhance benchmarking and interpretability. It focuses on unified interfaces for VLMs and does not involve diffusion models, iterative refinement processes, or multi-step logical reasoning as defined in the topic.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02294",
      "title": "F2LLM Technical Report: Matching SOTA Embedding Performance with 6\n  Million Open-Source Data",
      "authors": [
        "Ziyin Zhang",
        "Zihan Liao",
        "Hang Yu",
        "Peng Di",
        "Rui Wang"
      ],
      "categories": [
        "cs.CL (Computation and Language)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "We introduce F2LLM - Foundation to Feature Large Language Models, a suite of\nstate-of-the-art embedding models in three sizes: 0.6B, 1.7B, and 4B. Unlike\nprevious top-ranking embedding models that require massive contrastive\npretraining, sophisticated training pipelines, and costly synthetic training\ndata, F2LLM is directly finetuned from foundation models on 6 million\nquery-document-negative tuples curated from open-source, non-synthetic\ndatasets, striking a strong balance between training cost, model size, and\nembedding performance. On the MTEB English leaderboard, F2LLM-4B ranks 2nd\namong models with approximately 4B parameters and 7th overall, while F2LLM-1.7B\nranks 1st among models in the 1B-2B size range. To facilitate future research\nin the field, we release the models, training dataset, and code, positioning\nF2LLM as a strong, reproducible, and budget-friendly baseline for future works.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02294v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02294v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.377,
      "weak_supervision_score": 0.36,
      "diffusion_reasoning_score": 0.372,
      "distributed_training_score": 0.4,
      "datasets_score": 0.375,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "Not Relevant",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "The paper's main contribution is the introduction of F2LLM, a suite of embedding models finetuned on open-source data, focusing on achieving high performance with efficient training methods. It discusses the training process in terms of data curation and finetuning from foundation models, but does not address distributed training, parallel computing, multi-node machine learning, or strategies for partitioning data/computation across processors. As such, there is no direct or indirect relevance to this topic.",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02295",
      "title": "VideoNSA: Native Sparse Attention Scales Video Understanding",
      "authors": [
        "Enxin Song",
        "Wenhao Chai",
        "Shusheng Yang",
        "Ethan Armand",
        "Xiaojun Shan",
        "Haiyang Xu",
        "Jianwen Xie",
        "Zhuowen Tu"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.AI (Artificial Intelligence)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "Video understanding in multimodal language models remains limited by context\nlength: models often miss key transition frames and struggle to maintain\ncoherence across long time scales. To address this, we adapt Native Sparse\nAttention (NSA) to video-language models. Our method, VideoNSA, adapts\nQwen2.5-VL through end-to-end training on a 216K video instruction dataset. We\nemploy a hardware-aware hybrid approach to attention, preserving dense\nattention for text, while employing NSA for video. Compared to\ntoken-compression and training-free sparse baselines, VideoNSA achieves\nimproved performance on long-video understanding, temporal reasoning, and\nspatial benchmarks. Further ablation analysis reveals four key findings: (1)\nreliable scaling to 128K tokens; (2) an optimal global-local attention\nallocation at a fixed budget; (3) task-dependent branch usage patterns; and (4)\nthe learnable combined sparse attention help induce dynamic attention sinks.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02295v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02295v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.336,
      "weak_supervision_score": 0.369,
      "diffusion_reasoning_score": 0.44,
      "distributed_training_score": 0.378,
      "datasets_score": 0.331,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on adapting Native Sparse Attention for video understanding in multimodal language models, emphasizing efficient handling of long video contexts through sparse mechanisms. It does not involve diffusion models, iterative refinement processes, or multi-step logical reasoning as described in the topic. There is no mention of treating a Chain-of-Thought as a single entity or using diffusion for holistic correction.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02296",
      "title": "Continual Personalization for Diffusion Models",
      "authors": [
        "Yu-Chien Liao",
        "Jr-Jen Chen",
        "Chi-Pin Huang",
        "Ci-Siang Lin",
        "Meng-Lin Wu",
        "Yu-Chiang Frank Wang"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Updating diffusion models in an incremental setting would be practical in\nreal-world applications yet computationally challenging. We present a novel\nlearning strategy of Concept Neuron Selection (CNS), a simple yet effective\napproach to perform personalization in a continual learning scheme. CNS\nuniquely identifies neurons in diffusion models that are closely related to the\ntarget concepts. In order to mitigate catastrophic forgetting problems while\npreserving zero-shot text-to-image generation ability, CNS finetunes concept\nneurons in an incremental manner and jointly preserves knowledge learned of\nprevious concepts. Evaluation of real-world datasets demonstrates that CNS\nachieves state-of-the-art performance with minimal parameter adjustments,\noutperforming previous methods in both single and multi-concept personalization\nworks. CNS also achieves fusion-free operation, reducing memory storage and\nprocessing time for continual personalization.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02296v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02296v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.374,
      "weak_supervision_score": 0.344,
      "diffusion_reasoning_score": 0.527,
      "distributed_training_score": 0.353,
      "datasets_score": 0.295,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on continual personalization of diffusion models for image generation, specifically through neuron selection and incremental finetuning to handle user-specific concepts without forgetting. It does not involve adapting diffusion models for multi-step logical reasoning, chain-of-thought processes, or solving complex logical tasks, which are the core elements of diffusion-based reasoning.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02297",
      "title": "Interactive Training: Feedback-Driven Neural Network Optimization",
      "authors": [
        "Wentao Zhang",
        "Yang Young Lu",
        "Yuntian Deng"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)",
        "cs.CL (Computation and Language)"
      ],
      "abstract": "Traditional neural network training typically follows fixed, predefined\noptimization recipes, lacking the flexibility to dynamically respond to\ninstabilities or emerging training issues. In this paper, we introduce\nInteractive Training, an open-source framework that enables real-time,\nfeedback-driven intervention during neural network training by human experts or\nautomated AI agents. At its core, Interactive Training uses a control server to\nmediate communication between users or agents and the ongoing training process,\nallowing users to dynamically adjust optimizer hyperparameters, training data,\nand model checkpoints. Through three case studies, we demonstrate that\nInteractive Training achieves superior training stability, reduced sensitivity\nto initial hyperparameters, and improved adaptability to evolving user needs,\npaving the way toward a future training paradigm where AI agents autonomously\nmonitor training logs, proactively resolve instabilities, and optimize training\ndynamics.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02297v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02297v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.496,
      "weak_supervision_score": 0.413,
      "diffusion_reasoning_score": 0.392,
      "distributed_training_score": 0.504,
      "datasets_score": 0.324,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Tangentially Relevant",
      "weak_supervision_relevance": "Not Relevant",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "Tangentially Relevant",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper involves human feedback for real-time adjustments during training, such as modifying hyperparameters, which shares a loose connection to human-guided optimization. However, it does not involve training a reward model on human-ranked data or using reinforcement learning for fine-tuning, making it only peripherally related to RLHF.",
      "weak_supervision_justification": "The paper focuses on interactive, feedback-driven adjustments to neural network training, with no discussion of programmatically generating labels from noisy sources or using weak supervision techniques for training data. Its core contribution is about real-time interventions, not label generation or supervision methods.",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "The paper mentions training on managed clusters and job queues, which could imply distributed environments, but its main contribution is interactive training adjustments, not algorithms or systems for partitioning data/computation across nodes. It does not focus on parallel computing or multi-node acceleration.",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02300",
      "title": "Equilibrium Matching: Generative Modeling with Implicit Energy-Based\n  Models",
      "authors": [
        "Runqian Wang",
        "Yilun Du"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)",
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "We introduce Equilibrium Matching (EqM), a generative modeling framework\nbuilt from an equilibrium dynamics perspective. EqM discards the\nnon-equilibrium, time-conditional dynamics in traditional diffusion and\nflow-based generative models and instead learns the equilibrium gradient of an\nimplicit energy landscape. Through this approach, we can adopt an\noptimization-based sampling process at inference time, where samples are\nobtained by gradient descent on the learned landscape with adjustable step\nsizes, adaptive optimizers, and adaptive compute. EqM surpasses the generation\nperformance of diffusion/flow models empirically, achieving an FID of 1.90 on\nImageNet 256$\\times$256. EqM is also theoretically justified to learn and\nsample from the data manifold. Beyond generation, EqM is a flexible framework\nthat naturally handles tasks including partially noised image denoising, OOD\ndetection, and image composition. By replacing time-conditional velocities with\na unified equilibrium landscape, EqM offers a tighter bridge between flow and\nenergy-based models and a simple route to optimization-driven inference.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02300v3",
      "pdf_url": "http://arxiv.org/pdf/2510.02300v3",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.338,
      "weak_supervision_score": 0.307,
      "diffusion_reasoning_score": 0.496,
      "distributed_training_score": 0.343,
      "datasets_score": 0.278,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on Equilibrium Matching (EqM), a generative modeling framework for image generation that modifies diffusion models to use equilibrium dynamics, emphasizing tasks like image denoising and sampling. It does not involve adapting diffusion processes for multi-step logical reasoning, chain-of-thought processing, or solving complex logical tasks. There is no component for holistic correction of reasoning paths, making it unrelated to the topic.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02305",
      "title": "Diffusion Models and the Manifold Hypothesis: Log-Domain Smoothing is\n  Geometry Adaptive",
      "authors": [
        "Tyler Farghly",
        "Peter Potaptchik",
        "Samuel Howard",
        "George Deligiannidis",
        "Jakiw Pidstrigach"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)",
        "math.ST (Statistics Theory)",
        "stat.ML (Machine Learning)",
        "stat.TH (Statistics Theory)"
      ],
      "abstract": "Diffusion models have achieved state-of-the-art performance, demonstrating\nremarkable generalisation capabilities across diverse domains. However, the\nmechanisms underpinning these strong capabilities remain only partially\nunderstood. A leading conjecture, based on the manifold hypothesis, attributes\nthis success to their ability to adapt to low-dimensional geometric structure\nwithin the data. This work provides evidence for this conjecture, focusing on\nhow such phenomena could result from the formulation of the learning problem\nthrough score matching. We inspect the role of implicit regularisation by\ninvestigating the effect of smoothing minimisers of the empirical score\nmatching objective. Our theoretical and empirical results confirm that\nsmoothing the score function -- or equivalently, smoothing in the log-density\ndomain -- produces smoothing tangential to the data manifold. In addition, we\nshow that the manifold along which the diffusion model generalises can be\ncontrolled by choosing an appropriate smoothing.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02305v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02305v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.343,
      "weak_supervision_score": 0.356,
      "diffusion_reasoning_score": 0.571,
      "distributed_training_score": 0.327,
      "datasets_score": 0.287,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper primarily explores the generative aspects of diffusion models, focusing on their adaptation to data manifolds through score matching and smoothing techniques. It does not involve adapting diffusion processes for multi-step logical reasoning, chain-of-thought processing, or solving complex logical tasks, which are central to the topic.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02307",
      "title": "NoiseShift: Resolution-Aware Noise Recalibration for Better\n  Low-Resolution Image Generation",
      "authors": [
        "Ruozhen He",
        "Moayed Haji-Ali",
        "Ziyan Yang",
        "Vicente Ordonez"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Text-to-image diffusion models trained on a fixed set of resolutions often\nfail to generalize, even when asked to generate images at lower resolutions\nthan those seen during training. High-resolution text-to-image generators are\ncurrently unable to easily offer an out-of-the-box budget-efficient alternative\nto their users who might not need high-resolution images. We identify a key\ntechnical insight in diffusion models that when addressed can help tackle this\nlimitation: Noise schedulers have unequal perceptual effects across\nresolutions. The same level of noise removes disproportionately more signal\nfrom lower-resolution images than from high-resolution images, leading to a\ntrain-test mismatch. We propose NoiseShift, a training-free method that\nrecalibrates the noise level of the denoiser conditioned on resolution size.\nNoiseShift requires no changes to model architecture or sampling schedule and\nis compatible with existing models. When applied to Stable Diffusion 3, Stable\nDiffusion 3.5, and Flux-Dev, quality at low resolutions is significantly\nimproved. On LAION-COCO, NoiseShift improves SD3.5 by 15.89%, SD3 by 8.56%, and\nFlux-Dev by 2.44% in FID on average. On CelebA, NoiseShift improves SD3.5 by\n10.36%, SD3 by 5.19%, and Flux-Dev by 3.02% in FID on average. These results\ndemonstrate the effectiveness of NoiseShift in mitigating resolution-dependent\nartifacts and enhancing the quality of low-resolution image generation.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02307v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02307v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.355,
      "weak_supervision_score": 0.377,
      "diffusion_reasoning_score": 0.491,
      "distributed_training_score": 0.366,
      "datasets_score": 0.282,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper's main contribution is a method to improve low-resolution image generation in text-to-image diffusion models by recalibrating noise levels, focusing on perceptual effects and resolution mismatches. It does not involve adapting diffusion models for multi-step logical reasoning, chain-of-thought processes, or solving complex logical tasks; instead, it is solely about image synthesis enhancements.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02311",
      "title": "Inferring Dynamic Physical Properties from Video Foundation Models",
      "authors": [
        "Guanqi Zhan",
        "Xianzheng Ma",
        "Weidi Xie",
        "Andrew Zisserman"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "We study the task of predicting dynamic physical properties from videos. More\nspecifically, we consider physical properties that require temporal information\nto be inferred: elasticity of a bouncing object, viscosity of a flowing liquid,\nand dynamic friction of an object sliding on a surface. To this end, we make\nthe following contributions: (i) We collect a new video dataset for each\nphysical property, consisting of synthetic training and testing splits, as well\nas a real split for real world evaluation. (ii) We explore three ways to infer\nthe physical property from videos: (a) an oracle method where we supply the\nvisual cues that intrinsically reflect the property using classical computer\nvision techniques; (b) a simple read out mechanism using a visual prompt and\ntrainable prompt vector for cross-attention on pre-trained video generative and\nself-supervised models; and (c) prompt strategies for Multi-modal Large\nLanguage Models (MLLMs). (iii) We show that video foundation models trained in\na generative or self-supervised manner achieve a similar performance, though\nbehind that of the oracle, and MLLMs are currently inferior to the other\nmodels, though their performance can be improved through suitable prompting.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02311v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02311v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.362,
      "weak_supervision_score": 0.357,
      "diffusion_reasoning_score": 0.451,
      "distributed_training_score": 0.329,
      "datasets_score": 0.354,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on inferring dynamic physical properties from videos using pre-trained video foundation models, including generative models that may involve diffusion (e.g., DynamicRafter or Sora). However, it does not adapt the iterative refinement process of diffusion for multi-step logical reasoning or treat a chain-of-thought as a single entity. Instead, it uses these models for property extraction via readout mechanisms, without any clear component for diffusion-based reasoning as defined.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02313",
      "title": "Clink! Chop! Thud! -- Learning Object Sounds from Real-World\n  Interactions",
      "authors": [
        "Mengyu Yang",
        "Yiming Chen",
        "Haozheng Pei",
        "Siddhant Agarwal",
        "Arun Balajee Vasudevan",
        "James Hays"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Can a model distinguish between the sound of a spoon hitting a hardwood floor\nversus a carpeted one? Everyday object interactions produce sounds unique to\nthe objects involved. We introduce the sounding object detection task to\nevaluate a model's ability to link these sounds to the objects directly\ninvolved. Inspired by human perception, our multimodal object-aware framework\nlearns from in-the-wild egocentric videos. To encourage an object-centric\napproach, we first develop an automatic pipeline to compute segmentation masks\nof the objects involved to guide the model's focus during training towards the\nmost informative regions of the interaction. A slot attention visual encoder is\nused to further enforce an object prior. We demonstrate state of the art\nperformance on our new task along with existing multimodal action understanding\ntasks.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02313v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02313v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.323,
      "weak_supervision_score": 0.366,
      "diffusion_reasoning_score": 0.371,
      "distributed_training_score": 0.286,
      "datasets_score": 0.369,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02314",
      "title": "StealthAttack: Robust 3D Gaussian Splatting Poisoning via Density-Guided\n  Illusions",
      "authors": [
        "Bo-Hsu Ke",
        "You-Zhe Xie",
        "Yu-Lun Liu",
        "Wei-Chen Chiu"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "3D scene representation methods like Neural Radiance Fields (NeRF) and 3D\nGaussian Splatting (3DGS) have significantly advanced novel view synthesis. As\nthese methods become prevalent, addressing their vulnerabilities becomes\ncritical. We analyze 3DGS robustness against image-level poisoning attacks and\npropose a novel density-guided poisoning method. Our method strategically\ninjects Gaussian points into low-density regions identified via Kernel Density\nEstimation (KDE), embedding viewpoint-dependent illusory objects clearly\nvisible from poisoned views while minimally affecting innocent views.\nAdditionally, we introduce an adaptive noise strategy to disrupt multi-view\nconsistency, further enhancing attack effectiveness. We propose a KDE-based\nevaluation protocol to assess attack difficulty systematically, enabling\nobjective benchmarking for future research. Extensive experiments demonstrate\nour method's superior performance compared to state-of-the-art techniques.\nProject page: https://hentci.github.io/stealthattack/",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02314v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02314v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.276,
      "weak_supervision_score": 0.316,
      "diffusion_reasoning_score": 0.351,
      "distributed_training_score": 0.282,
      "datasets_score": 0.234,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02315",
      "title": "Optimal Control Meets Flow Matching: A Principled Route to Multi-Subject\n  Fidelity",
      "authors": [
        "Eric Tillmann Bill",
        "Enis Simsar",
        "Thomas Hofmann"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Text-to-image (T2I) models excel on single-entity prompts but struggle with\nmulti-subject descriptions, often showing attribute leakage, identity\nentanglement, and subject omissions. We introduce the first theoretical\nframework with a principled, optimizable objective for steering sampling\ndynamics toward multi-subject fidelity. Viewing flow matching (FM) through\nstochastic optimal control (SOC), we formulate subject disentanglement as\ncontrol over a trained FM sampler. This yields two architecture-agnostic\nalgorithms: (i) a training-free test-time controller that perturbs the base\nvelocity with a single-pass update, and (ii) Adjoint Matching, a lightweight\nfine-tuning rule that regresses a control network to a backward adjoint signal\nwhile preserving base-model capabilities. The same formulation unifies prior\nattention heuristics, extends to diffusion models via a flow-diffusion\ncorrespondence, and provides the first fine-tuning route explicitly designed\nfor multi-subject fidelity. Empirically, on Stable Diffusion 3.5, FLUX, and\nStable Diffusion XL, both algorithms consistently improve multi-subject\nalignment while maintaining base-model style. Test-time control runs\nefficiently on commodity GPUs, and fine-tuned controllers trained on limited\nprompts generalize to unseen ones. We further highlight FOCUS (Flow Optimal\nControl for Unentangled Subjects), which achieves state-of-the-art\nmulti-subject fidelity across models.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02315v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02315v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.401,
      "weak_supervision_score": 0.334,
      "diffusion_reasoning_score": 0.462,
      "distributed_training_score": 0.379,
      "datasets_score": 0.29,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on stochastic optimal control for improving text-to-image models via flow matching, without any mention of human feedback, reward models, or reinforcement learning techniques. It relies on optimization objectives for disentanglement, not alignment with human preferences.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper applies diffusion models to enhance image generation for multi-subject fidelity, but it does not adapt the iterative refinement process for solving complex logical tasks or treat a Chain-of-Thought as an entity for reasoning. It is limited to generative image tasks without multi-step logical reasoning components.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02407",
      "title": "Extreme value forecasting using relevance-based data augmentation with\n  deep learning models",
      "authors": [
        "Junru Hua",
        "Rahul Ahluwalia",
        "Rohitash Chandra"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Data augmentation with generative adversarial networks (GANs) has been\npopular for class imbalance problems, mainly for pattern classification and\ncomputer vision-related applications. Extreme value forecasting is a\nchallenging field that has various applications from finance to climate change\nproblems. In this study, we present a data augmentation framework for extreme\nvalue forecasting. In this framework, our focus is on forecasting extreme\nvalues using deep learning models in combination with data augmentation models\nsuch as GANs and synthetic minority oversampling technique (SMOTE). We use deep\nlearning models such as convolutional long short-term memory (Conv-LSTM) and\nbidirectional long short-term memory (BD-LSTM) networks for multistep ahead\nprediction featuring extremes. We investigate which data augmentation models\nare the most suitable, taking into account the prediction accuracy overall and\nat extreme regions, along with computational efficiency. We also present novel\nstrategies for incorporating data augmentation, considering extreme values\nbased on a relevance function. Our results indicate that the SMOTE-based\nstrategy consistently demonstrated superior adaptability, leading to improved\nperformance across both short- and long-horizon forecasts. Conv-LSTM and\nBD-LSTM exhibit complementary strengths: the former excels in periodic, stable\ndatasets, while the latter performs better in chaotic or non-stationary\nsequences.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02407v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02407v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.384,
      "weak_supervision_score": 0.416,
      "diffusion_reasoning_score": 0.384,
      "distributed_training_score": 0.379,
      "datasets_score": 0.384,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "Tangentially Relevant",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "The paper employs a relevance function to programmatically identify and label extreme values in time series data, which shares similarities with weak supervision by using high-level or imprecise sources for labeling rather than manual annotation. However, the main contribution focuses on data augmentation techniques like GANs and SMOTE for forecasting, not on developing or primarily relying on weak supervision methods for training models.",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02414",
      "title": "RainSeer: Fine-Grained Rainfall Reconstruction via Physics-Guided\n  Modeling",
      "authors": [
        "Lin Chen",
        "Jun Chen",
        "Minghui Qiu",
        "Shuxin Zhong",
        "Binghong Chen",
        "Kaishun Wu"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Reconstructing high-resolution rainfall fields is essential for flood\nforecasting, hydrological modeling, and climate analysis. However, existing\nspatial interpolation methods-whether based on automatic weather station (AWS)\nmeasurements or enhanced with satellite/radar observations often over-smooth\ncritical structures, failing to capture sharp transitions and localized\nextremes. We introduce RainSeer, a structure-aware reconstruction framework\nthat reinterprets radar reflectivity as a physically grounded structural\nprior-capturing when, where, and how rain develops. This shift, however,\nintroduces two fundamental challenges: (i) translating high-resolution\nvolumetric radar fields into sparse point-wise rainfall observations, and (ii)\nbridging the physical disconnect between aloft hydro-meteors and ground-level\nprecipitation. RainSeer addresses these through a physics-informed two-stage\narchitecture: a Structure-to-Point Mapper performs spatial alignment by\nprojecting mesoscale radar structures into localized ground-level rainfall,\nthrough a bidirectional mapping, and a Geo-Aware Rain Decoder captures the\nsemantic transformation of hydro-meteors through descent, melting, and\nevaporation via a causal spatiotemporal attention mechanism. We evaluate\nRainSeer on two public datasets-RAIN-F (Korea, 2017-2019) and MeteoNet (France,\n2016-2018)-and observe consistent improvements over state-of-the-art baselines,\nreducing MAE by over 13.31% and significantly enhancing structural fidelity in\nreconstructed rainfall fields.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02414v2",
      "pdf_url": "http://arxiv.org/pdf/2510.02414v2",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.323,
      "weak_supervision_score": 0.348,
      "diffusion_reasoning_score": 0.37,
      "distributed_training_score": 0.336,
      "datasets_score": 0.332,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02416",
      "title": "Cross-Platform DNA Methylation Classifier for the Eight Molecular\n  Subtypes of Group 3 & 4 Medulloblastoma",
      "authors": [
        "Omer Abid",
        "Gholamreza Rafiee"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Medulloblastoma is a malignant pediatric brain cancer, and the discovery of\nmolecular subgroups is enabling personalized treatment strategies. In 2019, a\nconsensus identified eight novel subtypes within Groups 3 and 4, each\ndisplaying heterogeneous characteristics. Classifiers are essential for\ntranslating these findings into clinical practice by supporting clinical\ntrials, personalized therapy development and application, and patient\nmonitoring. This study presents a DNA methylation-based, cross-platform machine\nlearning classifier capable of distinguishing these subtypes on both HM450 and\nEPIC methylation array samples. Across two independent test sets, the model\nachieved weighted F1 = 0.95 and balanced accuracy = 0.957, consistent across\nplatforms. As the first cross-platform solution, it provides backward\ncompatibility while extending applicability to a newer platform, also enhancing\naccessibility. It also has the potential to become the first publicly available\nclassifier for these subtypes once deployed through a web application, as\nplanned in the future. This work overall takes steps in the direction of\nadvancing precision medicine and improving clinical outcomes for patients\nwithin the majority prevalence medulloblastoma subgroups, groups 3 and 4.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02416v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02416v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "extraction_failed",
      "embedding_status": "completed",
      "rlhf_score": 0.256,
      "weak_supervision_score": 0.302,
      "diffusion_reasoning_score": 0.286,
      "distributed_training_score": 0.295,
      "datasets_score": 0.301,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02417",
      "title": "NEURODNAAI: Neural pipeline approaches for the advancing dna-based\n  information storage as a sustainable digital medium using deep learning\n  framework",
      "authors": [
        "Rakesh Thakur",
        "Lavanya Singh",
        "Yashika",
        "Manomay Bundawala",
        "Aruna Kumar"
      ],
      "categories": [
        "cs.ET (Emerging Technologies)",
        "cs.AI (Artificial Intelligence)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "DNA is a promising medium for digital information storage for its exceptional\ndensity and durability. While prior studies advanced coding theory, workflow\ndesign, and simulation tools, challenges such as synthesis costs, sequencing\nerrors, and biological constraints (GC-content imbalance, homopolymers) limit\npractical deployment. To address this, our framework draws from quantum\nparallelism concepts to enhance encoding diversity and resilience, integrating\nbiologically informed constraints with deep learning to enhance error\nmitigation in DNA storage. NeuroDNAAI encodes binary data streams into symbolic\nDNA sequences, transmits them through a noisy channel with substitutions,\ninsertions, and deletions, and reconstructs them with high fidelity. Our\nresults show that traditional prompting or rule-based schemes fail to adapt\neffectively to realistic noise, whereas NeuroDNAAI achieves superior accuracy.\nExperiments on benchmark datasets demonstrate low bit error rates for both text\nand images. By unifying theory, workflow, and simulation into one pipeline,\nNeuroDNAAI enables scalable, biologically valid archival DNA storage",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02417v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02417v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.336,
      "weak_supervision_score": 0.364,
      "diffusion_reasoning_score": 0.428,
      "distributed_training_score": 0.399,
      "datasets_score": 0.381,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on a Transformer-based neural decoder for error correction in DNA storage, emphasizing encoding, noise simulation, and data reconstruction. It does not involve diffusion models, iterative refinement processes, or multi-step logical reasoning for complex tasks. Therefore, there is no connection to diffusion-based reasoning.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02418",
      "title": "BrowserArena: Evaluating LLM Agents on Real-World Web Navigation Tasks",
      "authors": [
        "Sagnik Anupam",
        "Davis Brown",
        "Shuo Li",
        "Eric Wong",
        "Hamed Hassani",
        "Osbert Bastani"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "LLM web agents now browse and take actions on the open web, yet current agent\nevaluations are constrained to sandboxed environments or artificial tasks. We\nintroduce BrowserArena, a live open-web agent evaluation platform that collects\nuser-submitted tasks, runs Arena-style head-to-head comparisons, and uses\nstep-level human feedback to surface failure modes. Collecting and analyzing\nstep-level annotations on the agent traces, we identify three consistent\nfailure modes: captcha resolution, pop-up banner removal, and direct navigation\nto URLs. By constructing targeted datasets to further study these tasks, we\ndiscover variations in how different language models navigate these failure\nmodes. We find, for example, that o4-mini deploys a wider variety of strategies\nto circumvent captcha resolution than other models and DeepSeek-R1 consistently\nmisleads users about pop-up banner closure. Our findings surface both the\ndiversity and brittleness of current web agents. More broadly, our benchmarking\nmethodology provides an approach to evaluating and understanding web agent\nfailure modes at scale.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02418v2",
      "pdf_url": "http://arxiv.org/pdf/2510.02418v2",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.453,
      "weak_supervision_score": 0.419,
      "diffusion_reasoning_score": 0.413,
      "distributed_training_score": 0.342,
      "datasets_score": 0.392,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Tangentially Relevant",
      "weak_supervision_relevance": "Not Relevant",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper collects human feedback through user votes and step-level annotations to evaluate LLM agents and identify failure modes, similar to preference ranking in RLHF. However, it does not involve training a reward model or using reinforcement learning to fine-tune models; instead, the feedback is used for benchmarking and analysis, not for model alignment or optimization.",
      "weak_supervision_justification": "The paper relies on direct human input for task submissions, annotations, and feedback, rather than programmatically generating noisy or imprecise labels for training models. While it analyzes user annotations to identify patterns and construct datasets, this process does not constitute weak supervision, as it depends on explicit human labeling without the use of high-level, programmatic sources.",
      "diffusion_reasoning_justification": "The paper focuses on evaluating LLM agents for web navigation tasks using human feedback and pairwise comparisons, with no mention of diffusion models, iterative refinement processes, or multi-step logical reasoning via diffusion. There is no component involving the adaptation of diffusion for reasoning tasks.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02422",
      "title": "Dynamic Target Attack",
      "authors": [
        "Kedong Xiu",
        "Churui Zeng",
        "Tianhang Zheng",
        "Xinzhe Huang",
        "Xiaojun Jia",
        "Di Wang",
        "Puning Zhao",
        "Zhan Qin",
        "Kui Ren"
      ],
      "categories": [
        "cs.CR (Cryptography and Security)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Existing gradient-based jailbreak attacks typically optimize an adversarial\nsuffix to induce a fixed affirmative response. However, this fixed target\nusually resides in an extremely low-density region of a safety-aligned LLM's\noutput distribution conditioned on diverse harmful inputs. Due to the\nsubstantial discrepancy between the target and the original output, existing\nattacks require numerous iterations to optimize the adversarial prompt, which\nmight still fail to induce the low-probability target response from the target\nLLM. In this paper, we propose Dynamic Target Attack (DTA), a new jailbreaking\nframework relying on the target LLM's own responses as targets to optimize the\nadversarial prompts. In each optimization round, DTA iteratively samples\nmultiple candidate responses directly from the output distribution conditioned\non the current prompt, and selects the most harmful response as a temporary\ntarget for prompt optimization. In contrast to existing attacks, DTA\nsignificantly reduces the discrepancy between the target and the output\ndistribution, substantially easing the optimization process to search for an\neffective adversarial prompt.\n  Extensive experiments demonstrate the superior effectiveness and efficiency\nof DTA: under the white-box setting, DTA only needs 200 optimization iterations\nto achieve an average attack success rate (ASR) of over 87\\% on recent\nsafety-aligned LLMs, exceeding the state-of-the-art baselines by over 15\\%. The\ntime cost of DTA is 2-26 times less than existing baselines. Under the\nblack-box setting, DTA uses Llama-3-8B-Instruct as a surrogate model for target\nsampling and achieves an ASR of 85\\% against the black-box target model\nLlama-3-70B-Instruct, exceeding its counterparts by over 25\\%.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02422v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02422v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.453,
      "weak_supervision_score": 0.384,
      "diffusion_reasoning_score": 0.418,
      "distributed_training_score": 0.371,
      "datasets_score": 0.319,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Tangentially Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper references RLHF as a technique for aligning LLMs, noting its use in making models safer, but the main contribution—Dynamic Target Attack (DTA) for jailbreaking—does not involve developing, implementing, or evaluating RLHF systems. It only discusses attacking models aligned via RLHF, making it peripherally related.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on adversarial attacks and prompt optimization for jailbreaking LLMs, with no mention of diffusion models, iterative refinement processes, or multi-step logical reasoning. There is no component involving diffusion-based techniques for solving complex tasks.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02423",
      "title": "RefineShot: Rethinking Cinematography Understanding with Foundational\n  Skill Evaluation",
      "authors": [
        "Hang Wu",
        "Yujun Cai",
        "Haonan Ge",
        "Hongkai Chen",
        "Ming-Hsuan Yang",
        "Yiwei Wang"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Cinematography understanding refers to the ability to recognize not only the\nvisual content of a scene but also the cinematic techniques that shape\nnarrative meaning. This capability is attracting increasing attention, as it\nenhances multimodal understanding in real-world applications and underpins\ncoherent content creation in film and media. As the most comprehensive\nbenchmark for this task, ShotBench spans a wide range of cinematic concepts and\nVQA-style evaluations, with ShotVL achieving state-of-the-art results on it.\nHowever, our analysis reveals that ambiguous option design in ShotBench and\nShotVL's shortcomings in reasoning consistency and instruction adherence\nundermine evaluation reliability, limiting fair comparison and hindering future\nprogress. To overcome these issues, we systematically refine ShotBench through\nconsistent option restructuring, conduct the first critical analysis of\nShotVL's reasoning behavior, and introduce an extended evaluation protocol that\njointly assesses task accuracy and core model competencies. These efforts lead\nto RefineShot, a refined and expanded benchmark that enables more reliable\nassessment and fosters future advances in cinematography understanding.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02423v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02423v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.398,
      "weak_supervision_score": 0.351,
      "diffusion_reasoning_score": 0.424,
      "distributed_training_score": 0.328,
      "datasets_score": 0.38,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on refining a benchmark for cinematography understanding, analyzing model reasoning consistency in ShotVL, and introducing an expanded evaluation protocol. It does not mention or utilize diffusion-based models or processes for iterative refinement in logical tasks. There is no evidence of adapting diffusion mechanisms for multi-step reasoning, making the paper unrelated to this topic.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02425",
      "title": "Words That Make Language Models Perceive",
      "authors": [
        "Sophie L. Wang",
        "Phillip Isola",
        "Brian Cheung"
      ],
      "categories": [
        "cs.CL (Computation and Language)",
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "Large language models (LLMs) trained purely on text ostensibly lack any\ndirect perceptual experience, yet their internal representations are implicitly\nshaped by multimodal regularities encoded in language. We test the hypothesis\nthat explicit sensory prompting can surface this latent structure, bringing a\ntext-only LLM into closer representational alignment with specialist vision and\naudio encoders. When a sensory prompt tells the model to 'see' or 'hear', it\ncues the model to resolve its next-token predictions as if they were\nconditioned on latent visual or auditory evidence that is never actually\nsupplied. Our findings reveal that lightweight prompt engineering can reliably\nactivate modality-appropriate representations in purely text-trained LLMs.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02425v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02425v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.409,
      "weak_supervision_score": 0.378,
      "diffusion_reasoning_score": 0.479,
      "distributed_training_score": 0.296,
      "datasets_score": 0.3,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on prompt engineering to align LLM representations with sensory encoders, without any mention of human feedback, reward models, or reinforcement learning for fine-tuning. There is no training process involving human-ranked data or alignment with human preferences.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper discusses sensory prompting in LLMs for representational alignment and does not involve diffusion models, iterative refinement processes, or multi-step logical reasoning for complex tasks. It centers on text generation and prompting, not holistic correction of reasoning paths.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02453",
      "title": "How to Train Your Advisor: Steering Black-Box LLMs with Advisor Models",
      "authors": [
        "Parth Asawa",
        "Alan Zhu",
        "Matei Zaharia",
        "Alexandros G. Dimakis",
        "Joseph E. Gonzalez"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)",
        "cs.CL (Computation and Language)"
      ],
      "abstract": "Foundation models are increasingly deployed as black-box services, where\nmodel weights cannot be modified and customization is limited to prompting.\nWhile static prompt optimization has shown promise, it produces a single fixed\nprompt that fails to adapt to different inputs, users, or environments. We\nintroduce Advisor Models, lightweight parametric policies trained with\nreinforcement learning to reactively issue natural language steering\ninstructions in-context to black-box models. The advisor is a second small\nmodel that sits between the input and the model, shaping behavior on a\nper-instance basis using reward signals from the environment. Across multiple\ndomains involving reasoning and personalization, we show that Advisor Models\noutperform static prompt optimizers, discovering environment dynamics and\nimproving downstream task performance. We also demonstrate the generalizability\nof advisors by transferring them across black-box models, as well as the\nframework's ability to achieve specialization while retaining robustness to\nout-of-distribution inputs. Viewed more broadly, Advisor Models provide a\nlearnable interface to black-box systems where the advisor acts as a\nparametric, environment-specific memory. We argue that dynamic optimization of\nblack-box models via Advisor Models is a promising direction for enabling\npersonalization and environment-adaptable AI with frontier-level capabilities.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02453v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02453v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.481,
      "weak_supervision_score": 0.429,
      "diffusion_reasoning_score": 0.452,
      "distributed_training_score": 0.393,
      "datasets_score": 0.294,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Tangentially Relevant",
      "weak_supervision_relevance": "Not Relevant",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper uses reinforcement learning to train advisor models with rewards from the environment, which is conceptually related to RLHF. However, it does not involve human feedback or a reward model trained on human-ranked data; instead, rewards are task-specific and environment-derived, making it only loosely connected to RLHF.",
      "weak_supervision_justification": "The paper focuses on training advisor models using reinforcement learning with environmental rewards, with no mention of programmatically generating noisy labels or relying on high-level, imprecise sources for supervision. It does not address weak supervision techniques.",
      "diffusion_reasoning_justification": "The paper discusses steering black-box models for reasoning tasks using advisor models, but it does not involve diffusion models, iterative refinement processes, or treating chain-of-thought as a holistically corrected entity. There is no component related to diffusion-based methods.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02456",
      "title": "Market-Driven Subset Selection for Budgeted Training",
      "authors": [
        "Ashish Jha",
        "Valentin Leplat",
        "AH Phan"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)",
        "cs.NA (Numerical Analysis)",
        "math.NA (Numerical Analysis)"
      ],
      "abstract": "Training large language models on massive datasets is computationally\nexpensive, yet empirical evidence suggests that substantial portions of\ntraining examples contribute minimally to final performance. Data subset\nselection addresses this inefficiency by identifying small, high-utility\nsubsets under resource constraints. However, example utility is inherently\nmulti-faceted, encompassing uncertainty, distributional rarity, and diversity\nsignals that are heterogeneous and typically combined through ad hoc weighted\nsums lacking theoretical grounding. We propose a market-based framework that\ntreats each training example as a tradeable contract and employs the\nLogarithmic Market Scoring Rule to aggregate multiple utility signals into\ncoherent prices. Heterogeneous signals act as traders, a single liquidity\nparameter controls concentration versus smoothing, and topic-wise normalization\nensures calibrated aggregation. Token budgets are handled explicitly through a\nprice-per-token decision rule with an interpretable length-bias parameter. We\nestablish theoretical connections to maximum-entropy aggregation and provide\nutility recovery guarantees under noisy but monotone signals. On GSM8K\nmathematical reasoning under strict 60k-token budgets, our selector achieves\nparity with strong single-signal baselines while exhibiting lower variance and\nincurring less than 0.1 GPU-hour overhead. On AGNews classification at 5-25\\%\nretention rates, the market formulation delivers competitive accuracy with\nimproved stability. Our framework unifies multi-signal data curation under\nfixed computational budgets for prompt-level reasoning and classification\ntasks.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02456v2",
      "pdf_url": "http://arxiv.org/pdf/2510.02456v2",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.423,
      "weak_supervision_score": 0.432,
      "diffusion_reasoning_score": 0.401,
      "distributed_training_score": 0.413,
      "datasets_score": 0.399,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "Not Relevant",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "Tangentially Relevant",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on market-based data subset selection for efficient training of language models, using utility signals and computational budgets. It does not involve human feedback, reward models, or reinforcement learning techniques to align AI models with human preferences.",
      "weak_supervision_justification": "The paper addresses selecting high-utility subsets from existing datasets for training, but it does not involve programmatically generating labels from noisy or imprecise sources. It relies on predefined utility signals rather than weak supervision methods for label creation.",
      "diffusion_reasoning_justification": "The paper proposes a framework for data selection and aggregation of utility signals, applied to tasks like mathematical reasoning, but it does not incorporate diffusion models, iterative refinement processes, or multi-step logical reasoning as described in diffusion-based approaches.",
      "distributed_training_justification": "The paper discusses computational efficiency and token budgets for training language models, which could indirectly relate to distributed training by addressing resource constraints. However, it does not focus on algorithms for partitioning data or computation across multiple nodes, making the connection peripheral.",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02463",
      "title": "CLARITY: Clinical Assistant for Routing, Inference, and Triage",
      "authors": [
        "Vladimir Shaposhnikov",
        "Aleksandr Nesterov",
        "Ilia Kopanichuk",
        "Ivan Bakulin",
        "Egor Zhelvakov",
        "Ruslan Abramov",
        "Ekaterina Tsapieva",
        "Iaroslav Bespalov",
        "Dmitry V. Dylov",
        "Ivan Oseledets"
      ],
      "categories": [
        "cs.CL (Computation and Language)",
        "cs.AI (Artificial Intelligence)",
        "cs.MA (Multiagent Systems)"
      ],
      "abstract": "We present CLARITY (Clinical Assistant for Routing, Inference and Triage), an\nAI-driven platform designed to facilitate patient-to-specialist routing,\nclinical consultations, and severity assessment of patient conditions. Its\nhybrid architecture combines a Finite State Machine (FSM) for structured\ndialogue flows with collaborative agents that employ Large Language Model (LLM)\nto analyze symptoms and prioritize referrals to appropriate specialists. Built\non a modular microservices framework, CLARITY ensures safe, efficient, and\nrobust performance, flexible and readily scalable to meet the demands of\nexisting workflows and IT solutions in healthcare. We report integration of our\nclinical assistant into a large-scale national interhospital platform, with\nmore than 55,000 content-rich user dialogues completed within the two months of\ndeployment, 2,500 of which were expert-annotated for subsequent validation. The\nvalidation results show that CLARITY surpasses human-level performance in terms\nof the first-attempt routing precision, naturally requiring up to 3 times\nshorter duration of the consultation than with a human.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02463v2",
      "pdf_url": "http://arxiv.org/pdf/2510.02463v2",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.408,
      "weak_supervision_score": 0.352,
      "diffusion_reasoning_score": 0.408,
      "distributed_training_score": 0.359,
      "datasets_score": 0.319,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper describes CLARITY, a hybrid system using FSM and LLMs for healthcare tasks, with expert-annotated data for validation. However, there is no mention of using human feedback to train a reward model or fine-tune the main model via reinforcement learning. The annotations appear to be for evaluation purposes only, not for RLHF processes.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on a hybrid architecture with FSM and LLMs for structured dialogues and symptom analysis, but it does not involve diffusion models or iterative refinement processes for multi-step logical reasoning. There is no indication of treating a Chain-of-Thought as an entity for holistic correction.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02469",
      "title": "SIMSplat: Predictive Driving Scene Editing with Language-aligned 4D\n  Gaussian Splatting",
      "authors": [
        "Sung-Yeon Park",
        "Adam Lee",
        "Juanwu Lu",
        "Can Cui",
        "Luyang Jiang",
        "Rohit Gupta",
        "Kyungtae Han",
        "Ahmadreza Moradipari",
        "Ziran Wang"
      ],
      "categories": [
        "cs.RO (Robotics)",
        "cs.AI (Artificial Intelligence)",
        "cs.CL (Computation and Language)",
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Driving scene manipulation with sensor data is emerging as a promising\nalternative to traditional virtual driving simulators. However, existing\nframeworks struggle to generate realistic scenarios efficiently due to limited\nediting capabilities. To address these challenges, we present SIMSplat, a\npredictive driving scene editor with language-aligned Gaussian splatting. As a\nlanguage-controlled editor, SIMSplat enables intuitive manipulation using\nnatural language prompts. By aligning language with Gaussian-reconstructed\nscenes, it further supports direct querying of road objects, allowing precise\nand flexible editing. Our method provides detailed object-level editing,\nincluding adding new objects and modifying the trajectories of both vehicles\nand pedestrians, while also incorporating predictive path refinement through\nmulti-agent motion prediction to generate realistic interactions among all\nagents in the scene. Experiments on the Waymo dataset demonstrate SIMSplat's\nextensive editing capabilities and adaptability across a wide range of\nscenarios. Project page: https://sungyeonparkk.github.io/simsplat/",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02469v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02469v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.36,
      "weak_supervision_score": 0.341,
      "diffusion_reasoning_score": 0.445,
      "distributed_training_score": 0.333,
      "datasets_score": 0.332,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Tangentially Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper mentions diffusion models in the introduction as part of broader generative approaches for scene reconstruction, but SIMSplat's main contribution focuses on language-aligned 4D Gaussian Splatting and multi-agent motion prediction, not on adapting diffusion for multi-step logical reasoning or Chain-of-Thought processes. Thus, while diffusion is referenced in the background, it is not a core element of the method.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02480",
      "title": "Safe and Efficient In-Context Learning via Risk Control",
      "authors": [
        "Andrea Wynn",
        "Metod Jazbec",
        "Charith Peris",
        "Rinat Khaziev",
        "Anqi Liu",
        "Daniel Khashabi",
        "Eric Nalisnick"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "Large language models (LLMs) demonstrate a remarkable ability to learn new\ntasks from a few in-context examples. However, this flexibility introduces\nsafety concerns: LLMs can be influenced by incorrect or malicious\ndemonstrations -- for example, if an adversary tampers with or injects harmful\nexamples without a human supervisor noticing. This motivates principled designs\nin which the system itself includes built-in mechanisms to guard against such\nattacks. We propose a novel approach to limit the degree to which harmful\ndemonstrations can degrade model performance. First, we define a baseline\n``safe'' behavior for the model -- the model's performance given no in-context\ndemonstrations (zero-shot). Next, we apply distribution-free risk control\n(DFRC) to control the extent to which in-context samples can decay performance\nbelow zero-shot. We achieve this by leveraging dynamic early exit prediction,\nignoring later attention heads that attend the most to the unsafe inputs.\nFinally, we propose modifications to DFRC that allow it to both control risk\nfor harmful inputs \\textit{and} leverage performance and efficiency gains on\nhelpful inputs. We present both theoretical and empirical results showing that\nour approach can effectively control risk for harmful in-context demonstrations\nwhile simultaneously achieving substantial computational efficiency gains with\nhelpful demonstrations.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02480v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02480v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.518,
      "weak_supervision_score": 0.452,
      "diffusion_reasoning_score": 0.446,
      "distributed_training_score": 0.414,
      "datasets_score": 0.341,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "Tangentially Relevant",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "Tangentially Relevant",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on risk control for in-context learning in LLMs, using techniques like early exiting and DFRC to mitigate harmful demonstrations, without involving human feedback, reward models, or reinforcement learning for model alignment.",
      "weak_supervision_justification": "The paper addresses noisy or harmful in-context demonstrations, which could be seen as similar to noisy labels in weak supervision, but it does not involve programmatically generating training labels or training models with weak supervision techniques.",
      "diffusion_reasoning_justification": "The paper discusses in-context learning and risk control in LLMs, including early exiting, but does not involve diffusion models, iterative refinement, or multi-step logical reasoning processes.",
      "distributed_training_justification": "The paper mentions computational efficiency gains through early exiting, which relates to optimizing model computation, but it does not address distributed training, parallel computing, or partitioning across multiple nodes.",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02483",
      "title": "Litespark Technical Report: High-Throughput, Energy-Efficient LLM\n  Training Framework",
      "authors": [
        "Nii Osae Osae Dade",
        "Moinul Hossain Rahat"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)",
        "cs.CL (Computation and Language)"
      ],
      "abstract": "Training Large Language Models (LLMs) is plagued by long training times and\nmassive energy consumption, with modern models requiring months of computation\nand gigawatt-hours of electricity. In light of these challenges,we introduce\nLitespark, a novel pre-training framework that addresses these inefficiencies\nthrough targeted optimizations to transformer attention and MLP layers. Our\napproach combines architectural improvements with algorithmic enhancements to\nmaximize Model FLOPs Utilization (MFU) while maintaining compatibility with\nstandard transformer implementations. Comprehensive benchmarking on 3B and 30B\nparameter Llama models using the SlimPajama-627B dataset demonstrates\nsubstantial performance gains: 2x-6x training throughput improvement and\n$55\\%-83$% energy consumption reduction across multi-node H200 GPU clusters.\nThese optimizations are model- and hardware-agnostic, enabling broad\napplicability across transformer architectures and extending to post-training\nphases including supervised fine-tuning and direct preference optimization.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02483v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02483v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.396,
      "weak_supervision_score": 0.362,
      "diffusion_reasoning_score": 0.367,
      "distributed_training_score": 0.486,
      "datasets_score": 0.322,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "Moderately Relevant",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "The paper introduces Litespark, a framework that optimizes transformer layers for efficient LLM training, and demonstrates improvements on multi-node H200 GPU clusters. This involves distributed training elements, such as parallel computing across nodes to enhance throughput and reduce energy use. However, the primary focus is on architectural and algorithmic optimizations to the model itself, rather than innovating new strategies for data partitioning, computation distribution, or multi-node coordination. Thus, it relates to distributed training but does not center on it.",
      "datasets_justification": "below_threshold",
      "llm_score_status": "completed",
      "summary": "Litespark is a novel framework aimed at optimizing the training of Large Language Models (LLMs) by addressing inefficiencies in transformer attention and MLP layers, combining architectural improvements and algorithmic enhancements to maximize Model FLOPs Utilization (MFU) while maintaining compatibility with standard implementations. Through comprehensive benchmarking on Llama models, it achieves 2x-6x improvements in training throughput and 55%-83% reductions in energy consumption, making it model- and hardware-agnostic for broader applicability in pre-training and post-training phases.",
      "novelty_score": "Moderate",
      "novelty_justification": "The paper presents a clever combination of existing ideas, such as optimizations to attention and MLP layers, to create a new framework that notably improves LLM training efficiency without introducing a entirely new problem or technique.",
      "impact_score": "High",
      "impact_justification": "The work's significant reductions in training time and energy consumption for LLMs could influence a wide range of future research and commercial applications by promoting more sustainable AI practices and accelerating model development.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper provides high-quality, practical contributions to LLM training efficiency that are relevant for AI researchers and practitioners, offering valuable insights into optimizing computational resources without being essential for all audiences.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7a254c83f1e5f634d50bf6658a595897111e88cb",
      "total_authors": 2,
      "authors_found": 2,
      "highest_h_index": 9,
      "average_h_index": 5.5,
      "notable_authors_count": 1,
      "author_h_indexes": [
        {
          "name": "Nii Osae Osae Dade",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2256999625"
        },
        {
          "name": "M. H. Rahat",
          "h_index": 9,
          "profile_url": "https://www.semanticscholar.org/author/103082842"
        }
      ]
    },
    {
      "id": "2510.02484",
      "title": "From Pixels to Factors: Learning Independently Controllable State\n  Variables for Reinforcement Learning",
      "authors": [
        "Rafael Rodriguez-Sanchez",
        "Cameron Allen",
        "George Konidaris"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Algorithms that exploit factored Markov decision processes are far more\nsample-efficient than factor-agnostic methods, yet they assume a factored\nrepresentation is known a priori -- a requirement that breaks down when the\nagent sees only high-dimensional observations. Conversely, deep reinforcement\nlearning handles such inputs but cannot benefit from factored structure. We\naddress this representation problem with Action-Controllable Factorization\n(ACF), a contrastive learning approach that uncovers independently controllable\nlatent variables -- state components each action can influence separately. ACF\nleverages sparsity: actions typically affect only a subset of variables, while\nthe rest evolve under the environment's dynamics, yielding informative data for\ncontrastive training. ACF recovers the ground truth controllable factors\ndirectly from pixel observations on three benchmarks with known factored\nstructure -- Taxi, FourRooms, and MiniGrid-DoorKey -- consistently\noutperforming baseline disentanglement algorithms.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02484v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02484v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.455,
      "weak_supervision_score": 0.371,
      "diffusion_reasoning_score": 0.396,
      "distributed_training_score": 0.371,
      "datasets_score": 0.317,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper's main contribution is a contrastive learning method for discovering independently controllable state variables in reinforcement learning from pixel observations, focusing on improving sample efficiency through factored representations. It does not involve human feedback, preference data, or a reward model trained on human rankings, which are core to RLHF. Thus, there is no direct or indirect connection to the topic.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02514",
      "title": "Learning a distance measure from the information-estimation geometry of\n  data",
      "authors": [
        "Guy Ohayon",
        "Pierre-Etienne H. Fiquet",
        "Florentin Guth",
        "Jona Ballé",
        "Eero P. Simoncelli"
      ],
      "categories": [
        "eess.IV (Image and Video Processing)",
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.IT (Information Theory)",
        "eess.SP (Signal Processing)",
        "math.IT (Information Theory)",
        "stat.ML (Machine Learning)"
      ],
      "abstract": "We introduce the Information-Estimation Metric (IEM), a novel form of\ndistance function derived from an underlying continuous probability density\nover a domain of signals. The IEM is rooted in a fundamental relationship\nbetween information theory and estimation theory, which links the\nlog-probability of a signal with the errors of an optimal denoiser, applied to\nnoisy observations of the signal. In particular, the IEM between a pair of\nsignals is obtained by comparing their denoising error vectors over a range of\nnoise amplitudes. Geometrically, this amounts to comparing the score vector\nfields of the blurred density around the signals over a range of blur levels.\nWe prove that the IEM is a valid global metric and derive a closed-form\nexpression for its local second-order approximation, which yields a Riemannian\nmetric. For Gaussian-distributed signals, the IEM coincides with the\nMahalanobis distance. But for more complex distributions, it adapts, both\nlocally and globally, to the geometry of the distribution. In practice, the IEM\ncan be computed using a learned denoiser (analogous to generative diffusion\nmodels) and solving a one-dimensional integral. To demonstrate the value of our\nframework, we learn an IEM on the ImageNet database. Experiments show that this\nIEM is competitive with or outperforms state-of-the-art supervised image\nquality metrics in predicting human perceptual judgments.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02514v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02514v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.319,
      "weak_supervision_score": 0.335,
      "diffusion_reasoning_score": 0.396,
      "distributed_training_score": 0.264,
      "datasets_score": 0.335,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02528",
      "title": "Multimodal Function Vectors for Spatial Relations",
      "authors": [
        "Shuhao Fu",
        "Esther Goldberg",
        "Ying Nian Wu",
        "Hongjing Lu"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "Large Multimodal Models (LMMs) demonstrate impressive in-context learning\nabilities from limited multimodal demonstrations, yet the internal mechanisms\nsupporting such task learning remain opaque. Building on prior work of large\nlanguage models, we show that a small subset of attention heads in the\nvision-language model OpenFlamingo-4B is responsible for transmitting\nrepresentations of spatial relations. The activations of these attention heads,\ntermed function vectors, can be extracted and manipulated to alter an LMM's\nperformance on relational tasks. First, using both synthetic and real image\ndatasets, we apply causal mediation analysis to identify attention heads that\nstrongly influence relational predictions, and extract multimodal function\nvectors that improve zero-shot accuracy at inference time. We further\ndemonstrate that these multimodal function vectors can be fine-tuned with a\nmodest amount of training data, while keeping LMM parameters frozen, to\nsignificantly outperform in-context learning baselines. Finally, we show that\nrelation-specific function vectors can be linearly combined to solve analogy\nproblems involving novel and untrained spatial relations, highlighting the\nstrong generalization ability of this approach. Our results show that LMMs\nencode spatial relational knowledge within localized internal structures, which\ncan be systematically extracted and optimized, thereby advancing our\nunderstanding of model modularity and enhancing control over relational\nreasoning in LMMs.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02528v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02528v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.415,
      "weak_supervision_score": 0.34,
      "diffusion_reasoning_score": 0.475,
      "distributed_training_score": 0.334,
      "datasets_score": 0.313,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on extracting and manipulating function vectors in Large Multimodal Models for spatial relations, using techniques like causal mediation analysis and in-context learning. It does not involve human feedback, reward models, or reinforcement learning for model alignment, making it unrelated to RLHF.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper examines internal representations and function vectors in LMMs for relational tasks, without any reference to diffusion models, iterative refinement processes, or multi-step logical reasoning as described. It is centered on attention mechanisms and vector extraction, not diffusion-based approaches.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02535",
      "title": "PHORECAST: Enabling AI Understanding of Public Health Outreach Across\n  Populations",
      "authors": [
        "Rifaa Qadri",
        "Anh Nhat Nhu",
        "Swati Ramnath",
        "Laura Yu Zheng",
        "Raj Bhansali",
        "Sylvette La Touche-Howard",
        "Tracy Marie Zeeger",
        "Tom Goldstein",
        "Ming Lin"
      ],
      "categories": [
        "cs.CY (Computers and Society)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Understanding how diverse individuals and communities respond to persuasive\nmessaging holds significant potential for advancing personalized and socially\naware machine learning. While Large Vision and Language Models (VLMs) offer\npromise, their ability to emulate nuanced, heterogeneous human responses,\nparticularly in high stakes domains like public health, remains underexplored\ndue in part to the lack of comprehensive, multimodal dataset. We introduce\nPHORECAST (Public Health Outreach REceptivity and CAmpaign Signal Tracking), a\nmultimodal dataset curated to enable fine-grained prediction of both\nindividuallevel behavioral responses and community-wide engagement patterns to\nhealth messaging. This dataset supports tasks in multimodal understanding,\nresponse prediction, personalization, and social forecasting, allowing rigorous\nevaluation of how well modern AI systems can emulate, interpret, and anticipate\nheterogeneous public sentiment and behavior. By providing a new dataset to\nenable AI advances for public health, PHORECAST aims to catalyze the\ndevelopment of models that are not only more socially aware but also aligned\nwith the goals of adaptive and inclusive health communication",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02535v2",
      "pdf_url": "http://arxiv.org/pdf/2510.02535v2",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.503,
      "weak_supervision_score": 0.363,
      "diffusion_reasoning_score": 0.391,
      "distributed_training_score": 0.355,
      "datasets_score": 0.43,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Tangentially Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "Highly Relevant",
      "rlhf_justification": "The paper discusses using human response data to tune VLMs for better alignment with human preferences, which involves human feedback. However, it does not explicitly mention reinforcement learning, a reward model, or the RLHF process, focusing instead on general model tuning and simulation, making it only loosely connected.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "The paper's main contribution is the introduction, curation, and analysis of the PHORECAST dataset, including its use for benchmarking AI models in public health applications, which directly aligns with research on creating and evaluating datasets for machine learning.",
      "llm_score_status": "completed",
      "summary": "The paper introduces PHORECAST, a novel multimodal dataset derived from responses of over 1,000 participants to 37 public health posters across seven topics, aiming to enhance AI's ability to predict individual and community reactions to health messaging based on demographics and personality traits. It details the methodology of curating this dataset, which includes sentiment, emotional reactions, and behavioral intent, and demonstrates its utility through use cases like training predictive models for response simulation and benchmarking personality influences, ultimately seeking to improve AI's social awareness and personalization in public health communication.",
      "novelty_score": "Moderate",
      "novelty_justification": "The paper presents a notable improvement by introducing a new dataset for AI-driven behavioral simulation in public health, combining existing vision-language models with fresh human response data to address a specific gap, though it doesn't introduce entirely new techniques.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to be cited and built upon in subfields like AI for social sciences and public health, as it provides a valuable resource for developing more personalized and socially aware models, though its influence may remain niche.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper represents a strong contribution by offering a new dataset and insights for AI in high-stakes domains like public health, making it essential for researchers focused on behavioral modeling and personalization.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/7c98de6e1d7ecc6a4e058ebde51aab69ee95462f",
      "total_authors": 9,
      "authors_found": 9,
      "highest_h_index": 2,
      "average_h_index": 0.3333333333333333,
      "notable_authors_count": 0,
      "author_h_indexes": [
        {
          "name": "Rifaa Qadri",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2307002140"
        },
        {
          "name": "Anh N. Nhu",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2219690286"
        },
        {
          "name": "Swati Ramnath",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383975029"
        },
        {
          "name": "L. Zheng",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2379600274"
        },
        {
          "name": "Raj Bhansali",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383973920"
        },
        {
          "name": "Sylvette La Touche-Howard",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383974083"
        },
        {
          "name": "Tracy Marie Zeeger",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383974113"
        },
        {
          "name": "Tom Goldstein",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383975027"
        },
        {
          "name": "Ming Lin",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2384183160"
        }
      ]
    },
    {
      "id": "2510.02543",
      "title": "Exploring OCR-augmented Generation for Bilingual VQA",
      "authors": [
        "JoonHo Lee",
        "Sunho Park"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "We investigate OCR-augmented generation with Vision Language Models (VLMs),\nexploring tasks in Korean and English toward multilingualism. To support\nresearch in this domain, we train and release KLOCR, a strong bilingual OCR\nbaseline trained on 100M instances to augment VLMs with OCR ability. To\ncomplement existing VQA benchmarks, we curate KOCRBench for Korean VQA, and\nanalyze different prompting methods. Extensive experiments show that\nOCR-extracted text significantly boosts performance across open source and\ncommercial models. Our work offers new insights into OCR-augmented generation\nfor bilingual VQA. Model, code, and data are available at\nhttps://github.com/JHLee0513/KLOCR.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02543v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02543v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.33,
      "weak_supervision_score": 0.367,
      "diffusion_reasoning_score": 0.406,
      "distributed_training_score": 0.297,
      "datasets_score": 0.353,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper's main contribution is on OCR-augmented generation for bilingual Visual Question Answering (VQA) using Vision Language Models (VLMs), including training a bilingual OCR baseline and analyzing prompting methods. It does not involve diffusion models, iterative refinement processes, or multi-step logical reasoning as described in the topic. There is no component related to adapting diffusion for complex logical tasks.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02549",
      "title": "Knowledge-Graph Based RAG System Evaluation Framework",
      "authors": [
        "Sicheng Dong",
        "Vahid Zolfaghari",
        "Nenad Petrovic",
        "Alois Knoll"
      ],
      "categories": [
        "cs.CL (Computation and Language)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Large language models (LLMs) has become a significant research focus and is\nutilized in various fields, such as text generation and dialog systems. One of\nthe most essential applications of LLM is Retrieval Augmented Generation (RAG),\nwhich greatly enhances generated content's reliability and relevance. However,\nevaluating RAG systems remains a challenging task. Traditional evaluation\nmetrics struggle to effectively capture the key features of modern\nLLM-generated content that often exhibits high fluency and naturalness.\nInspired by the RAGAS tool, a well-known RAG evaluation framework, we extended\nthis framework into a KG-based evaluation paradigm, enabling multi-hop\nreasoning and semantic community clustering to derive more comprehensive\nscoring metrics. By incorporating these comprehensive evaluation criteria, we\ngain a deeper understanding of RAG systems and a more nuanced perspective on\ntheir performance. To validate the effectiveness of our approach, we compare\nits performance with RAGAS scores and construct a human-annotated subset to\nassess the correlation between human judgments and automated metrics. In\naddition, we conduct targeted experiments to demonstrate that our KG-based\nevaluation method is more sensitive to subtle semantic differences in generated\noutputs. Finally, we discuss the key challenges in evaluating RAG systems and\nhighlight potential directions for future research.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02549v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02549v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.408,
      "weak_supervision_score": 0.345,
      "diffusion_reasoning_score": 0.441,
      "distributed_training_score": 0.31,
      "datasets_score": 0.398,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on evaluating RAG systems using knowledge graphs and compares metrics with human annotations, but it does not involve training or fine-tuning models with a reward model based on human-ranked data via reinforcement learning.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper discusses multi-hop reasoning in a knowledge-graph based evaluation framework for RAG systems, but it does not adapt diffusion processes, iterative refinement, or treat reasoning paths as entities for holistic correction.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02554",
      "title": "ToolTweak: An Attack on Tool Selection in LLM-based Agents",
      "authors": [
        "Jonathan Sneh",
        "Ruomei Yan",
        "Jialin Yu",
        "Philip Torr",
        "Yarin Gal",
        "Sunando Sengupta",
        "Eric Sommerlade",
        "Alasdair Paren",
        "Adel Bibi"
      ],
      "categories": [
        "cs.CR (Cryptography and Security)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "As LLMs increasingly power agents that interact with external tools, tool use\nhas become an essential mechanism for extending their capabilities. These\nagents typically select tools from growing databases or marketplaces to solve\nuser tasks, creating implicit competition among tool providers and developers\nfor visibility and usage. In this paper, we show that this selection process\nharbors a critical vulnerability: by iteratively manipulating tool names and\ndescriptions, adversaries can systematically bias agents toward selecting\nspecific tools, gaining unfair advantage over equally capable alternatives. We\npresent ToolTweak, a lightweight automatic attack that increases selection\nrates from a baseline of around 20% to as high as 81%, with strong\ntransferability between open-source and closed-source models. Beyond individual\ntools, we show that such attacks cause distributional shifts in tool usage,\nrevealing risks to fairness, competition, and security in emerging tool\necosystems. To mitigate these risks, we evaluate two defenses: paraphrasing and\nperplexity filtering, which reduce bias and lead agents to select functionally\nsimilar tools more equally. All code will be open-sourced upon acceptance.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02554v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02554v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.437,
      "weak_supervision_score": 0.413,
      "diffusion_reasoning_score": 0.383,
      "distributed_training_score": 0.343,
      "datasets_score": 0.335,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Tangentially Relevant",
      "weak_supervision_relevance": "Not Relevant",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper describes an iterative process using LLM feedback to refine tool metadata, which involves a feedback loop, but it does not involve human-ranked data, reward models, or reinforcement learning for model alignment. Thus, it is only tangentially related through the general concept of feedback, not the core RLHF methodology.",
      "weak_supervision_justification": "The paper focuses on adversarial attacks to manipulate tool selection in LLM-based agents and does not involve training models using programmatically generated labels from noisy sources. There is no discussion of weak supervision techniques for label generation or model training.",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02557",
      "title": "Orchestrating Human-AI Teams: The Manager Agent as a Unifying Research\n  Challenge",
      "authors": [
        "Charlie Masters",
        "Advaith Vellanki",
        "Jiangbo Shangguan",
        "Bart Kultys",
        "Jonathan Gilmore",
        "Alastair Moore",
        "Stefano V. Albrecht"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "While agentic AI has advanced in automating individual tasks, managing\ncomplex multi-agent workflows remains a challenging problem. This paper\npresents a research vision for autonomous agentic systems that orchestrate\ncollaboration within dynamic human-AI teams. We propose the Autonomous Manager\nAgent as a core challenge: an agent that decomposes complex goals into task\ngraphs, allocates tasks to human and AI workers, monitors progress, adapts to\nchanging conditions, and maintains transparent stakeholder communication. We\nformalize workflow management as a Partially Observable Stochastic Game and\nidentify four foundational challenges: (1) compositional reasoning for\nhierarchical decomposition, (2) multi-objective optimization under shifting\npreferences, (3) coordination and planning in ad hoc teams, and (4) governance\nand compliance by design. To advance this agenda, we release MA-Gym, an\nopen-source simulation and evaluation framework for multi-agent workflow\norchestration. Evaluating GPT-5-based Manager Agents across 20 workflows, we\nfind they struggle to jointly optimize for goal completion, constraint\nadherence, and workflow runtime - underscoring workflow management as a\ndifficult open problem. We conclude with organizational and ethical\nimplications of autonomous management systems.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02557v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02557v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.431,
      "weak_supervision_score": 0.386,
      "diffusion_reasoning_score": 0.374,
      "distributed_training_score": 0.395,
      "datasets_score": 0.36,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Tangentially Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on the Autonomous Manager Agent for orchestrating human-AI workflows, formalized as a Partially Observable Stochastic Game, and evaluates GPT-5-based agents on workflow management tasks. While GPT-5 models are likely trained using RLHF, the paper does not discuss, implement, or contribute to RLHF techniques such as training reward models from human feedback or fine-tuning with reinforcement learning. The relevance is tangential due to the indirect use of potentially RLHF-trained models, but the core contributions are in multi-agent coordination and workflow optimization, not alignment via human feedback.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02561",
      "title": "Oracle-RLAIF: An Improved Fine-Tuning Framework for Multi-modal Video\n  Models through Reinforcement Learning from Ranking Feedback",
      "authors": [
        "Derek Shi",
        "Ruben Glatt",
        "Christine Klymko",
        "Shubham Mohole",
        "Hongjun Choi",
        "Shashank Kushwaha",
        "Sam Sakla",
        "Felipe Leno da Silva"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Recent advances in large video-language models (VLMs) rely on extensive\nfine-tuning techniques that strengthen alignment between textual and visual\ncomprehension. Leading pipelines typically pair supervised fine-tuning (SFT)\nwith reinforcement learning from preference data to enhance video\ncomprehension. However, as VLMs scale in parameter size, so does the cost of\ngathering enough human feedback. To make fine-tuning more cost-effective,\nrecent frameworks explore reinforcement learning with AI feedback (RLAIF),\nwhich replace human preference with AI as a judge. Current RLAIF frameworks\nrely on a specialized reward model trained with video narratives to create\ncalibrated scalar rewards -- an expensive and restrictive pipeline. We propose\nOracle-RLAIF, a novel framework that replaces the trained reward model with a\nmore general Oracle ranker which acts as a drop-in model ranking candidate\nmodel responses rather than scoring them. Alongside Oracle-RLAIF, we introduce\n$GRPO_{rank}$, a novel rank-based loss function based on Group Relative Policy\nOptimization (GRPO) that directly optimizes ordinal feedback with rank-aware\nadvantages. Empirically, we demonstrate that Oracle-RLAIF consistently\noutperforms leading VLMs using existing fine-tuning methods when evaluated\nacross various video comprehension benchmarks. Oracle-RLAIF paves the path to\ncreating flexible and data-efficient frameworks for aligning large multi-modal\nvideo models with reinforcement learning from rank rather than score.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02561v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02561v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.573,
      "weak_supervision_score": 0.42,
      "diffusion_reasoning_score": 0.454,
      "distributed_training_score": 0.371,
      "datasets_score": 0.36,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "Moderately Relevant",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on Oracle-RLAIF, a framework using AI feedback (RLAIF) instead of human feedback for fine-tuning video models. While it references RLHF as a prior method, it explicitly replaces human-ranked data with an AI Oracle for ranking, which does not align with the core definition of RLHF that requires human preferences to train a reward model.",
      "weak_supervision_justification": "The paper employs an AI Oracle to generate rankings as feedback, which can be seen as a form of weak supervision since it uses programmatically derived, potentially noisy labels from AI rather than precise human annotations. However, the primary focus is on reinforcement learning frameworks rather than broadly applying weak supervision techniques for training.",
      "diffusion_reasoning_justification": "The paper does not involve diffusion models or iterative refinement processes for logical reasoning. It centers on reinforcement learning from ranking feedback for fine-tuning video-language models, with no mention of multi-step reasoning or diffusion-based approaches.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "completed",
      "summary": "The paper introduces Oracle-RLAIF, a novel framework designed to enhance the fine-tuning of multi-modal video-language models (VLMs) by utilizing reinforcement learning from ranking feedback instead of traditional scoring-based rewards, thereby reducing costs associated with human or specialized AI feedback. It proposes a rank-based loss function, GRPO_rank, derived from Group Relative Policy Optimization, and demonstrates through empirical evaluations on various video comprehension benchmarks that Oracle-RLAIF outperforms existing state-of-the-art VLMs, making fine-tuning more flexible and data-efficient.",
      "novelty_score": "Moderate",
      "novelty_justification": "The paper presents a notable improvement by introducing a rank-based approach in RLAIF and a new loss function, which cleverly adapts existing reinforcement learning techniques for multi-modal models without introducing an entirely new paradigm.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to influence future research in fine-tuning large multi-modal models by offering a more cost-effective method, potentially leading to wider adoption in AI subfields like computer vision, though its applicability is primarily limited to video comprehension tasks.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper provides a valuable and empirically validated contribution to efficient model alignment techniques, making it essential for researchers in AI and computer vision to consider for advancing their work on multi-modal systems.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/5d86a3921c76f6933cf3debfd50ac5a70d1a5b4f",
      "total_authors": 8,
      "authors_found": 8,
      "highest_h_index": 8,
      "average_h_index": 1.875,
      "notable_authors_count": 1,
      "author_h_indexes": [
        {
          "name": "Derek Shi",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2372202713"
        },
        {
          "name": "Ruben Glatt",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2294720741"
        },
        {
          "name": "Christine Klymko",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2371993486"
        },
        {
          "name": "Shubham Mohole",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2345188370"
        },
        {
          "name": "Hongjun Choi",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2294811926"
        },
        {
          "name": "Shashank Kushwaha",
          "h_index": 8,
          "profile_url": "https://www.semanticscholar.org/author/145979499"
        },
        {
          "name": "Sam Sakla",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2383976629"
        },
        {
          "name": "Felipe Leno da Silva",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2253703155"
        }
      ]
    },
    {
      "id": "2510.02566",
      "title": "PhysHMR: Learning Humanoid Control Policies from Vision for Physically\n  Plausible Human Motion Reconstruction",
      "authors": [
        "Qiao Feng",
        "Yiming Huang",
        "Yufu Wang",
        "Jiatao Gu",
        "Lingjie Liu"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Reconstructing physically plausible human motion from monocular videos\nremains a challenging problem in computer vision and graphics. Existing methods\nprimarily focus on kinematics-based pose estimation, often leading to\nunrealistic results due to the lack of physical constraints. To address such\nartifacts, prior methods have typically relied on physics-based post-processing\nfollowing the initial kinematics-based motion estimation. However, this\ntwo-stage design introduces error accumulation, ultimately limiting the overall\nreconstruction quality. In this paper, we present PhysHMR, a unified framework\nthat directly learns a visual-to-action policy for humanoid control in a\nphysics-based simulator, enabling motion reconstruction that is both physically\ngrounded and visually aligned with the input video. A key component of our\napproach is the pixel-as-ray strategy, which lifts 2D keypoints into 3D spatial\nrays and transforms them into global space. These rays are incorporated as\npolicy inputs, providing robust global pose guidance without depending on noisy\n3D root predictions. This soft global grounding, combined with local visual\nfeatures from a pretrained encoder, allows the policy to reason over both\ndetailed pose and global positioning. To overcome the sample inefficiency of\nreinforcement learning, we further introduce a distillation scheme that\ntransfers motion knowledge from a mocap-trained expert to the\nvision-conditioned policy, which is then refined using physically motivated\nreinforcement learning rewards. Extensive experiments demonstrate that PhysHMR\nproduces high-fidelity, physically plausible motion across diverse scenarios,\noutperforming prior approaches in both visual accuracy and physical realism.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02566v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02566v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.476,
      "weak_supervision_score": 0.331,
      "diffusion_reasoning_score": 0.364,
      "distributed_training_score": 0.336,
      "datasets_score": 0.268,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on PhysHMR, a framework for learning humanoid control policies using reinforcement learning with rewards based on motion imitation, physical realism, and smoothness, derived from mocap data and programmatic criteria. It does not involve training a reward model on human-ranked data or aligning an AI model with human preferences through human feedback, which are core to RLHF. Thus, the paper's contributions are unrelated to RLHF.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02567",
      "title": "Agentic Additive Manufacturing Alloy Discovery",
      "authors": [
        "Peter Pak",
        "Achuth Chandrasekhar",
        "Amir Barati Farimani"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "Agentic systems enable the intelligent use of research tooling, augmenting a\nresearcher's ability to investigate and propose novel solutions to existing\nproblems. Within Additive Manufacturing (AM), alloy discovery remains a complex\nchallenge, often requiring expertise in the various domains of materials\nscience, thermodynamic simulations, and experimental analysis. Large Language\nModel (LLM) enabled agents can facilitate this endeavor by utilizing their\nextensive knowledge base to dispatch tool calls via Model Context Protocol\n(MCP) to perform actions such as Thermo-Calc property diagram calculations and\nlack of fusion process map generation. In addition, the multi-agent system\ndeveloped in this work is able to effectively reason through complex user\nprompts and provide analysis on the printability of proposed alloys. These\nagents can dynamically adjust their task trajectory to the outcomes of tool\ncall results, effectively enabling autonomous decision-making in practical\nenvironments. This work aims to utilize LLM enabled agents to automate and\naccelerate the task of alloy discovery within the field of additive\nmanufacturing and showcase the benefits of adopting this multi-agent system.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02567v2",
      "pdf_url": "http://arxiv.org/pdf/2510.02567v2",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.382,
      "weak_supervision_score": 0.33,
      "diffusion_reasoning_score": 0.395,
      "distributed_training_score": 0.365,
      "datasets_score": 0.317,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02570",
      "title": "Unlocking the power of partnership: How humans and machines can work\n  together to improve face recognition",
      "authors": [
        "P. Jonathon Phillips",
        "Geraldine Jeckeln",
        "Carina A. Hahn",
        "Amy N. Yates",
        "Peter C. Fontana",
        "Alice J. O'Toole"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Human review of consequential decisions by face recognition algorithms\ncreates a \"collaborative\" human-machine system. Individual differences between\npeople and machines, however, affect whether collaboration improves or degrades\naccuracy in any given case. We establish the circumstances under which\ncombining human and machine face identification decisions improves accuracy.\nUsing data from expert and non-expert face identifiers, we examined the\nbenefits of human-human and human-machine collaborations. The benefits of\ncollaboration increased as the difference in baseline accuracy between\ncollaborators decreased-following the Proximal Accuracy Rule (PAR). This rule\npredicted collaborative (fusion) benefit across a wide range of baseline\nabilities, from people with no training to those with extensive training. Using\nthe PAR, we established a critical fusion zone, where humans are less accurate\nthan the machine, but fusing the two improves system accuracy. This zone was\nsurprisingly large. We implemented \"intelligent human-machine fusion\" by\nselecting people with the potential to increase the accuracy of a\nhigh-performing machine. Intelligent fusion was more accurate than the machine\noperating alone and more accurate than combining all human and machine\njudgments. The highest system-wide accuracy achievable with human-only\npartnerships was found by graph theory. This fully human system approximated\nthe average performance achieved by intelligent human-machine collaboration.\nHowever, intelligent human-machine collaboration more effectively minimized the\nimpact of low-performing humans on system-wide accuracy. The results\ndemonstrate a meaningful role for both humans and machines in assuring accurate\nface identification. This study offers an evidence-based road map for the\nintelligent use of AI in face identification.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02570v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02570v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.429,
      "weak_supervision_score": 0.359,
      "diffusion_reasoning_score": 0.35,
      "distributed_training_score": 0.35,
      "datasets_score": 0.342,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper's main contribution is on human-machine collaboration for improving face recognition accuracy, including the Proximal Accuracy Rule and intelligent fusion of decisions. It involves human feedback in decision-making but does not address training an AI model using human-ranked data to create a reward model for reinforcement learning fine-tuning. RLHF specifically requires iterative AI training based on human preferences, which is absent here.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02571",
      "title": "How Confident are Video Models? Empowering Video Models to Express their\n  Uncertainty",
      "authors": [
        "Zhiting Mei",
        "Ola Shorinwa",
        "Anirudha Majumdar"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.AI (Artificial Intelligence)",
        "cs.CL (Computation and Language)"
      ],
      "abstract": "Generative video models demonstrate impressive text-to-video capabilities,\nspurring widespread adoption in many real-world applications. However, like\nlarge language models (LLMs), video generation models tend to hallucinate,\nproducing plausible videos even when they are factually wrong. Although\nuncertainty quantification (UQ) of LLMs has been extensively studied in prior\nwork, no UQ method for video models exists, raising critical safety concerns.\nTo our knowledge, this paper represents the first work towards quantifying the\nuncertainty of video models. We present a framework for uncertainty\nquantification of generative video models, consisting of: (i) a metric for\nevaluating the calibration of video models based on robust rank correlation\nestimation with no stringent modeling assumptions; (ii) a black-box UQ method\nfor video models (termed S-QUBED), which leverages latent modeling to\nrigorously decompose predictive uncertainty into its aleatoric and epistemic\ncomponents; and (iii) a UQ dataset to facilitate benchmarking calibration in\nvideo models. By conditioning the generation task in the latent space, we\ndisentangle uncertainty arising due to vague task specifications from that\narising from lack of knowledge. Through extensive experiments on benchmark\nvideo datasets, we demonstrate that S-QUBED computes calibrated total\nuncertainty estimates that are negatively correlated with the task accuracy and\neffectively computes the aleatoric and epistemic constituents.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02571v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02571v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.375,
      "weak_supervision_score": 0.406,
      "diffusion_reasoning_score": 0.447,
      "distributed_training_score": 0.333,
      "datasets_score": 0.359,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "Not Relevant",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "The paper focuses on uncertainty quantification for existing video models, including metrics, methods, and datasets for assessing uncertainty in video generation. It does not involve training models using programmatically generated noisy labels or weak supervision techniques, as it assumes pre-trained models and emphasizes evaluation rather than training processes.",
      "diffusion_reasoning_justification": "The paper discusses uncertainty quantification for generative video models, which may implicitly use diffusion processes for video generation, but it does not adapt diffusion for multi-step logical reasoning, treat a chain-of-thought as an entity, or focus on solving complex logical tasks through iterative refinement. Instead, it centers on uncertainty decomposition in latent spaces for video accuracy.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02589",
      "title": "A Benchmark Study of Deep Reinforcement Learning Algorithms for the\n  Container Stowage Planning Problem",
      "authors": [
        "Yunqi Huang",
        "Nishith Chennakeshava",
        "Alexis Carras",
        "Vladislav Neverov",
        "Wei Liu",
        "Aske Plaat",
        "Yingjie Fan"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Container stowage planning (CSPP) is a critical component of maritime\ntransportation and terminal operations, directly affecting supply chain\nefficiency. Owing to its complexity, CSPP has traditionally relied on human\nexpertise. While reinforcement learning (RL) has recently been applied to CSPP,\nsystematic benchmark comparisons across different algorithms remain limited. To\naddress this gap, we develop a Gym environment that captures the fundamental\nfeatures of CSPP and extend it to include crane scheduling in both multi-agent\nand single-agent formulations. Within this framework, we evaluate five RL\nalgorithms: DQN, QR-DQN, A2C, PPO, and TRPO under multiple scenarios of varying\ncomplexity. The results reveal distinct performance gaps with increasing\ncomplexity, underscoring the importance of algorithm choice and problem\nformulation for CSPP. Overall, this paper benchmarks multiple RL methods for\nCSPP while providing a reusable Gym environment with crane scheduling, thus\noffering a foundation for future research and practical deployment in maritime\nlogistics.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02589v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02589v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.394,
      "weak_supervision_score": 0.323,
      "diffusion_reasoning_score": 0.336,
      "distributed_training_score": 0.362,
      "datasets_score": 0.31,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02592",
      "title": "Multimodal Large Language Model Framework for Safe and Interpretable\n  Grid-Integrated EVs",
      "authors": [
        "Jean Douglas Carvalho",
        "Hugo Kenji",
        "Ahmad Mohammad Saber",
        "Glaucia Melo",
        "Max Mauro Dias Santos",
        "Deepa Kundur"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "The integration of electric vehicles (EVs) into smart grids presents unique\nopportunities to enhance both transportation systems and energy networks.\nHowever, ensuring safe and interpretable interactions between drivers,\nvehicles, and the surrounding environment remains a critical challenge. This\npaper presents a multi-modal large language model (LLM)-based framework to\nprocess multimodal sensor data - such as object detection, semantic\nsegmentation, and vehicular telemetry - and generate natural-language alerts\nfor drivers. The framework is validated using real-world data collected from\ninstrumented vehicles driving on urban roads, ensuring its applicability to\nreal-world scenarios. By combining visual perception (YOLOv8), geocoded\npositioning, and CAN bus telemetry, the framework bridges raw sensor data and\ndriver comprehension, enabling safer and more informed decision-making in urban\ndriving scenarios. Case studies using real data demonstrate the framework's\neffectiveness in generating context-aware alerts for critical situations, such\nas proximity to pedestrians, cyclists, and other vehicles. This paper\nhighlights the potential of LLMs as assistive tools in e-mobility, benefiting\nboth transportation systems and electric networks by enabling scalable fleet\ncoordination, EV load forecasting, and traffic-aware energy planning.\n  Index Terms - Electric vehicles, visual perception, large language models,\nYOLOv8, semantic segmentation, CAN bus, prompt engineering, smart grid.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02592v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02592v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.427,
      "weak_supervision_score": 0.36,
      "diffusion_reasoning_score": 0.437,
      "distributed_training_score": 0.38,
      "datasets_score": 0.377,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper describes a framework using pre-existing LLMs for processing sensor data and generating alerts via prompt engineering, but it does not involve training models with human feedback, reward models, or reinforcement learning techniques. There is no mention of aligning AI with human preferences through human-ranked data.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper utilizes LLMs for generating natural-language alerts from multimodal data, but it does not incorporate diffusion models, iterative refinement processes, or multi-step logical reasoning as described. There is no evidence of treating Chain-of-Thought as a holistic entity for correction and improvement.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02599",
      "title": "PEO: Training-Free Aesthetic Quality Enhancement in Pre-Trained\n  Text-to-Image Diffusion Models with Prompt Embedding Optimization",
      "authors": [
        "Hovhannes Margaryan",
        "Bo Wan",
        "Tinne Tuytelaars"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "This paper introduces a novel approach to aesthetic quality improvement in\npre-trained text-to-image diffusion models when given a simple prompt. Our\nmethod, dubbed Prompt Embedding Optimization (PEO), leverages a pre-trained\ntext-to-image diffusion model as a backbone and optimizes the text embedding of\na given simple and uncurated prompt to enhance the visual quality of the\ngenerated image. We achieve this by a tripartite objective function that\nimproves the aesthetic fidelity of the generated image, ensures adherence to\nthe optimized text embedding, and minimal divergence from the initial prompt.\nThe latter is accomplished through a prompt preservation term. Additionally,\nPEO is training-free and backbone-independent. Quantitative and qualitative\nevaluations confirm the effectiveness of the proposed method, exceeding or\nequating the performance of state-of-the-art text-to-image and prompt\nadaptation methods.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02599v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02599v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.413,
      "weak_supervision_score": 0.361,
      "diffusion_reasoning_score": 0.502,
      "distributed_training_score": 0.344,
      "datasets_score": 0.32,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on optimizing text embeddings in pre-trained diffusion models to enhance image aesthetics, using an objective function based on automated metrics like LAION Aesthetic Predictor. It does not involve human feedback, a reward model trained on human-ranked data, or reinforcement learning for model fine-tuning.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper uses diffusion models for text-to-image generation and optimizes embeddings for aesthetic improvements, but it does not adapt diffusion for multi-step logical reasoning, Chain-of-Thought processing, or solving complex logical tasks. It is limited to image synthesis.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02601",
      "title": "Ego-Exo 3D Hand Tracking in the Wild with a Mobile Multi-Camera Rig",
      "authors": [
        "Patrick Rim",
        "Kun He",
        "Kevin Harris",
        "Braden Copple",
        "Shangchen Han",
        "Sizhe An",
        "Ivan Shugurov",
        "Tomas Hodan",
        "He Wen",
        "Xu Xie"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Accurate 3D tracking of hands and their interactions with the world in\nunconstrained settings remains a significant challenge for egocentric computer\nvision. With few exceptions, existing datasets are predominantly captured in\ncontrolled lab setups, limiting environmental diversity and model\ngeneralization. To address this, we introduce a novel marker-less multi-camera\nsystem designed to capture precise 3D hands and objects, which allows for\nnearly unconstrained mobility in genuinely in-the-wild conditions. We combine a\nlightweight, back-mounted capture rig with eight exocentric cameras, and a\nuser-worn Meta Quest 3 headset, which contributes two egocentric views. We\ndesign an ego-exo tracking pipeline to generate accurate 3D hand pose ground\ntruth from this system, and rigorously evaluate its quality. By collecting an\nannotated dataset featuring synchronized multi-view images and precise 3D hand\nposes, we demonstrate the capability of our approach to significantly reduce\nthe trade-off between environmental realism and 3D annotation accuracy.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02601v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02601v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.319,
      "weak_supervision_score": 0.311,
      "diffusion_reasoning_score": 0.307,
      "distributed_training_score": 0.336,
      "datasets_score": 0.33,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02608",
      "title": "Mitigating Modal Imbalance in Multimodal Reasoning",
      "authors": [
        "Chen Henry Wu",
        "Neil Kale",
        "Aditi Raghunathan"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Foundation models (FMs) deployed in real-world tasks such as computer-use\nagents must integrate diverse modalities. How good are FMs at performing joint\nreasoning, simultaneously reasoning over multiple modalities, especially when\nthe modalities interact and relate to each other to form cross-modal context?\nTo better understand this problem, we study FMs on cross-modal conflicts:\nscenarios where conflicting evidence is presented across modalities. This\nallows us to examine whether FMs prioritize one modality over another or reason\njointly to reconcile the conflict. Our experiments reveal that FMs can\nrecognize conflicts in unimodal contexts, composed of a single modality, 90% of\nthe time, but the ratio falls as low as 3% when evidence is split across\nmodalities -- similar observations hold in cross-lingual contexts, composed of\nmultiple languages. We trace this failure to cross-modal attention imbalance,\nshowing that FMs exhibit extreme asymmetry in attention scores,\ndisproportionately prioritizing certain modalities. We show that cross-modal\nattention imbalance does not go away by simply scaling up multimodal or\nmultilingual datasets blindly, since they lack training examples that\nexplicitly require cross-modal reasoning. We demonstrate that even a simple and\nscalable method of explicitly combining multiple modalities within each\ntraining instance significantly reduces attention imbalance. Reduced attention\nimbalance directly translates to improved downstream performance on several\nvision-language benchmarks. Our findings underscore the importance of\nsystematically addressing cross-modal contexts to build reliable foundation\nmodels.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02608v2",
      "pdf_url": "http://arxiv.org/pdf/2510.02608v2",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.411,
      "weak_supervision_score": 0.396,
      "diffusion_reasoning_score": 0.481,
      "distributed_training_score": 0.361,
      "datasets_score": 0.372,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on mitigating modal imbalance in multimodal reasoning for foundation models through attention mechanisms and fine-tuning with combined modalities, without any mention of human feedback, reward models, or reinforcement learning techniques.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper addresses cross-modal attention imbalance and joint reasoning in foundation models, but it does not involve diffusion models, iterative refinement processes, or multi-step logical reasoning as described in the topic.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02610",
      "title": "MINERVA: Mutual Information Neural Estimation for Supervised Feature\n  Selection",
      "authors": [
        "Taurai Muvunza",
        "Egor Kraev",
        "Pere Planell-Morell",
        "Alexander Y. Shestopaloff"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Existing feature filters rely on statistical pair-wise dependence metrics to\nmodel feature-target relationships, but this approach may fail when the target\ndepends on higher-order feature interactions rather than individual\ncontributions. We introduce Mutual Information Neural Estimation Regularized\nVetting Algorithm (MINERVA), a novel approach to supervised feature selection\nbased on neural estimation of mutual information between features and targets.\nWe paramaterize the approximation of mutual information with neural networks\nand perform feature selection using a carefully designed loss function\naugmented with sparsity-inducing regularizers. Our method is implemented in a\ntwo-stage process to decouple representation learning from feature selection,\nensuring better generalization and a more accurate expression of feature\nimportance. We present examples of ubiquitous dependency structures that are\nrarely captured in literature and show that our proposed method effectively\ncaptures these complex feature-target relationships by evaluating feature\nsubsets as an ensemble. Experimental results on synthetic and real-life fraud\ndatasets demonstrate the efficacy of our method and its ability to perform\nexact solutions.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02610v2",
      "pdf_url": "http://arxiv.org/pdf/2510.02610v2",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.353,
      "weak_supervision_score": 0.389,
      "diffusion_reasoning_score": 0.334,
      "distributed_training_score": 0.322,
      "datasets_score": 0.332,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02611",
      "title": "On the Role of Temperature Sampling in Test-Time Scaling",
      "authors": [
        "Yuheng Wu",
        "Azalia Mirhoseini",
        "Thierry Tambe"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)",
        "cs.CL (Computation and Language)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "Large language models (LLMs) can improve reasoning at inference time through\ntest-time scaling (TTS), where multiple reasoning traces are generated and the\nbest one is selected. Prior work shows that increasing the number of samples K\nsteadily improves accuracy. In this paper, we demonstrate that this trend does\nnot hold indefinitely: at large K, further scaling yields no gains, and certain\nhard questions remain unsolved regardless of the number of traces.\nInterestingly, we find that different sampling temperatures solve different\nsubsets of problems, implying that single-temperature scaling explores only\npart of a model's potential. We therefore propose scaling along the temperature\ndimension, which enlarges the reasoning boundary of LLMs. Averaged over Qwen3\n(0.6B, 1.7B, 4B, 8B) and five representative reasoning benchmarks (AIME\n2024/2025, MATH500, LiveCodeBench, Hi-ToM), temperature scaling yields an\nadditional 7.3 points over single-temperature TTS. Temperature scaling also\nenables base models to reach performance comparable to reinforcement learning\n(RL)-trained counterparts, without additional post-training. We further provide\na comprehensive analysis of this phenomenon and design a multi-temperature\nvoting method that reduces the overhead of temperature scaling. Overall, our\nfindings suggest that TTS is more powerful than previously thought, and that\ntemperature scaling offers a simple and effective way to unlock the latent\npotential of base models.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02611v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02611v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.352,
      "weak_supervision_score": 0.346,
      "diffusion_reasoning_score": 0.439,
      "distributed_training_score": 0.431,
      "datasets_score": 0.338,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "Not Relevant",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on test-time scaling in LLMs using sampling temperatures to generate and select reasoning traces, without any mention or adaptation of diffusion models or their iterative refinement processes. It does not treat Chain-of-Thought as a holistically corrected entity over multiple steps via diffusion, making it unrelated to diffusion-based reasoning.",
      "distributed_training_justification": "The paper discusses inference-time techniques like generating multiple reasoning traces and reusing KV cache for efficiency, but it does not address distributed training, parallel computing for model training, or strategies for partitioning data/computation across nodes during training. Its focus is solely on test-time scaling, not training acceleration.",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.02617",
      "title": "Input-Aware Sparse Attention for Real-Time Co-Speech Video Generation",
      "authors": [
        "Beijia Lu",
        "Ziyi Chen",
        "Jing Xiao",
        "Jun-Yan Zhu"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Diffusion models can synthesize realistic co-speech video from audio for\nvarious applications, such as video creation and virtual agents. However,\nexisting diffusion-based methods are slow due to numerous denoising steps and\ncostly attention mechanisms, preventing real-time deployment. In this work, we\ndistill a many-step diffusion video model into a few-step student model.\nUnfortunately, directly applying recent diffusion distillation methods degrades\nvideo quality and falls short of real-time performance. To address these\nissues, our new video distillation method leverages input human pose\nconditioning for both attention and loss functions. We first propose using\naccurate correspondence between input human pose keypoints to guide attention\nto relevant regions, such as the speaker's face, hands, and upper body. This\ninput-aware sparse attention reduces redundant computations and strengthens\ntemporal correspondences of body parts, improving inference efficiency and\nmotion coherence. To further enhance visual quality, we introduce an\ninput-aware distillation loss that improves lip synchronization and hand motion\nrealism. By integrating our input-aware sparse attention and distillation loss,\nour method achieves real-time performance with improved visual quality compared\nto recent audio-driven and input-driven methods. We also conduct extensive\nexperiments showing the effectiveness of our algorithmic design choices.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.02617v1",
      "pdf_url": "http://arxiv.org/pdf/2510.02617v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.32,
      "weak_supervision_score": 0.329,
      "diffusion_reasoning_score": 0.479,
      "distributed_training_score": 0.334,
      "datasets_score": 0.288,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper's main contribution is the development of an efficient diffusion-based method for co-speech video generation, focusing on distillation, sparse attention, and loss functions to improve speed and quality in video synthesis. It does not involve adapting diffusion models for multi-step logical reasoning, chain-of-thought processes, or solving complex logical tasks; instead, it applies diffusion for generative tasks in multimedia, lacking any component for holistic reasoning path correction.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.03336",
      "title": "Linguistic and Audio Embedding-Based Machine Learning for Alzheimer's\n  Dementia and Mild Cognitive Impairment Detection: Insights from the PROCESS\n  Challenge",
      "authors": [
        "Adharsha Sam Edwin Sam Devahi",
        "Sohail Singh Sangha",
        "Prachee Priyadarshinee",
        "Jithin Thilakan",
        "Ivan Fu Xing Tan",
        "Christopher Johann Clarke",
        "Sou Ka Lon",
        "Balamurali B T",
        "Yow Wei Quin",
        "Chen Jer-Ming"
      ],
      "categories": [
        "cs.SD (Sound)",
        "cs.AI (Artificial Intelligence)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "Early detection of Alzheimer's Dementia (AD) and Mild Cognitive Impairment\n(MCI) is critical for timely intervention, yet current diagnostic approaches\nremain resource-intensive and invasive. Speech, encompassing both acoustic and\nlinguistic dimensions, offers a promising non-invasive biomarker for cognitive\ndecline. In this study, we present a machine learning framework for the PROCESS\nChallenge, leveraging both audio embeddings and linguistic features derived\nfrom spontaneous speech recordings. Audio representations were extracted using\nWhisper embeddings from the Cookie Theft description task, while linguistic\nfeatures-spanning pronoun usage, syntactic complexity, filler words, and clause\nstructure-were obtained from transcriptions across Semantic Fluency, Phonemic\nFluency, and Cookie Theft picture description. Classification models aimed to\ndistinguish between Healthy Controls (HC), MCI, and AD participants, while\nregression models predicted Mini-Mental State Examination (MMSE) scores.\nResults demonstrated that voted ensemble models trained on concatenated\nlinguistic features achieved the best classification performance (F1 = 0.497),\nwhile Whisper embedding-based ensemble regressors yielded the lowest MMSE\nprediction error (RMSE = 2.843). Comparative evaluation within the PROCESS\nChallenge placed our models among the top submissions in regression task, and\nmid-range for classification, highlighting the complementary strengths of\nlinguistic and audio embeddings. These findings reinforce the potential of\nmultimodal speech-based approaches for scalable, non-invasive cognitive\nassessment and underline the importance of integrating task-specific linguistic\nand acoustic markers in dementia detection.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.03336v1",
      "pdf_url": "http://arxiv.org/pdf/2510.03336v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.35,
      "weak_supervision_score": 0.395,
      "diffusion_reasoning_score": 0.428,
      "distributed_training_score": 0.319,
      "datasets_score": 0.364,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper's main contribution involves developing machine learning models for detecting Alzheimer's Dementia and Mild Cognitive Impairment using audio embeddings and linguistic features from speech data. It focuses on classification and regression tasks for cognitive assessment, with no mention of diffusion models, iterative refinement processes, or multi-step logical reasoning. Therefore, it does not align with the topic of diffusion-based reasoning.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.03337",
      "title": "Error correction in multiclass image classification of facial emotion on\n  unbalanced samples",
      "authors": [
        "Andrey A. Lebedev",
        "Victor B. Kazantsev",
        "Sergey V. Stasenko"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "This paper considers the problem of error correction in multi-class\nclassification of face images on unbalanced samples. The study is based on the\nanalysis of a data frame containing images labeled by seven different emotional\nstates of people of different ages. Particular attention is paid to the problem\nof class imbalance, in which some emotions significantly prevail over others.\nTo solve the classification problem, a neural network model based on LSTM with\nan attention mechanism focusing on key areas of the face that are informative\nfor emotion recognition is used. As part of the experiments, the model is\ntrained on all possible configurations of subsets of six classes with\nsubsequent error correction for the seventh class, excluded at the training\nstage. The results show that correction is possible for all classes, although\nthe degree of success varies: some classes are better restored, others are\nworse. In addition, on the test sample, when correcting some classes, an\nincrease in key quality metrics for small classes was recorded, which indicates\nthe promise of the proposed approach in solving applied problems related to the\nsearch for rare events, for example, in anti-fraud systems. Thus, the proposed\nmethod can be effectively applied in facial expression analysis systems and in\ntasks requiring stable classification under skewed class distribution.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.03337v1",
      "pdf_url": "http://arxiv.org/pdf/2510.03337v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.372,
      "weak_supervision_score": 0.387,
      "diffusion_reasoning_score": 0.339,
      "distributed_training_score": 0.337,
      "datasets_score": 0.356,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.03339",
      "title": "Pool Me Wisely: On the Effect of Pooling in Transformer-Based Models",
      "authors": [
        "Sofiane Ennadir",
        "Levente Zólyomi",
        "Oleg Smirnov",
        "Tianze Wang",
        "John Pertoft",
        "Filip Cornell",
        "Lele Cao"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Transformer models have become the dominant backbone for sequence modeling,\nleveraging self-attention to produce contextualized token representations.\nThese are typically aggregated into fixed-size vectors via pooling operations\nfor downstream tasks. While much of the literature has focused on attention\nmechanisms, the role of pooling remains underexplored despite its critical\nimpact on model behavior. In this paper, we introduce a theoretical framework\nthat rigorously characterizes the expressivity of Transformer-based models\nequipped with widely used pooling methods by deriving closed-form bounds on\ntheir representational capacity and the ability to distinguish similar inputs.\nOur analysis extends to different variations of attention formulations,\ndemonstrating that these bounds hold across diverse architectural variants. We\nempirically evaluate pooling strategies across tasks requiring both global and\nlocal contextual understanding, spanning three major modalities: computer\nvision, natural language processing, and time-series analysis. Results reveal\nconsistent trends in how pooling choices affect accuracy, sensitivity, and\noptimization behavior. Our findings unify theoretical and empirical\nperspectives, providing practical guidance for selecting or designing pooling\nmechanisms suited to specific tasks. This work positions pooling as a key\narchitectural component in Transformer models and lays the foundation for more\nprincipled model design beyond attention alone.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.03339v1",
      "pdf_url": "http://arxiv.org/pdf/2510.03339v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.345,
      "weak_supervision_score": 0.35,
      "diffusion_reasoning_score": 0.427,
      "distributed_training_score": 0.401,
      "datasets_score": 0.336,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "Not Relevant",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on the theoretical and empirical analysis of pooling mechanisms in Transformer-based models, emphasizing their impact on representational capacity and task performance. It does not involve diffusion models, iterative refinement processes, or multi-step logical reasoning for tasks like Chain-of-Thought. Therefore, there is no connection to diffusion-based reasoning.",
      "distributed_training_justification": "The paper examines the role of pooling in Transformers for sequence modeling and does not discuss distributed training, parallel computing, multi-node machine learning, or strategies for partitioning data/computation across processors. Its contributions are centered on model architecture and expressivity, not training acceleration techniques.",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.03340",
      "title": "Learning Pareto-Optimal Pandemic Intervention Policies with MORL",
      "authors": [
        "Marian Chen",
        "Miri Zilka"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)",
        "cs.CY (Computers and Society)"
      ],
      "abstract": "The COVID-19 pandemic underscored a critical need for intervention strategies\nthat balance disease containment with socioeconomic stability. We approach this\nchallenge by designing a framework for modeling and evaluating disease-spread\nprevention strategies. Our framework leverages multi-objective reinforcement\nlearning (MORL) - a formulation necessitated by competing objectives - combined\nwith a new stochastic differential equation (SDE) pandemic simulator,\ncalibrated and validated against global COVID-19 data. Our simulator reproduces\nnational-scale pandemic dynamics with orders of magnitude higher fidelity than\nother models commonly used in reinforcement learning (RL) approaches to\npandemic intervention. Training a Pareto-Conditioned Network (PCN) agent on\nthis simulator, we illustrate the direct policy trade-offs between\nepidemiological control and economic stability for COVID-19. Furthermore, we\ndemonstrate the framework's generality by extending it to pathogens with\ndifferent epidemiological profiles, such as polio and influenza, and show how\nthese profiles lead the agent to discover fundamentally different intervention\npolicies. To ground our work in contemporary policymaking challenges, we apply\nthe model to measles outbreaks, quantifying how a modest 5% drop in vaccination\ncoverage necessitates significantly more stringent and costly interventions to\ncurb disease spread. This work provides a robust and adaptable framework to\nsupport transparent, evidence-based policymaking for mitigating public health\ncrises.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.03340v1",
      "pdf_url": "http://arxiv.org/pdf/2510.03340v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.421,
      "weak_supervision_score": 0.333,
      "diffusion_reasoning_score": 0.336,
      "distributed_training_score": 0.364,
      "datasets_score": 0.275,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on using Multi-Objective Reinforcement Learning (MORL) with a stochastic differential equation-based simulator to develop pandemic intervention policies, emphasizing objectives like disease control and economic stability. It does not involve training a reward model on human-ranked data or fine-tuning an AI model based on human preferences, which are core to RLHF. Instead, the approach relies on simulated environments and historical epidemiological data, making it unrelated to RLHF concepts.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.03341",
      "title": "OpusAnimation: Code-Based Dynamic Chart Generation",
      "authors": [
        "Bozheng Li",
        "Miao Yang",
        "Zhenhan Chen",
        "Jiawang Cao",
        "Mushui Liu",
        "Yi Lu",
        "Yongliang Wu",
        "Bin Zhang",
        "Yangguang Ji",
        "Licheng Tang",
        "Jay Wu",
        "Wenbo Zhu"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Dynamic Chart Generation (DCG) involves producing code-rendered animated\nvisualizations as charts. While recent advances in multi-modal large language\nmodels (MLLMs) have significantly improved their capability on static chart\ngeneration and comprehension, MLLMs' potential for handling dynamic chart\ngeneration and understanding remains underexplored. To bridge this research\ngap, we introduce DCG-Bench (Dynamic Chart Generation Benchmark), the first\nbenchmark evaluating MLLM's capability on dynamic chart generation tasks from\nthree dimensions: Simple Text-to-Chart, Detailed Text-to-Chart, and\nVideo-to-Chart tasks. We construct DCG-8K, a high-quality DCG dataset with\nannotations covering instruction-code-video triplets and QA pairs for both code\nand video evaluation. Based on DCG-8K, we explored a two-stage training recipe,\nproposing Joint-Code-Visual Reward for group relative policy optimization to\nconstruct expert MLLM Qwen2.5-VL-DCG-3B for the DCG task. Our benchmarking\nresult reveals shortcomings of existing MLLMs in the visual-to-chart task, and\nour model beats the best open-sourced MLLM with an average 8.31% performance\ngain across three tasks, and shows on par performance against proprietary\nmodels with only 3B parameters, proving the effectiveness of our training\nrecipe. Our code and dataset will be publicly available.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.03341v1",
      "pdf_url": "http://arxiv.org/pdf/2510.03341v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.35,
      "weak_supervision_score": 0.372,
      "diffusion_reasoning_score": 0.429,
      "distributed_training_score": 0.35,
      "datasets_score": 0.397,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on developing a benchmark, dataset, and training recipe for MLLMs in dynamic chart generation, using techniques like supervised fine-tuning and Group Relative Policy Optimization. It does not involve diffusion models, iterative refinement processes for logical reasoning, or treating a Chain-of-Thought as a single entity for holistic correction. Therefore, there is no connection to diffusion-based reasoning.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.03343",
      "title": "Defining a Strategic Action Plan for AI in Higher Education",
      "authors": [
        "Nikolaos Avouris"
      ],
      "categories": [
        "cs.CY (Computers and Society)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "This paper discusses key challenges of Artificial Intelligence in Education,\nwith main focus on higher education institutions. We start with reviewing\nnormative actions of international organizations and concerns expressed about\nthe current technical landscape. Then we proceed with proposing a framework\nthat comprises five key dimensions relating to the main challenges relating to\nAI in higher education institutions, followed by five key strategic actions\nthat the main stakeholders need to take in order to address the current\ndevelopments. We map these actions to the main stakeholders of higher education\nand propose a deployment plan. This defines a framework along the dimensions:\nChallenges, Actions, Stakeholders, Deployment CASD. Examples of AI specific\nactions at the institutional and individual course level are also provided and\ndiscussed.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.03343v1",
      "pdf_url": "http://arxiv.org/pdf/2510.03343v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "extraction_failed",
      "embedding_status": "completed",
      "rlhf_score": 0.33,
      "weak_supervision_score": 0.249,
      "diffusion_reasoning_score": 0.281,
      "distributed_training_score": 0.308,
      "datasets_score": 0.348,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.03345",
      "title": "Pilot selection in the era of Virtual reality: algorithms for accurate\n  and interpretable machine learning models",
      "authors": [
        "Luoma Ke",
        "Guangpeng Zhang",
        "Jibo He",
        "Yajing Li",
        "Yan Li",
        "Xufeng Liu",
        "Peng Fang"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "With the rapid growth of the aviation industry, there is a need for a large\nnumber of flight crew. How to select the right pilots in a cost-efficient\nmanner has become an important research question. In the current study,\ntwenty-three pilots were recruited from China Eastern Airlines, and 23 novices\nwere from the community of Tsinghua University. A novel approach incorporating\nmachine learning and virtual reality technology was applied to distinguish\nfeatures between these participants with different flight skills. Results\nindicate that SVM with the MIC feature selection method consistently achieved\nthe highest prediction performance on all metrics with an Accuracy of 0.93, an\nAUC of 0.96, and an F1 of 0.93, which outperforms four other classifier\nalgorithms and two other feature selection methods. From the perspective of\nfeature selection methods, the MIC method can select features with a nonlinear\nrelationship to sampling labels, instead of a simple filter-out. Our new\nimplementation of the SVM + MIC algorithm outperforms all existing pilot\nselection algorithms and perhaps provides the first implementation based on eye\ntracking and flight dynamics data. This study's VR simulation platforms and\nalgorithms can be used for pilot selection and training.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.03345v1",
      "pdf_url": "http://arxiv.org/pdf/2510.03345v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "extraction_failed",
      "embedding_status": "completed",
      "rlhf_score": 0.393,
      "weak_supervision_score": 0.353,
      "diffusion_reasoning_score": 0.284,
      "distributed_training_score": 0.333,
      "datasets_score": 0.345,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.03346",
      "title": "KVComm: Enabling Efficient LLM Communication through Selective KV\n  Sharing",
      "authors": [
        "Xiangyu Shi",
        "Marco Chiesa",
        "Gerald Q. Maguire Jr.",
        "Dejan Kostic"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)",
        "cs.MA (Multiagent Systems)"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly deployed in multi-agent\nsystems, where effective inter-model communication is crucial. Existing\ncommunication protocols either rely on natural language, incurring high\ninference costs and information loss, or on hidden states, which suffer from\ninformation concentration bias and inefficiency. To address these limitations,\nwe propose KVComm, a novel communication framework that enables efficient\ncommunication between LLMs through selective sharing of KV pairs. KVComm\nleverages the rich information encoded in the KV pairs while avoiding the\npitfalls of hidden states. We introduce a KV layer-wise selection strategy\nbased on attention importance scores with a Gaussian prior to identify the most\ninformative KV pairs for communication. Extensive experiments across diverse\ntasks and model pairs demonstrate that KVComm achieves comparable performance\nto the upper-bound method, which directly merges inputs to one model without\nany communication, while transmitting as few as 30\\% of layers' KV pairs. Our\nstudy highlights the potential of KV pairs as an effective medium for inter-LLM\ncommunication, paving the way for scalable and efficient multi-agent systems.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.03346v1",
      "pdf_url": "http://arxiv.org/pdf/2510.03346v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.369,
      "weak_supervision_score": 0.34,
      "diffusion_reasoning_score": 0.409,
      "distributed_training_score": 0.403,
      "datasets_score": 0.308,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "Tangentially Relevant",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on efficient communication between LLMs in multi-agent systems using selective KV pair sharing, with no mention of diffusion models, iterative refinement processes, or holistic correction of reasoning paths. It deals with attention mechanisms and inter-model communication, not diffusion-based logical reasoning.",
      "distributed_training_justification": "The paper involves multi-agent systems and efficient data transmission (e.g., reducing KV pairs shared), which could relate to distributed computing environments, but it primarily addresses inference-time communication between pre-trained LLMs, not distributed training algorithms, parallel computing for training acceleration, or partitioning data/models across nodes.",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.03348",
      "title": "Visual Odometry with Transformers",
      "authors": [
        "Vlardimir Yugay",
        "Duy-Kien Nguyen",
        "Theo Gevers",
        "Cees G. M. Snoek",
        "Martin R. Oswald"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Modern monocular visual odometry methods typically combine pre-trained deep\nlearning components with optimization modules, resulting in complex pipelines\nthat rely heavily on camera calibration and hyperparameter tuning, and often\nstruggle in unseen real-world scenarios. Recent large-scale 3D models trained\non massive amounts of multi-modal data have partially alleviated these\nchallenges, providing generalizable dense reconstruction and camera pose\nestimation. Still, they remain limited in handling long videos and providing\naccurate per-frame estimates, which are required for visual odometry. In this\nwork, we demonstrate that monocular visual odometry can be addressed\neffectively in an end-to-end manner, thereby eliminating the need for\nhandcrafted components such as bundle adjustment, feature matching, camera\ncalibration, or dense 3D reconstruction. We introduce VoT, short for Visual\nodometry Transformer, which processes sequences of monocular frames by\nextracting features and modeling global relationships through temporal and\nspatial attention. Unlike prior methods, VoT directly predicts camera motion\nwithout estimating dense geometry and relies solely on camera poses for\nsupervision. The framework is modular and flexible, allowing seamless\nintegration of various pre-trained encoders as feature extractors. Experimental\nresults demonstrate that VoT scales effectively with larger datasets, benefits\nsubstantially from stronger pre-trained backbones, generalizes across diverse\ncamera motions and calibration settings, and outperforms traditional methods\nwhile running more than 3 times faster. The code will be released.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.03348v1",
      "pdf_url": "http://arxiv.org/pdf/2510.03348v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.272,
      "weak_supervision_score": 0.269,
      "diffusion_reasoning_score": 0.368,
      "distributed_training_score": 0.349,
      "datasets_score": 0.285,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.03349",
      "title": "AgentCaster: Reasoning-Guided Tornado Forecasting",
      "authors": [
        "Michael Chen"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)",
        "cs.CL (Computation and Language)"
      ],
      "abstract": "There is a growing need to evaluate Large Language Models (LLMs) on complex,\nhigh-impact, real-world tasks to assess their true readiness as reasoning\nagents. To address this gap, we introduce AgentCaster, a contamination-free\nframework employing multimodal LLMs end-to-end for the challenging,\nlong-horizon task of tornado forecasting. Within AgentCaster, models interpret\nheterogeneous spatiotemporal data from a high-resolution convection-allowing\nforecast archive. We assess model performance over a 40-day period featuring\ndiverse historical data, spanning several major tornado outbreaks and including\nover 500 tornado reports. Each day, models query interactively from a pool of\n3,625 forecast maps and 40,125 forecast soundings for a forecast horizon of\n12-36 hours. Probabilistic tornado-risk polygon predictions are verified\nagainst ground truths derived from geometric comparisons across disjoint risk\nbands in projected coordinate space. To quantify accuracy, we propose\ndomain-specific TornadoBench and TornadoHallucination metrics, with\nTornadoBench highly challenging for both LLMs and domain expert human\nforecasters. Notably, human experts significantly outperform state-of-the-art\nmodels, which demonstrate a strong tendency to hallucinate and overpredict risk\nintensity, struggle with precise geographic placement, and exhibit poor\nspatiotemporal reasoning in complex, dynamically evolving systems. AgentCaster\naims to advance research on improving LLM agents for challenging reasoning\ntasks in critical domains.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.03349v1",
      "pdf_url": "http://arxiv.org/pdf/2510.03349v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.383,
      "weak_supervision_score": 0.395,
      "diffusion_reasoning_score": 0.45,
      "distributed_training_score": 0.352,
      "datasets_score": 0.374,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper introduces AgentCaster, a framework for evaluating LLMs on tornado forecasting tasks, focusing on multimodal reasoning, interactive data querying, and domain-specific metrics. However, it does not involve diffusion-based models or any adaptation of iterative refinement processes for multi-step logical reasoning. The reasoning described is based on standard LLM agent workflows, such as chain-of-thought and tool use, without any reference to diffusion mechanisms. Thus, the paper's contributions are unrelated to the specified topic.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.03351",
      "title": "Interpretable Neuropsychiatric Diagnosis via Concept-Guided Graph Neural\n  Networks",
      "authors": [
        "Song Wang",
        "Zhenyu Lei",
        "Zhen Tan",
        "Jundong Li",
        "Javier Rasero",
        "Aiying Zhang",
        "Chirag Agarwal"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)",
        "eess.IV (Image and Video Processing)"
      ],
      "abstract": "Nearly one in five adolescents currently live with a diagnosed mental or\nbehavioral health condition, such as anxiety, depression, or conduct disorder,\nunderscoring the urgency of developing accurate and interpretable diagnostic\ntools. Resting-state functional magnetic resonance imaging (rs-fMRI) provides a\npowerful lens into large-scale functional connectivity, where brain regions are\nmodeled as nodes and inter-regional synchrony as edges, offering clinically\nrelevant biomarkers for psychiatric disorders. While prior works use graph\nneural network (GNN) approaches for disorder prediction, they remain complex\nblack-boxes, limiting their reliability and clinical translation. In this work,\nwe propose CONCEPTNEURO, a concept-based diagnosis framework that leverages\nlarge language models (LLMs) and neurobiological domain knowledge to\nautomatically generate, filter, and encode interpretable functional\nconnectivity concepts. Each concept is represented as a structured subgraph\nlinking specific brain regions, which are then passed through a concept\nclassifier. Our design ensures predictions through clinically meaningful\nconnectivity patterns, enabling both interpretability and strong predictive\nperformance. Extensive experiments across multiple psychiatric disorder\ndatasets demonstrate that CONCEPTNEURO-augmented GNNs consistently outperform\ntheir vanilla counterparts, improving accuracy while providing transparent,\nclinically aligned explanations. Furthermore, concept analyses highlight\ndisorder-specific connectivity patterns that align with expert knowledge and\nsuggest new hypotheses for future investigation, establishing CONCEPTNEURO as\nan interpretable, domain-informed framework for psychiatric disorder diagnosis.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.03351v1",
      "pdf_url": "http://arxiv.org/pdf/2510.03351v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.373,
      "weak_supervision_score": 0.336,
      "diffusion_reasoning_score": 0.454,
      "distributed_training_score": 0.331,
      "datasets_score": 0.335,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper's main contribution is a framework called CONCEPTNEURO, which integrates large language models and graph neural networks for interpretable diagnosis of psychiatric disorders using fMRI data. It focuses on concept generation, subgraph encoding, and predictive modeling for brain connectivity, with no mention of diffusion models, iterative refinement processes, or multi-step logical reasoning as defined in the topic.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.03352",
      "title": "Inference-Time Search using Side Information for Diffusion-based Image\n  Reconstruction",
      "authors": [
        "Mahdi Farahbakhsh",
        "Vishnu Teja Kunde",
        "Dileep Kalathil",
        "Krishna Narayanan",
        "Jean-Francois Chamberland"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.AI (Artificial Intelligence)",
        "cs.LG (Machine Learning)"
      ],
      "abstract": "Diffusion models have emerged as powerful priors for solving inverse\nproblems. However, existing approaches typically overlook side information that\ncould significantly improve reconstruction quality, especially in severely\nill-posed settings. In this work, we propose a novel inference-time search\nalgorithm that guides the sampling process using the side information in a\nmanner that balances exploration and exploitation. This enables more accurate\nand reliable reconstructions, providing an alternative to the gradient-based\nguidance that is prone to reward-hacking artifacts. Our approach can be\nseamlessly integrated into a wide range of existing diffusion-based image\nreconstruction pipelines. Through extensive experiments on a number of inverse\nproblems, such as box inpainting, super-resolution, and various deblurring\ntasks including motion, Gaussian, nonlinear, and blind deblurring, we show that\nour approach consistently improves the qualitative and quantitative performance\nof diffusion-based image reconstruction algorithms. We also show the superior\nperformance of our approach with respect to other baselines, including reward\ngradient-based guidance algorithms. The code is available at\n\\href{https://github.com/mhdfb/sideinfo-search-reconstruction}{this\nrepository}.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.03352v1",
      "pdf_url": "http://arxiv.org/pdf/2510.03352v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.37,
      "weak_supervision_score": 0.374,
      "diffusion_reasoning_score": 0.559,
      "distributed_training_score": 0.334,
      "datasets_score": 0.298,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper's main contribution is developing an inference-time search algorithm for diffusion-based image reconstruction using side information, focusing on tasks like inpainting and deblurring. While it involves iterative refinement in diffusion models, this is applied to visual inverse problems, not to multi-step logical reasoning or Chain-of-Thought processes for complex logical tasks. Therefore, it lacks the core elements of diffusion-based reasoning as defined.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.03353",
      "title": "Sonar Image Datasets: A Comprehensive Survey of Resources, Challenges,\n  and Applications",
      "authors": [
        "Larissa S. Gomes",
        "Gustavo P. Almeida",
        "Bryan U. Moreira",
        "Marco Quiroz",
        "Breno Xavier",
        "Lucas Soares",
        "Stephanie L. Brião",
        "Felipe G. Oliveira",
        "Paulo L. J. Drews-Jr"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "Sonar images are relevant for advancing underwater exploration, autonomous\nnavigation, and ecosystem monitoring. However, the progress depends on data\navailability. The scarcity of publicly available, well-annotated sonar image\ndatasets creates a significant bottleneck for the development of robust machine\nlearning models. This paper presents a comprehensive and concise review of the\ncurrent landscape of sonar image datasets, seeking not only to catalog existing\nresources but also to contextualize them, identify gaps, and provide a clear\nroadmap, serving as a base guide for researchers of any kind who wish to start\nor advance in the field of underwater acoustic data analysis. We mapped\npublicly accessible datasets across various sonar modalities, including Side\nScan Sonar (SSS), Forward-Looking Sonar (FLS), Synthetic Aperture Sonar (SAS),\nMultibeam Echo Sounder (MBES), and Dual-Frequency Identification Sonar\n(DIDSON). An analysis was conducted on applications such as classification,\ndetection, segmentation, and 3D reconstruction. This work focuses on\nstate-of-the-art advancements, incorporating newly released datasets. The\nfindings are synthesized into a master table and a chronological timeline,\noffering a clear and accessible comparison of characteristics, sizes, and\nannotation details datasets.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.03353v1",
      "pdf_url": "http://arxiv.org/pdf/2510.03353v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.257,
      "weak_supervision_score": 0.389,
      "diffusion_reasoning_score": 0.279,
      "distributed_training_score": 0.288,
      "datasets_score": 0.479,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "Highly Relevant",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "The paper's main contribution is a comprehensive review of sonar image datasets, including cataloging publicly available resources, analyzing their characteristics (e.g., sizes, annotations), identifying gaps, and providing comparisons via tables and timelines. This directly aligns with dataset analysis, evaluation, and benchmarking for machine learning and AI applications in underwater contexts, as it focuses on resources essential for tasks like object detection and segmentation.",
      "llm_score_status": "completed",
      "summary": "This paper presents a comprehensive survey of publicly available sonar image datasets, focusing on various modalities such as Side Scan Sonar (SSS), Forward-Looking Sonar (FLS), Synthetic Aperture Sonar (SAS), Multibeam Echo Sounder (MBES), and Dual-Frequency Identification Sonar (DIDSON), while cataloging resources, analyzing applications like classification and detection, and identifying gaps in the field. It synthesizes findings into a master table and chronological timeline, providing an updated overview of dataset characteristics, sizes, and annotations to guide researchers in underwater acoustic data analysis by incorporating recent advancements and state-of-the-art developments.",
      "novelty_score": "Moderate",
      "novelty_justification": "The paper presents a notable improvement by compiling and analyzing recently released sonar datasets, offering an updated roadmap that builds on previous reviews without introducing entirely new problems or techniques. While it contextualizes existing resources and identifies gaps, it primarily synthesizes known information rather than pioneering a new architecture or method.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to be cited and built upon within the subfield of underwater computer vision and robotics, as it provides a valuable resource for dataset selection and gap identification. However, its influence may be limited to specialized applications and not extend broadly to general AI or commercial sectors.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper represents a strong, valuable contribution by offering a clear and updated guide for researchers entering or advancing in sonar image analysis, making it essential for those in underwater perception fields. While not groundbreaking, its comprehensive synthesis and practical roadmap justify reading for relevant audiences.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/efc841a9a4e6c2a5e032b3e2a75940db8ba241e7",
      "total_authors": 9,
      "authors_found": 9,
      "highest_h_index": 4,
      "average_h_index": 0.8888888888888888,
      "notable_authors_count": 0,
      "author_h_indexes": [
        {
          "name": "Larissa S. Gomes",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2370877204"
        },
        {
          "name": "Gustavo P. Almeida",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2376193795"
        },
        {
          "name": "Bryan U. Moreira",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2384118215"
        },
        {
          "name": "Marco Quiroz",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2384120144"
        },
        {
          "name": "Breno Xavier",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2384120147"
        },
        {
          "name": "Lucas Soares",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2384124829"
        },
        {
          "name": "S. L. Brião",
          "h_index": 3,
          "profile_url": "https://www.semanticscholar.org/author/2033378"
        },
        {
          "name": "Felipe G. Oliveira",
          "h_index": 1,
          "profile_url": "https://www.semanticscholar.org/author/2351156321"
        },
        {
          "name": "Paulo L. J. Drews-Jr",
          "h_index": 4,
          "profile_url": "https://www.semanticscholar.org/author/2141665654"
        }
      ]
    },
    {
      "id": "2510.03356",
      "title": "Learned Display Radiance Fields with Lensless Cameras",
      "authors": [
        "Ziyang Chen",
        "Yuta Itoh",
        "Kaan Akşit"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)",
        "cs.ET (Emerging Technologies)"
      ],
      "abstract": "Calibrating displays is a basic and regular task that content creators must\nperform to maintain optimal visual experience, yet it remains a troublesome\nissue. Measuring display characteristics from different viewpoints often\nrequires specialized equipment and a dark room, making it inaccessible to most\nusers. To avoid specialized hardware requirements in display calibrations, our\nwork co-designs a lensless camera and an Implicit Neural Representation based\nalgorithm for capturing display characteristics from various viewpoints. More\nspecifically, our pipeline enables efficient reconstruction of light fields\nemitted from a display from a viewing cone of 46.6{\\deg} X 37.6{\\deg}. Our\nemerging pipeline paves the initial steps towards effortless display\ncalibration and characterization.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.03356v2",
      "pdf_url": "http://arxiv.org/pdf/2510.03356v2",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.337,
      "weak_supervision_score": 0.315,
      "diffusion_reasoning_score": 0.329,
      "distributed_training_score": 0.327,
      "datasets_score": 0.296,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.03358",
      "title": "Understanding Transformers for Time Series: Rank Structure,\n  Flow-of-ranks, and Compressibility",
      "authors": [
        "Annan Yu",
        "Danielle C. Maddix",
        "Boran Han",
        "Xiyuan Zhang",
        "Abdul Fatir Ansari",
        "Oleksandr Shchur",
        "Christos Faloutsos",
        "Andrew Gordon Wilson",
        "Michael W. Mahoney",
        "Yuyang Wang"
      ],
      "categories": [
        "cs.LG (Machine Learning)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Transformers are widely used across data modalities, and yet the principles\ndistilled from text models often transfer imperfectly to models trained to\nother modalities. In this paper, we analyze Transformers through the lens of\nrank structure. Our focus is on the time series setting, where the structural\nproperties of the data differ remarkably from those of text or vision. We show\nthat time-series embeddings, unlike text or vision, exhibit sharply decaying\nsingular value spectra: small patch sizes and smooth continuous mappings\nconcentrate the data into low-rank subspaces. From this, we prove that the\nassociated $Q/K/V$ projections admit accurate low-rank approximations, and that\nattention layers become compressible in proportion to the decay of the\nembedding spectrum. We introduce the concept of flow-of-ranks, a phenomenon by\nwhich nonlinear mixing across depth inflates the rank, explaining why early\nlayers are most amenable to compression and why ranks grow with depth. Guided\nby these theoretical and empirical results, we use these insights to compress\nChronos, a large time series foundation model, achieving a reduction of $65\\%$\nin inference time and $81\\%$ in memory, without loss of accuracy. Our findings\nprovide principled guidance for allocating width, depth, and heads in time\nseries foundation models, and for exploiting their inherent compressibility.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.03358v1",
      "pdf_url": "http://arxiv.org/pdf/2510.03358v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.334,
      "weak_supervision_score": 0.322,
      "diffusion_reasoning_score": 0.399,
      "distributed_training_score": 0.393,
      "datasets_score": 0.304,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.05145",
      "title": "FlashResearch: Real-time Agent Orchestration for Efficient Deep Research",
      "authors": [
        "Lunyiu Nie",
        "Nedim Lipka",
        "Ryan A. Rossi",
        "Swarat Chaudhuri"
      ],
      "categories": [
        "cs.DC (Distributed, Parallel, and Cluster Computing)",
        "cs.AI (Artificial Intelligence)",
        "cs.MA (Multiagent Systems)"
      ],
      "abstract": "Deep research agents, which synthesize information across diverse sources,\nare significantly constrained by their sequential reasoning processes. This\narchitectural bottleneck results in high latency, poor runtime adaptability,\nand inefficient resource allocation, making them impractical for interactive\napplications. To overcome this, we introduce FlashResearch, a novel framework\nfor efficient deep research that transforms sequential processing into\nparallel, runtime orchestration by dynamically decomposing complex queries into\ntree-structured sub-tasks. Our core contributions are threefold: (1) an\nadaptive planner that dynamically allocates computational resources by\ndetermining research breadth and depth based on query complexity; (2) a\nreal-time orchestration layer that monitors research progress and prunes\nredundant paths to reallocate resources and optimize efficiency; and (3) a\nmulti-dimensional parallelization framework that enables concurrency across\nboth research breadth and depth. Experiments show that FlashResearch\nconsistently improves final report quality within fixed time budgets, and can\ndeliver up to a 5x speedup while maintaining comparable quality.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.05145v1",
      "pdf_url": "http://arxiv.org/pdf/2510.05145v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.417,
      "weak_supervision_score": 0.383,
      "diffusion_reasoning_score": 0.447,
      "distributed_training_score": 0.479,
      "datasets_score": 0.361,
      "llm_validation_status": "completed",
      "rlhf_relevance": "Not Relevant",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "Moderately Relevant",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "The paper focuses on parallel orchestration and dynamic planning for AI research tasks, with no mention of human feedback, reward models, or reinforcement learning techniques for model alignment.",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper describes iterative reasoning and dynamic adjustments in research tasks but does not involve diffusion models, iterative refinement of logical paths, or any adaptation of diffusion processes for reasoning.",
      "distributed_training_justification": "The paper's framework includes multi-dimensional parallelization, concurrent execution, and asynchronous task management, which align with parallel computing concepts, but it applies these to research orchestration rather than specifically to distributed training of machine learning models.",
      "datasets_justification": "below_threshold",
      "llm_score_status": "completed",
      "summary": "FlashResearch is a framework aimed at improving deep research agents by shifting from sequential to parallel processing, addressing issues like high latency and inefficient resource use in synthesizing information from diverse sources. It incorporates an adaptive planner for dynamic resource allocation based on query complexity, a real-time orchestration layer for monitoring and pruning tasks, and a multi-dimensional parallelization framework for concurrent execution, with experiments demonstrating up to 5x speedup and enhanced report quality within fixed time budgets.",
      "novelty_score": "High",
      "novelty_justification": "The paper introduces a truly new framework with innovative elements like dynamic task decomposition, real-time orchestration, and multi-dimensional parallelization, significantly advancing the state-of-the-art in efficient deep research agents.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to be cited and built upon in subfields such as distributed computing and multiagent systems, given its improvements in research efficiency, though its influence may be confined to specific AI applications rather than widespread adoption.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper offers a strong, valuable contribution by addressing critical inefficiencies in AI research agents, making it essential for researchers in related fields to be aware of its innovations and potential applications.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/ea4acc77eefef67328c1128fc8f0578d0ff051ff",
      "total_authors": 4,
      "authors_found": 4,
      "highest_h_index": 35,
      "average_h_index": 13.75,
      "notable_authors_count": 2,
      "author_h_indexes": [
        {
          "name": "Lunyiu Nie",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2313699525"
        },
        {
          "name": "Nedim Lipka",
          "h_index": 16,
          "profile_url": "https://www.semanticscholar.org/author/1793409"
        },
        {
          "name": "Ryan A. Rossi",
          "h_index": 2,
          "profile_url": "https://www.semanticscholar.org/author/2299780933"
        },
        {
          "name": "Swarat Chaudhuri",
          "h_index": 35,
          "profile_url": "https://www.semanticscholar.org/author/35865989"
        }
      ]
    },
    {
      "id": "2510.05148",
      "title": "Every Step Counts: Decoding Trajectories as Authorship Fingerprints of\n  dLLMs",
      "authors": [
        "Qi Li",
        "Runpeng Yu",
        "Haiquan Lu",
        "Xinchao Wang"
      ],
      "categories": [
        "cs.CL (Computation and Language)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Discrete Diffusion Large Language Models (dLLMs) have recently emerged as a\ncompetitive paradigm for non-autoregressive language modeling. Their\ndistinctive decoding mechanism enables faster inference speed and strong\nperformance in code generation and mathematical tasks. In this work, we show\nthat the decoding mechanism of dLLMs not only enhances model utility but also\ncan be used as a powerful tool for model attribution. A key challenge in this\nproblem lies in the diversity of attribution scenarios, including\ndistinguishing between different models as well as between different\ncheckpoints or backups of the same model. To ensure broad applicability, we\nidentify two fundamental problems: what information to extract from the\ndecoding trajectory, and how to utilize it effectively. We first observe that\nrelying directly on per-step model confidence yields poor performance. This is\nmainly due to the bidirectional decoding nature of dLLMs: each newly decoded\ntoken influences the confidence of other decoded tokens, making model\nconfidence highly redundant and washing out structural signal regarding\ndecoding order or dependencies. To overcome this, we propose a novel\ninformation extraction scheme called the Directed Decoding Map (DDM), which\ncaptures structural relationships between decoding steps and better reveals\nmodel-specific behaviors. Furthermore, to make full use of the extracted\nstructural information during attribution, we propose Gaussian-Trajectory\nAttribution (GTA), where we fit a cell-wise Gaussian distribution at each\ndecoding position for each target model, and define the likelihood of a\ntrajectory as the attribution score: if a trajectory exhibits higher\nlog-likelihood under the distribution of a specific model, it is more likely to\nhave been generated by that model. Extensive experiments under different\nsettings validate the utility of our methods.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.05148v1",
      "pdf_url": "http://arxiv.org/pdf/2510.05148v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.397,
      "weak_supervision_score": 0.346,
      "diffusion_reasoning_score": 0.536,
      "distributed_training_score": 0.379,
      "datasets_score": 0.342,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Moderately Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper discusses Discrete Diffusion Large Language Models (dLLMs), which use an iterative decoding process similar to diffusion models, and mentions their application in tasks like code generation and mathematical reasoning. This involves multi-step refinement of token sequences, which could relate to holistic correction in reasoning paths. However, the paper's main focus is on model attribution using decoding trajectories, not on adapting diffusion for solving complex logical tasks or Chain-of-Thought reasoning, making it only moderately relevant.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "completed",
      "summary": "This paper investigates model attribution for Discrete Diffusion Large Language Models (dLLMs) by leveraging their unique decoding trajectories to distinguish between different models or their checkpoints. It introduces the Directed Decoding Map (DDM) to extract structural information from trajectories and the Gaussian-Trajectory Attribution (GTA) method, which fits Gaussian distributions to create model-specific fingerprints for attribution, demonstrating strong performance in extensive experiments across various scenarios.",
      "novelty_score": "High",
      "novelty_justification": "The paper introduces a truly new problem by being the first to explore model attribution specifically for dLLMs and proposes innovative techniques like DDM and GTA, significantly advancing the state-of-the-art in language model attribution.",
      "impact_score": "Moderate",
      "impact_justification": "The work is likely to be cited and built upon within the subfield of AI and language processing, particularly for dLLMs and attribution tasks, due to its practical applications in combating misinformation, though its influence may be limited to specialized areas.",
      "recommendation_score": "Should Read",
      "recommendation_justification": "This paper offers a high-quality contribution with novel methods and robust experimental results that advance model attribution techniques, making it essential for researchers in AI and language models to be aware of for potential applications.",
      "h_index_status": "completed",
      "semantic_scholar_url": "https://www.semanticscholar.org/paper/985fe45952ea046f544178e1a3eace0d97f842a1",
      "total_authors": 4,
      "authors_found": 4,
      "highest_h_index": 9,
      "average_h_index": 4.25,
      "notable_authors_count": 1,
      "author_h_indexes": [
        {
          "name": "Qi Li",
          "h_index": 3,
          "profile_url": "https://www.semanticscholar.org/author/2311590482"
        },
        {
          "name": "Runpeng Yu",
          "h_index": 9,
          "profile_url": "https://www.semanticscholar.org/author/2044524205"
        },
        {
          "name": "Haiquan Lu",
          "h_index": 0,
          "profile_url": "https://www.semanticscholar.org/author/2384702543"
        },
        {
          "name": "Xinchao Wang",
          "h_index": 5,
          "profile_url": "https://www.semanticscholar.org/author/2279825737"
        }
      ]
    },
    {
      "id": "2510.05149",
      "title": "Percepta: High Performance Stream Processing at the Edge",
      "authors": [
        "Clarisse Sousa",
        "Tiago Fonseca",
        "Luis Lino Ferreira",
        "Ricardo Venâncio",
        "Ricardo Severino"
      ],
      "categories": [
        "cs.DC (Distributed, Parallel, and Cluster Computing)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "The rise of real-time data and the proliferation of Internet of Things (IoT)\ndevices have highlighted the limitations of cloud-centric solutions,\nparticularly regarding latency, bandwidth, and privacy. These challenges have\ndriven the growth of Edge Computing. Associated with IoT appears a set of other\nproblems, like: data rate harmonization between multiple sources, protocol\nconversion, handling the loss of data and the integration with Artificial\nIntelligence (AI) models. This paper presents Percepta, a lightweight Data\nStream Processing (DSP) system tailored to support AI workloads at the edge,\nwith a particular focus on such as Reinforcement Learning (RL). It introduces\nspecialized features such as reward function computation, data storage for\nmodel retraining, and real-time data preparation to support continuous\ndecision-making. Additional functionalities include data normalization,\nharmonization across heterogeneous protocols and sampling rates, and robust\nhandling of missing or incomplete data, making it well suited for the\nchallenges of edge-based AI deployment.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.05149v1",
      "pdf_url": "http://arxiv.org/pdf/2510.05149v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "extraction_failed",
      "embedding_status": "completed",
      "rlhf_score": 0.378,
      "weak_supervision_score": 0.37,
      "diffusion_reasoning_score": 0.345,
      "distributed_training_score": 0.445,
      "datasets_score": 0.374,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "Tangentially Relevant",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "The paper focuses on Percepta, a system for edge-based stream processing that supports AI workloads like Reinforcement Learning, including features for data preparation and model retraining. While it involves computation at the edge, which could imply distributed elements in a broader edge computing context, it does not directly address distributed training techniques such as partitioning data or models across multiple nodes for accelerated training. Thus, the connection is indirect and not central to the paper's contributions.",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.05150",
      "title": "Chronological Thinking in Full-Duplex Spoken Dialogue Language Models",
      "authors": [
        "Donghang Wu",
        "Haoyang Zhang",
        "Chen Chen",
        "Tianyu Zhang",
        "Fei Tian",
        "Xuerui Yang",
        "Gang Yu",
        "Hexin Liu",
        "Nana Hou",
        "Yuchen Hu",
        "Eng Siong Chng"
      ],
      "categories": [
        "cs.CL (Computation and Language)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Recent advances in spoken dialogue language models (SDLMs) reflect growing\ninterest in shifting from turn-based to full-duplex systems, where the models\ncontinuously perceive user speech streams while generating responses. This\nsimultaneous listening and speaking design enables real-time interaction and\nthe agent can handle dynamic conversational behaviors like user barge-in.\nHowever, during the listening phase, existing systems keep the agent idle by\nrepeatedly predicting the silence token, which departs from human behavior: we\nusually engage in lightweight thinking during conversation rather than\nremaining absent-minded. Inspired by this, we propose Chronological Thinking, a\non-the-fly conversational thinking mechanism that aims to improve response\nquality in full-duplex SDLMs. Specifically, chronological thinking presents a\nparadigm shift from conventional LLM thinking approaches, such as\nChain-of-Thought, purpose-built for streaming acoustic input. (1) Strictly\ncausal: the agent reasons incrementally while listening, updating internal\nhypotheses only from past audio with no lookahead. (2) No additional latency:\nreasoning is amortized during the listening window; once the user stops\nspeaking, the agent halts thinking and begins speaking without further delay.\nExperiments demonstrate the effectiveness of chronological thinking through\nboth objective metrics and human evaluations show consistent improvements in\nresponse quality. Furthermore, chronological thinking robustly handles\nconversational dynamics and attains competitive performance on full-duplex\ninteraction metrics.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.05150v2",
      "pdf_url": "http://arxiv.org/pdf/2510.05150v2",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.394,
      "weak_supervision_score": 0.332,
      "diffusion_reasoning_score": 0.549,
      "distributed_training_score": 0.359,
      "datasets_score": 0.284,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper proposes Chronological Thinking for full-duplex spoken dialogue language models, focusing on incremental, causal reasoning during user speech without lookahead or added latency. It draws from the ACT-R framework and contrasts with Chain-of-Thought methods, but it does not involve diffusion models, iterative refinement processes, or any adaptation of diffusion for multi-step logical reasoning. Therefore, the paper lacks any components related to diffusion-based techniques.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.05152",
      "title": "A Single Character can Make or Break Your LLM Evals",
      "authors": [
        "Jingtong Su",
        "Jianyu Zhang",
        "Karen Ullrich",
        "Léon Bottou",
        "Mark Ibrahim"
      ],
      "categories": [
        "cs.CL (Computation and Language)",
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Common Large Language model (LLM) evaluations rely on demonstration examples\nto steer models' responses to the desired style. While the number of examples\nused has been studied and standardized, the choice of how to format examples is\nless investigated. In evaluation protocols and real world usage, users face the\nchoice how to separate in-context examples: use a comma? new line? semi-colon?\nhashtag? etc.? Surprisingly, we find this seemingly minor choice can\ndramatically alter model response quality. Across leading model families\n(Llama, Qwen, Gemma), performance on MMLU for example can vary by $\\pm 23\\%$\ndepending on the choice of delimiter. In fact, one can manipulate model\nrankings to put any model in the lead by only modifying the single character\nseparating examples. We find LLMs' brittleness pervades topics, model families,\nand doesn't improve with scale. By probing attention head scores, we find that\ngood-performing delimiters steer attention towards key tokens in the input.\nFinally, we explore methods to improve LLMs' robustness to the choice of\ndelimiter. We find specifying the selected delimiter in the prompt boosts\nrobustness and offer practical recommendations for the best-performing\ndelimiters to select.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.05152v1",
      "pdf_url": "http://arxiv.org/pdf/2510.05152v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.387,
      "weak_supervision_score": 0.368,
      "diffusion_reasoning_score": 0.382,
      "distributed_training_score": 0.329,
      "datasets_score": 0.322,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.05153",
      "title": "An Algorithmic Information-Theoretic Perspective on the Symbol Grounding\n  Problem",
      "authors": [
        "Zhangchi Liu"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)",
        "cs.IT (Information Theory)",
        "math.IT (Information Theory)"
      ],
      "abstract": "This paper provides a definitive, unifying framework for the Symbol Grounding\nProblem (SGP) by reformulating it within Algorithmic Information Theory (AIT).\nWe demonstrate that the grounding of meaning is a process fundamentally\nconstrained by information-theoretic limits, thereby unifying the G\\\"odelian\n(self-reference) and No Free Lunch (statistical) perspectives. We model a\nsymbolic system as a universal Turing machine and define grounding as an act of\ninformation compression. The argument proceeds in four stages. First, we prove\nthat a purely symbolic system cannot ground almost all possible \"worlds\" (data\nstrings), as they are algorithmically random and thus incompressible. Second,\nwe show that any statically grounded system, specialized for compressing a\nspecific world, is inherently incomplete because an adversarial, incompressible\nworld relative to the system can always be constructed. Third, the \"grounding\nact\" of adapting to a new world is proven to be non-inferable, as it requires\nthe input of new information (a shorter program) that cannot be deduced from\nthe system's existing code. Finally, we use Chaitin's Incompleteness Theorem to\nprove that any algorithmic learning process is itself a finite system that\ncannot comprehend or model worlds whose complexity provably exceeds its own.\nThis establishes that meaning is the open-ended process of a system perpetually\nattempting to overcome its own information-theoretic limitations.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.05153v1",
      "pdf_url": "http://arxiv.org/pdf/2510.05153v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.324,
      "weak_supervision_score": 0.337,
      "diffusion_reasoning_score": 0.388,
      "distributed_training_score": 0.262,
      "datasets_score": 0.277,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.06233",
      "title": "User to Video: A Model for Spammer Detection Inspired by Video\n  Classification Technology",
      "authors": [
        "Haoyang Zhang",
        "Zhou Yang",
        "Yucai Pang"
      ],
      "categories": [
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "This article is inspired by video classification technology. If the user\nbehavior subspace is viewed as a frame image, consecutive frame images are\nviewed as a video. Following this novel idea, a model for spammer detection\nbased on user videoization, called UVSD, is proposed. Firstly, a user2piexl\nalgorithm for user pixelization is proposed. Considering the adversarial\nbehavior of user stances, the user is viewed as a pixel, and the stance is\nquantified as the pixel's RGB. Secondly, a behavior2image algorithm is proposed\nfor transforming user behavior subspace into frame images. Low-rank dense\nvectorization of subspace user relations is performed using representation\nlearning, while cutting and diffusion algorithms are introduced to complete the\nframe imageization. Finally, user behavior videos are constructed based on\ntemporal features. Subsequently, a video classification algorithm is combined\nto identify the spammers. Experiments using publicly available datasets, i.e.,\nWEIBO and TWITTER, show an advantage of the UVSD model over state-of-the-art\nmethods.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.06233v1",
      "pdf_url": "http://arxiv.org/pdf/2510.06233v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.321,
      "weak_supervision_score": 0.314,
      "diffusion_reasoning_score": 0.354,
      "distributed_training_score": 0.281,
      "datasets_score": 0.302,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.06235",
      "title": "Stacked Regression using Off-the-shelf, Stimulus-tuned and Fine-tuned\n  Neural Networks for Predicting fMRI Brain Responses to Movies (Algonauts 2025\n  Report)",
      "authors": [
        "Robert Scholz",
        "Kunal Bagga",
        "Christine Ahrends",
        "Carlo Alberto Barbano"
      ],
      "categories": [
        "eess.IV (Image and Video Processing)",
        "cs.AI (Artificial Intelligence)",
        "cs.CV (Computer Vision and Pattern Recognition)"
      ],
      "abstract": "We present our submission to the Algonauts 2025 Challenge, where the goal is\nto predict fMRI brain responses to movie stimuli. Our approach integrates\nmultimodal representations from large language models, video encoders, audio\nmodels, and vision-language models, combining both off-the-shelf and fine-tuned\nvariants. To improve performance, we enhanced textual inputs with detailed\ntranscripts and summaries, and we explored stimulus-tuning and fine-tuning\nstrategies for language and vision models. Predictions from individual models\nwere combined using stacked regression, yielding solid results. Our submission,\nunder the team name Seinfeld, ranked 10th. We make all code and resources\npublicly available, contributing to ongoing efforts in developing multimodal\nencoding models for brain activity.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.06235v1",
      "pdf_url": "http://arxiv.org/pdf/2510.06235v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.373,
      "weak_supervision_score": 0.316,
      "diffusion_reasoning_score": 0.445,
      "distributed_training_score": 0.354,
      "datasets_score": 0.336,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper's main contribution is developing a multimodal encoding model to predict fMRI brain responses using neural networks like LLMs, video encoders, and audio models, combined via stacked regression. It does not involve diffusion models, iterative refinement processes, or multi-step logical reasoning for complex tasks, as defined by the topic. Therefore, there is no connection to diffusion-based reasoning.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.08586",
      "title": "Dynamic Stress Detection: A Study of Temporal Progression Modelling of\n  Stress in Speech",
      "authors": [
        "Vishakha Lall",
        "Yisi Liu"
      ],
      "categories": [
        "eess.AS (Audio and Speech Processing)",
        "cs.AI (Artificial Intelligence)",
        "cs.CL (Computation and Language)",
        "cs.SD (Sound)"
      ],
      "abstract": "Detecting psychological stress from speech is critical in high-pressure\nsettings. While prior work has leveraged acoustic features for stress\ndetection, most treat stress as a static label. In this work, we model stress\nas a temporally evolving phenomenon influenced by historical emotional state.\nWe propose a dynamic labelling strategy that derives fine-grained stress\nannotations from emotional labels and introduce cross-attention-based\nsequential models, a Unidirectional LSTM and a Transformer Encoder, to capture\ntemporal stress progression. Our approach achieves notable accuracy gains on\nMuSE (+5%) and StressID (+18%) over existing baselines, and generalises well to\na custom real-world dataset. These results highlight the value of modelling\nstress as a dynamic construct in speech.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.08586v1",
      "pdf_url": "http://arxiv.org/pdf/2510.08586v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "intro_successful",
      "embedding_status": "completed",
      "rlhf_score": 0.353,
      "weak_supervision_score": 0.377,
      "diffusion_reasoning_score": 0.397,
      "distributed_training_score": 0.345,
      "datasets_score": 0.371,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "not_validated",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "below_threshold",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    },
    {
      "id": "2510.17830",
      "title": "Multi-Agent Design Assistant for the Simulation of Inertial Fusion\n  Energy",
      "authors": [
        "Meir H. Shachar",
        "Dane M. Sterbentz",
        "Harshitha Menon",
        "Charles F. Jekel",
        "M. Giselle Fernández-Godino",
        "Yue Hao",
        "Kevin Korner",
        "Robert Rieben",
        "Daniel A. White",
        "William J. Schill",
        "Jonathan L. Belof"
      ],
      "categories": [
        "cs.AI (Artificial Intelligence)"
      ],
      "abstract": "Inertial fusion energy promises nearly unlimited, clean power if it can be\nachieved. However, the design and engineering of fusion systems requires\ncontrolling and manipulating matter at extreme energies and timescales; the\nshock physics and radiation transport governing the physical behavior under\nthese conditions are complex requiring the development, calibration, and use of\npredictive multiphysics codes to navigate the highly nonlinear and\nmulti-faceted design landscape. We hypothesize that artificial intelligence\nreasoning models can be combined with physics codes and emulators to\nautonomously design fusion fuel capsules. In this article, we construct a\nmulti-agent system where natural language is utilized to explore the complex\nphysics regimes around fusion energy. The agentic system is capable of\nexecuting a high-order multiphysics inertial fusion computational code. We\ndemonstrate the capacity of the multi-agent design assistant to both\ncollaboratively and autonomously manipulate, navigate, and optimize capsule\ngeometry while accounting for high fidelity physics that ultimately achieve\nsimulated ignition via inverse design.",
      "published_date": "2025-10-02",
      "arxiv_url": "http://arxiv.org/abs/2510.17830v1",
      "pdf_url": "http://arxiv.org/pdf/2510.17830v1",
      "scraper_status": "successfully_scraped",
      "intro_status": "no_intro_found",
      "embedding_status": "completed",
      "rlhf_score": 0.359,
      "weak_supervision_score": 0.289,
      "diffusion_reasoning_score": 0.402,
      "distributed_training_score": 0.363,
      "datasets_score": 0.289,
      "llm_validation_status": "completed",
      "rlhf_relevance": "not_validated",
      "weak_supervision_relevance": "not_validated",
      "diffusion_reasoning_relevance": "Not Relevant",
      "distributed_training_relevance": "not_validated",
      "datasets_relevance": "not_validated",
      "rlhf_justification": "below_threshold",
      "weak_supervision_justification": "below_threshold",
      "diffusion_reasoning_justification": "The paper focuses on a multi-agent system using AI reasoning models, natural language, and physics codes to optimize fusion fuel capsule designs. It does not involve diffusion-based models or iterative refinement processes for multi-step logical reasoning, as defined by the topic. Thus, there is no relevant connection.",
      "distributed_training_justification": "below_threshold",
      "datasets_justification": "below_threshold",
      "llm_score_status": "not_relevant_enough",
      "summary": null,
      "novelty_score": null,
      "novelty_justification": null,
      "impact_score": null,
      "impact_justification": null,
      "recommendation_score": null,
      "recommendation_justification": null,
      "h_index_status": "not_fetched",
      "semantic_scholar_url": null,
      "total_authors": 0,
      "authors_found": 0,
      "highest_h_index": 0,
      "average_h_index": 0.0,
      "notable_authors_count": 0,
      "author_h_indexes": []
    }
  ],
  "total_papers": 260,
  "date": "2025-10-02"
};
    </script>

    <script>
        // ============================================================================
        // GLOBAL VARIABLES & CONFIGURATION
        // ============================================================================
        
        // Page configuration - get data from embedded PAPER_DATA
        const PAGE_DATE = PAPER_DATA.date;
        const PAPERS_PER_PAGE = 5;
        let currentPage = 1;
        let totalPapers = PAPER_DATA.total_papers;
        let totalPages = 0;
        let allPapers = PAPER_DATA.papers;  // Use embedded papers data
        let filteredSortedPapers = [];  // Store papers after filtering/sorting
        let currentPagePapers = [];  // Store papers for current page display
        let currentSort = 'recommend_best';  // Default sort
        
        // H-Index Filter State Management
        let currentHIndexFilters = {
            found: true,
            notFound: true,
            highestMin: 0,
            highestMax: 1000,
            averageMin: 0,
            averageMax: 1000
        };
        
        let pendingHIndexFilters = { ...currentHIndexFilters };
        
        // Topic Filter State Management
        let currentTopicFilters = {
            rlhf: true,
            weakSupervision: true,
            diffusionReasoning: true,
            distributedTraining: true,
            datasets: true
        };
        
        let pendingTopicFilters = { ...currentTopicFilters };
        
        // Relevance Filter State Management
        let currentRelevanceFilters = {
            highlyRelevant: true,
            moderatelyRelevant: true,
            tangentiallyRelevant: true,
            notRelevant: true
        };
        
        let pendingRelevanceFilters = { ...currentRelevanceFilters };
        
        // Sidebar state variables
        let isMobileSidebarOpen = false;
        let isDesktopSidebarOpen = false;

        // ============================================================================
        // URL PARAMETER UTILITIES
        // ============================================================================
        
        function getUrlParameter(name) {
            const urlParams = new URLSearchParams(window.location.search);
            return urlParams.get(name);
        }
        
        function setUrlParameter(name, value) {
            const url = new URL(window.location.href);
            url.searchParams.set(name, value);
            window.history.pushState(null, '', url.toString());
        }
        
        function updateHIndexFiltersFromURL() {
            // Get H-Index filter parameters from URL
            const hindexFound = getUrlParameter('hindex_found');
            const hindexNotFound = getUrlParameter('hindex_not_found');
            const highestMin = getUrlParameter('highest_min');
            const highestMax = getUrlParameter('highest_max');
            const averageMin = getUrlParameter('average_min');
            const averageMax = getUrlParameter('average_max');
            
            // Update current filters if parameters exist
            if (hindexFound !== null) currentHIndexFilters.found = hindexFound === 'true';
            if (hindexNotFound !== null) currentHIndexFilters.notFound = hindexNotFound === 'true';
            if (highestMin !== null) currentHIndexFilters.highestMin = parseInt(highestMin) || 0;
            if (highestMax !== null) currentHIndexFilters.highestMax = parseInt(highestMax) || 1000;
            if (averageMin !== null) currentHIndexFilters.averageMin = parseInt(averageMin) || 0;
            if (averageMax !== null) currentHIndexFilters.averageMax = parseInt(averageMax) || 1000;
            
            // Sync pending filters
            pendingHIndexFilters = { ...currentHIndexFilters };
            
            // Sync UI and update button text
            syncHIndexUI();
        }
        
        function updateURLWithHIndexFilters() {
            const url = new URL(window.location.href);
            
            // Only set parameters if they differ from defaults
            if (!currentHIndexFilters.found || !currentHIndexFilters.notFound) {
                url.searchParams.set('hindex_found', currentHIndexFilters.found);
                url.searchParams.set('hindex_not_found', currentHIndexFilters.notFound);
            } else {
                url.searchParams.delete('hindex_found');
                url.searchParams.delete('hindex_not_found');
            }
            
            if (currentHIndexFilters.highestMin !== 0 || currentHIndexFilters.highestMax !== 1000) {
                url.searchParams.set('highest_min', currentHIndexFilters.highestMin);
                url.searchParams.set('highest_max', currentHIndexFilters.highestMax);
            } else {
                url.searchParams.delete('highest_min');
                url.searchParams.delete('highest_max');
            }
            
            if (currentHIndexFilters.averageMin !== 0 || currentHIndexFilters.averageMax !== 1000) {
                url.searchParams.set('average_min', currentHIndexFilters.averageMin);
                url.searchParams.set('average_max', currentHIndexFilters.averageMax);
            } else {
                url.searchParams.delete('average_min');
                url.searchParams.delete('average_max');
            }
            
            window.history.pushState(null, '', url.toString());
        }

        // ============================================================================
        // DATE FORMATTING FUNCTIONS
        // ============================================================================
        
        function formatPageDate(dateString) {
            const date = new Date(dateString);
            const options = { day: 'numeric', month: 'long', year: 'numeric' };
            return date.toLocaleDateString('en-GB', options);
        }

        function formatPublicationDate(dateString) {
            const date = new Date(dateString);
            const options = { day: 'numeric', month: 'long', year: 'numeric' };
            return date.toLocaleDateString('en-GB', options);
        }

        // ============================================================================
        // UI UPDATE FUNCTIONS FOR PAGE LOAD
        // ============================================================================
        
        function updatePageTitles(date) {
            const formattedDate = formatPageDate(date);
            const titleText = `Papers Published on ${formattedDate}`;
            
            // Update page title
            document.title = `Research Feed -- ${formattedDate}`;
            
            // Update mobile and desktop headers
            const mobileTitle = document.getElementById('page-title-mobile');
            const desktopTitle = document.getElementById('page-title-desktop');
            
            if (mobileTitle) {
                mobileTitle.textContent = titleText;
            }
            if (desktopTitle) {
                desktopTitle.textContent = titleText;
            }
        }

        function updatePaperCount() {
            const mobileCount = document.getElementById('mobile-paper-count');
            const desktopCount = document.getElementById('desktop-paper-count');
            const mobileMainCount = document.getElementById('mobile-main-paper-count');
            const desktopMainCount = document.getElementById('desktop-main-paper-count');
            
            const showing = filteredSortedPapers.length;
            const sidebarCountText = `Showing: ${showing}/${totalPapers} Papers`;
            const mainCountText = `Showing ${showing} / ${totalPapers} papers`;
            
            // Update sidebar counts
            if (mobileCount) {
                mobileCount.textContent = sidebarCountText;
            }
            if (desktopCount) {
                desktopCount.textContent = sidebarCountText;
            }
            
            // Update main header counts
            if (mobileMainCount) {
                mobileMainCount.textContent = mainCountText;
            }
            if (desktopMainCount) {
                desktopMainCount.textContent = mainCountText;
            }
        }

        // ============================================================================
        // SORTING FUNCTIONS
        // ============================================================================
        
        function calculateRecommendationScore(paper) {
            // Skip calculation if already calculated or if not relevant enough
            if (paper.recommendation_numerical_score !== undefined) {
                return paper.recommendation_numerical_score;
            }
            
            if (paper.llm_score_status === 'not_relevant_enough') {
                paper.recommendation_numerical_score = 0;
                return 0;
            }
            
            let score = 0;
            
            // Recommendation scores (primary)
            const recommendationScores = {
                'Must Read': 40,
                'Should Read': 30,
                'Can Skip': 20,
                'Ignore': 10
            };
            score += recommendationScores[paper.recommendation_score] || 0;
            
            // Novelty scores (first tiebreaker)
            const noveltyScores = {
                'High': 4,
                'Moderate': 3,
                'Low': 2,
                'None': 1
            };
            score += noveltyScores[paper.novelty_score] || 0;
            
            // Impact scores (second tiebreaker)
            const impactScores = {
                'High': 4,
                'Moderate': 3,
                'Low': 2,
                'Negligible': 1
            };
            score += impactScores[paper.impact_score] || 0;
            
            paper.recommendation_numerical_score = score;
            return score;
        }
        
        function getHighestHIndex(paper) {
            // Return the highest H-index value, or -1 if not available (so unavailable papers sort last)
            return paper.highest_h_index !== undefined ? paper.highest_h_index : -1;
        }
        
        function getAverageHIndex(paper) {
            // Return the average H-index value, or -1 if not available (so unavailable papers sort last)
            return paper.average_h_index !== undefined ? paper.average_h_index : -1;
        }
        
        function calculateRelevanceScore(paper) {
            let score = 0;
            
            // Only consider topics that are currently selected/enabled in the topic filter
            const topicsToConsider = [];
            if (currentTopicFilters.rlhf) topicsToConsider.push('rlhf_relevance');
            if (currentTopicFilters.weakSupervision) topicsToConsider.push('weak_supervision_relevance');
            if (currentTopicFilters.diffusionReasoning) topicsToConsider.push('diffusion_reasoning_relevance');
            if (currentTopicFilters.distributedTraining) topicsToConsider.push('distributed_training_relevance');
            if (currentTopicFilters.datasets) topicsToConsider.push('datasets_relevance');
            
            // If no topics are selected, return 0
            if (topicsToConsider.length === 0) return 0;
            
            // Weighted scoring system
            const relevanceWeights = {
                'Highly Relevant': 4,
                'Moderately Relevant': 3,
                'Tangentially Relevant': 2,
                'Not Relevant': 1
            };
            
            // Sum up scores for selected topics only
            for (let topicField of topicsToConsider) {
                const relevance = paper[topicField];
                // Treat "not_validated" same as "Not Relevant"
                const normalizedRelevance = relevance === "not_validated" ? "Not Relevant" : relevance;
                score += relevanceWeights[normalizedRelevance] || 1; // Default to 1 if unknown
            }
            
            return score;
        }
        
        function sortPapers(sortType) {
            switch (sortType) {
                case 'recommend_best':
                    filteredSortedPapers.sort((a, b) => calculateRecommendationScore(b) - calculateRecommendationScore(a));
                    break;
                case 'recommend_worst':
                    filteredSortedPapers.sort((a, b) => calculateRecommendationScore(a) - calculateRecommendationScore(b));
                    break;
                case 'relevance_high':
                    filteredSortedPapers.sort((a, b) => calculateRelevanceScore(b) - calculateRelevanceScore(a));
                    break;
                case 'relevance_low':
                    filteredSortedPapers.sort((a, b) => calculateRelevanceScore(a) - calculateRelevanceScore(b));
                    break;
                case 'highest_hindex_asc':
                    filteredSortedPapers.sort((a, b) => getHighestHIndex(a) - getHighestHIndex(b));
                    break;
                case 'highest_hindex_desc':
                    filteredSortedPapers.sort((a, b) => getHighestHIndex(b) - getHighestHIndex(a));
                    break;
                case 'average_hindex_asc':
                    filteredSortedPapers.sort((a, b) => getAverageHIndex(a) - getAverageHIndex(b));
                    break;
                case 'average_hindex_desc':
                    filteredSortedPapers.sort((a, b) => getAverageHIndex(b) - getAverageHIndex(a));
                    break;
                case 'id_asc':
                    filteredSortedPapers.sort((a, b) => a.id.localeCompare(b.id));
                    break;
                case 'id_desc':
                    filteredSortedPapers.sort((a, b) => b.id.localeCompare(a.id));
                    break;
                case 'title_az':
                    filteredSortedPapers.sort((a, b) => a.title.localeCompare(b.title));
                    break;
                case 'title_za':
                    filteredSortedPapers.sort((a, b) => b.title.localeCompare(a.title));
                    break;
                default:
                    // Default to recommendation best first
                    filteredSortedPapers.sort((a, b) => calculateRecommendationScore(b) - calculateRecommendationScore(a));
            }
        }

        // ============================================================================
        // DROPDOWN DIRECTION FUNCTIONS
        // ============================================================================
        
        function setDropdownDirection(button, dropdown) {
            const buttonRect = button.getBoundingClientRect();
            const sidebar = button.closest('#mobile-sidebar, #desktop-sidebar');
            
            // Get the sidebar content area instead of the entire sidebar
            const sidebarContent = sidebar.querySelector('.flex-1');
            const sidebarContentRect = sidebarContent ? sidebarContent.getBoundingClientRect() : sidebar.getBoundingClientRect();
            
            // Calculate available space within the entire sidebar content area
            const spaceBelow = sidebarContentRect.bottom - buttonRect.bottom;
            const spaceAbove = buttonRect.top - sidebarContentRect.top;
            
            // Estimate dropdown height (roughly 6 items * 40px each)
            const estimatedDropdownHeight = 240;
            
            // Determine direction based on available space in the whole sidebar content
            if (spaceBelow >= estimatedDropdownHeight || spaceBelow >= spaceAbove) {
                // Dropdown goes down
                dropdown.classList.remove('dropdown-up');
                dropdown.classList.add('dropdown-down');
            } else {
                // Dropdown goes up
                dropdown.classList.remove('dropdown-down');
                dropdown.classList.add('dropdown-up');
            }
        }

        // ============================================================================
        // SORTING DROPDOWN FUNCTIONS
        // ============================================================================
        
        function toggleMobileSortDropdown() {
            const button = document.getElementById('mobile-sort-btn');
            const dropdown = document.getElementById('mobile-sort-dropdown');
            
            if (dropdown.classList.contains('hidden')) {
                // Set direction before showing
                setDropdownDirection(button, dropdown);
                // Change button to expanded state
                button.classList.remove('bg-neutral-500');
                button.classList.add('bg-neutral-600');
            } else {
                // Change button back to normal state
                button.classList.remove('bg-neutral-600');
                button.classList.add('bg-neutral-500');
            }
            
            dropdown.classList.toggle('hidden');
        }
        
        function toggleDesktopSortDropdown() {
            const button = document.getElementById('desktop-sort-btn');
            const dropdown = document.getElementById('desktop-sort-dropdown');
            
            if (dropdown.classList.contains('hidden')) {
                // Set direction before showing
                setDropdownDirection(button, dropdown);
                // Change button to expanded state
                button.classList.remove('bg-neutral-500');
                button.classList.add('bg-neutral-600');
            } else {
                // Change button back to normal state
                button.classList.remove('bg-neutral-600');
                button.classList.add('bg-neutral-500');
            }
            
            dropdown.classList.toggle('hidden');
        }
        
        function changeSortAndClose(sortType) {
            // Update current sort
            currentSort = sortType;
            
            // Update URL
            setUrlParameter('sort', sortType);
            
            // Update dropdown text
            updateSortDropdownUI();
            
            // Close dropdowns and reset button states
            const mobileDropdown = document.getElementById('mobile-sort-dropdown');
            const desktopDropdown = document.getElementById('desktop-sort-dropdown');
            const mobileButton = document.getElementById('mobile-sort-btn');
            const desktopButton = document.getElementById('desktop-sort-btn');
            
            mobileDropdown.classList.add('hidden');
            desktopDropdown.classList.add('hidden');
            
            // Reset button states to normal
            mobileButton.classList.remove('bg-neutral-600');
            mobileButton.classList.add('bg-neutral-500');
            desktopButton.classList.remove('bg-neutral-600');
            desktopButton.classList.add('bg-neutral-500');
            
            // Close the appropriate sidebar
            if (isMobileSidebarOpen) {
                closeMobileMenu();
            }
            if (isDesktopSidebarOpen) {
                closeDesktopMenu();
            }
            
            // Apply new sorting
            applyFiltersAndSort();
            displayCurrentPage();
        }
        
        function updateSortDropdownUI() {
            const sortNames = {
                'recommend_best': 'Recommendation (Best First)',
                'recommend_worst': 'Recommendation (Worst First)',
                'relevance_high': 'Relevance (Highest to Lowest)',
                'relevance_low': 'Relevance (Lowest to Highest)',
                'highest_hindex_asc': 'Highest H-Index (Ascending)',
                'highest_hindex_desc': 'Highest H-Index (Descending)',
                'average_hindex_asc': 'Average H-Index (Ascending)',
                'average_hindex_desc': 'Average H-Index (Descending)',
                'id_asc': 'arXiv ID (Ascending)',
                'id_desc': 'arXiv ID (Descending)',
                'title_az': 'Title (A-Z)',
                'title_za': 'Title (Z-A)'
            };
            
            const sortName = sortNames[currentSort] || 'Recommendation (Best First)';
            
            const mobileText = document.getElementById('mobile-sort-text');
            const desktopText = document.getElementById('desktop-sort-text');
            
            if (mobileText) {
                mobileText.textContent = sortName;
            }
            if (desktopText) {
                desktopText.textContent = sortName;
            }
        }

        // ============================================================================
        // H-INDEX FILTER DROPDOWN FUNCTIONS
        // ============================================================================
        
        function toggleMobileHIndexDropdown() {
            const button = document.getElementById('mobile-hindex-btn');
            const dropdown = document.getElementById('mobile-hindex-dropdown');
            
            if (dropdown.classList.contains('hidden')) {
                // Set direction before showing
                setDropdownDirection(button, dropdown);
                // Change button to expanded state
                button.classList.remove('bg-neutral-500');
                button.classList.add('bg-neutral-600');
            } else {
                // Change button back to normal state
                button.classList.remove('bg-neutral-600');
                button.classList.add('bg-neutral-500');
            }
            
            dropdown.classList.toggle('hidden');
        }
        
        function toggleDesktopHIndexDropdown() {
            const button = document.getElementById('desktop-hindex-btn');
            const dropdown = document.getElementById('desktop-hindex-dropdown');
            
            if (dropdown.classList.contains('hidden')) {
                // Set direction before showing
                setDropdownDirection(button, dropdown);
                // Change button to expanded state
                button.classList.remove('bg-neutral-500');
                button.classList.add('bg-neutral-600');
            } else {
                // Change button back to normal state
                button.classList.remove('bg-neutral-600');
                button.classList.add('bg-neutral-500');
            }
            
            dropdown.classList.toggle('hidden');
        }
        
        function toggleHIndexRanges() {
            const mobileFoundCheckbox = document.getElementById('mobile-hindex-found');
            const desktopFoundCheckbox = document.getElementById('desktop-hindex-found');
            const mobileHighestRange = document.getElementById('mobile-highest-range');
            const mobileAverageRange = document.getElementById('mobile-average-range');
            const desktopHighestRange = document.getElementById('desktop-highest-range');
            const desktopAverageRange = document.getElementById('desktop-average-range');
            
            // Sync the checkboxes
            if (event.target.id === 'mobile-hindex-found') {
                desktopFoundCheckbox.checked = mobileFoundCheckbox.checked;
            } else if (event.target.id === 'desktop-hindex-found') {
                mobileFoundCheckbox.checked = desktopFoundCheckbox.checked;
            }
            
            const isEnabled = mobileFoundCheckbox.checked;
            
            // Update pending filters
            updatePendingHIndexFilters();
            
            // Update button text to reflect current state
            updateHIndexButtonText();
            
            // Toggle disabled state for range sections
            [mobileHighestRange, mobileAverageRange, desktopHighestRange, desktopAverageRange].forEach(range => {
                if (range) {
                    if (isEnabled) {
                        range.classList.remove('disabled');
                        range.querySelectorAll('input').forEach(input => {
                            input.disabled = false;
                        });
                    } else {
                        range.classList.add('disabled');
                        range.querySelectorAll('input').forEach(input => {
                            input.disabled = true;
                        });
                    }
                }
            });
        }
        
        function updatePendingHIndexFilters() {
            // Read current UI state into pending filters
            const mobileFoundCheckbox = document.getElementById('mobile-hindex-found');
            const mobileNotFoundCheckbox = document.getElementById('mobile-hindex-not-found');
            const mobileHighestMin = document.getElementById('mobile-highest-min');
            const mobileHighestMax = document.getElementById('mobile-highest-max');
            const mobileAverageMin = document.getElementById('mobile-average-min');
            const mobileAverageMax = document.getElementById('mobile-average-max');
            
            pendingHIndexFilters = {
                found: mobileFoundCheckbox.checked,
                notFound: mobileNotFoundCheckbox.checked,
                highestMin: parseInt(mobileHighestMin.value) || 0,
                highestMax: parseInt(mobileHighestMax.value) || 1000,
                averageMin: parseInt(mobileAverageMin.value) || 0,
                averageMax: parseInt(mobileAverageMax.value) || 1000
            };
        }
        
        function resetPendingHIndexFilters() {
            // Revert pending filters to current applied filters
            pendingHIndexFilters = { ...currentHIndexFilters };
            
            // Update UI to reflect current filters
            syncHIndexUI();
        }
        
        function resetPendingNoveltyFilters() {
            // Revert pending filters to current applied filters
            pendingNoveltyFilters = { ...currentNoveltyFilters };
            
            // Update UI to reflect current filters
            syncPendingNoveltyUI();
            updateNoveltyButtonText();
        }
        
        function resetPendingImpactFilters() {
            // Revert pending filters to current applied filters
            pendingImpactFilters = { ...currentImpactFilters };
            
            // Update UI to reflect current filters
            syncPendingImpactUI();
            updateImpactButtonText();
        }
        
        function syncHIndexUI() {
            // Update checkboxes
            document.getElementById('mobile-hindex-found').checked = currentHIndexFilters.found;
            document.getElementById('mobile-hindex-not-found').checked = currentHIndexFilters.notFound;
            document.getElementById('desktop-hindex-found').checked = currentHIndexFilters.found;
            document.getElementById('desktop-hindex-not-found').checked = currentHIndexFilters.notFound;
            
            // Update range inputs
            document.getElementById('mobile-highest-min').value = currentHIndexFilters.highestMin;
            document.getElementById('mobile-highest-max').value = currentHIndexFilters.highestMax;
            document.getElementById('mobile-average-min').value = currentHIndexFilters.averageMin;
            document.getElementById('mobile-average-max').value = currentHIndexFilters.averageMax;
            document.getElementById('desktop-highest-min').value = currentHIndexFilters.highestMin;
            document.getElementById('desktop-highest-max').value = currentHIndexFilters.highestMax;
            document.getElementById('desktop-average-min').value = currentHIndexFilters.averageMin;
            document.getElementById('desktop-average-max').value = currentHIndexFilters.averageMax;
            
            // Update disabled states
            toggleHIndexRanges();
            
            // Update button text
            updateHIndexButtonText();
        }
        
        function updateHIndexButtonText() {
            // Read the current checkbox states from the UI
            const foundChecked = document.getElementById('mobile-hindex-found').checked;
            const notFoundChecked = document.getElementById('mobile-hindex-not-found').checked;
            
            let selectionText;
            if (foundChecked && notFoundChecked) {
                selectionText = "All Selected";
            } else if (foundChecked && !notFoundChecked) {
                selectionText = "H-Index Found";
            } else if (!foundChecked && notFoundChecked) {
                selectionText = "H-Index Not Found";
            } else {
                selectionText = "None Selected";
            }
            
            // Update mobile button
            const mobileButton = document.getElementById('mobile-hindex-btn');
            if (mobileButton) {
                mobileButton.innerHTML = `<span class="font-bold">H-Index:</span> <span class="font-normal">${selectionText}</span> <span class="text-base">▼</span>`;
            }
            
            // Update desktop button
            const desktopButton = document.getElementById('desktop-hindex-btn');
            if (desktopButton) {
                desktopButton.innerHTML = `<span class="font-bold">H-Index:</span> <span class="font-normal">${selectionText}</span> <span class="text-sm">▼</span>`;
            }
        }
        
        function applyHIndexFilter() {
            // Update pending filters one final time
            updatePendingHIndexFilters();
            
            // Apply pending filters as current filters
            currentHIndexFilters = { ...pendingHIndexFilters };
            
            // Update URL with new filter state
            updateURLWithHIndexFilters();
            
            // Update button text to reflect applied filters
            updateHIndexButtonText();
            
            // Close both dropdowns
            const mobileDropdown = document.getElementById('mobile-hindex-dropdown');
            const desktopDropdown = document.getElementById('desktop-hindex-dropdown');
            const mobileButton = document.getElementById('mobile-hindex-btn');
            const desktopButton = document.getElementById('desktop-hindex-btn');
            
            mobileDropdown.classList.add('hidden');
            desktopDropdown.classList.add('hidden');
            
            // Reset button states to normal
            mobileButton.classList.remove('bg-neutral-600');
            mobileButton.classList.add('bg-neutral-500');
            desktopButton.classList.remove('bg-neutral-600');
            desktopButton.classList.add('bg-neutral-500');
            
            // Don't close sidebar - just close dropdown
            // (Sidebar should stay open for more filtering)
            
            // Apply new filtering and update display
            applyFiltersAndSort();
            displayCurrentPage();
        }

        // ============================================================================
        // INPUT VALIDATION FOR H-INDEX RANGES
        // ============================================================================
        
        function validateHIndexInput(input) {
            // Allow empty input temporarily (user might be typing)
            if (input.value === '') {
                return;
            }
            
            let value = parseInt(input.value);
            
            // Ensure value is within 0-1000 range
            if (isNaN(value) || value < 0) {
                input.value = 0;
            } else if (value > 1000) {
                input.value = 1000;
            }
            
            // Auto-correct min/max relationships
            enforceMinMaxConstraints(input);
        }
        
        function enforceMinMaxConstraints(changedInput) {
            const inputId = changedInput.id;
            let minInput, maxInput;
            
            // Determine which min/max pair this input belongs to
            if (inputId.includes('highest-min')) {
                minInput = changedInput;
                maxInput = document.getElementById(inputId.replace('min', 'max'));
            } else if (inputId.includes('highest-max')) {
                maxInput = changedInput;
                minInput = document.getElementById(inputId.replace('max', 'min'));
            } else if (inputId.includes('average-min')) {
                minInput = changedInput;
                maxInput = document.getElementById(inputId.replace('min', 'max'));
            } else if (inputId.includes('average-max')) {
                maxInput = changedInput;
                minInput = document.getElementById(inputId.replace('max', 'min'));
            }
            
            if (minInput && maxInput) {
                const minVal = parseInt(minInput.value) || 0;
                const maxVal = parseInt(maxInput.value) || 0;
                
                // If min > max, auto-correct
                if (minVal > maxVal) {
                    if (changedInput === minInput) {
                        // User changed min to be > max, set max = min
                        maxInput.value = minVal;
                    } else {
                        // User changed max to be < min, set min = max
                        minInput.value = maxVal;
                    }
                }
            }
        }
        
        // Add input validation when page loads
        function setupHIndexValidation() {
            const inputs = [
                'mobile-highest-min', 'mobile-highest-max',
                'mobile-average-min', 'mobile-average-max',
                'desktop-highest-min', 'desktop-highest-max',
                'desktop-average-min', 'desktop-average-max'
            ];
            
            inputs.forEach(id => {
                const input = document.getElementById(id);
                if (input) {
                    // Validate on input (while typing) - but allow empty temporarily
                    input.addEventListener('input', () => {
                        validateHIndexInput(input);
                        updatePendingHIndexFilters(); // Update pending filters as user types
                    });
                    
                    // Validate on blur (when user leaves field) - ensure it's not empty
                    input.addEventListener('blur', () => {
                        if (input.value === '') {
                            input.value = 0; // Set default if user leaves it empty
                        }
                        validateHIndexInput(input);
                        updatePendingHIndexFilters(); // Update pending filters
                    });
                    
                    // Prevent non-numeric characters except for selection/deletion
                    input.addEventListener('keydown', (e) => {
                        // Allow: backspace, delete, tab, escape, enter, and numbers
                        if ([8, 9, 27, 13, 46].includes(e.keyCode) || 
                            // Allow Ctrl+A, Ctrl+C, Ctrl+V, Ctrl+X
                            (e.keyCode === 65 && e.ctrlKey) || 
                            (e.keyCode === 67 && e.ctrlKey) || 
                            (e.keyCode === 86 && e.ctrlKey) || 
                            (e.keyCode === 88 && e.ctrlKey) ||
                            // Allow numbers (0-9) on main keyboard and numpad
                            (e.keyCode >= 48 && e.keyCode <= 57) ||
                            (e.keyCode >= 96 && e.keyCode <= 105)) {
                            return;
                        }
                        e.preventDefault();
                    });
                }
            });
            
            // Add event listeners for checkboxes to update pending filters
            document.getElementById('mobile-hindex-not-found').addEventListener('change', () => {
                // Sync desktop checkbox
                document.getElementById('desktop-hindex-not-found').checked = 
                    document.getElementById('mobile-hindex-not-found').checked;
                updatePendingHIndexFilters();
                updateHIndexButtonText();
            });
            
            document.getElementById('desktop-hindex-not-found').addEventListener('change', () => {
                // Sync mobile checkbox
                document.getElementById('mobile-hindex-not-found').checked = 
                    document.getElementById('desktop-hindex-not-found').checked;
                updatePendingHIndexFilters();
                updateHIndexButtonText();
            });
            
            // Add event listeners for scoring checkboxes to update pending filters
            document.getElementById('mobile-scoring-has').addEventListener('change', () => {
                // Sync desktop checkbox
                document.getElementById('desktop-scoring-has').checked = 
                    document.getElementById('mobile-scoring-has').checked;
                updatePendingScoringFilters();
                updateScoringButtonText();
            });
            
            document.getElementById('mobile-scoring-no').addEventListener('change', () => {
                // Sync desktop checkbox
                document.getElementById('desktop-scoring-no').checked = 
                    document.getElementById('mobile-scoring-no').checked;
                updatePendingScoringFilters();
                updateScoringButtonText();
            });
            
            document.getElementById('desktop-scoring-has').addEventListener('change', () => {
                // Sync mobile checkbox
                document.getElementById('mobile-scoring-has').checked = 
                    document.getElementById('desktop-scoring-has').checked;
                updatePendingScoringFilters();
                updateScoringButtonText();
            });
            
            document.getElementById('desktop-scoring-no').addEventListener('change', () => {
                // Sync mobile checkbox
                document.getElementById('mobile-scoring-no').checked = 
                    document.getElementById('desktop-scoring-no').checked;
                updatePendingScoringFilters();
                updateScoringButtonText();
            });
            
            // Add event listeners for scoring checkboxes to update pending filters
            document.getElementById('mobile-scoring-has').addEventListener('change', () => {
                // Sync desktop checkbox
                document.getElementById('desktop-scoring-has').checked = 
                    document.getElementById('mobile-scoring-has').checked;
                updatePendingScoringFilters();
                updateScoringButtonText();
            });
            
            document.getElementById('desktop-scoring-has').addEventListener('change', () => {
                // Sync mobile checkbox
                document.getElementById('mobile-scoring-has').checked = 
                    document.getElementById('desktop-scoring-has').checked;
                updatePendingScoringFilters();
                updateScoringButtonText();
            });
            
            document.getElementById('mobile-scoring-no').addEventListener('change', () => {
                // Sync desktop checkbox
                document.getElementById('desktop-scoring-no').checked = 
                    document.getElementById('mobile-scoring-no').checked;
                updatePendingScoringFilters();
                updateScoringButtonText();
            });
            
            document.getElementById('desktop-scoring-no').addEventListener('change', () => {
                // Sync mobile checkbox
                document.getElementById('mobile-scoring-no').checked = 
                    document.getElementById('desktop-scoring-no').checked;
                updatePendingScoringFilters();
                updateScoringButtonText();
            });
            
            // Add event listeners for recommendation checkboxes to sync between mobile and desktop
            document.getElementById('mobile-recommendation-must').addEventListener('change', () => {
                document.getElementById('desktop-recommendation-must').checked = 
                    document.getElementById('mobile-recommendation-must').checked;
                updatePendingRecommendationFilters();
                updateRecommendationButtonText();
            });
            
            document.getElementById('mobile-recommendation-should').addEventListener('change', () => {
                document.getElementById('desktop-recommendation-should').checked = 
                    document.getElementById('mobile-recommendation-should').checked;
                updatePendingRecommendationFilters();
                updateRecommendationButtonText();
            });
            
            document.getElementById('mobile-recommendation-skip').addEventListener('change', () => {
                document.getElementById('desktop-recommendation-skip').checked = 
                    document.getElementById('mobile-recommendation-skip').checked;
                updatePendingRecommendationFilters();
                updateRecommendationButtonText();
            });
            
            document.getElementById('mobile-recommendation-ignore').addEventListener('change', () => {
                document.getElementById('desktop-recommendation-ignore').checked = 
                    document.getElementById('mobile-recommendation-ignore').checked;
                updatePendingRecommendationFilters();
                updateRecommendationButtonText();
            });
            
            document.getElementById('desktop-recommendation-must').addEventListener('change', () => {
                document.getElementById('mobile-recommendation-must').checked = 
                    document.getElementById('desktop-recommendation-must').checked;
                updatePendingRecommendationFilters();
                updateRecommendationButtonText();
            });
            
            document.getElementById('desktop-recommendation-should').addEventListener('change', () => {
                document.getElementById('mobile-recommendation-should').checked = 
                    document.getElementById('desktop-recommendation-should').checked;
                updatePendingRecommendationFilters();
                updateRecommendationButtonText();
            });
            
            document.getElementById('desktop-recommendation-skip').addEventListener('change', () => {
                document.getElementById('mobile-recommendation-skip').checked = 
                    document.getElementById('desktop-recommendation-skip').checked;
                updatePendingRecommendationFilters();
                updateRecommendationButtonText();
            });
            
            document.getElementById('desktop-recommendation-ignore').addEventListener('change', () => {
                document.getElementById('mobile-recommendation-ignore').checked = 
                    document.getElementById('desktop-recommendation-ignore').checked;
                updatePendingRecommendationFilters();
                updateRecommendationButtonText();
            });
            
            // Add event listeners for novelty checkboxes to sync between mobile and desktop
            document.getElementById('mobile-novelty-high').addEventListener('change', () => {
                document.getElementById('desktop-novelty-high').checked = 
                    document.getElementById('mobile-novelty-high').checked;
                updatePendingNoveltyFilters();
                updateNoveltyButtonText();
            });
            
            document.getElementById('mobile-novelty-moderate').addEventListener('change', () => {
                document.getElementById('desktop-novelty-moderate').checked = 
                    document.getElementById('mobile-novelty-moderate').checked;
                updatePendingNoveltyFilters();
                updateNoveltyButtonText();
            });
            
            document.getElementById('mobile-novelty-low').addEventListener('change', () => {
                document.getElementById('desktop-novelty-low').checked = 
                    document.getElementById('mobile-novelty-low').checked;
                updatePendingNoveltyFilters();
                updateNoveltyButtonText();
            });
            
            document.getElementById('mobile-novelty-none').addEventListener('change', () => {
                document.getElementById('desktop-novelty-none').checked = 
                    document.getElementById('mobile-novelty-none').checked;
                updatePendingNoveltyFilters();
                updateNoveltyButtonText();
            });
            
            document.getElementById('desktop-novelty-high').addEventListener('change', () => {
                document.getElementById('mobile-novelty-high').checked = 
                    document.getElementById('desktop-novelty-high').checked;
                updatePendingNoveltyFilters();
                updateNoveltyButtonText();
            });
            
            document.getElementById('desktop-novelty-moderate').addEventListener('change', () => {
                document.getElementById('mobile-novelty-moderate').checked = 
                    document.getElementById('desktop-novelty-moderate').checked;
                updatePendingNoveltyFilters();
                updateNoveltyButtonText();
            });
            
            document.getElementById('desktop-novelty-low').addEventListener('change', () => {
                document.getElementById('mobile-novelty-low').checked = 
                    document.getElementById('desktop-novelty-low').checked;
                updatePendingNoveltyFilters();
                updateNoveltyButtonText();
            });
            
            document.getElementById('desktop-novelty-none').addEventListener('change', () => {
                document.getElementById('mobile-novelty-none').checked = 
                    document.getElementById('desktop-novelty-none').checked;
                updatePendingNoveltyFilters();
                updateNoveltyButtonText();
            });
            
            // Add event listeners for impact checkboxes to sync between mobile and desktop
            document.getElementById('mobile-impact-high').addEventListener('change', () => {
                document.getElementById('desktop-impact-high').checked = 
                    document.getElementById('mobile-impact-high').checked;
                updatePendingImpactFilters();
                updateImpactButtonText();
            });
            
            document.getElementById('mobile-impact-moderate').addEventListener('change', () => {
                document.getElementById('desktop-impact-moderate').checked = 
                    document.getElementById('mobile-impact-moderate').checked;
                updatePendingImpactFilters();
                updateImpactButtonText();
            });
            
            document.getElementById('mobile-impact-low').addEventListener('change', () => {
                document.getElementById('desktop-impact-low').checked = 
                    document.getElementById('mobile-impact-low').checked;
                updatePendingImpactFilters();
                updateImpactButtonText();
            });
            
            document.getElementById('mobile-impact-negligible').addEventListener('change', () => {
                document.getElementById('desktop-impact-negligible').checked = 
                    document.getElementById('mobile-impact-negligible').checked;
                updatePendingImpactFilters();
                updateImpactButtonText();
            });
            
            document.getElementById('desktop-impact-high').addEventListener('change', () => {
                document.getElementById('mobile-impact-high').checked = 
                    document.getElementById('desktop-impact-high').checked;
                updatePendingImpactFilters();
                updateImpactButtonText();
            });
            
            document.getElementById('desktop-impact-moderate').addEventListener('change', () => {
                document.getElementById('mobile-impact-moderate').checked = 
                    document.getElementById('desktop-impact-moderate').checked;
                updatePendingImpactFilters();
                updateImpactButtonText();
            });
            
            document.getElementById('desktop-impact-low').addEventListener('change', () => {
                document.getElementById('mobile-impact-low').checked = 
                    document.getElementById('desktop-impact-low').checked;
                updatePendingImpactFilters();
                updateImpactButtonText();
            });
            
            document.getElementById('desktop-impact-negligible').addEventListener('change', () => {
                document.getElementById('mobile-impact-negligible').checked = 
                    document.getElementById('desktop-impact-negligible').checked;
                updatePendingImpactFilters();
                updateImpactButtonText();
            });
            
            // Add event listeners for relevance checkboxes to sync between mobile and desktop
            document.getElementById('mobile-relevance-highly').addEventListener('change', () => {
                document.getElementById('desktop-relevance-highly').checked = 
                    document.getElementById('mobile-relevance-highly').checked;
                updatePendingRelevanceFilters();
                updateRelevanceButtonText();
            });
            
            document.getElementById('mobile-relevance-moderately').addEventListener('change', () => {
                document.getElementById('desktop-relevance-moderately').checked = 
                    document.getElementById('mobile-relevance-moderately').checked;
                updatePendingRelevanceFilters();
                updateRelevanceButtonText();
            });
            
            document.getElementById('mobile-relevance-tangentially').addEventListener('change', () => {
                document.getElementById('desktop-relevance-tangentially').checked = 
                    document.getElementById('mobile-relevance-tangentially').checked;
                updatePendingRelevanceFilters();
                updateRelevanceButtonText();
            });
            
            document.getElementById('mobile-relevance-not').addEventListener('change', () => {
                document.getElementById('desktop-relevance-not').checked = 
                    document.getElementById('mobile-relevance-not').checked;
                updatePendingRelevanceFilters();
                updateRelevanceButtonText();
            });
            
            document.getElementById('desktop-relevance-highly').addEventListener('change', () => {
                document.getElementById('mobile-relevance-highly').checked = 
                    document.getElementById('desktop-relevance-highly').checked;
                updatePendingRelevanceFilters();
                updateRelevanceButtonText();
            });
            
            document.getElementById('desktop-relevance-moderately').addEventListener('change', () => {
                document.getElementById('mobile-relevance-moderately').checked = 
                    document.getElementById('desktop-relevance-moderately').checked;
                updatePendingRelevanceFilters();
                updateRelevanceButtonText();
            });
            
            document.getElementById('desktop-relevance-tangentially').addEventListener('change', () => {
                document.getElementById('mobile-relevance-tangentially').checked = 
                    document.getElementById('desktop-relevance-tangentially').checked;
                updatePendingRelevanceFilters();
                updateRelevanceButtonText();
            });
            
            document.getElementById('desktop-relevance-not').addEventListener('change', () => {
                document.getElementById('mobile-relevance-not').checked = 
                    document.getElementById('desktop-relevance-not').checked;
                updatePendingRelevanceFilters();
                updateRelevanceButtonText();
            });
            
            // Add event listeners for topic checkboxes to sync between mobile and desktop
            document.getElementById('mobile-topic-rlhf').addEventListener('change', () => {
                document.getElementById('desktop-topic-rlhf').checked = 
                    document.getElementById('mobile-topic-rlhf').checked;
                updatePendingTopicFilters();
                updateTopicButtonText();
            });
            
            document.getElementById('mobile-topic-weak-supervision').addEventListener('change', () => {
                document.getElementById('desktop-topic-weak-supervision').checked = 
                    document.getElementById('mobile-topic-weak-supervision').checked;
                updatePendingTopicFilters();
                updateTopicButtonText();
            });
            
            document.getElementById('mobile-topic-diffusion-reasoning').addEventListener('change', () => {
                document.getElementById('desktop-topic-diffusion-reasoning').checked = 
                    document.getElementById('mobile-topic-diffusion-reasoning').checked;
                updatePendingTopicFilters();
                updateTopicButtonText();
            });
            
            document.getElementById('mobile-topic-distributed-training').addEventListener('change', () => {
                document.getElementById('desktop-topic-distributed-training').checked = 
                    document.getElementById('mobile-topic-distributed-training').checked;
                updatePendingTopicFilters();
                updateTopicButtonText();
            });
            
            document.getElementById('mobile-topic-datasets').addEventListener('change', () => {
                document.getElementById('desktop-topic-datasets').checked = 
                    document.getElementById('mobile-topic-datasets').checked;
                updatePendingTopicFilters();
                updateTopicButtonText();
            });
            
            document.getElementById('desktop-topic-rlhf').addEventListener('change', () => {
                document.getElementById('mobile-topic-rlhf').checked = 
                    document.getElementById('desktop-topic-rlhf').checked;
                updatePendingTopicFilters();
                updateTopicButtonText();
            });
            
            document.getElementById('desktop-topic-weak-supervision').addEventListener('change', () => {
                document.getElementById('mobile-topic-weak-supervision').checked = 
                    document.getElementById('desktop-topic-weak-supervision').checked;
                updatePendingTopicFilters();
                updateTopicButtonText();
            });
            
            document.getElementById('desktop-topic-diffusion-reasoning').addEventListener('change', () => {
                document.getElementById('mobile-topic-diffusion-reasoning').checked = 
                    document.getElementById('desktop-topic-diffusion-reasoning').checked;
                updatePendingTopicFilters();
                updateTopicButtonText();
            });
            
            document.getElementById('desktop-topic-distributed-training').addEventListener('change', () => {
                document.getElementById('mobile-topic-distributed-training').checked = 
                    document.getElementById('desktop-topic-distributed-training').checked;
                updatePendingTopicFilters();
                updateTopicButtonText();
            });
            
            document.getElementById('desktop-topic-datasets').addEventListener('change', () => {
                document.getElementById('mobile-topic-datasets').checked = 
                    document.getElementById('desktop-topic-datasets').checked;
                updatePendingTopicFilters();
                updateTopicButtonText();
            });
        }

        // ============================================================================
        // SCORING FILTER DROPDOWN FUNCTIONS
        // ============================================================================
        
        // Current and pending scoring filter states
        let currentScoringFilters = {
            hasScoring: true,
            noScoring: true
        };
        
        let pendingScoringFilters = {
            hasScoring: true,
            noScoring: true
        };
        
        function toggleMobileScoringDropdown() {
            const button = document.getElementById('mobile-scoring-btn');
            const dropdown = document.getElementById('mobile-scoring-dropdown');
            
            if (dropdown.classList.contains('hidden')) {
                // Set direction before showing
                setDropdownDirection(button, dropdown);
                // Change button to expanded state
                button.classList.remove('bg-neutral-500');
                button.classList.add('bg-neutral-600');
            } else {
                // Change button back to normal state
                button.classList.remove('bg-neutral-600');
                button.classList.add('bg-neutral-500');
            }
            
            dropdown.classList.toggle('hidden');
        }
        
        function toggleDesktopScoringDropdown() {
            const button = document.getElementById('desktop-scoring-btn');
            const dropdown = document.getElementById('desktop-scoring-dropdown');
            
            if (dropdown.classList.contains('hidden')) {
                // Set direction before showing
                setDropdownDirection(button, dropdown);
                // Change button to expanded state
                button.classList.remove('bg-neutral-500');
                button.classList.add('bg-neutral-600');
            } else {
                // Change button back to normal state
                button.classList.remove('bg-neutral-600');
                button.classList.add('bg-neutral-500');
            }
            
            dropdown.classList.toggle('hidden');
        }
        
        
        function syncPendingScoringUI() {
            // Update all checkboxes to match pending state
            document.getElementById('mobile-scoring-has').checked = pendingScoringFilters.hasScoring;
            document.getElementById('mobile-scoring-no').checked = pendingScoringFilters.noScoring;
            document.getElementById('desktop-scoring-has').checked = pendingScoringFilters.hasScoring;
            document.getElementById('desktop-scoring-no').checked = pendingScoringFilters.noScoring;
        }
        
        function syncScoringUI() {
            // Update checkboxes
            document.getElementById('mobile-scoring-has').checked = currentScoringFilters.hasScoring;
            document.getElementById('mobile-scoring-no').checked = currentScoringFilters.noScoring;
            document.getElementById('desktop-scoring-has').checked = currentScoringFilters.hasScoring;
            document.getElementById('desktop-scoring-no').checked = currentScoringFilters.noScoring;
            
            // Update button text
            updateScoringButtonText();
        }
        
        function updateScoringButtonText() {
            // Read the current checkbox states from the UI
            const hasChecked = document.getElementById('mobile-scoring-has').checked;
            const noChecked = document.getElementById('mobile-scoring-no').checked;
            
            let selectionText;
            if (hasChecked && noChecked) {
                selectionText = "All Selected";
            } else if (hasChecked && !noChecked) {
                selectionText = "Completed";
            } else if (!hasChecked && noChecked) {
                selectionText = "Not relevant enough";
            } else {
                selectionText = "None Selected";
            }
            
            // Update mobile button
            const mobileButton = document.getElementById('mobile-scoring-btn');
            if (mobileButton) {
                mobileButton.innerHTML = `<span class="font-bold">Scoring:</span> <span class="font-normal">${selectionText}</span> <span class="text-base">▼</span>`;
            }
            
            // Update desktop button
            const desktopButton = document.getElementById('desktop-scoring-btn');
            if (desktopButton) {
                desktopButton.innerHTML = `<span class="font-bold">Scoring:</span> <span class="font-normal">${selectionText}</span> <span class="text-sm">▼</span>`;
            }
        }
        
        function applyScoringFilter() {
            // Update pending filters one final time
            updatePendingScoringFilters();
            
            // Apply the pending filters as current filters
            currentScoringFilters = { ...pendingScoringFilters };
            
            // Update UI to reflect current state
            syncScoringUI();
            
            // Update URL with current filters
            updateScoringFiltersInURL();
            
            // Close dropdown and apply filters
            closeMobileScoringDropdown();
            closeDesktopScoringDropdown();
            
            // Update disabled state for advanced filters
            updateAdvancedFiltersDisabledState();
            
            // Apply all filters and redisplay
            applyFiltersAndSort();
        }
        
        function updatePendingScoringFilters() {
            // Read current UI state into pending filters
            const mobileScoringHas = document.getElementById('mobile-scoring-has');
            const mobileScoringNo = document.getElementById('mobile-scoring-no');
            
            if (mobileScoringHas && mobileScoringNo) {
                pendingScoringFilters.hasScoring = mobileScoringHas.checked;
                pendingScoringFilters.noScoring = mobileScoringNo.checked;
            }
        }
        
        function resetPendingScoringFilters() {
            pendingScoringFilters = { ...currentScoringFilters };
            syncPendingScoringUI();
            updateScoringButtonText();
        }
        
        function closeMobileScoringDropdown() {
            const dropdown = document.getElementById('mobile-scoring-dropdown');
            const button = document.getElementById('mobile-scoring-btn');
            if (dropdown && !dropdown.classList.contains('hidden')) {
                dropdown.classList.add('hidden');
                button.classList.remove('bg-neutral-600');
                button.classList.add('bg-neutral-500');
            }
        }
        
        function closeDesktopScoringDropdown() {
            const dropdown = document.getElementById('desktop-scoring-dropdown');
            const button = document.getElementById('desktop-scoring-btn');
            if (dropdown && !dropdown.classList.contains('hidden')) {
                dropdown.classList.add('hidden');
                button.classList.remove('bg-neutral-600');
                button.classList.add('bg-neutral-500');
            }
        }
        
        function updateScoringFiltersInURL() {
            const params = new URLSearchParams(window.location.search);
            
            // Add scoring filter parameters
            params.set('scoring_has', currentScoringFilters.hasScoring.toString());
            params.set('scoring_no', currentScoringFilters.noScoring.toString());
            
            // Update URL without reload
            const newURL = `${window.location.pathname}?${params.toString()}`;
            window.history.pushState({}, '', newURL);
        }
        
        function updateScoringFiltersFromURL() {
            const params = new URLSearchParams(window.location.search);
            
            // Read scoring filter parameters from URL
            const hasScoring = params.get('scoring_has');
            const noScoring = params.get('scoring_no');
            
            if (hasScoring !== null) {
                currentScoringFilters.hasScoring = hasScoring === 'true';
                pendingScoringFilters.hasScoring = hasScoring === 'true';
            }
            
            if (noScoring !== null) {
                currentScoringFilters.noScoring = noScoring === 'true';
                pendingScoringFilters.noScoring = noScoring === 'true';
            }
            
            // Update UI to match loaded filters
            syncScoringUI();
            
            // Update disabled state for advanced filters
            updateAdvancedFiltersDisabledState();
        }

        // ============================================================================
        // RECOMMENDATION FILTER DROPDOWN FUNCTIONS
        // ============================================================================
        
        // Current and pending recommendation filter states
        let currentRecommendationFilters = {
            mustRead: true,
            shouldRead: true,
            canSkip: true,
            ignore: true
        };
        
        let pendingRecommendationFilters = {
            mustRead: true,
            shouldRead: true,
            canSkip: true,
            ignore: true
        };
        
        function toggleMobileRecommendationDropdown() {
            const button = document.getElementById('mobile-recommendation-btn');
            const dropdown = document.getElementById('mobile-recommendation-dropdown');
            
            if (dropdown.classList.contains('hidden')) {
                setDropdownDirection(button, dropdown);
                button.classList.remove('bg-neutral-500');
                button.classList.add('bg-neutral-600');
            } else {
                button.classList.remove('bg-neutral-600');
                button.classList.add('bg-neutral-500');
            }
            
            dropdown.classList.toggle('hidden');
        }
        
        function toggleDesktopRecommendationDropdown() {
            const button = document.getElementById('desktop-recommendation-btn');
            const dropdown = document.getElementById('desktop-recommendation-dropdown');
            
            if (dropdown.classList.contains('hidden')) {
                setDropdownDirection(button, dropdown);
                button.classList.remove('bg-neutral-500');
                button.classList.add('bg-neutral-600');
            } else {
                button.classList.remove('bg-neutral-600');
                button.classList.add('bg-neutral-500');
            }
            
            dropdown.classList.toggle('hidden');
        }
        
        function syncPendingRecommendationUI() {
            document.getElementById('mobile-recommendation-must').checked = pendingRecommendationFilters.mustRead;
            document.getElementById('mobile-recommendation-should').checked = pendingRecommendationFilters.shouldRead;
            document.getElementById('mobile-recommendation-skip').checked = pendingRecommendationFilters.canSkip;
            document.getElementById('mobile-recommendation-ignore').checked = pendingRecommendationFilters.ignore;
            document.getElementById('desktop-recommendation-must').checked = pendingRecommendationFilters.mustRead;
            document.getElementById('desktop-recommendation-should').checked = pendingRecommendationFilters.shouldRead;
            document.getElementById('desktop-recommendation-skip').checked = pendingRecommendationFilters.canSkip;
            document.getElementById('desktop-recommendation-ignore').checked = pendingRecommendationFilters.ignore;
        }
        
        function syncRecommendationUI() {
            document.getElementById('mobile-recommendation-must').checked = currentRecommendationFilters.mustRead;
            document.getElementById('mobile-recommendation-should').checked = currentRecommendationFilters.shouldRead;
            document.getElementById('mobile-recommendation-skip').checked = currentRecommendationFilters.canSkip;
            document.getElementById('mobile-recommendation-ignore').checked = currentRecommendationFilters.ignore;
            document.getElementById('desktop-recommendation-must').checked = currentRecommendationFilters.mustRead;
            document.getElementById('desktop-recommendation-should').checked = currentRecommendationFilters.shouldRead;
            document.getElementById('desktop-recommendation-skip').checked = currentRecommendationFilters.canSkip;
            document.getElementById('desktop-recommendation-ignore').checked = currentRecommendationFilters.ignore;
            
            updateRecommendationButtonText();
        }
        
        function updateRecommendationButtonText() {
            const mustChecked = document.getElementById('mobile-recommendation-must').checked;
            const shouldChecked = document.getElementById('mobile-recommendation-should').checked;
            const skipChecked = document.getElementById('mobile-recommendation-skip').checked;
            const ignoreChecked = document.getElementById('mobile-recommendation-ignore').checked;
            
            const checkedCount = [mustChecked, shouldChecked, skipChecked, ignoreChecked].filter(Boolean).length;
            
            let selectionText;
            if (checkedCount === 4) {
                selectionText = "All Selected";
            } else if (checkedCount === 0) {
                selectionText = "None Selected";
            } else {
                selectionText = `${checkedCount} Selected`;
            }
            
            const mobileButton = document.getElementById('mobile-recommendation-btn');
            if (mobileButton) {
                mobileButton.innerHTML = `<span class="font-bold">Recommendation:</span> <span class="font-normal">${selectionText}</span> <span class="text-base">▼</span>`;
            }
            
            const desktopButton = document.getElementById('desktop-recommendation-btn');
            if (desktopButton) {
                desktopButton.innerHTML = `<span class="font-bold">Recommendation:</span> <span class="font-normal">${selectionText}</span> <span class="text-sm">▼</span>`;
            }
        }
        
        function applyRecommendationFilter() {
            updatePendingRecommendationFilters();
            currentRecommendationFilters = { ...pendingRecommendationFilters };
            syncRecommendationUI();
            updateRecommendationFiltersInURL();
            closeMobileRecommendationDropdown();
            closeDesktopRecommendationDropdown();
            applyFiltersAndSort();
        }
        
        function updatePendingRecommendationFilters() {
            pendingRecommendationFilters.mustRead = document.getElementById('mobile-recommendation-must').checked;
            pendingRecommendationFilters.shouldRead = document.getElementById('mobile-recommendation-should').checked;
            pendingRecommendationFilters.canSkip = document.getElementById('mobile-recommendation-skip').checked;
            pendingRecommendationFilters.ignore = document.getElementById('mobile-recommendation-ignore').checked;
        }
        
        function resetPendingRecommendationFilters() {
            pendingRecommendationFilters = { ...currentRecommendationFilters };
            syncPendingRecommendationUI();
            updateRecommendationButtonText();
        }
        
        function closeMobileRecommendationDropdown() {
            const dropdown = document.getElementById('mobile-recommendation-dropdown');
            const button = document.getElementById('mobile-recommendation-btn');
            if (dropdown && !dropdown.classList.contains('hidden')) {
                dropdown.classList.add('hidden');
                button.classList.remove('bg-neutral-600');
                button.classList.add('bg-neutral-500');
            }
        }
        
        function closeDesktopRecommendationDropdown() {
            const dropdown = document.getElementById('desktop-recommendation-dropdown');
            const button = document.getElementById('desktop-recommendation-btn');
            if (dropdown && !dropdown.classList.contains('hidden')) {
                dropdown.classList.add('hidden');
                button.classList.remove('bg-neutral-600');
                button.classList.add('bg-neutral-500');
            }
        }
        
        function updateRecommendationFiltersInURL() {
            const params = new URLSearchParams(window.location.search);
            params.set('recommendation_must', currentRecommendationFilters.mustRead.toString());
            params.set('recommendation_should', currentRecommendationFilters.shouldRead.toString());
            params.set('recommendation_skip', currentRecommendationFilters.canSkip.toString());
            params.set('recommendation_ignore', currentRecommendationFilters.ignore.toString());
            const newURL = `${window.location.pathname}?${params.toString()}`;
            window.history.pushState({}, '', newURL);
        }
        
        function updateRecommendationFiltersFromURL() {
            const params = new URLSearchParams(window.location.search);
            
            const mustRead = params.get('recommendation_must');
            const shouldRead = params.get('recommendation_should');
            const canSkip = params.get('recommendation_skip');
            const ignore = params.get('recommendation_ignore');
            
            if (mustRead !== null) {
                currentRecommendationFilters.mustRead = mustRead === 'true';
                pendingRecommendationFilters.mustRead = mustRead === 'true';
            }
            if (shouldRead !== null) {
                currentRecommendationFilters.shouldRead = shouldRead === 'true';
                pendingRecommendationFilters.shouldRead = shouldRead === 'true';
            }
            if (canSkip !== null) {
                currentRecommendationFilters.canSkip = canSkip === 'true';
                pendingRecommendationFilters.canSkip = canSkip === 'true';
            }
            if (ignore !== null) {
                currentRecommendationFilters.ignore = ignore === 'true';
                pendingRecommendationFilters.ignore = ignore === 'true';
            }
            
            syncRecommendationUI();
        }

        // ============================================================================
        // NOVELTY FILTER DROPDOWN FUNCTIONS
        // ============================================================================
        
        // Current and pending novelty filter states
        let currentNoveltyFilters = {
            high: true,
            moderate: true,
            low: true,
            none: true
        };
        
        let pendingNoveltyFilters = {
            high: true,
            moderate: true,
            low: true,
            none: true
        };
        
        function toggleMobileNoveltyDropdown() {
            const button = document.getElementById('mobile-novelty-btn');
            const dropdown = document.getElementById('mobile-novelty-dropdown');
            
            if (dropdown.classList.contains('hidden')) {
                setDropdownDirection(button, dropdown);
                button.classList.remove('bg-neutral-500');
                button.classList.add('bg-neutral-600');
            } else {
                button.classList.remove('bg-neutral-600');
                button.classList.add('bg-neutral-500');
            }
            
            dropdown.classList.toggle('hidden');
        }
        
        function toggleDesktopNoveltyDropdown() {
            const button = document.getElementById('desktop-novelty-btn');
            const dropdown = document.getElementById('desktop-novelty-dropdown');
            
            if (dropdown.classList.contains('hidden')) {
                setDropdownDirection(button, dropdown);
                button.classList.remove('bg-neutral-500');
                button.classList.add('bg-neutral-600');
            } else {
                button.classList.remove('bg-neutral-600');
                button.classList.add('bg-neutral-500');
            }
            
            dropdown.classList.toggle('hidden');
        }
        
        function syncPendingNoveltyUI() {
            document.getElementById('mobile-novelty-high').checked = pendingNoveltyFilters.high;
            document.getElementById('mobile-novelty-moderate').checked = pendingNoveltyFilters.moderate;
            document.getElementById('mobile-novelty-low').checked = pendingNoveltyFilters.low;
            document.getElementById('mobile-novelty-none').checked = pendingNoveltyFilters.none;
            document.getElementById('desktop-novelty-high').checked = pendingNoveltyFilters.high;
            document.getElementById('desktop-novelty-moderate').checked = pendingNoveltyFilters.moderate;
            document.getElementById('desktop-novelty-low').checked = pendingNoveltyFilters.low;
            document.getElementById('desktop-novelty-none').checked = pendingNoveltyFilters.none;
        }
        
        function syncNoveltyUI() {
            document.getElementById('mobile-novelty-high').checked = currentNoveltyFilters.high;
            document.getElementById('mobile-novelty-moderate').checked = currentNoveltyFilters.moderate;
            document.getElementById('mobile-novelty-low').checked = currentNoveltyFilters.low;
            document.getElementById('mobile-novelty-none').checked = currentNoveltyFilters.none;
            document.getElementById('desktop-novelty-high').checked = currentNoveltyFilters.high;
            document.getElementById('desktop-novelty-moderate').checked = currentNoveltyFilters.moderate;
            document.getElementById('desktop-novelty-low').checked = currentNoveltyFilters.low;
            document.getElementById('desktop-novelty-none').checked = currentNoveltyFilters.none;
            
            updateNoveltyButtonText();
        }
        
        function updateNoveltyButtonText() {
            const highChecked = document.getElementById('mobile-novelty-high').checked;
            const moderateChecked = document.getElementById('mobile-novelty-moderate').checked;
            const lowChecked = document.getElementById('mobile-novelty-low').checked;
            const noneChecked = document.getElementById('mobile-novelty-none').checked;
            
            const checkedCount = [highChecked, moderateChecked, lowChecked, noneChecked].filter(Boolean).length;
            
            let selectionText;
            if (checkedCount === 4) {
                selectionText = "All Selected";
            } else if (checkedCount === 0) {
                selectionText = "None Selected";
            } else {
                selectionText = `${checkedCount} Selected`;
            }
            
            const mobileButton = document.getElementById('mobile-novelty-btn');
            if (mobileButton) {
                mobileButton.innerHTML = `<span class="font-bold">Novelty:</span> <span class="font-normal">${selectionText}</span> <span class="text-base">▼</span>`;
            }
            
            const desktopButton = document.getElementById('desktop-novelty-btn');
            if (desktopButton) {
                desktopButton.innerHTML = `<span class="font-bold">Novelty:</span> <span class="font-normal">${selectionText}</span> <span class="text-sm">▼</span>`;
            }
        }
        
        function applyNoveltyFilter() {
            updatePendingNoveltyFilters();
            currentNoveltyFilters = { ...pendingNoveltyFilters };
            syncNoveltyUI();
            updateNoveltyFiltersInURL();
            closeMobileNoveltyDropdown();
            closeDesktopNoveltyDropdown();
            applyFiltersAndSort();
        }
        
        function updatePendingNoveltyFilters() {
            pendingNoveltyFilters.high = document.getElementById('mobile-novelty-high').checked;
            pendingNoveltyFilters.moderate = document.getElementById('mobile-novelty-moderate').checked;
            pendingNoveltyFilters.low = document.getElementById('mobile-novelty-low').checked;
            pendingNoveltyFilters.none = document.getElementById('mobile-novelty-none').checked;
        }
        
        function closeMobileNoveltyDropdown() {
            const dropdown = document.getElementById('mobile-novelty-dropdown');
            const button = document.getElementById('mobile-novelty-btn');
            if (dropdown && !dropdown.classList.contains('hidden')) {
                dropdown.classList.add('hidden');
                button.classList.remove('bg-neutral-600');
                button.classList.add('bg-neutral-500');
            }
        }
        
        function closeDesktopNoveltyDropdown() {
            const dropdown = document.getElementById('desktop-novelty-dropdown');
            const button = document.getElementById('desktop-novelty-btn');
            if (dropdown && !dropdown.classList.contains('hidden')) {
                dropdown.classList.add('hidden');
                button.classList.remove('bg-neutral-600');
                button.classList.add('bg-neutral-500');
            }
        }
        
        function updateNoveltyFiltersInURL() {
            const params = new URLSearchParams(window.location.search);
            params.set('novelty_high', currentNoveltyFilters.high.toString());
            params.set('novelty_moderate', currentNoveltyFilters.moderate.toString());
            params.set('novelty_low', currentNoveltyFilters.low.toString());
            params.set('novelty_none', currentNoveltyFilters.none.toString());
            const newURL = `${window.location.pathname}?${params.toString()}`;
            window.history.pushState({}, '', newURL);
        }
        
        function updateNoveltyFiltersFromURL() {
            const params = new URLSearchParams(window.location.search);
            
            const high = params.get('novelty_high');
            const moderate = params.get('novelty_moderate');
            const low = params.get('novelty_low');
            const none = params.get('novelty_none');
            
            if (high !== null) {
                currentNoveltyFilters.high = high === 'true';
                pendingNoveltyFilters.high = high === 'true';
            }
            if (moderate !== null) {
                currentNoveltyFilters.moderate = moderate === 'true';
                pendingNoveltyFilters.moderate = moderate === 'true';
            }
            if (low !== null) {
                currentNoveltyFilters.low = low === 'true';
                pendingNoveltyFilters.low = low === 'true';
            }
            if (none !== null) {
                currentNoveltyFilters.none = none === 'true';
                pendingNoveltyFilters.none = none === 'true';
            }
            
            syncNoveltyUI();
        }

        // ============================================================================
        // POTENTIAL IMPACT FILTER DROPDOWN FUNCTIONS
        // ============================================================================
        
        // Current and pending impact filter states
        let currentImpactFilters = {
            high: true,
            moderate: true,
            low: true,
            negligible: true
        };
        
        let pendingImpactFilters = {
            high: true,
            moderate: true,
            low: true,
            negligible: true
        };
        
        function toggleMobileImpactDropdown() {
            const button = document.getElementById('mobile-impact-btn');
            const dropdown = document.getElementById('mobile-impact-dropdown');
            
            if (dropdown.classList.contains('hidden')) {
                setDropdownDirection(button, dropdown);
                button.classList.remove('bg-neutral-500');
                button.classList.add('bg-neutral-600');
            } else {
                button.classList.remove('bg-neutral-600');
                button.classList.add('bg-neutral-500');
            }
            
            dropdown.classList.toggle('hidden');
        }
        
        function toggleDesktopImpactDropdown() {
            const button = document.getElementById('desktop-impact-btn');
            const dropdown = document.getElementById('desktop-impact-dropdown');
            
            if (dropdown.classList.contains('hidden')) {
                setDropdownDirection(button, dropdown);
                button.classList.remove('bg-neutral-500');
                button.classList.add('bg-neutral-600');
            } else {
                button.classList.remove('bg-neutral-600');
                button.classList.add('bg-neutral-500');
            }
            
            dropdown.classList.toggle('hidden');
        }
        
        function syncPendingImpactUI() {
            document.getElementById('mobile-impact-high').checked = pendingImpactFilters.high;
            document.getElementById('mobile-impact-moderate').checked = pendingImpactFilters.moderate;
            document.getElementById('mobile-impact-low').checked = pendingImpactFilters.low;
            document.getElementById('mobile-impact-negligible').checked = pendingImpactFilters.negligible;
            document.getElementById('desktop-impact-high').checked = pendingImpactFilters.high;
            document.getElementById('desktop-impact-moderate').checked = pendingImpactFilters.moderate;
            document.getElementById('desktop-impact-low').checked = pendingImpactFilters.low;
            document.getElementById('desktop-impact-negligible').checked = pendingImpactFilters.negligible;
        }
        
        function syncImpactUI() {
            document.getElementById('mobile-impact-high').checked = currentImpactFilters.high;
            document.getElementById('mobile-impact-moderate').checked = currentImpactFilters.moderate;
            document.getElementById('mobile-impact-low').checked = currentImpactFilters.low;
            document.getElementById('mobile-impact-negligible').checked = currentImpactFilters.negligible;
            document.getElementById('desktop-impact-high').checked = currentImpactFilters.high;
            document.getElementById('desktop-impact-moderate').checked = currentImpactFilters.moderate;
            document.getElementById('desktop-impact-low').checked = currentImpactFilters.low;
            document.getElementById('desktop-impact-negligible').checked = currentImpactFilters.negligible;
            
            updateImpactButtonText();
        }
        
        function updateImpactButtonText() {
            const highChecked = document.getElementById('mobile-impact-high').checked;
            const moderateChecked = document.getElementById('mobile-impact-moderate').checked;
            const lowChecked = document.getElementById('mobile-impact-low').checked;
            const negligibleChecked = document.getElementById('mobile-impact-negligible').checked;
            
            const checkedCount = [highChecked, moderateChecked, lowChecked, negligibleChecked].filter(Boolean).length;
            
            let selectionText;
            if (checkedCount === 4) {
                selectionText = "All Selected";
            } else if (checkedCount === 0) {
                selectionText = "None Selected";
            } else {
                selectionText = `${checkedCount} Selected`;
            }
            
            const mobileButton = document.getElementById('mobile-impact-btn');
            if (mobileButton) {
                mobileButton.innerHTML = `<span class="font-bold">Potential Impact:</span> <span class="font-normal">${selectionText}</span> <span class="text-base">▼</span>`;
            }
            
            const desktopButton = document.getElementById('desktop-impact-btn');
            if (desktopButton) {
                desktopButton.innerHTML = `<span class="font-bold">Potential Impact:</span> <span class="font-normal">${selectionText}</span> <span class="text-sm">▼</span>`;
            }
        }
        
        function applyImpactFilter() {
            updatePendingImpactFilters();
            currentImpactFilters = { ...pendingImpactFilters };
            syncImpactUI();
            updateImpactFiltersInURL();
            closeMobileImpactDropdown();
            closeDesktopImpactDropdown();
            applyFiltersAndSort();
        }
        
        function updatePendingImpactFilters() {
            pendingImpactFilters.high = document.getElementById('mobile-impact-high').checked;
            pendingImpactFilters.moderate = document.getElementById('mobile-impact-moderate').checked;
            pendingImpactFilters.low = document.getElementById('mobile-impact-low').checked;
            pendingImpactFilters.negligible = document.getElementById('mobile-impact-negligible').checked;
        }
        
        function closeMobileImpactDropdown() {
            const dropdown = document.getElementById('mobile-impact-dropdown');
            const button = document.getElementById('mobile-impact-btn');
            if (dropdown && !dropdown.classList.contains('hidden')) {
                dropdown.classList.add('hidden');
                button.classList.remove('bg-neutral-600');
                button.classList.add('bg-neutral-500');
            }
        }
        
        function closeDesktopImpactDropdown() {
            const dropdown = document.getElementById('desktop-impact-dropdown');
            const button = document.getElementById('desktop-impact-btn');
            if (dropdown && !dropdown.classList.contains('hidden')) {
                dropdown.classList.add('hidden');
                button.classList.remove('bg-neutral-600');
                button.classList.add('bg-neutral-500');
            }
        }
        
        function updateImpactFiltersInURL() {
            const params = new URLSearchParams(window.location.search);
            params.set('impact_high', currentImpactFilters.high.toString());
            params.set('impact_moderate', currentImpactFilters.moderate.toString());
            params.set('impact_low', currentImpactFilters.low.toString());
            params.set('impact_negligible', currentImpactFilters.negligible.toString());
            const newURL = `${window.location.pathname}?${params.toString()}`;
            window.history.pushState({}, '', newURL);
        }
        
        function updateImpactFiltersFromURL() {
            const params = new URLSearchParams(window.location.search);
            
            const high = params.get('impact_high');
            const moderate = params.get('impact_moderate');
            const low = params.get('impact_low');
            const negligible = params.get('impact_negligible');
            
            if (high !== null) {
                currentImpactFilters.high = high === 'true';
                pendingImpactFilters.high = high === 'true';
            }
            if (moderate !== null) {
                currentImpactFilters.moderate = moderate === 'true';
                pendingImpactFilters.moderate = moderate === 'true';
            }
            if (low !== null) {
                currentImpactFilters.low = low === 'true';
                pendingImpactFilters.low = low === 'true';
            }
            if (negligible !== null) {
                currentImpactFilters.negligible = negligible === 'true';
                pendingImpactFilters.negligible = negligible === 'true';
            }
            
            syncImpactUI();
        }

        // ============================================================================
        // TOPIC FILTER DROPDOWN FUNCTIONS
        // ============================================================================
        
        function toggleMobileTopicDropdown() {
            const button = document.getElementById('mobile-topic-btn');
            const dropdown = document.getElementById('mobile-topic-dropdown');
            
            if (dropdown.classList.contains('hidden')) {
                setDropdownDirection(button, dropdown);
                button.classList.remove('bg-neutral-500');
                button.classList.add('bg-neutral-600');
            } else {
                button.classList.remove('bg-neutral-600');
                button.classList.add('bg-neutral-500');
            }
            
            dropdown.classList.toggle('hidden');
        }
        
        function toggleDesktopTopicDropdown() {
            const button = document.getElementById('desktop-topic-btn');
            const dropdown = document.getElementById('desktop-topic-dropdown');
            
            if (dropdown.classList.contains('hidden')) {
                setDropdownDirection(button, dropdown);
                button.classList.remove('bg-neutral-500');
                button.classList.add('bg-neutral-600');
            } else {
                button.classList.remove('bg-neutral-600');
                button.classList.add('bg-neutral-500');
            }
            
            dropdown.classList.toggle('hidden');
        }
        
        function syncPendingTopicUI() {
            document.getElementById('mobile-topic-rlhf').checked = pendingTopicFilters.rlhf;
            document.getElementById('mobile-topic-weak-supervision').checked = pendingTopicFilters.weakSupervision;
            document.getElementById('mobile-topic-diffusion-reasoning').checked = pendingTopicFilters.diffusionReasoning;
            document.getElementById('mobile-topic-distributed-training').checked = pendingTopicFilters.distributedTraining;
            document.getElementById('mobile-topic-datasets').checked = pendingTopicFilters.datasets;
            document.getElementById('desktop-topic-rlhf').checked = pendingTopicFilters.rlhf;
            document.getElementById('desktop-topic-weak-supervision').checked = pendingTopicFilters.weakSupervision;
            document.getElementById('desktop-topic-diffusion-reasoning').checked = pendingTopicFilters.diffusionReasoning;
            document.getElementById('desktop-topic-distributed-training').checked = pendingTopicFilters.distributedTraining;
            document.getElementById('desktop-topic-datasets').checked = pendingTopicFilters.datasets;
        }
        
        function syncTopicUI() {
            document.getElementById('mobile-topic-rlhf').checked = currentTopicFilters.rlhf;
            document.getElementById('mobile-topic-weak-supervision').checked = currentTopicFilters.weakSupervision;
            document.getElementById('mobile-topic-diffusion-reasoning').checked = currentTopicFilters.diffusionReasoning;
            document.getElementById('mobile-topic-distributed-training').checked = currentTopicFilters.distributedTraining;
            document.getElementById('mobile-topic-datasets').checked = currentTopicFilters.datasets;
            document.getElementById('desktop-topic-rlhf').checked = currentTopicFilters.rlhf;
            document.getElementById('desktop-topic-weak-supervision').checked = currentTopicFilters.weakSupervision;
            document.getElementById('desktop-topic-diffusion-reasoning').checked = currentTopicFilters.diffusionReasoning;
            document.getElementById('desktop-topic-distributed-training').checked = currentTopicFilters.distributedTraining;
            document.getElementById('desktop-topic-datasets').checked = currentTopicFilters.datasets;
            
            updateTopicButtonText();
        }
        
        function updateTopicButtonText() {
            const rlhfChecked = document.getElementById('mobile-topic-rlhf').checked;
            const weakSupervisionChecked = document.getElementById('mobile-topic-weak-supervision').checked;
            const diffusionReasoningChecked = document.getElementById('mobile-topic-diffusion-reasoning').checked;
            const distributedTrainingChecked = document.getElementById('mobile-topic-distributed-training').checked;
            const datasetsChecked = document.getElementById('mobile-topic-datasets').checked;
            
            const checkedCount = [rlhfChecked, weakSupervisionChecked, diffusionReasoningChecked, distributedTrainingChecked, datasetsChecked].filter(Boolean).length;
            
            let selectionText;
            if (checkedCount === 5) {
                selectionText = "All Selected";
            } else if (checkedCount === 0) {
                selectionText = "None Selected";
            } else {
                selectionText = `${checkedCount} Selected`;
            }
            
            const mobileButton = document.getElementById('mobile-topic-btn');
            if (mobileButton) {
                mobileButton.innerHTML = `<span class="font-bold">Topics:</span> <span class="font-normal">${selectionText}</span> <span class="text-base">▼</span>`;
            }
            
            const desktopButton = document.getElementById('desktop-topic-btn');
            if (desktopButton) {
                desktopButton.innerHTML = `<span class="font-bold">Topics:</span> <span class="font-normal">${selectionText}</span> <span class="text-sm">▼</span>`;
            }
        }
        
        function applyTopicFilter() {
            updatePendingTopicFilters();
            currentTopicFilters = { ...pendingTopicFilters };
            syncTopicUI();
            updateTopicFiltersInURL();
            closeMobileTopicDropdown();
            closeDesktopTopicDropdown();
            updateAllPaperModules();
            applyFiltersAndSort();
        }
        
        function updatePendingTopicFilters() {
            pendingTopicFilters.rlhf = document.getElementById('mobile-topic-rlhf').checked;
            pendingTopicFilters.weakSupervision = document.getElementById('mobile-topic-weak-supervision').checked;
            pendingTopicFilters.diffusionReasoning = document.getElementById('mobile-topic-diffusion-reasoning').checked;
            pendingTopicFilters.distributedTraining = document.getElementById('mobile-topic-distributed-training').checked;
            pendingTopicFilters.datasets = document.getElementById('mobile-topic-datasets').checked;
        }
        
        function resetPendingTopicFilters() {
            pendingTopicFilters = { ...currentTopicFilters };
            syncPendingTopicUI();
            updateTopicButtonText();
        }
        
        function closeMobileTopicDropdown() {
            const dropdown = document.getElementById('mobile-topic-dropdown');
            const button = document.getElementById('mobile-topic-btn');
            if (dropdown && !dropdown.classList.contains('hidden')) {
                dropdown.classList.add('hidden');
                button.classList.remove('bg-neutral-600');
                button.classList.add('bg-neutral-500');
            }
        }
        
        function closeDesktopTopicDropdown() {
            const dropdown = document.getElementById('desktop-topic-dropdown');
            const button = document.getElementById('desktop-topic-btn');
            if (dropdown && !dropdown.classList.contains('hidden')) {
                dropdown.classList.add('hidden');
                button.classList.remove('bg-neutral-600');
                button.classList.add('bg-neutral-500');
            }
        }
        
        function updateTopicFiltersInURL() {
            const params = new URLSearchParams(window.location.search);
            params.set('topic_rlhf', currentTopicFilters.rlhf.toString());
            params.set('topic_weak_supervision', currentTopicFilters.weakSupervision.toString());
            params.set('topic_diffusion_reasoning', currentTopicFilters.diffusionReasoning.toString());
            params.set('topic_distributed_training', currentTopicFilters.distributedTraining.toString());
            params.set('topic_datasets', currentTopicFilters.datasets.toString());
            const newURL = `${window.location.pathname}?${params.toString()}`;
            window.history.pushState({}, '', newURL);
        }
        
        function updateTopicFiltersFromURL() {
            const params = new URLSearchParams(window.location.search);
            
            const rlhf = params.get('topic_rlhf');
            const weakSupervision = params.get('topic_weak_supervision');
            const diffusionReasoning = params.get('topic_diffusion_reasoning');
            const distributedTraining = params.get('topic_distributed_training');
            const datasets = params.get('topic_datasets');
            
            if (rlhf !== null) {
                currentTopicFilters.rlhf = rlhf === 'true';
                pendingTopicFilters.rlhf = rlhf === 'true';
            }
            if (weakSupervision !== null) {
                currentTopicFilters.weakSupervision = weakSupervision === 'true';
                pendingTopicFilters.weakSupervision = weakSupervision === 'true';
            }
            if (diffusionReasoning !== null) {
                currentTopicFilters.diffusionReasoning = diffusionReasoning === 'true';
                pendingTopicFilters.diffusionReasoning = diffusionReasoning === 'true';
            }
            if (distributedTraining !== null) {
                currentTopicFilters.distributedTraining = distributedTraining === 'true';
                pendingTopicFilters.distributedTraining = distributedTraining === 'true';
            }
            if (datasets !== null) {
                currentTopicFilters.datasets = datasets === 'true';
                pendingTopicFilters.datasets = datasets === 'true';
            }
            
            syncTopicUI();
        }
        
        function passesTopicFilter(paper) {
            // Topic filter doesn't actually filter papers, it only affects module display
            return true;
        }
        
        function updateAllPaperModules() {
            // Update all similarity and relevance modules when topic filters change
            currentPagePapers.forEach(paper => {
                updateSimilarityModuleTopics(paper.id);
                updateRelevanceModuleTopics(paper.id);
            });
        }

        // ============================================================================
        // RELEVANCE FILTER FUNCTIONS  
        // ============================================================================
        
        function toggleMobileRelevanceDropdown() {
            const button = document.getElementById('mobile-relevance-btn');
            const dropdown = document.getElementById('mobile-relevance-dropdown');
            
            if (dropdown.classList.contains('hidden')) {
                setDropdownDirection(button, dropdown);
                button.classList.remove('bg-neutral-500');
                button.classList.add('bg-neutral-600');
            } else {
                button.classList.remove('bg-neutral-600');
                button.classList.add('bg-neutral-500');
            }
            
            dropdown.classList.toggle('hidden');
        }
        
        function toggleDesktopRelevanceDropdown() {
            const button = document.getElementById('desktop-relevance-btn');
            const dropdown = document.getElementById('desktop-relevance-dropdown');
            
            if (dropdown.classList.contains('hidden')) {
                setDropdownDirection(button, dropdown);
                button.classList.remove('bg-neutral-500');
                button.classList.add('bg-neutral-600');
            } else {
                button.classList.remove('bg-neutral-600');
                button.classList.add('bg-neutral-500');
            }
            
            dropdown.classList.toggle('hidden');
        }
        
        function syncPendingRelevanceUI() {
            document.getElementById('mobile-relevance-highly').checked = pendingRelevanceFilters.highlyRelevant;
            document.getElementById('mobile-relevance-moderately').checked = pendingRelevanceFilters.moderatelyRelevant;
            document.getElementById('mobile-relevance-tangentially').checked = pendingRelevanceFilters.tangentiallyRelevant;
            document.getElementById('mobile-relevance-not').checked = pendingRelevanceFilters.notRelevant;
            document.getElementById('desktop-relevance-highly').checked = pendingRelevanceFilters.highlyRelevant;
            document.getElementById('desktop-relevance-moderately').checked = pendingRelevanceFilters.moderatelyRelevant;
            document.getElementById('desktop-relevance-tangentially').checked = pendingRelevanceFilters.tangentiallyRelevant;
            document.getElementById('desktop-relevance-not').checked = pendingRelevanceFilters.notRelevant;
        }
        
        function syncRelevanceUI() {
            document.getElementById('mobile-relevance-highly').checked = currentRelevanceFilters.highlyRelevant;
            document.getElementById('mobile-relevance-moderately').checked = currentRelevanceFilters.moderatelyRelevant;
            document.getElementById('mobile-relevance-tangentially').checked = currentRelevanceFilters.tangentiallyRelevant;
            document.getElementById('mobile-relevance-not').checked = currentRelevanceFilters.notRelevant;
            document.getElementById('desktop-relevance-highly').checked = currentRelevanceFilters.highlyRelevant;
            document.getElementById('desktop-relevance-moderately').checked = currentRelevanceFilters.moderatelyRelevant;
            document.getElementById('desktop-relevance-tangentially').checked = currentRelevanceFilters.tangentiallyRelevant;
            document.getElementById('desktop-relevance-not').checked = currentRelevanceFilters.notRelevant;
            
            updateRelevanceButtonText();
        }
        
        function updateRelevanceButtonText() {
            // Read the current checkbox states from the UI (like H-Index filter does)
            const highlyRelevantChecked = document.getElementById('mobile-relevance-highly').checked;
            const moderatelyRelevantChecked = document.getElementById('mobile-relevance-moderately').checked;
            const tangentiallyRelevantChecked = document.getElementById('mobile-relevance-tangentially').checked;
            const notRelevantChecked = document.getElementById('mobile-relevance-not').checked;
            
            const selectedOptions = [];
            if (highlyRelevantChecked) selectedOptions.push("Highly Relevant");
            if (moderatelyRelevantChecked) selectedOptions.push("Moderately Relevant");
            if (tangentiallyRelevantChecked) selectedOptions.push("Tangentially Relevant");
            if (notRelevantChecked) selectedOptions.push("Not Relevant");
            
            const selectionText = selectedOptions.length === 4 ? "All Selected" : 
                                selectedOptions.length === 0 ? "None Selected" : 
                                `${selectedOptions.length} Selected`;
            
            const mobileButton = document.getElementById('mobile-relevance-btn');
            if (mobileButton) {
                mobileButton.innerHTML = `<span class="font-bold">Relevance:</span> <span class="font-normal">${selectionText}</span> <span class="text-base">▼</span>`;
            }
            
            const desktopButton = document.getElementById('desktop-relevance-btn');
            if (desktopButton) {
                desktopButton.innerHTML = `<span class="font-bold">Relevance:</span> <span class="font-normal">${selectionText}</span> <span class="text-sm">▼</span>`;
            }
        }
        
        function applyRelevanceFilter() {
            updatePendingRelevanceFilters();
            currentRelevanceFilters = { ...pendingRelevanceFilters };
            syncRelevanceUI();
            updateRelevanceFiltersInURL();
            closeMobileRelevanceDropdown();
            closeDesktopRelevanceDropdown();
            applyFiltersAndSort();
        }
        
        function updatePendingRelevanceFilters() {
            // Get values from mobile (primary source)
            const mobileHighly = document.getElementById('mobile-relevance-highly');
            const mobileModerately = document.getElementById('mobile-relevance-moderately');
            const mobileTangentially = document.getElementById('mobile-relevance-tangentially');
            const mobileNot = document.getElementById('mobile-relevance-not');
            
            // Update pending filters from mobile if available, otherwise from desktop
            pendingRelevanceFilters.highlyRelevant = mobileHighly ? mobileHighly.checked : document.getElementById('desktop-relevance-highly').checked;
            pendingRelevanceFilters.moderatelyRelevant = mobileModerately ? mobileModerately.checked : document.getElementById('desktop-relevance-moderately').checked;
            pendingRelevanceFilters.tangentiallyRelevant = mobileTangentially ? mobileTangentially.checked : document.getElementById('desktop-relevance-tangentially').checked;
            pendingRelevanceFilters.notRelevant = mobileNot ? mobileNot.checked : document.getElementById('desktop-relevance-not').checked;
        }
        
        function resetPendingRelevanceFilters() {
            pendingRelevanceFilters = { ...currentRelevanceFilters };
            syncPendingRelevanceUI();
            updateRelevanceButtonText();
        }
        
        function closeMobileRelevanceDropdown() {
            const dropdown = document.getElementById('mobile-relevance-dropdown');
            const button = document.getElementById('mobile-relevance-btn');
            if (dropdown && !dropdown.classList.contains('hidden')) {
                dropdown.classList.add('hidden');
                button.classList.remove('bg-neutral-600');
                button.classList.add('bg-neutral-500');
            }
        }
        
        function closeDesktopRelevanceDropdown() {
            const dropdown = document.getElementById('desktop-relevance-dropdown');
            const button = document.getElementById('desktop-relevance-btn');
            if (dropdown && !dropdown.classList.contains('hidden')) {
                dropdown.classList.add('hidden');
                button.classList.remove('bg-neutral-600');
                button.classList.add('bg-neutral-500');
            }
        }
        
        function updateRelevanceFiltersInURL() {
            const params = new URLSearchParams(window.location.search);
            params.set('relevance_highly', currentRelevanceFilters.highlyRelevant.toString());
            params.set('relevance_moderately', currentRelevanceFilters.moderatelyRelevant.toString());
            params.set('relevance_tangentially', currentRelevanceFilters.tangentiallyRelevant.toString());
            params.set('relevance_not', currentRelevanceFilters.notRelevant.toString());
            window.history.replaceState({}, '', `${window.location.pathname}?${params.toString()}`);
        }
        
        function loadRelevanceFiltersFromURL() {
            const highlyRelevant = getUrlParameter('relevance_highly');
            const moderatelyRelevant = getUrlParameter('relevance_moderately');
            const tangentiallyRelevant = getUrlParameter('relevance_tangentially');
            const notRelevant = getUrlParameter('relevance_not');
            
            if (highlyRelevant !== null) {
                currentRelevanceFilters.highlyRelevant = highlyRelevant === 'true';
                pendingRelevanceFilters.highlyRelevant = highlyRelevant === 'true';
            }
            if (moderatelyRelevant !== null) {
                currentRelevanceFilters.moderatelyRelevant = moderatelyRelevant === 'true';
                pendingRelevanceFilters.moderatelyRelevant = moderatelyRelevant === 'true';
            }
            if (tangentiallyRelevant !== null) {
                currentRelevanceFilters.tangentiallyRelevant = tangentiallyRelevant === 'true';
                pendingRelevanceFilters.tangentiallyRelevant = tangentiallyRelevant === 'true';
            }
            if (notRelevant !== null) {
                currentRelevanceFilters.notRelevant = notRelevant === 'true';
                pendingRelevanceFilters.notRelevant = notRelevant === 'true';
            }
            
            syncRelevanceUI();
        }
        
        function passesRelevanceFilter(paper) {
            // Get selected topics
            const selectedTopics = [];
            if (currentTopicFilters.rlhf) selectedTopics.push('rlhf');
            if (currentTopicFilters.weakSupervision) selectedTopics.push('weak_supervision');
            if (currentTopicFilters.diffusionReasoning) selectedTopics.push('diffusion_reasoning');
            if (currentTopicFilters.distributedTraining) selectedTopics.push('distributed_training');
            if (currentTopicFilters.datasets) selectedTopics.push('datasets');
            
            // If no topics selected, skip relevance filtering
            if (selectedTopics.length === 0) return true;
            
            // Get selected relevance levels
            const selectedRelevanceLevels = [];
            if (currentRelevanceFilters.highlyRelevant) selectedRelevanceLevels.push('Highly Relevant');
            if (currentRelevanceFilters.moderatelyRelevant) selectedRelevanceLevels.push('Moderately Relevant');
            if (currentRelevanceFilters.tangentiallyRelevant) selectedRelevanceLevels.push('Tangentially Relevant');
            if (currentRelevanceFilters.notRelevant) selectedRelevanceLevels.push('Not Relevant');
            
            // If no relevance levels selected, show 0 papers
            if (selectedRelevanceLevels.length === 0) return false;
            
            // Check each selected topic
            for (let topic of selectedTopics) {
                const relevanceField = `${topic}_relevance`;
                const paperRelevance = paper[relevanceField];
                
                // Treat "not_validated" same as "Not Relevant"
                const normalizedRelevance = paperRelevance === "not_validated" ? "Not Relevant" : paperRelevance;
                
                // If this topic's relevance matches any selected relevance level, paper passes
                if (selectedRelevanceLevels.includes(normalizedRelevance)) {
                    return true; // At least one topic matches
                }
            }
            
            // No selected topics had matching relevance levels
            return false;
        }

        // ============================================================================
        // FILTERING AND DISPLAY FUNCTIONS
        // ============================================================================
        
        function shouldDisableAdvancedFilters() {
            return !currentScoringFilters.hasScoring && currentScoringFilters.noScoring;
        }
        
        function updateDropdownDisabledState(buttonId, dropdownId, shouldDisable) {
            const button = document.getElementById(buttonId);
            const dropdown = document.getElementById(dropdownId);
            
            if (button && dropdown) {
                if (shouldDisable) {
                    button.classList.add('opacity-50', 'cursor-not-allowed');
                    button.style.pointerEvents = 'none';
                    dropdown.classList.add('hidden'); // Close if open
                } else {
                    button.classList.remove('opacity-50', 'cursor-not-allowed');
                    button.style.pointerEvents = 'auto';
                }
            }
        }
        
        function updateAdvancedFiltersDisabledState() {
            const shouldDisable = shouldDisableAdvancedFilters();
            
            // Update Recommendation
            updateDropdownDisabledState('mobile-recommendation-btn', 'mobile-recommendation-dropdown', shouldDisable);
            updateDropdownDisabledState('desktop-recommendation-btn', 'desktop-recommendation-dropdown', shouldDisable);
            
            // Update Novelty  
            updateDropdownDisabledState('mobile-novelty-btn', 'mobile-novelty-dropdown', shouldDisable);
            updateDropdownDisabledState('desktop-novelty-btn', 'desktop-novelty-dropdown', shouldDisable);
            
            // Update Impact
            updateDropdownDisabledState('mobile-impact-btn', 'mobile-impact-dropdown', shouldDisable);
            updateDropdownDisabledState('desktop-impact-btn', 'desktop-impact-dropdown', shouldDisable);
            
            // Update Relevance
            updateDropdownDisabledState('mobile-relevance-btn', 'mobile-relevance-dropdown', shouldDisable);
            updateDropdownDisabledState('desktop-relevance-btn', 'desktop-relevance-dropdown', shouldDisable);
        }
        
        function applyFiltersAndSort() {
            // Apply H-Index filtering first
            filteredSortedPapers = allPapers.filter(paper => passesHIndexFilter(paper));
            
            // Apply Scoring filtering
            filteredSortedPapers = filteredSortedPapers.filter(paper => passesScoringFilter(paper));
            
            // Apply Recommendation filtering
            filteredSortedPapers = filteredSortedPapers.filter(paper => passesRecommendationFilter(paper));
            
            // Apply Novelty filtering
            filteredSortedPapers = filteredSortedPapers.filter(paper => passesNoveltyFilter(paper));
            
            // Apply Impact filtering
            filteredSortedPapers = filteredSortedPapers.filter(paper => passesImpactFilter(paper));
            
            // Apply Relevance filtering
            filteredSortedPapers = filteredSortedPapers.filter(paper => passesRelevanceFilter(paper));
            
            // Apply Topic filtering (note: this doesn't filter papers, just affects display)
            filteredSortedPapers = filteredSortedPapers.filter(paper => passesTopicFilter(paper));
            
            // Apply current sorting
            sortPapers(currentSort);
            
            // Calculate pagination
            totalPages = Math.ceil(filteredSortedPapers.length / PAPERS_PER_PAGE);
            currentPage = 1;
            
            updatePaperCount();
            updatePaginationUI();
            displayCurrentPage();
        }
        
        function passesHIndexFilter(paper) {
            const { found, notFound, highestMin, highestMax, averageMin, averageMax } = currentHIndexFilters;
            
            // Check H-Index status
            const hasHIndex = paper.h_index_status === 'completed';
            const noHIndex = paper.h_index_status === 'not_fetched';
            
            // If neither found nor not-found is checked, hide all papers
            if (!found && !notFound) return false;
            
            // Check status inclusion
            if (hasHIndex && !found) return false;
            if (noHIndex && !notFound) return false;
            
            // For papers with H-Index data, check ranges (only if "found" is checked)
            if (hasHIndex && found) {
                // Treat null h-index values as 0
                const paperHighest = paper.highest_h_index || 0;
                const paperAverage = paper.average_h_index || 0;
                
                // Check if paper's H-Index values fall within ranges
                if (paperHighest < highestMin || paperHighest > highestMax) return false;
                if (paperAverage < averageMin || paperAverage > averageMax) return false;
            }
            
            return true;
        }
        
        function passesScoringFilter(paper) {
            const { hasScoring, noScoring } = currentScoringFilters;
            
            // Check scoring status
            const hasLLMScoring = paper.llm_score_status === 'completed';
            const noLLMScoring = paper.llm_score_status === 'not_relevant_enough';
            
            // If neither hasScoring nor noScoring is checked, hide all papers
            if (!hasScoring && !noScoring) return false;
            
            // Check status inclusion
            if (hasLLMScoring && !hasScoring) return false;
            if (noLLMScoring && !noScoring) return false;
            
            // Handle other statuses - if paper has a different status, only show if both filters are enabled
            if (!hasLLMScoring && !noLLMScoring) {
                return hasScoring && noScoring;
            }
            
            return true;
        }
        
        function passesRecommendationFilter(paper) {
            const { mustRead, shouldRead, canSkip, ignore } = currentRecommendationFilters;
            
            // If no filters are selected, hide all papers
            if (!mustRead && !shouldRead && !canSkip && !ignore) return false;
            
            // Check recommendation score
            const score = paper.recommendation_score;
            
            if (score === 'Must Read' && !mustRead) return false;
            if (score === 'Should Read' && !shouldRead) return false;
            if (score === 'Can Skip' && !canSkip) return false;
            if (score === 'Ignore' && !ignore) return false;
            
            // If paper has a different/null score, only show if all filters are enabled
            if (!['Must Read', 'Should Read', 'Can Skip', 'Ignore'].includes(score)) {
                return mustRead && shouldRead && canSkip && ignore;
            }
            
            return true;
        }
        
        function passesNoveltyFilter(paper) {
            const { high, moderate, low, none } = currentNoveltyFilters;
            
            // If no filters are selected, hide all papers
            if (!high && !moderate && !low && !none) return false;
            
            // Check novelty score
            const score = paper.novelty_score;
            
            if (score === 'High' && !high) return false;
            if (score === 'Moderate' && !moderate) return false;
            if (score === 'Low' && !low) return false;
            if ((score === null || score === undefined) && !none) return false;
            
            // If paper has a different score, only show if all filters are enabled
            if (score && !['High', 'Moderate', 'Low'].includes(score)) {
                return high && moderate && low && none;
            }
            
            return true;
        }
        
        function passesImpactFilter(paper) {
            const { high, moderate, low, negligible } = currentImpactFilters;
            
            // If no filters are selected, hide all papers
            if (!high && !moderate && !low && !negligible) return false;
            
            // Check impact score
            const score = paper.impact_score;
            
            if (score === 'High' && !high) return false;
            if (score === 'Moderate' && !moderate) return false;
            if (score === 'Low' && !low) return false;
            if (score === 'Negligible' && !negligible) return false;
            
            // If paper has a different/null score, only show if all filters are enabled
            if (!['High', 'Moderate', 'Low', 'Negligible'].includes(score)) {
                return high && moderate && low && negligible;
            }
            
            return true;
        }
        
        function displayCurrentPage() {
            // Check if there are no papers to display
            if (filteredSortedPapers.length === 0) {
                showNoPapersMessage();
                hidePaginationSections();
                return;
            }
            
            const startIndex = (currentPage - 1) * PAPERS_PER_PAGE;
            const endIndex = startIndex + PAPERS_PER_PAGE;
            currentPagePapers = filteredSortedPapers.slice(startIndex, endIndex);
            
            showPaginationSections();
            populatePaperCards(currentPagePapers, startIndex + 1);
            
            // Re-run truncation after new content is displayed
            setTimeout(() => {
                setupAbstractTruncation();
                setupInitialProgressBars();
            }, 50);
        }

        function populatePaperCards(papers, startIndex = 1) {
            const mobileContainer = document.getElementById('mobile-papers');
            const desktopContainer = document.getElementById('desktop-papers');
            
            const papersHTML = papers.map((paper, index) => createPaperCard(paper, startIndex + index)).join('');
            
            if (mobileContainer) {
                mobileContainer.innerHTML = papersHTML;
            }
            if (desktopContainer) {
                desktopContainer.innerHTML = papersHTML;
            }
        }

        function showNoPapersMessage() {
            const mobileContainer = document.getElementById('mobile-papers');
            const desktopContainer = document.getElementById('desktop-papers');
            
            const noPapersHTML = '<div class="flex items-center justify-center min-h-screen"><h2 class="font-heading text-2xl text-neutral-600">No papers to show</h2></div>';
            
            if (mobileContainer) {
                mobileContainer.innerHTML = noPapersHTML;
            }
            if (desktopContainer) {
                desktopContainer.innerHTML = noPapersHTML;
            }
        }

        function hidePaginationSections() {
            const paginationIds = [
                'mobile-prev-btn', 'mobile-next-btn', 'mobile-pagination-numbers',
                'desktop-prev-btn', 'desktop-next-btn', 'desktop-pagination-numbers',
                'mobile-footer-prev-btn', 'mobile-footer-next-btn', 'mobile-footer-pagination-numbers',
                'desktop-footer-prev-btn', 'desktop-footer-next-btn', 'desktop-footer-pagination-numbers'
            ];
            
            paginationIds.forEach(id => {
                const element = document.getElementById(id);
                if (element) {
                    element.style.display = 'none';
                }
            });
        }

        function showPaginationSections() {
            const paginationIds = [
                'mobile-prev-btn', 'mobile-next-btn', 'mobile-pagination-numbers',
                'desktop-prev-btn', 'desktop-next-btn', 'desktop-pagination-numbers',
                'mobile-footer-prev-btn', 'mobile-footer-next-btn', 'mobile-footer-pagination-numbers',
                'desktop-footer-prev-btn', 'desktop-footer-next-btn', 'desktop-footer-pagination-numbers'
            ];
            
            paginationIds.forEach(id => {
                const element = document.getElementById(id);
                if (element) {
                    element.style.display = '';
                }
            });
        }

        // ============================================================================
        // PAGINATION FUNCTIONS
        // ============================================================================
        
        function goToPage(page) {
            if (page < 1 || page > totalPages) return;
            currentPage = page;
            updatePaginationUI();
            displayCurrentPage();
        }
        
        function updatePaginationUI() {
            // Update all pagination controls
            updatePaginationButtons();
            updatePaginationNumbers();
        }
        
        function updatePaginationButtons() {
            // Previous buttons
            const prevButtons = ['mobile-prev-btn', 'desktop-prev-btn', 'mobile-footer-prev-btn', 'desktop-footer-prev-btn'];
            prevButtons.forEach(id => {
                const btn = document.getElementById(id);
                if (btn) {
                    if (currentPage <= 1) {
                        btn.classList.add('disabled');
                    } else {
                        btn.classList.remove('disabled');
                    }
                }
            });
            
            // Next buttons
            const nextButtons = ['mobile-next-btn', 'desktop-next-btn', 'mobile-footer-next-btn', 'desktop-footer-next-btn'];
            nextButtons.forEach(id => {
                const btn = document.getElementById(id);
                if (btn) {
                    if (currentPage >= totalPages) {
                        btn.classList.add('disabled');
                    } else {
                        btn.classList.remove('disabled');
                    }
                }
            });
        }
        
        function updatePaginationNumbers() {
            const containers = [
                'mobile-pagination-numbers',
                'desktop-pagination-numbers', 
                'mobile-footer-pagination-numbers',
                'desktop-footer-pagination-numbers'
            ];
            
            containers.forEach(containerId => {
                const container = document.getElementById(containerId);
                if (container) {
                    container.innerHTML = generatePaginationNumbers();
                }
            });
        }
        
        function generatePaginationNumbers() {
            if (totalPages <= 1) return '';
            
            let html = '';
            const maxVisiblePages = 5;
            let startPage = Math.max(1, currentPage - Math.floor(maxVisiblePages / 2));
            let endPage = Math.min(totalPages, startPage + maxVisiblePages - 1);
            
            // Adjust if we're near the end
            if (endPage - startPage + 1 < maxVisiblePages) {
                startPage = Math.max(1, endPage - maxVisiblePages + 1);
            }
            
            for (let i = startPage; i <= endPage; i++) {
                const isActive = i === currentPage;
                const activeClass = isActive ? 'bg-neutral-500 text-neutral-10' : 'bg-transparent text-neutral-70 hover:bg-neutral-300';
                html += `<button class="pagination-square w-8 h-8 ${activeClass} flex items-center justify-center cursor-pointer font-heading font-bold text-sm" onclick="goToPage(${i})">${i}</button>`;
            }
            
            return html;
        }

        // ============================================================================
        // HELPER FUNCTIONS FOR STYLING
        // ============================================================================

        function getScoreColor(scoreType, value) {
            const colorMap = {
                recommendation: {
                    'Must Read': 'bg-status-green',      
                    'Should Read': 'bg-status-blue',   
                    'Can Skip': 'bg-status-orange',       
                    'Ignore': 'bg-status-red'          
                },
                novelty: {
                    'High': 'bg-status-green',           
                    'Moderate': 'bg-status-blue',      
                    'Low': 'bg-status-orange',            
                    'None': 'bg-status-red'            
                },
                impact: {
                    'High': 'bg-status-green',           
                    'Moderate': 'bg-status-blue',      
                    'Low': 'bg-status-orange',            
                    'Negligible': 'bg-status-red'      
                }
            };
            
            return colorMap[scoreType][value] || 'bg-neutral-500';  // fallback to neutral-500
        }

        function getRelevanceColor(relevanceValue) {
            const colorMap = {
                'Highly Relevant': 'bg-status-green',      
                'Moderately Relevant': 'bg-status-blue', 
                'Tangentially Relevant': 'bg-status-orange', 
                'Not Relevant': 'bg-status-red',         
                'not_validated': 'bg-status-red'         
            };
            
            return colorMap[relevanceValue] || 'bg-status-red';  // fallback to status-red
        }

        function getRelevanceDisplayText(relevanceValue) {
            if (relevanceValue === 'not_validated') {
                return 'Not Relevant';
            }
            return relevanceValue;
        }

        function getJustificationText(justificationValue) {
            if (justificationValue === 'below_threshold') {
                return "Topic similarity score below 0.4, hence default to 'Not Relevant'.";
            }
            return justificationValue;
        }

        // ============================================================================
        // KATEX RENDERING FUNCTIONS
        // ============================================================================

        function renderKatexInElement(element) {
            if (typeof renderMathInElement !== 'undefined' && element) {
                renderMathInElement(element, {
                    delimiters: [
                        {left: '$$', right: '$$', display: true},
                        {left: '$', right: '$', display: false},
                        {left: '\\(', right: '\\)', display: false},
                        {left: '\\[', right: '\\]', display: true},
                    ],
                    throwOnError: false,
                    trust: true
                });
            }
        }

        // ============================================================================
        // TOPIC VISIBILITY HELPER FUNCTIONS
        // ============================================================================
        
        function getTopicKeyMapping() {
            return {
                'rlhf': 'rlhf',
                'weakSupervision': 'weak_supervision', 
                'diffusionReasoning': 'diffusion_reasoning',
                'distributedTraining': 'distributed_training',
                'datasets': 'datasets'
            };
        }
        
        function getTopicDisplayNames() {
            return {
                'rlhf': 'RLHF',
                'weakSupervision': 'Weak Supervision',
                'diffusionReasoning': 'Diffusion Reasoning', 
                'distributedTraining': 'Distributed Training',
                'datasets': 'Datasets'
            };
        }
        
        function getHiddenTopicsCount() {
            const filters = currentTopicFilters;
            return Object.values(filters).filter(visible => !visible).length;
        }
        
        function getVisibleTopics() {
            const filters = currentTopicFilters;
            return Object.keys(filters).filter(topic => filters[topic]);
        }
        
        function getHiddenTopics() {
            const filters = currentTopicFilters;
            return Object.keys(filters).filter(topic => !filters[topic]);
        }
        
        function generateSimilarityTopicRows(paper) {
            const topicMapping = getTopicKeyMapping();
            const displayNames = getTopicDisplayNames();
            const visibleTopics = getVisibleTopics();
            
            let html = '';
            
            // Add visible topic rows
            visibleTopics.forEach(topic => {
                const dataKey = topicMapping[topic];
                const displayName = displayNames[topic];
                const score = paper[`${dataKey}_score`];
                
                html += `
                    <!-- ${displayName} Score Row -->
                    <div class="flex flex-col topic-row visible-topic" data-topic="${topic}">
                        <div class="text-left">
                            <span class="text-neutral-70 font-heading font-bold text-lg">${displayName}:</span>
                        </div>
                        <div class="bg-neutral-200 relative flex items-center justify-end">
                            <div class="similarity-progress-bar ${dataKey.replace('_', '-')}-progress-bar bg-bar-raw absolute inset-0 z-0" 
                                 data-paper-id="${paper.id}" 
                                 data-topic="${dataKey}">
                            </div>
                            <span class="text-neutral-70 font-heading font-bold text-md py-tag-y px-tag-x relative z-10 ${dataKey.replace('_', '-')}-similarity-score">
                                ${score.toFixed(3)}
                            </span>
                        </div>
                    </div>
                `;
            });
            
            return html;
        }
        
        function generateRelevanceTopicRows(paper) {
            const topicMapping = getTopicKeyMapping();
            const displayNames = getTopicDisplayNames();
            const visibleTopics = getVisibleTopics();
            
            let html = '';
            
            // Add visible topic rows
            visibleTopics.forEach(topic => {
                const dataKey = topicMapping[topic];
                const displayName = displayNames[topic];
                const relevance = paper[`${dataKey}_relevance`];
                
                html += `
                    <!-- ${displayName} Relevance Row -->
                    <div class="flex flex-col topic-row visible-topic" data-topic="${topic}">
                        <div class="text-left">
                            <span class="text-neutral-70 font-heading font-bold text-lg">${displayName}:</span>
                        </div>
                        <div class="w-full text-center py-tag-y font-heading font-bold text-md text-neutral-10 ${getRelevanceColor(relevance)}">
                            ${getRelevanceDisplayText(relevance)}
                        </div>
                    </div>
                `;
            });
            
            return html;
        }
        
        function generateRelevanceJustificationContent(paper, showingHidden = false) {
            const topicMapping = getTopicKeyMapping();
            const displayNames = getTopicDisplayNames();
            const visibleTopics = getVisibleTopics();
            
            let html = '';
            
            // Add justification for visible topics only unless showing hidden topics
            const topicsToShow = showingHidden ? Object.keys(displayNames) : visibleTopics;
            
            topicsToShow.forEach(topic => {
                const dataKey = topicMapping[topic];
                const displayName = displayNames[topic];
                const justification = paper[`${dataKey}_justification`];
                
                html += `
                    <div class="justification-topic-section visible-justification" data-topic="${topic}">
                        <div class="font-heading font-bold">${displayName}:</div>
                        <div>${getJustificationText(justification)}</div>
                    </div>
                `;
            });
            
            return html;
        }
        
        function toggleSimilarityHiddenTopics(paperId) {
            // Find the similarity module specifically
            const containers = document.querySelectorAll(`[data-paper-id="${paperId}"][data-show-hidden-topics]`);
            let container = null;
            
            // Find the similarity container (the one that contains similarity-scores-container)
            // and ensure it's in the currently visible layout (mobile or desktop)
            containers.forEach(cont => {
                if (cont.querySelector('.similarity-scores-container')) {
                    // Check if this container is in a visible layout
                    const mobileLayout = cont.closest('#mobile-main-container');
                    const desktopLayout = cont.closest('.tablet\\:block');
                    
                    if (mobileLayout && getComputedStyle(mobileLayout).display !== 'none') {
                        container = cont;
                    } else if (desktopLayout && getComputedStyle(desktopLayout).display !== 'none') {
                        container = cont;
                    }
                }
            });
            
            if (!container) return;
            
            const isShowingHidden = container.getAttribute('data-show-hidden-topics') === 'true';
            const button = container.querySelector('.show-other-topics-container button');
            const hiddenTopicsContainer = container.querySelector('.hidden-topics-container');
            
            if (!isShowingHidden) {
                // Show hidden topics
                container.setAttribute('data-show-hidden-topics', 'true');
                button.innerHTML = 'Hide Other Topics <span class="text-xs">▲</span>';
                button.className = 'bg-neutral-700 text-neutral-10 font-heading font-bold text-md py-tag-y mt-md w-full text-center hover:bg-neutral-600';
                
                // Show and populate the hidden topics container
                hiddenTopicsContainer.style.display = 'block';
                addHiddenSimilarityTopics(paperId, hiddenTopicsContainer);
            } else {
                // Hide other topics  
                container.setAttribute('data-show-hidden-topics', 'false');
                button.innerHTML = 'Show Other Topics <span class="text-xs">▼</span>';
                button.className = 'bg-neutral-500 text-neutral-10 font-heading font-bold text-md py-tag-y mt-md w-full text-center hover:bg-neutral-600';
                
                // Hide and clear the hidden topics container
                hiddenTopicsContainer.style.display = 'none';
                hiddenTopicsContainer.innerHTML = '';
            }
            
            // Recalculate normalized scores if in normalized mode
            if (container.getAttribute('data-normalized') === 'true') {
                updateNormalizedScores(paperId);
            }
        }
        
        function toggleRelevanceHiddenTopics(paperId) {
            // Find the relevance module specifically (not similarity module)
            const containers = document.querySelectorAll(`[data-paper-id="${paperId}"][data-show-hidden-topics]`);
            let container = null;
            
            // Find the relevance container (the one that contains relevance-scores-container)
            // and ensure it's in the currently visible layout (mobile or desktop)
            containers.forEach(cont => {
                if (cont.querySelector('.relevance-scores-container')) {
                    // Check if this container is in a visible layout
                    const mobileLayout = cont.closest('#mobile-main-container');
                    const desktopLayout = cont.closest('.tablet\\:block');
                    
                    if (mobileLayout && getComputedStyle(mobileLayout).display !== 'none') {
                        container = cont;
                    } else if (desktopLayout && getComputedStyle(desktopLayout).display !== 'none') {
                        container = cont;
                    }
                }
            });
            
            if (!container) return;
            
            const isShowingHidden = container.getAttribute('data-show-hidden-topics') === 'true';
            const button = container.querySelector('.show-other-topics-container button');
            const hiddenTopicsContainer = container.querySelector('.hidden-topics-container');
            
            if (!isShowingHidden) {
                // Show hidden topics
                container.setAttribute('data-show-hidden-topics', 'true');
                button.innerHTML = 'Hide Other Topics <span class="text-xs">▲</span>';
                button.className = 'bg-neutral-700 text-neutral-10 font-heading font-bold text-md py-tag-y mt-md w-full text-center hover:bg-neutral-600';
                
                // Show and populate the hidden topics container
                hiddenTopicsContainer.style.display = 'block';
                addHiddenRelevanceTopics(paperId, hiddenTopicsContainer);
            } else {
                // Hide other topics
                container.setAttribute('data-show-hidden-topics', 'false');
                button.innerHTML = 'Show Other Topics <span class="text-xs">▼</span>';
                button.className = 'bg-neutral-500 text-neutral-10 font-heading font-bold text-md py-tag-y mt-md w-full text-center hover:bg-neutral-600';
                
                // Hide and clear the hidden topics container
                hiddenTopicsContainer.style.display = 'none';
                hiddenTopicsContainer.innerHTML = '';
            }
            
            // Update justification content based on new state
            const justificationContainer = container.querySelector('.relevance-justification-section .justification-text');
            if (justificationContainer) {
                const paper = currentPagePapers.find(p => p.id === paperId);
                if (paper) {
                    const newShowingHidden = container.getAttribute('data-show-hidden-topics') === 'true';
                    justificationContainer.innerHTML = generateRelevanceJustificationContent(paper, newShowingHidden);
                }
            }
            
            // Update justification if it's currently visible
            updateRelevanceJustificationVisibility(paperId);
        }
        
        function addHiddenSimilarityTopics(paperId, container) {
            const paper = currentPagePapers.find(p => p.id === paperId);
            if (!paper) return;
            
            const topicMapping = getTopicKeyMapping();
            const displayNames = getTopicDisplayNames();
            const hiddenTopics = getHiddenTopics();
            
            // Check if the parent container is in normalized mode
            const parentContainer = container.closest('[data-normalized]');
            const isNormalized = parentContainer && parentContainer.getAttribute('data-normalized') === 'true';
            const barColorClass = isNormalized ? 'bg-bar-normalized' : 'bg-bar-raw';
            
            hiddenTopics.forEach(topic => {
                const dataKey = topicMapping[topic];
                const displayName = displayNames[topic];
                const score = paper[`${dataKey}_score`];
                
                const rowHtml = `
                    <div class="flex flex-col topic-row hidden-topic" data-topic="${topic}">
                        <div class="text-left">
                            <span class="text-neutral-70 font-heading font-bold text-lg">${displayName}:</span>
                        </div>
                        <div class="bg-neutral-200 relative flex items-center justify-end">
                            <div class="similarity-progress-bar ${dataKey.replace('_', '-')}-progress-bar ${barColorClass} absolute inset-0 z-0" 
                                 data-paper-id="${paperId}" 
                                 data-topic="${dataKey}">
                            </div>
                            <span class="text-neutral-70 font-heading font-bold text-md py-tag-y px-tag-x relative z-10 ${dataKey.replace('_', '-')}-similarity-score">
                                ${score.toFixed(3)}
                            </span>
                        </div>
                    </div>
                `;
                
                container.insertAdjacentHTML('beforeend', rowHtml);
            });
            
            // Update progress bars for newly added rows with correct values and colors
            setupProgressBarsForPaper(paper);
            
            // If in normalized mode, update all scores including the newly added ones
            if (isNormalized) {
                updateNormalizedScores(paperId);
            }
        }
        
        function addHiddenRelevanceTopics(paperId, container) {
            const paper = currentPagePapers.find(p => p.id === paperId);
            if (!paper) return;
            
            const topicMapping = getTopicKeyMapping();
            const displayNames = getTopicDisplayNames();
            const hiddenTopics = getHiddenTopics();
            
            hiddenTopics.forEach(topic => {
                const dataKey = topicMapping[topic];
                const displayName = displayNames[topic];
                const relevance = paper[`${dataKey}_relevance`];
                
                const rowHtml = `
                    <div class="flex flex-col topic-row hidden-topic" data-topic="${topic}">
                        <div class="text-left">
                            <span class="text-neutral-70 font-heading font-bold text-lg">${displayName}:</span>
                        </div>
                        <div class="w-full text-center py-tag-y font-heading font-bold text-md text-neutral-10 ${getRelevanceColor(relevance)}">
                            ${getRelevanceDisplayText(relevance)}
                        </div>
                    </div>
                `;
                
                container.insertAdjacentHTML('beforeend', rowHtml);
            });
        }
        
        function removeHiddenTopicRows(container) {
            const hiddenRows = container.querySelectorAll('.hidden-topic');
            hiddenRows.forEach(row => row.remove());
        }
        
        function updateSimilarityModuleTopics(paperId) {
            // Find the similarity module specifically
            const containers = document.querySelectorAll(`[data-paper-id="${paperId}"][data-normalized]`);
            let container = null;
            
            // Find the similarity container in the currently visible layout
            containers.forEach(cont => {
                if (cont.querySelector('.similarity-scores-container')) {
                    // Check if this container is in a visible layout
                    const mobileLayout = cont.closest('#mobile-main-container');
                    const desktopLayout = cont.closest('.tablet\\:block');
                    
                    if (mobileLayout && getComputedStyle(mobileLayout).display !== 'none') {
                        container = cont;
                    } else if (desktopLayout && getComputedStyle(desktopLayout).display !== 'none') {
                        container = cont;
                    }
                }
            });
            
            if (!container) return;
            
            const scoresContainer = container.querySelector('.similarity-scores-container');
            const showOtherButton = container.querySelector('.show-other-topics-container');
            
            // Remove all existing topic rows
            scoresContainer.innerHTML = '';
            
            // Regenerate visible topic rows
            const paper = currentPagePapers.find(p => p.id === paperId);
            if (paper) {
                scoresContainer.innerHTML = generateSimilarityTopicRows(paper);
                setupProgressBarsForPaper(paper);
                
                // Update normalized scores if needed
                if (container.getAttribute('data-normalized') === 'true') {
                    updateNormalizedScores(paperId);
                }
            }
            
            // Show/hide the "Show Other Topics" button
            if (getHiddenTopicsCount() > 0) {
                if (showOtherButton) {
                    showOtherButton.style.display = 'block';
                }
            } else {
                if (showOtherButton) {
                    showOtherButton.style.display = 'none';
                }
            }
            
            // Reset the hidden topics state
            container.setAttribute('data-show-hidden-topics', 'false');
            
            // Reset button text if it exists
            const button = showOtherButton?.querySelector('button');
            if (button) {
                button.innerHTML = 'Show Other Topics <span class="text-xs">▼</span>';
            }
        }
        
        function updateRelevanceModuleTopics(paperId) {
            // Find all relevance containers for this paper
            const containers = document.querySelectorAll(`[data-paper-id="${paperId}"][data-show-hidden-topics]`);
            
            containers.forEach(container => {
                const scoresContainer = container.querySelector('.relevance-scores-container');
                if (!scoresContainer) return; // Skip if this is not a relevance container
                
                const showOtherButton = container.querySelector('.show-other-topics-container');
                const justificationContainer = container.querySelector('.relevance-justification-section .justification-text');
                
                // Remove all existing topic rows
                scoresContainer.innerHTML = '';
                
                // Regenerate visible topic rows
                const paper = currentPagePapers.find(p => p.id === paperId);
                if (paper) {
                    scoresContainer.innerHTML = generateRelevanceTopicRows(paper);
                    
                    // Update justification content based on current visibility state
                    if (justificationContainer) {
                        const isShowingHidden = container.getAttribute('data-show-hidden-topics') === 'true';
                        justificationContainer.innerHTML = generateRelevanceJustificationContent(paper, isShowingHidden);
                    }
                }
                
                // Show/hide the "Show Other Topics" button
                if (getHiddenTopicsCount() > 0) {
                    if (showOtherButton) {
                        showOtherButton.style.display = 'block';
                    }
                } else {
                    if (showOtherButton) {
                        showOtherButton.style.display = 'none';
                    }
                }
                
                // Reset the hidden topics state
                container.setAttribute('data-show-hidden-topics', 'false');
                
                // Reset button text if it exists
                const button = showOtherButton?.querySelector('button');
                if (button) {
                    button.innerHTML = 'Show Other Topics <span class="text-xs">▼</span>';
                }
            });
        }
        
        function updateRelevanceJustificationVisibility(paperId) {
            // Find the justification container in the currently visible layout
            const containers = document.querySelectorAll(`.relevance-justification-section[data-paper-id="${paperId}"]`);
            let container = null;
            
            containers.forEach(cont => {
                // Check if this container is in a visible layout
                const mobileLayout = cont.closest('#mobile-main-container');
                const desktopLayout = cont.closest('.tablet\\:block');
                
                if (mobileLayout && getComputedStyle(mobileLayout).display !== 'none') {
                    container = cont;
                } else if (desktopLayout && getComputedStyle(desktopLayout).display !== 'none') {
                    container = cont;
                }
            });
            
            if (!container) return;
            
            const justificationDiv = container.querySelector('.justification-text');
            const isVisible = !justificationDiv.classList.contains('hidden');
            
            if (isVisible) {
                const paper = currentPagePapers.find(p => p.id === paperId);
                const relevanceContainer = container.closest('[data-show-hidden-topics]');
                const isShowingHidden = relevanceContainer && relevanceContainer.getAttribute('data-show-hidden-topics') === 'true';
                
                if (paper) {
                    if (isShowingHidden) {
                        // Show all justifications
                        justificationDiv.innerHTML = generateFullRelevanceJustificationContent(paper);
                    } else {
                        // Show only visible justifications
                        justificationDiv.innerHTML = generateRelevanceJustificationContent(paper);
                    }
                }
            }
        }
        
        function generateFullRelevanceJustificationContent(paper) {
            const allTopics = ['rlhf', 'weakSupervision', 'diffusionReasoning', 'distributedTraining', 'datasets'];
            const topicMapping = getTopicKeyMapping();
            const displayNames = getTopicDisplayNames();
            
            let html = '';
            
            allTopics.forEach(topic => {
                const dataKey = topicMapping[topic];
                const displayName = displayNames[topic];
                const justification = paper[`${dataKey}_justification`];
                const isVisible = currentTopicFilters[topic];
                
                html += `
                    <div class="justification-topic-section ${isVisible ? 'visible-justification' : 'hidden-justification'}" data-topic="${topic}">
                        <div class="font-heading font-bold">${displayName}:</div>
                        <div>${getJustificationText(justification)}</div>
                    </div>
                `;
            });
            
            return html;
        }
        
        function setupProgressBarsForPaper(paper) {
            const topics = ['rlhf', 'weak_supervision', 'diffusion_reasoning', 'distributed_training', 'datasets'];
            
            topics.forEach(topic => {
                const progressBars = document.querySelectorAll(
                    `.similarity-progress-bar[data-paper-id="${paper.id}"][data-topic="${topic}"]`
                );
                
                progressBars.forEach(progressBar => {
                    const score = paper[`${topic}_score`];
                    const percentage = (score * 100);
                    progressBar.style.width = `${percentage}%`;
                });
            });
        }
        
        function updateNormalizedScores(paperId) {
            // Find the normalized similarity container in the currently visible layout
            const containers = document.querySelectorAll(`[data-paper-id="${paperId}"][data-normalized="true"]`);
            let container = null;
            
            containers.forEach(cont => {
                // Check if this container is in a visible layout
                const mobileLayout = cont.closest('#mobile-main-container');
                const desktopLayout = cont.closest('.tablet\\:block');
                
                if (mobileLayout && getComputedStyle(mobileLayout).display !== 'none') {
                    container = cont;
                } else if (desktopLayout && getComputedStyle(desktopLayout).display !== 'none') {
                    container = cont;
                }
            });
            
            if (!container) return;
            
            const paper = currentPagePapers.find(p => p.id === paperId);
            if (!paper) return;
            
            const isShowingHidden = container.getAttribute('data-show-hidden-topics') === 'true';
            const topicsToCalculate = isShowingHidden ? 
                ['rlhf', 'weakSupervision', 'diffusionReasoning', 'distributedTraining', 'datasets'] :
                getVisibleTopics();
                
            const topicMapping = getTopicKeyMapping();
            
            // Calculate total score for normalization
            const totalScore = topicsToCalculate.reduce((sum, topic) => {
                const dataKey = topicMapping[topic];
                return sum + paper[`${dataKey}_score`];
            }, 0);
            
            // Update each visible topic
            topicsToCalculate.forEach(topic => {
                const dataKey = topicMapping[topic];
                const rawScore = paper[`${dataKey}_score`];
                const normalizedScore = (rawScore / totalScore) * 100;
                
                // Update progress bar
                const progressBar = container.querySelector(`.${dataKey.replace('_', '-')}-progress-bar`);
                if (progressBar) {
                    progressBar.style.width = `${normalizedScore}%`;
                }
                
                // Update score text
                const scoreElement = container.querySelector(`.${dataKey.replace('_', '-')}-similarity-score`);
                if (scoreElement) {
                    const sigFigScore = normalizedScore.toPrecision(3);
                    scoreElement.textContent = `${sigFigScore}%`;
                }
            });
        }

        // ============================================================================
        // PAPER CARD CREATION FUNCTIONS
        // ============================================================================
        function createPaperCard(paper, paperNumber) {
            const cardId = `paper-${paperNumber}`;
            
            return `
                <article class="bg-neutral-200" role="article" aria-labelledby="${cardId}">
                    <!-- Title Section -->
                    <div class="p-md">
                        <h2 id="${cardId}" class="text-neutral-70 font-heading font-bold text-2xl">
                            <span class="mr-sm">${paperNumber}.</span><a href="${paper.pdf_url}" 
                               class="paper-title-link" 
                               target="_blank" 
                               rel="noopener noreferrer"
                               aria-label="View paper PDF">${paper.title}</a>
                        </h2>
                    </div>
                    
                    <!-- Paper Info Section -->
                    <div class="grid grid-cols-1 gap-lg pb-xl px-xl">
                        <!-- Row 1: Metadata Module -->
                        <div class="flex flex-col gap-xs">
                            <!-- First row: arXiv ID and Publication Date -->
                            <div class="flex gap-xs">
                                <span class="bg-neutral-500 text-neutral-10 font-heading font-bold text-md px-tag-x py-tag-y">
                                    arXiv ID: <a href="${paper.arxiv_url}" target="_blank" rel="noopener noreferrer" class="text-neutral-10 underline hover:no-underline">${paper.id}</a>
                                </span>
                                <span class="bg-neutral-500 text-neutral-10 font-heading font-bold text-md px-tag-x py-tag-y">
                                    Published: ${formatPublicationDate(paper.published_date)}
                                </span>
                            </div>
                            
                            <!-- Second row: Authors -->
                            <div>
                                <span class="bg-neutral-500 text-neutral-10 font-heading font-bold text-md px-tag-x py-tag-y metadata-tag">
                                    Authors: ${paper.h_index_status === 'completed' && paper.author_h_indexes && paper.author_h_indexes.length > 0 
                                        ? paper.author_h_indexes.map(author => 
                                            author.profile_url && author.profile_url !== null && author.profile_url !== '' 
                                                ? `<a href="${author.profile_url}" target="_blank" rel="noopener noreferrer" class="text-neutral-10 underline hover:no-underline">${author.name}</a>`
                                                : author.name
                                        ).join(', ')
                                        : paper.authors.join(', ')
                                    }
                                </span>
                            </div>
                            
                            <!-- Third row: Categories -->
                            <div>
                                <span class="bg-neutral-500 text-neutral-10 font-heading font-bold text-md px-tag-x py-tag-y metadata-tag">
                                    Categories: ${paper.categories.join(', ')}
                                </span>
                            </div>
                        </div>
                        
                        <!-- Row 2: AI Generated Summary Module -->
                        ${paper.summary && paper.summary.trim() ? `
                        <div class="bg-neutral-300 p-lg">
                            <div class="flex flex-col gap-xs">
                                <h3 class="text-neutral-70 font-heading font-bold text-lg">AI-generated summary</h3>
                                <p class="text-neutral-70 font-body text-md">${paper.summary}</p>
                            </div>
                        </div>
                        ` : ''}
                        
                        <!-- Row 3: Abstract Module -->
                        <div class="bg-neutral-300 p-lg">
                            <div class="flex flex-col gap-xs">
                                <h3 class="text-neutral-70 font-heading font-bold text-lg">Abstract</h3>
                                <div class="abstract-container" data-paper-id="${paper.id}">
                                    <p class="abstract-text text-neutral-70 font-body text-md" 
                                       style="line-height: calc(1.5em);">${paper.abstract}</p>
                                </div>
                            </div>
                        </div>
                        
                        <!-- Row 4: Score Row Section -->
                        ${paper.llm_score_status !== 'not_relevant_enough' ? `
                        <div class="flex flex-col tablet:flex-row gap-lg items-start">
                            <!-- Recommendation Score Module -->
                            <div class="bg-neutral-300 p-lg flex-1 w-full">
                                <div class="flex flex-col gap-xs">
                                    <!-- Score Section -->
                                    <div class="flex">
                                        <span class="bg-neutral-500 text-neutral-10 font-heading font-bold text-md px-tag-x py-tag-y text-center">
                                            Recommendation:
                                        </span>
                                        <span class="text-neutral-10 font-heading font-bold text-md px-tag-x py-tag-y text-center ${getScoreColor('recommendation', paper.recommendation_score)}">
                                            ${paper.recommendation_score}
                                        </span>
                                    </div>
                                    
                                    <!-- Justification Section -->
                                    <div class="w-full recommendation-justification-section" data-paper-id="${paper.id}">
                                        <button class="bg-neutral-500 text-neutral-10 font-heading font-bold text-md px-tag-x py-tag-y w-full text-left cursor-pointer border-none transition-opacity duration-200" 
                                                onclick="toggleRecommendationJustification('${paper.id}')">
                                            Show Justification <span class="text-xs">▲</span>
                                        </button>
                                        <div class="justification-text hidden text-neutral-20 font-body text-md px-tag-x py-tag-y bg-neutral-500 transition-all duration-300 ease-in-out">
                                            ${paper.recommendation_justification}
                                        </div>
                                    </div>
                                </div>
                            </div>
                            
                            <!-- Novelty Score Module -->
                            <div class="bg-neutral-300 p-lg flex-1 w-full">
                                <div class="flex flex-col gap-xs">
                                    <!-- Score Section -->
                                    <div class="flex">
                                        <span class="bg-neutral-500 text-neutral-10 font-heading font-bold text-md px-tag-x py-tag-y text-center">
                                            Novelty:
                                        </span>
                                        <span class="text-neutral-10 font-heading font-bold text-md px-tag-x py-tag-y text-center ${getScoreColor('novelty', paper.novelty_score)}">
                                            ${paper.novelty_score}
                                        </span>
                                    </div>
                                    
                                    <!-- Justification Section -->
                                    <div class="w-full novelty-justification-section" data-paper-id="${paper.id}">
                                        <button class="bg-neutral-500 text-neutral-10 font-heading font-bold text-md px-tag-x py-tag-y w-full text-left cursor-pointer border-none transition-opacity duration-200" 
                                                onclick="toggleNoveltyJustification('${paper.id}')">
                                            Show Justification <span class="text-xs">▲</span>
                                        </button>
                                        <div class="justification-text hidden text-neutral-20 font-body text-md px-tag-x py-tag-y bg-neutral-500 transition-all duration-300 ease-in-out">
                                            ${paper.novelty_justification}
                                        </div>
                                    </div>
                                </div>
                            </div>
                            
                            <!-- Potential Impact Score Module -->
                            <div class="bg-neutral-300 p-lg flex-1 w-full">
                                <div class="flex flex-col gap-xs">
                                    <!-- Score Section -->
                                    <div class="flex">
                                        <span class="bg-neutral-500 text-neutral-10 font-heading font-bold text-md px-tag-x py-tag-y text-center">
                                            Potential Impact:
                                        </span>
                                        <span class="text-neutral-10 font-heading font-bold text-md px-tag-x py-tag-y text-center ${getScoreColor('impact', paper.impact_score)}">
                                            ${paper.impact_score}
                                        </span>
                                    </div>
                                    
                                    <!-- Justification Section -->
                                    <div class="w-full impact-justification-section" data-paper-id="${paper.id}">
                                        <button class="bg-neutral-500 text-neutral-10 font-heading font-bold text-md px-tag-x py-tag-y w-full text-left cursor-pointer border-none transition-opacity duration-200" 
                                                onclick="toggleImpactJustification('${paper.id}')">
                                            Show Justification <span class="text-xs">▲</span>
                                        </button>
                                        <div class="justification-text hidden text-neutral-20 font-body text-md px-tag-x py-tag-y bg-neutral-500 transition-all duration-300 ease-in-out">
                                            ${paper.impact_justification}
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                        ` : ''}
                        
                        <!-- Row 5: Similarity, Relevance, H-index Section -->
                        <div class="flex flex-col tablet:flex-row gap-lg items-start">
                            <!-- Similarity Scores Module -->
                            <div class="bg-neutral-300 p-lg flex-1 w-full" data-paper-id="${paper.id}" data-normalized="false" data-show-hidden-topics="false">
                                <div class="flex flex-col gap-xs">
                                    <!-- Title Section -->
                                    <div class="text-center py-tag-y">
                                        <h3 class="text-neutral-70 font-heading font-bold text-xl">Similarity Scores</h3>
                                    </div>
                                    
                                    <!-- Scores Section -->
                                    <div class="flex flex-col gap-xs similarity-scores-container">
                                        ${generateSimilarityTopicRows(paper)}
                                    </div>
                                    
                                    <!-- Show Other Topics Button (conditionally shown) -->
                                    <div class="show-other-topics-container" ${getHiddenTopicsCount() > 0 ? '' : 'style="display: none;"'}>
                                        <button class="bg-neutral-500 text-neutral-10 font-heading font-bold text-md py-tag-y mt-md w-full text-center hover:bg-neutral-600" onclick="toggleSimilarityHiddenTopics('${paper.id}')">
                                            Show Other Topics <span class="text-xs">▼</span>
                                        </button>
                                    </div>
                                    
                                    <!-- Hidden Topics Container (appears after button when toggled) -->
                                    <div class="hidden-topics-container" style="display: none;"></div>
                                    
                                    <!-- Button Section -->
                                    <div>
                                        <button class="bg-neutral-500 text-neutral-10 font-heading font-bold text-md py-tag-y mt-md w-full text-center" onclick="toggleSimilarityScores(this)">
                                            Show Normalized Scores ⇄
                                        </button>
                                    </div>
                                </div>
                            </div>
                            
                            <!-- Relevance Module -->
                            <div class="bg-neutral-300 p-lg flex-1 w-full" data-paper-id="${paper.id}" data-show-hidden-topics="false">
                                <div class="flex flex-col gap-xs">
                                    <!-- Title Section -->
                                    <div class="text-center py-tag-y">
                                        <h3 class="text-neutral-70 font-heading font-bold text-xl">Topic Relevance</h3>
                                    </div>
                                    
                                    <!-- Scores Section -->
                                    <div class="flex flex-col gap-xs relevance-scores-container">
                                        ${generateRelevanceTopicRows(paper)}
                                    </div>
                                    
                                    <!-- Show Other Topics Button (conditionally shown) -->
                                    <div class="show-other-topics-container" ${getHiddenTopicsCount() > 0 ? '' : 'style="display: none;"'}>
                                        <button class="bg-neutral-500 text-neutral-10 font-heading font-bold text-md py-tag-y mt-md w-full text-center hover:bg-neutral-600" onclick="toggleRelevanceHiddenTopics('${paper.id}')">
                                            Show Other Topics <span class="text-xs">▼</span>
                                        </button>
                                    </div>
                                    
                                    <!-- Hidden Topics Container (appears after button when toggled) -->
                                    <div class="hidden-topics-container" style="display: none;"></div>
                                    
                                    <!-- Justification Section -->
                                    <div class="w-full relevance-justification-section" data-paper-id="${paper.id}">
                                        <button class="bg-neutral-500 text-neutral-10 font-heading font-bold text-md px-tag-x py-tag-y mt-md w-full text-center cursor-pointer border-none transition-opacity duration-200" 
                                                onclick="toggleRelevanceJustification('${paper.id}')">
                                            Show Justification <span class="text-xs">▲</span>
                                        </button>
                                        <div class="justification-text hidden text-neutral-20 font-mono text-md px-tag-x py-tag-y bg-neutral-500 transition-all duration-300 ease-in-out flex flex-col gap-sm">
                                            ${generateRelevanceJustificationContent(paper)}
                                        </div>
                                    </div>
                                </div>
                            </div>
                            
                            <!-- Author H-Index Module -->
                            <div class="bg-neutral-300 p-lg flex-1 w-full">
                                <div class="flex flex-col gap-md">
                                    <!-- Title Section -->
                                    <div class="text-center py-tag-y">
                                        <h3 class="text-neutral-70 font-heading font-bold text-xl">Author H-Index</h3>
                                    </div>
                                    
                                    ${paper.h_index_status === 'not_fetched' || paper.h_index_status === 'failed' ? `
                                        <!-- No Data Available Section -->
                                        <div class="text-center pt-lg pb-sm">
                                            <p class="text-neutral-60 font-heading font-bold text-lg">No H-Index data available</p>
                                        </div>
                                    ` : `
                                        <!-- H-Index Info Section -->
                                        <div class="flex flex-col gap-sm">
                                            <!-- Authors Found Row -->
                                            <div class="flex justify-between items-center">
                                                <span class="text-neutral-60 font-heading font-bold text-xl px-tag-x py-tag-y">Authors found:</span>
                                                <span class="text-neutral-60 font-heading font-bold text-xl px-tag-x py-tag-y">${paper.authors_found}/${paper.total_authors}</span>
                                            </div>
                                            
                                            <!-- Highest H-Index Row -->
                                            <div class="flex justify-between items-center">
                                                <span class="text-neutral-60 font-heading font-bold text-xl px-tag-x py-tag-y">Highest H-Index:</span>
                                                <span class="text-neutral-60 font-heading font-bold text-xl px-tag-x py-tag-y">${paper.highest_h_index || 'N/A'}</span>
                                            </div>
                                            
                                            <!-- Average H-Index Row -->
                                            <div class="flex justify-between items-center">
                                                <span class="text-neutral-60 font-heading font-bold text-xl px-tag-x py-tag-y">Average H-Index:</span>
                                                <span class="text-neutral-60 font-heading font-bold text-xl px-tag-x py-tag-y">${paper.average_h_index ? paper.average_h_index.toFixed(1) : 'N/A'}</span>
                                            </div>
                                            
                                            <!-- Notable Authors Row -->
                                            <div class="flex justify-between items-center">
                                                <span class="text-neutral-60 font-heading font-bold text-xl px-tag-x py-tag-y">Notable (H>5):</span>
                                                <span class="text-neutral-60 font-heading font-bold text-xl px-tag-x py-tag-y">${paper.notable_authors_count || 0}</span>
                                            </div>
                                        </div>
                                        
                                        <!-- Semantic Scholar Button -->
                                        <div>
                                            <button class="bg-neutral-500 text-neutral-10 font-heading font-bold text-md py-tag-y mt-md w-full text-center" 
                                                    onclick="window.open('${paper.semantic_scholar_url}', '_blank')">
                                                Verify source on Semantic Scholar
                                            </button>
                                        </div>
                                        
                                        <!-- Individual H-Indices Section -->
                                        <div class="w-full author-h-index-section" data-paper-id="${paper.id}">
                                            <button class="bg-neutral-500 text-neutral-10 font-heading font-bold text-md px-tag-x py-tag-y w-full text-center cursor-pointer border-none transition-opacity duration-200" 
                                                    onclick="toggleAuthorHIndices('${paper.id}')">
                                                Show Individual H-Indices <span class="text-xs">▼</span>
                                            </button>
                                            <div class="individual-authors-text hidden text-neutral-20 font-mono text-md px-xl py-tag-y bg-neutral-500 transition-all duration-300 ease-in-out">
                                                ${paper.author_h_indexes && paper.author_h_indexes.length > 0 ? 
                                                    paper.author_h_indexes.map(author => `
                                                        <div class="flex justify-between items-center py-xs">
                                                            ${author.profile_url && author.profile_url !== null && author.profile_url !== '' 
                                                                ? `<a href="${author.profile_url}" target="_blank" rel="noopener noreferrer" class="text-neutral-20 font-mono text-md underline hover:no-underline">${author.name}:</a>`
                                                                : `<span class="text-neutral-20 font-mono text-md">${author.name}:</span>`
                                                            }
                                                            <span class="text-neutral-20 font-mono text-md">${author.h_index !== null && author.h_index !== undefined ? author.h_index : 'N/A'}</span>
                                                        </div>
                                                    `).join('') 
                                                    : '<div class="text-center text-neutral-20">No individual author data available</div>'
                                                }
                                            </div>
                                        </div>
                                    `}
                                </div>
                            </div>
                        </div>
                    </div>
                </article>
            `;
        }

        // ============================================================================
        // QUICK FILTER FUNCTIONS
        // ============================================================================


        function applyQuickFilter(filterType) {
            // Build URL parameters based on filter type
            const url = new URL(window.location.href);
            
            // Clear all existing parameters
            url.search = '';
            
            // Set sort to recommendation best first for all filters
            url.searchParams.set('sort', 'recommend_best');
            
            switch(filterType) {
                case 'must-read':
                    // Recommendation: Only Must Read + Scoring: Only Has Scoring
                    url.searchParams.set('recommendation_must', 'true');
                    url.searchParams.set('recommendation_should', 'false');
                    url.searchParams.set('recommendation_skip', 'false');
                    url.searchParams.set('recommendation_ignore', 'false');
                    url.searchParams.set('scoring_has', 'true');
                    url.searchParams.set('scoring_no', 'false');
                    break;
                    
                case 'should-read':
                    // Recommendation: Only Should Read + Scoring: Only Has Scoring
                    url.searchParams.set('recommendation_must', 'false');
                    url.searchParams.set('recommendation_should', 'true');
                    url.searchParams.set('recommendation_skip', 'false');
                    url.searchParams.set('recommendation_ignore', 'false');
                    url.searchParams.set('scoring_has', 'true');
                    url.searchParams.set('scoring_no', 'false');
                    break;
                    
                case 'rlhf':
                    // Topic: Only RLHF + Relevance: Exclude Not Relevant
                    url.searchParams.set('topic_rlhf', 'true');
                    url.searchParams.set('topic_weak_supervision', 'false');
                    url.searchParams.set('topic_diffusion_reasoning', 'false');
                    url.searchParams.set('topic_distributed_training', 'false');
                    url.searchParams.set('topic_datasets', 'false');
                    url.searchParams.set('relevance_highly', 'true');
                    url.searchParams.set('relevance_moderately', 'true');
                    url.searchParams.set('relevance_tangentially', 'true');
                    url.searchParams.set('relevance_not', 'false');
                    break;
                    
                case 'weak-supervision':
                    url.searchParams.set('topic_rlhf', 'false');
                    url.searchParams.set('topic_weak_supervision', 'true');
                    url.searchParams.set('topic_diffusion_reasoning', 'false');
                    url.searchParams.set('topic_distributed_training', 'false');
                    url.searchParams.set('topic_datasets', 'false');
                    url.searchParams.set('relevance_highly', 'true');
                    url.searchParams.set('relevance_moderately', 'true');
                    url.searchParams.set('relevance_tangentially', 'true');
                    url.searchParams.set('relevance_not', 'false');
                    break;
                    
                case 'diffusion-reasoning':
                    url.searchParams.set('topic_rlhf', 'false');
                    url.searchParams.set('topic_weak_supervision', 'false');
                    url.searchParams.set('topic_diffusion_reasoning', 'true');
                    url.searchParams.set('topic_distributed_training', 'false');
                    url.searchParams.set('topic_datasets', 'false');
                    url.searchParams.set('relevance_highly', 'true');
                    url.searchParams.set('relevance_moderately', 'true');
                    url.searchParams.set('relevance_tangentially', 'true');
                    url.searchParams.set('relevance_not', 'false');
                    break;
                    
                case 'distributed-training':
                    url.searchParams.set('topic_rlhf', 'false');
                    url.searchParams.set('topic_weak_supervision', 'false');
                    url.searchParams.set('topic_diffusion_reasoning', 'false');
                    url.searchParams.set('topic_distributed_training', 'true');
                    url.searchParams.set('topic_datasets', 'false');
                    url.searchParams.set('relevance_highly', 'true');
                    url.searchParams.set('relevance_moderately', 'true');
                    url.searchParams.set('relevance_tangentially', 'true');
                    url.searchParams.set('relevance_not', 'false');
                    break;
                    
                case 'datasets':
                    url.searchParams.set('topic_rlhf', 'false');
                    url.searchParams.set('topic_weak_supervision', 'false');
                    url.searchParams.set('topic_diffusion_reasoning', 'false');
                    url.searchParams.set('topic_distributed_training', 'false');
                    url.searchParams.set('topic_datasets', 'true');
                    url.searchParams.set('relevance_highly', 'true');
                    url.searchParams.set('relevance_moderately', 'true');
                    url.searchParams.set('relevance_tangentially', 'true');
                    url.searchParams.set('relevance_not', 'false');
                    break;
                    
                case 'reset':
                    // Clear all parameters, which will reset everything to defaults
                    break;
                    
                default:
                    console.warn('Unknown quick filter type:', filterType);
                    return;
            }
            
            // Navigate to new URL, which will trigger existing URL parsing logic
            window.location.href = url.toString();
        }



        // ============================================================================
        // PAGE INITIALIZATION
        // ============================================================================

        function initializePage() {

            // Get sort parameter from URL, default to 'recommend_best'
            currentSort = getUrlParameter('sort') || 'recommend_best';
            
            // Load H-Index filters from URL
            updateHIndexFiltersFromURL();
            
            // Load Scoring filters from URL
            updateScoringFiltersFromURL();
            
            // Load Recommendation filters from URL
            updateRecommendationFiltersFromURL();
            
            // Load Novelty filters from URL
            updateNoveltyFiltersFromURL();
            
            // Load Impact filters from URL
            updateImpactFiltersFromURL();
            
            // Load Topic filters from URL
            updateTopicFiltersFromURL();
            
            // Load Relevance filters from URL
            loadRelevanceFiltersFromURL();
            
            // Update disabled state for advanced filters after loading scoring filters
            updateAdvancedFiltersDisabledState();
            
            // Update page title and headers based on embedded date
            updatePageTitles(PAGE_DATE);
            
            // Update sort dropdown UI
            updateSortDropdownUI();
            
            // Setup H-Index input validation
            setupHIndexValidation();
            
            // Sync H-Index UI with loaded filters
            syncHIndexUI();
            
            // Apply initial sorting and filtering
            applyFiltersAndSort();
            
            // Display first page
            displayCurrentPage();
            
        }

        // ============================================================================
        // ABSTRACT TRUNCATION LOGIC
        // ============================================================================
        
        let resizeTimer;

        function resetAbstractToOriginal(container) {
            const abstractText = container.querySelector('.abstract-text');
            const originalText = abstractText.getAttribute('data-original-text');
            
            if (originalText) {
                // Reset to clean original text
                abstractText.innerHTML = originalText;
                abstractText.setAttribute('data-expanded', 'false');
                // Clear any existing truncated text to force recalculation
                abstractText.removeAttribute('data-truncated-text');
            }
        }

        function calculateAverageCharWidth(fontStyle, fontSize, fontFamily) {
            const canvas = document.createElement('canvas');
            const ctx = canvas.getContext('2d');
            ctx.font = `${fontStyle} ${fontSize} ${fontFamily}`;
            
            const characterSet = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789 ';
            const totalWidth = ctx.measureText(characterSet).width;
            
            return totalWidth / characterSet.length;
        }

        function getTextContentWidth(element) {
            const computedStyle = getComputedStyle(element);
            return element.clientWidth - 
                parseFloat(computedStyle.paddingLeft) - 
                parseFloat(computedStyle.paddingRight);
        }

        function calculateThreeLineCharLimit(element) {
            const computedStyle = getComputedStyle(element);
            const fontSize = computedStyle.fontSize;
            const fontFamily = computedStyle.fontFamily;
            const fontWeight = computedStyle.fontWeight;
            
            // Get average character width
            const avgCharWidth = calculateAverageCharWidth(fontWeight, fontSize, fontFamily);
            
            // Get content width
            const contentWidth = getTextContentWidth(element);
            
            // Calculate characters per line
            const charsPerLine = Math.floor(contentWidth / avgCharWidth);
            
            // Total characters for 3 lines
            const totalChars = charsPerLine * 3;
            
            // Reserve space for "... [Expand]"
            const expandButtonChars = 30;
            
            return Math.max(0, totalChars - expandButtonChars);
        }

        function toggleAbstract(paperId) {
            const containers = document.querySelectorAll(`.abstract-container[data-paper-id="${paperId}"]`);
            
            containers.forEach(container => {
                const abstractText = container.querySelector('.abstract-text');
                if (!abstractText) return; // Safety check
                
                const isExpanded = abstractText.getAttribute('data-expanded') === 'true';
                
                if (isExpanded) {
                    // Collapse - restore truncated text
                    const truncatedText = abstractText.getAttribute('data-truncated-text');
                    abstractText.innerHTML = truncatedText;
                    abstractText.setAttribute('data-expanded', 'false');
                } else {
                    // Expand - show full text
                    const originalText = abstractText.getAttribute('data-original-text');
                    abstractText.innerHTML = `${originalText} <button class="text-neutral-60 font-body font-bold text-md cursor-pointer bg-transparent border-none p-0 hover:opacity-70 transition-opacity duration-200" onclick="toggleAbstract('${paperId}')">[Collapse]</button>`;
                    abstractText.setAttribute('data-expanded', 'true');
                }
                
                // Re-render KaTeX after content change
                setTimeout(() => renderKatexInElement(abstractText), 50);
            });
        }

        // Function to setup abstract truncation using font metrics and binary search
        function setupAbstractTruncation() {
            document.querySelectorAll('.abstract-container').forEach(container => {
                const abstractText = container.querySelector('.abstract-text');
                const paperId = container.getAttribute('data-paper-id');
                
                // Get original text - only set it if not already stored to prevent corruption
                let originalText = abstractText.getAttribute('data-original-text');
                if (!originalText) {
                    // First time setup - get clean text content
                    originalText = abstractText.textContent;
                    abstractText.setAttribute('data-original-text', originalText);
                } else {
                    // Subsequent calls - reset to clean state first
                    resetAbstractToOriginal(container);
                }
                
                // Always reset to collapsed state
                abstractText.setAttribute('data-expanded', 'false');
                
                // Calculate the rough character limit for 3 lines as starting point
                const roughCharLimit = calculateThreeLineCharLimit(abstractText);
                
                // Check if text needs truncation
                if (originalText.length > roughCharLimit) {
                    // Create expand button template
                    const expandButton = '... <button class="text-neutral-60 font-body font-bold text-md cursor-pointer bg-transparent border-none p-0 hover:opacity-70 transition-opacity duration-200" onclick="toggleAbstract(\'' + paperId + '\')">[Expand]</button>';
                    
                    // Calculate 3-line height for comparison
                    const computedStyle = getComputedStyle(abstractText);
                    const lineHeight = parseFloat(computedStyle.lineHeight);
                    const maxHeight = lineHeight * 3;
                    
                    // Binary search for perfect truncation point
                    let left = 0;
                    let right = Math.min(originalText.length, roughCharLimit + 100); // Use rough estimate + buffer
                    let bestFit = '';
                    let bestLength = 0;
                    
                    // Create temporary element for height testing
                    const testElement = abstractText.cloneNode(true);
                    testElement.style.position = 'absolute';
                    testElement.style.visibility = 'hidden';
                    testElement.style.width = abstractText.offsetWidth + 'px';
                    testElement.style.height = 'auto';
                    testElement.style.maxHeight = 'none';
                    document.body.appendChild(testElement);
                    
                    while (left <= right) {
                        const mid = Math.floor((left + right) / 2);
                        const testText = originalText.substring(0, mid) + expandButton;
                        
                        testElement.innerHTML = testText;
                        
                        if (testElement.offsetHeight <= maxHeight) {
                            // Text fits, try longer
                            bestFit = testText;
                            bestLength = mid;
                            left = mid + 1;
                        } else {
                            // Text too long, trying shorter
                            right = mid - 1;
                        }
                    }
                    
                    // Clean up temporary element
                    document.body.removeChild(testElement);
                    
                    // Apply the best fit result
                    if (bestFit) {
                        abstractText.setAttribute('data-truncated-text', bestFit);
                        abstractText.innerHTML = bestFit;
                    } else {
                        // Fallback to rough estimate if binary search fails
                        const fallbackText = originalText.substring(0, Math.max(0, roughCharLimit - 50)) + expandButton;
                        abstractText.setAttribute('data-truncated-text', fallbackText);
                        abstractText.innerHTML = fallbackText;
                    }
                } else {
                    // Text fits without truncation
                    abstractText.innerHTML = originalText;
                }
            });
        }

        // Function to toggle recommendation justification
        function toggleRecommendationJustification(paperId) {
            const containers = document.querySelectorAll(`.recommendation-justification-section[data-paper-id="${paperId}"]`);
            
            containers.forEach(container => {
                const button = container.querySelector('button');
                const textDiv = container.querySelector('.justification-text');
                const isHidden = textDiv.classList.contains('hidden');
                
                if (isHidden) {
                    // Show justification
                    textDiv.classList.remove('hidden');
                    button.innerHTML = 'Hide Justification <span class="text-xs">▼</span>';
                    button.classList.remove('bg-neutral-500');
                    button.classList.add('bg-neutral-600');
                } else {
                    // Hide justification
                    textDiv.classList.add('hidden');
                    button.innerHTML = 'Show Justification <span class="text-xs">▲</span>';
                    button.classList.remove('bg-neutral-600');
                    button.classList.add('bg-neutral-500');
                }
            });
        }

        // Function to toggle novelty justification
        function toggleNoveltyJustification(paperId) {
            const containers = document.querySelectorAll(`.novelty-justification-section[data-paper-id="${paperId}"]`);
            
            containers.forEach(container => {
                const button = container.querySelector('button');
                const textDiv = container.querySelector('.justification-text');
                const isHidden = textDiv.classList.contains('hidden');
                
                if (isHidden) {
                    // Show justification
                    textDiv.classList.remove('hidden');
                    button.innerHTML = 'Hide Justification <span class="text-xs">▼</span>';
                    button.classList.remove('bg-neutral-500');
                    button.classList.add('bg-neutral-600');
                } else {
                    // Hide justification
                    textDiv.classList.add('hidden');
                    button.innerHTML = 'Show Justification <span class="text-xs">▲</span>';
                    button.classList.remove('bg-neutral-600');
                    button.classList.add('bg-neutral-500');
                }
            });
        }

        // Function to toggle impact justification
        function toggleImpactJustification(paperId) {
            const containers = document.querySelectorAll(`.impact-justification-section[data-paper-id="${paperId}"]`);
            
            containers.forEach(container => {
                const button = container.querySelector('button');
                const textDiv = container.querySelector('.justification-text');
                const isHidden = textDiv.classList.contains('hidden');
                
                if (isHidden) {
                    // Show justification
                    textDiv.classList.remove('hidden');
                    button.innerHTML = 'Hide Justification <span class="text-xs">▼</span>';
                    button.classList.remove('bg-neutral-500');
                    button.classList.add('bg-neutral-600');
                } else {
                    // Hide justification
                    textDiv.classList.add('hidden');
                    button.innerHTML = 'Show Justification <span class="text-xs">▲</span>';
                    button.classList.remove('bg-neutral-600');
                    button.classList.add('bg-neutral-500');
                }
            });
        }

        // Function to toggle relevance justification
        function toggleRelevanceJustification(paperId) {
            const containers = document.querySelectorAll(`.relevance-justification-section[data-paper-id="${paperId}"]`);
            
            containers.forEach(container => {
                const button = container.querySelector('button');
                const textDiv = container.querySelector('.justification-text');
                const isHidden = textDiv.classList.contains('hidden');
                
                if (isHidden) {
                    // Show justification
                    textDiv.classList.remove('hidden');
                    button.innerHTML = 'Hide Justification <span class="text-xs">▼</span>';
                    button.classList.remove('bg-neutral-500');
                    button.classList.add('bg-neutral-600');
                } else {
                    // Hide justification
                    textDiv.classList.add('hidden');
                    button.innerHTML = 'Show Justification <span class="text-xs">▲</span>';
                    button.classList.remove('bg-neutral-600');
                    button.classList.add('bg-neutral-500');
                }
            });
        }

        // Function to toggle author H-indices
        function toggleAuthorHIndices(paperId) {
            const containers = document.querySelectorAll(`.author-h-index-section[data-paper-id="${paperId}"]`);
            
            containers.forEach(container => {
                const button = container.querySelector('button');
                const textDiv = container.querySelector('.individual-authors-text');
                const isHidden = textDiv.classList.contains('hidden');
                
                if (isHidden) {
                    // Show individual H-indices
                    textDiv.classList.remove('hidden');
                    button.innerHTML = 'Hide Individual H-Indices <span class="text-xs">▲</span>';
                    button.classList.remove('bg-neutral-500');
                    button.classList.add('bg-neutral-600');
                } else {
                    // Hide individual H-indices
                    textDiv.classList.add('hidden');
                    button.innerHTML = 'Show Individual H-Indices <span class="text-xs">▼</span>';
                    button.classList.remove('bg-neutral-600');
                    button.classList.add('bg-neutral-500');
                }
            });
        }

        // Function to setup initial similarity progress bars (raw scores only)
        function setupInitialProgressBars() {
            currentPagePapers.forEach(paper => {
                setupProgressBarsForPaper(paper);
            });
        }

        // Function to toggle similarity scores between raw and normalized
        function toggleSimilarityScores(buttonElement) {
            // Find the parent container with data-paper-id
            const container = buttonElement.closest('[data-paper-id]');
            if (!container) return;
            
            const paperId = container.getAttribute('data-paper-id');
            const isNormalized = container.getAttribute('data-normalized') === 'true';
            
            // Find the paper data from current page papers
            const paper = currentPagePapers.find(p => p.id === paperId);
            if (!paper) return;
            
            // Toggle state
            container.setAttribute('data-normalized', (!isNormalized).toString());
            
            // Update button text
            buttonElement.textContent = isNormalized ? 'Show Normalized Scores ⇄' : 'Show Raw Scores ⇄';
            
            if (!isNormalized) {
                // Switch to normalized mode
                updateNormalizedScores(paperId);
                
                // Change all progress bars to normalized color
                const progressBars = container.querySelectorAll('.similarity-progress-bar');
                progressBars.forEach(bar => {
                    bar.classList.remove('bg-bar-raw');
                    bar.classList.add('bg-bar-normalized');
                });
            } else {
                // Switch to raw mode
                const isShowingHidden = container.getAttribute('data-show-hidden-topics') === 'true';
                const topicsToShow = isShowingHidden ? 
                    ['rlhf', 'weakSupervision', 'diffusionReasoning', 'distributedTraining', 'datasets'] :
                    getVisibleTopics();
                    
                const topicMapping = getTopicKeyMapping();
                
                topicsToShow.forEach(topic => {
                    const dataKey = topicMapping[topic];
                    const rawScore = paper[`${dataKey}_score`];
                    
                    // Update progress bar
                    const progressBar = container.querySelector(`.${dataKey.replace('_', '-')}-progress-bar`);
                    if (progressBar) {
                        progressBar.style.width = `${(rawScore * 100)}%`;
                        // Change to raw bar color
                        progressBar.classList.remove('bg-bar-normalized');
                        progressBar.classList.add('bg-bar-raw');
                    }
                    
                    // Update score text
                    const scoreElement = container.querySelector(`.${dataKey.replace('_', '-')}-similarity-score`);
                    if (scoreElement) {
                        scoreElement.textContent = rawScore.toFixed(3);
                    }
                });
            }
        }

        // Pagination functions
        function calculatePaginationWindow(currentPage, totalPages) {
            const windowSize = 5;
            const halfWindow = Math.floor(windowSize / 2);
            
            let start = Math.max(1, currentPage - halfWindow);
            let end = Math.min(totalPages, start + windowSize - 1);
            
            // Adjust start if we can't show a full window at the end
            if (end - start + 1 < windowSize) {
                start = Math.max(1, end - windowSize + 1);
            }
            
            return { start, end };
        }

        function updatePaginationUI() {
            const { start, end } = calculatePaginationWindow(currentPage, totalPages);
            
            // Update mobile pagination
            updatePaginationButtons('mobile', start, end);
            
            // Update desktop pagination
            updatePaginationButtons('desktop', start, end);
            
            // Update footer pagination
            updateFooterPaginationButtons('mobile', start, end);
            updateFooterPaginationButtons('desktop', start, end);
        }

        function updatePaginationButtons(layout, start, end) {
            const container = layout === 'mobile' 
                ? document.getElementById('mobile-pagination-numbers')
                : document.getElementById('desktop-pagination-numbers');
            
            if (!container) return;
            
            // Clear existing buttons
            container.innerHTML = '';
            
            // Create pagination buttons
            for (let i = start; i <= end; i++) {
                const isActive = i === currentPage;
                const buttonClass = isActive 
                    ? 'bg-neutral-900 text-neutral-10' 
                    : 'bg-neutral-300 text-neutral-70 hover:bg-neutral-400 cursor-pointer';
                
                const sizeClasses = layout === 'mobile' 
                    ? 'w-8 h-8' 
                    : 'clamp(1.5rem, 3vw, 1.875rem)';
                
                const button = document.createElement('div');
                button.className = `pagination-square ${buttonClass} flex items-center justify-center`;
                
                if (layout === 'desktop') {
                    button.style.width = sizeClasses;
                    button.style.height = sizeClasses;
                } else {
                    button.className += ` ${sizeClasses}`;
                }
                
                button.innerHTML = `<span class="font-heading font-bold text-${layout === 'mobile' ? 'sm' : 'md'}">${i}</span>`;
                
                if (!isActive) {
                    button.onclick = () => goToPage(i);
                    button.style.cursor = 'pointer';
                }
                
                container.appendChild(button);
            }
            
            // Update arrow button states
            updateArrowButtons(layout);
        }

        function updateFooterPaginationButtons(layout, start, end) {
            const container = layout === 'mobile' 
                ? document.getElementById('mobile-footer-pagination-numbers')
                : document.getElementById('desktop-footer-pagination-numbers');
            
            if (!container) return;
            
            // Clear existing buttons
            container.innerHTML = '';
            
            // Create pagination buttons
            for (let i = start; i <= end; i++) {
                const isActive = i === currentPage;
                const buttonClass = isActive 
                    ? 'bg-neutral-900 text-neutral-10' 
                    : 'bg-neutral-300 text-neutral-70 hover:bg-neutral-400 cursor-pointer';
                
                const sizeClasses = layout === 'mobile' 
                    ? 'w-8 h-8' 
                    : 'clamp(1.5rem, 3vw, 1.875rem)';
                
                const button = document.createElement('div');
                button.className = `pagination-square ${buttonClass} flex items-center justify-center`;
                
                if (layout === 'desktop') {
                    button.style.width = sizeClasses;
                    button.style.height = sizeClasses;
                } else {
                    button.className += ` ${sizeClasses}`;
                }
                
                button.innerHTML = `<span class="font-heading font-bold text-${layout === 'mobile' ? 'sm' : 'md'}">${i}</span>`;
                
                if (!isActive) {
                    button.onclick = () => goToPage(i);
                    button.style.cursor = 'pointer';
                }
                
                container.appendChild(button);
            }
            
            // Update footer arrow button states
            updateFooterArrowButtons(layout);
        }

        function updateArrowButtons(layout) {
            const prevBtn = document.getElementById(`${layout}-prev-btn`);
            const nextBtn = document.getElementById(`${layout}-next-btn`);
            
            // Update previous button
            if (prevBtn) {
                if (currentPage <= 1) {
                    // Show disabled state instead of hiding
                    prevBtn.classList.add('disabled');
                    prevBtn.onclick = null;
                } else {
                    // Show enabled state
                    prevBtn.classList.remove('disabled');
                    prevBtn.onclick = () => goToPage(currentPage - 1);
                }
            }
            
            // Update next button
            if (nextBtn) {
                if (currentPage >= totalPages) {
                    // Show disabled state instead of hiding
                    nextBtn.classList.add('disabled');
                    nextBtn.onclick = null;
                } else {
                    // Show enabled state
                    nextBtn.classList.remove('disabled');
                    nextBtn.onclick = () => goToPage(currentPage + 1);
                }
            }
        }

        function updateFooterArrowButtons(layout) {
            const prevBtn = document.getElementById(`${layout}-footer-prev-btn`);
            const nextBtn = document.getElementById(`${layout}-footer-next-btn`);
            
            // Update previous button
            if (prevBtn) {
                if (currentPage <= 1) {
                    // Show disabled state instead of hiding
                    prevBtn.classList.add('disabled');
                    prevBtn.onclick = null;
                } else {
                    // Show enabled state
                    prevBtn.classList.remove('disabled');
                    prevBtn.onclick = () => goToPage(currentPage - 1);
                }
            }
            
            // Update next button
            if (nextBtn) {
                if (currentPage >= totalPages) {
                    // Show disabled state instead of hiding
                    nextBtn.classList.add('disabled');
                    nextBtn.onclick = null;
                } else {
                    // Show enabled state
                    nextBtn.classList.remove('disabled');
                    nextBtn.onclick = () => goToPage(currentPage + 1);
                }
            }
        }

        function goToPage(page) {
            // Prevent navigation if page is out of bounds or is current page
            if (page === currentPage || page < 1 || page > totalPages) {
                return;
            }
            
            console.log(`Navigating to page ${page}`);
            currentPage = page;
            updatePaginationUI();
            displayCurrentPage();
            
            // Re-run truncation after new content is displayed
            setTimeout(() => {
                setupAbstractTruncation();
                setupInitialProgressBars();
            }, 50);
            
            // Scroll to top after loading new page
            window.scrollTo({ top: 0, behavior: 'smooth' });
        }

        // ============================================================================
        // SCROLL LOCK FUNCTIONS
        // ============================================================================
        
        function lockBodyScroll() {
            // Get the width of the scrollbar
            const scrollbarWidth = window.innerWidth - document.documentElement.clientWidth;
            document.body.style.paddingRight = `${scrollbarWidth}px`;
            
            // Add the class to prevent scrolling
            document.body.classList.add('no-scroll');
        }

        function unlockBodyScroll() {
            // Remove the inline padding
            document.body.style.paddingRight = '';

            // Remove the class to re-enable scrolling
            document.body.classList.remove('no-scroll');
        }

        // ============================================================================
        // SIDEBAR FUNCTIONS
        // ============================================================================

        function toggleMobileMenu() {
            if (isMobileSidebarOpen) {
                closeMobileMenu();
            } else {
                openMobileMenu();
            }
        }

        function openMobileMenu() {
            const sidebar = document.getElementById('mobile-sidebar');
            const mainContainer = document.getElementById('mobile-main-container');
            
            // Move sidebar into view (full screen width)
            sidebar.style.transform = 'translateX(0)';
            
            // Lock body scrolling with padding compensation
            lockBodyScroll();
            
            isMobileSidebarOpen = true;
        }

        function closeMobileMenu() {
            const sidebar = document.getElementById('mobile-sidebar');
            const mainContainer = document.getElementById('mobile-main-container');
            
            // Move sidebar out of view
            sidebar.style.transform = 'translateX(-100%)';
            
            // Unlock body scrolling
            unlockBodyScroll();
            
            isMobileSidebarOpen = false;
        }

        function toggleDesktopMenu() {
            if (isDesktopSidebarOpen) {
                closeDesktopMenu();
            } else {
                openDesktopMenu();
            }
        }

        function openDesktopMenu() {
            const sidebar = document.getElementById('desktop-sidebar');
            const overlay = document.getElementById('desktop-sidebar-overlay');
            
            // Show sidebar
            sidebar.style.transform = 'translateX(0)';
            
            // Show overlay
            overlay.style.opacity = '1';
            overlay.style.pointerEvents = 'auto';
            
            // Lock body scrolling with padding compensation
            lockBodyScroll();
            
            isDesktopSidebarOpen = true;
        }

        function closeDesktopMenu() {
            const sidebar = document.getElementById('desktop-sidebar');
            const overlay = document.getElementById('desktop-sidebar-overlay');
            
            // Hide sidebar
            sidebar.style.transform = 'translateX(-100%)';
            
            // Hide overlay
            overlay.style.opacity = '0';
            overlay.style.pointerEvents = 'none';
            
            // Unlock body scrolling
            unlockBodyScroll();
            
            isDesktopSidebarOpen = false;
        }

        // Handle window resize to close mobile menu if switching to desktop
        window.addEventListener('resize', function() {
            if (window.innerWidth >= 768 && isMobileSidebarOpen) {
                closeMobileMenu();
            }
            if (window.innerWidth < 768 && isDesktopSidebarOpen) {
                closeDesktopMenu();
            }
        });

        // ============================================================================
        // CLICK OUTSIDE TO CLOSE DROPDOWNS
        // ============================================================================
        
        // Add click outside listener to close dropdowns
        document.addEventListener('click', function(event) {
            // List of all dropdown containers
            const dropdowns = [
                { dropdown: document.getElementById('mobile-sort-dropdown'), button: document.getElementById('mobile-sort-btn') },
                { dropdown: document.getElementById('desktop-sort-dropdown'), button: document.getElementById('desktop-sort-btn') },
                { dropdown: document.getElementById('mobile-hindex-dropdown'), button: document.getElementById('mobile-hindex-btn') },
                { dropdown: document.getElementById('desktop-hindex-dropdown'), button: document.getElementById('desktop-hindex-btn') },
                { dropdown: document.getElementById('mobile-scoring-dropdown'), button: document.getElementById('mobile-scoring-btn') },
                { dropdown: document.getElementById('desktop-scoring-dropdown'), button: document.getElementById('desktop-scoring-btn') },
                { dropdown: document.getElementById('mobile-recommendation-dropdown'), button: document.getElementById('mobile-recommendation-btn') },
                { dropdown: document.getElementById('desktop-recommendation-dropdown'), button: document.getElementById('desktop-recommendation-btn') },
                { dropdown: document.getElementById('mobile-novelty-dropdown'), button: document.getElementById('mobile-novelty-btn') },
                { dropdown: document.getElementById('desktop-novelty-dropdown'), button: document.getElementById('desktop-novelty-btn') },
                { dropdown: document.getElementById('mobile-impact-dropdown'), button: document.getElementById('mobile-impact-btn') },
                { dropdown: document.getElementById('desktop-impact-dropdown'), button: document.getElementById('desktop-impact-btn') },
                { dropdown: document.getElementById('mobile-relevance-dropdown'), button: document.getElementById('mobile-relevance-btn') },
                { dropdown: document.getElementById('desktop-relevance-dropdown'), button: document.getElementById('desktop-relevance-btn') },
                { dropdown: document.getElementById('mobile-topic-dropdown'), button: document.getElementById('mobile-topic-btn') },
                { dropdown: document.getElementById('desktop-topic-dropdown'), button: document.getElementById('desktop-topic-btn') }
            ];
            
            dropdowns.forEach(({ dropdown, button }) => {
                if (!dropdown || !button) return;
                
                // Check if dropdown is open and click is outside
                if (!dropdown.classList.contains('hidden')) {
                    const dropdownContainer = dropdown.parentElement; // The relative container
                    
                    // Check if click is outside the dropdown container
                    if (!dropdownContainer.contains(event.target)) {
                        dropdown.classList.add('hidden');
                        button.classList.remove('bg-neutral-600');
                        button.classList.add('bg-neutral-500');
                        
                        // Reset pending filters for specific dropdown types
                        if (dropdown.id.includes('hindex')) {
                            resetPendingHIndexFilters();
                        } else if (dropdown.id.includes('novelty')) {
                            resetPendingNoveltyFilters();
                        } else if (dropdown.id.includes('impact')) {
                            resetPendingImpactFilters();
                        } else if (dropdown.id.includes('relevance')) {
                            resetPendingRelevanceFilters();
                        } else if (dropdown.id.includes('topic')) {
                            resetPendingTopicFilters();
                        } else if (dropdown.id.includes('recommendation')) {
                            resetPendingRecommendationFilters();
                        } else if (dropdown.id.includes('scoring')) {
                            resetPendingScoringFilters();
                        }
                    }
                }
            });
        });

        // Initialize page on load
        document.addEventListener('DOMContentLoaded', function() {
            console.log('Papers Dashboard loaded successfully');
            initializePage();
        });

        // Setup abstract truncation when everything is fully loaded
        window.addEventListener('load', function() {
            setupAbstractTruncation();
            setupInitialProgressBars();
        });

        // Setup debounced resize handler for truncation
        window.addEventListener('resize', () => {
            clearTimeout(resizeTimer);
            resizeTimer = setTimeout(() => {
                setupAbstractTruncation();
            }, 250); // Delay to wait for resize to settle
        });
    </script>

    <!-- KaTeX JavaScript -->
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js" integrity="sha384-cpW21h6RZv/phavutF+AuVYrr+dA8xD9zs6FwLpaCct6O9ctzYFfFr4dgmgccOTx" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
    
    <!-- KaTeX Auto-render Configuration -->
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            // Configure KaTeX auto-render after page content is loaded
            setTimeout(function() {
                renderMathInElement(document.body, {
                    // KaTeX rendering options
                    delimiters: [
                        {left: '$$', right: '$$', display: true},       // Block math
                        {left: '$', right: '$', display: false},        // Inline math
                        {left: '\\(', right: '\\)', display: false},    // Inline math alternative
                        {left: '\\[', right: '\\]', display: true},     // Block math alternative
                        {left: '\\begin{equation}', right: '\\end{equation}', display: true},
                        {left: '\\begin{align}', right: '\\end{align}', display: true},
                        {left: '\\begin{alignat}', right: '\\end{alignat}', display: true},
                        {left: '\\begin{gather}', right: '\\end{gather}', display: true},
                        {left: '\\begin{CD}', right: '\\end{CD}', display: true},
                    ],
                    // Throw errors on unknown commands/symbols
                    throwOnError: false,
                    // Allow HTML in math expressions
                    trust: true,
                    // Ignore certain classes/elements
                    ignoredClasses: [
                        "nokatex", 
                        "katex-ignore"
                    ],
                    // Skip script and style tags
                    ignoredTags: [
                        "script", 
                        "noscript", 
                        "style", 
                        "textarea", 
                        "pre", 
                        "code"
                    ]
                });
            }, 500); // Delay to ensure all content is loaded
        });
    </script>
</body>
</html>
